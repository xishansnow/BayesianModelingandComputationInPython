{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1a201dd",
   "metadata": {},
   "source": [
    "(chap1)=\n",
    "\n",
    "# 第一章: 贝叶斯推断 \n",
    "\n",
    "<style>p{text-indent:2em;2}</style>\n",
    "\n",
    "现代贝叶斯统计主要使用计算机代码执行。从几十年前开始，这已经极大地改变了贝叶斯统计的执行方式。我们可以建立的模型的复杂性增加了，必要的数学和计算技能的障碍已经降低。此外，迭代建模过程在许多方面变得比以往更容易执行和更相关。非常强大的计算机方法的普及确实很棒，但也需要更高的责任感。即使表达统计方法比以往任何时候都容易，但统计是一个充满微妙之处的领域，使用强大的计算方法不会神奇地消失。因此，具有良好的理论背景知识，尤其是那些与实践相关的知识，对于有效应用统计方法非常有用。在第一章中，我们介绍了这些概念和方法，其中很多，将在本书的其余部分进一步探索和扩展。\n",
    "\n",
    "(bayesian_modeling)=\n",
    "\n",
    "## 1.1 贝叶斯建模 \n",
    "\n",
    "概念模型是对一个系统的表达，它由概念组合组成，用于帮助人们了解、理解或模拟模型所代表的对象或过程 {cite:p}`wikipedia_model_2020`。此外，模型是人为设计的表示，具有非常具体的目标。因此，谈论模型对给定问题的充分性通常比谈论其内在正确性更方便。模型仅作为对进一步目标的帮助而存在。\n",
    "\n",
    "在设计新车时，汽车公司会制作一个物理模型，以帮助其他人了解产品在制造时的外观。在这种情况下，具有汽车先验知识并且对模型的使用方式有良好估计的雕刻家需要提供粘土等原材料，使用手工工具雕刻物理模型。这个物理模型可以帮助其他人了解设计的各个方面，例如外观是否美观，或者汽车的形状是否符合空气动力学。它需要结合领域专业知识和雕刻专业知识才能获得有用的结果。建模过程通常需要构建多个模型，要么是为了探索不同的选项，要么是因为模型通过与汽车开发团队其他成员的互动而得到迭代改进和扩展。如今，除了实体汽车模型外，还有一个内置计算机辅助设计软件的数字模型也很常见。\n",
    "\n",
    "这种计算机模型相比物理模型有一些优势。与在实体汽车上进行测试相比，使用数字进行碰撞模拟更简单、更便宜。与不同办公室的同事共享此模型也更容易。\n",
    "\n",
    "这些相同的想法与贝叶斯建模类似。构建模型需要结合领域专业知识和统计技能，以将知识整合到一些可计算的目标中并确定结果的有用性。数据是原材料，而统计分布是塑造统计模型的主要数学工具。需要结合领域专业知识和统计专业知识才能获得有用的结果。贝叶斯从业者会以迭代方式构建了多个模型，第一个模型主要用于从业者自己识别他们思维中的差距或模型中的缺陷。然后将这些第一组模型用于构建后续改进和扩展的模型。\n",
    "\n",
    "此外，使用一种推断机制并不会消除所有其他推断机制的效用，就像汽车的物理模型不会消除数字模型的效用一样。同样，现代贝叶斯从业者有多种方式来表达他们的想法、产生结果和分享输出，从而为从业者和他们的同行提供更广泛的积极成果。\n",
    "\n",
    "(bayesian-models)=\n",
    "\n",
    "### 1.1.1 贝叶斯模型 \n",
    "\n",
    "贝叶斯模型，无论是计算模型还是其他模型，都有两个定义特征：\n",
    "\n",
    "- 使用概率分布 [^1] 描述未知量。我们称这些量为参数 [^2]。\n",
    "\n",
    "- 贝叶斯定理用于更新以数据为条件的参数值。我们也可以将此过程视为概率的重新分配。\n",
    "\n",
    "在高层次上，我们可以分三个步骤描述构建贝叶斯建模的过程：\n",
    "\n",
    "1. 给定一些数据和一些关于如何生成这些数据的假设，我们通过组合和转换随机变量来设计一个模型。\n",
    "\n",
    "2. 我们使用贝叶斯定理使模型适应可用数据。我们称这个过程为**推断**，因此我们获得了后验分布。我们希望数据可以减少可能参数值的不确定性，尽管这不是任何贝叶斯模型的保证。\n",
    "\n",
    "3. 我们通过根据不同的标准检查模型是否有意义来批评模型，包括数据和我们在领域知识方面的专业知识。因为我们通常对模型本身不确定，所以我们有时会比较几个模型。\n",
    "\n",
    "如果您熟悉其他形式的建模，您将认识到批评模型的重要性以及迭代执行这 3 个步骤的必要性。例如，我们可能需要在任何给定点回溯我们的步骤。也许我们引入了一个愚蠢的编码错误，或者在一些挑战之后我们找到了改进模型的方法，或者我们发现数据不像我们最初想象的那样有用，我们需要收集更多数据甚至是不同类型的数据数据。\n",
    " \n",
    "在本书中，我们将讨论执行这三个步骤中的每一个的不同方法，我们将学习如何将它们扩展为更复杂的**贝叶斯工作流程**。我们认为这个主题非常重要，以至于我们用一整章 [9](chap9) 来重新审视和讨论这些想法。\n",
    "\n",
    "(Bayesian_inference)=\n",
    "\n",
    "### 1.1.2 贝叶斯推断 \n",
    "\n",
    "通俗地说，推断与根据证据和推断得出结论有关。贝叶斯推断是一种特殊形式的统计推断，它基于组合概率分布以获得其他概率分布。鉴于我们已经观察到一些数据 $\\boldsymbol{Y}$，贝叶斯定理为我们提供了估计参数 $\\boldsymbol{\\theta}$ 值的通用方法：\n",
    "\n",
    "```{math} \n",
    ":label: eq:posterior_dist \n",
    "\n",
    "\\underbrace{p(\\boldsymbol{\\theta} \\mid \\boldsymbol{Y})}_{\\text{posterior}} = \\frac{\\overbrace{p(\\boldsymbol{Y} \\mid \\boldsymbol{\\theta})}^{\\text{likelihood}}\\; \\overbrace{p(\\boldsymbol{\\theta})}^{\\text{prior}}}{\\underbrace{{p(\\boldsymbol{Y})}}_{\\text{marginal likelihood}}}\n",
    "``` \n",
    "\n",
    "似然函数将观测数据与未知参数联系起来，而先验分布表示在观测数据 $\\boldsymbol{Y}$ 之前参数的不确定性 [^3]。通过将它们相乘，我们得到后验分布，即模型中所有参数的联合分布（以观测数据为条件）。 \n",
    "\n",
    "{numref}`fig:bayesian_triad` 显示了一个任意先验、似然和由此产生的后验的示例 [^4] 。\n",
    "\n",
    "```{figure} figures/bayesian_triad.png\n",
    ":name: fig:bayesian_triad\n",
    ":width: 8.00in \n",
    " \n",
    "左子图。一个假设的先验表明值 $\\theta = 0.5$ 的似然更大，其余值的合理性线性和对称地降低（黑色）。表明值 $\\theta = 0.2$ 的似然与假设数据（灰色）和结果后验（蓝色）更好地吻合，这是先验和似然之间的折衷。我们省略了 y 轴的值，以强调我们只关心相对值。右子图，功能与左子图相同，但 y 轴采用对数刻度。请注意，保留了有关相对值的信息，例如，两个子图中最大值和最小值的位置相同。由于计算在数值上更稳定，因此首选对数刻度来执行计算。\n",
    "\n",
    "``` \n",
    "\n",
    "请注意，虽然 $\\boldsymbol{Y}$ 是观测数据，但它也是一个随机向量，因为它的值取决于特定实验的结果 [^5]。为了获得后验分布，我们将数据视为固定在实际观察值上。出于这个原因，一个常见的替代符号是使用 $y_{obs}$，而不是 $\\boldsymbol{Y}$。\n",
    "\n",
    "正如您所看到的，在每个特定 * 点 * 评估后验在概念上很简单，我们只需要将先验时间乘以似然。然而，这还不足以告诉我们后验概率，因为我们不仅需要特定 *point* 的后验概率，还需要与周围 *points* 相关的后验概率。后验分布的这种*全局*信息由归一化常数表示。不幸的是，由于需要计算归一化常数 $p(\\boldsymbol{Y})$，因此出现了困难。如果我们将边缘似然写为：\n",
    "\n",
    "```{math} \n",
    ":label: eq:marginal_likelihood \n",
    "\n",
    "{p(\\boldsymbol{Y}) = \\int_{\\boldsymbol{\\Theta}} p(\\boldsymbol{Y} \\mid \\boldsymbol{\\theta})p(\\boldsymbol{\\theta}) d\\boldsymbol{\\theta}} \n",
    "``` \n",
    "\n",
    "其中 $\\Theta$ 表示我们正在整合 $\\theta$ 的所有可能值。\n",
    "\n",
    "像这样计算积分可能比第一次出现要困难得多（参见第 {ref}`marginal_likelihood` 和一个有趣的 XKCD 漫画 [^6]）。尤其是当我们意识到对于大多数问题，封闭式表达式甚至都不可用。幸运的是，如果使用得当，有一些数值方法可以帮助我们应对这一挑战。\n",
    "\n",
    "由于通常不计算边缘似然，因此将贝叶斯定理表示为比率形式是很常见的：\n",
    "\n",
    "```{math} \n",
    ":label: eq:proportional_bayes \n",
    "\n",
    "\\underbrace{p(\\boldsymbol{\\theta} \\mid \\boldsymbol{Y})}_{\\text{posterior}} \\propto \\overbrace{p(\\boldsymbol{Y} \\mid \\boldsymbol{\\theta})}^{\\text{likelihood}}\\; \\overbrace{p(\\boldsymbol{\\theta})}^{\\text{prior}}\n",
    "```\n",
    "\n",
    "::: {admonition} A note on notation \n",
    "\n",
    "在本书中，我们使用相同的符号 $p(\\cdot)$ 来表示不同的量，例如似然函数和先验概率分布。这是对符号的轻微滥用，但我们发现它很有用。这种符号为所有数量提供了相同的认识论地位。此外，它反映了即使似然不是严格意义上的概率密度函数，我们也不在乎，因为我们只考虑先验背景下的似然，反之亦然。换句话说，为了计算后验分布，我们将这两个量视为模型的同等必要元素。\n",
    "\n",
    "::: \n",
    "\n",
    "贝叶斯统计的一个很好的特点是后验（总是）是一个分布。这一事实使我们能够对参数做出概率性陈述，例如参数 $\\boldsymbol{\\tau}$ 为正的概率是 0.35。或者 $\\boldsymbol{\\phi}$ 的最可能值是 12，有 $50\\%$ 的机会介于 10 和 15 之间。\n",
    "\n",
    "此外，我们可以将后验分布视为将模型与数据相结合的逻辑结果，因此从它们得出的概率陈述保证在数学上是一致的。我们只需要记住，所有这些好的数学属性只在*柏拉图思想世界*中有效，其中存在诸如球体、高斯和马尔可夫链之类的数学对象。当我们从数学纯粹性转向*现实世界*的应用数学混乱时，我们必须始终牢记，我们的结果不仅取决于数据，还取决于模型。\n",
    "\n",
    "因此，不良数据和/或不良模型可能导致无意义的陈述，即使它们在数学上是一致的。我们必须始终对我们的数据、模型和结果保持健康的怀疑态度。\n",
    "\n",
    "为了使这一点更明确，我们可能希望以更细微的方式表达贝叶斯定理：\n",
    "\n",
    "```{math} \n",
    "p(\\boldsymbol{\\theta} \\mid  \\boldsymbol{Y}, M) \\propto  p(\\boldsymbol{Y} \\mid \\boldsymbol{\\theta}, M) \\; p(\\boldsymbol{\\theta}, M)\n",
    "```\n",
    "\n",
    "强调我们的推论总是依赖于模型 $M$ 所做的假设。\n",
    "\n",
    "话虽如此，一旦我们有了后验分布，我们就可以使用它来推导其他感兴趣的数量。这通常通过计算期望来完成，例如：\n",
    "\n",
    "```{math} \n",
    ":label: eq:posterior_expectation \n",
    "\n",
    "J = \\int f(\\boldsymbol{\\theta}) \\; \n",
    "p(\\boldsymbol{\\theta} \\mid \\boldsymbol{Y}) \\; \n",
    "d\\boldsymbol{\\theta} \n",
    "``` \n",
    "\n",
    "如果 $f$ 是恒等函数 $J$ 将变成 $\\boldsymbol{\\theta}.$ 的均值 [^7]：\n",
    "\n",
    "```{math} \n",
    "\\bar{\\boldsymbol{\\theta}} = \\int_{\\boldsymbol{\\Theta}} \\boldsymbol{\\theta}  p(\\boldsymbol{\\theta} \\mid \\boldsymbol{Y})  d\\boldsymbol{\\theta}\n",
    "```\n",
    "\n",
    "后验分布是贝叶斯统计的中心对象，但不是唯一的。除了对参数值进行推断外，我们可能还想对数据进行推断。这可以通过计算**先验预测分布**来完成：\n",
    "\n",
    "```{math} \n",
    ":label: eq:prior_pred_dist \n",
    "\n",
    "p(\\boldsymbol{Y}^\\ast) =  \\int_{\\boldsymbol{\\Theta}} p(\\boldsymbol{Y^\\ast} \\mid \\boldsymbol{\\theta}) \\; p(\\boldsymbol{\\theta}) \\; d\\boldsymbol{\\theta} \n",
    "\n",
    "``` \n",
    "\n",
    "这是根据模型（先验和似然）的数据的预期分布。给定模型，这是我们在实际看到任何观测数据 $\\boldsymbol{Y}^\\ast$ 之前所期望的数据。请注意，方程 {eq}`eq:marginal_likelihood`（边缘似然）和方程 {eq}`eq:prior_pred_dist`（先验预测分布）看起来非常相似。不同之处在于，在前一种情况下，我们以观测数据 $Y$ 为条件，而在后一种情况下，我们不以观测数据为条件。结果，边缘似然是一个数字，而先验预测分布是一个概率分布。\n",
    " \n",
    "我们可以使用来自先前预测分布的样本作为使用领域知识评估和校准模型的一种方式。例如，我们可能会问诸如“人类身高模型可以预测人类身高 -1.5 米吗？”之类的问题。甚至在测量一个人之前，我们就可以认识到这个查询的荒谬性。在本书的后面，我们将看到许多在实践中使用先验预测分布进行模型评估的具体示例，以及先验预测分布如何在后续建模选择中告知有效性或缺乏有效性。\n",
    "\n",
    "::: {admonition} Bayesian models as generative models \n",
    "\n",
    "采用概率视角进行建模导致了口头禅*模型生成数据* {cite:p}`WestfallUnderstandingAdvancedStatistical2013`。我们认为这个概念至关重要。一旦你将它内化，所有的统计模型都会变得更加清晰，甚至是非贝叶斯模型。这个口头禅可以帮助创建新模型；如果模型生成数据，我们可以*只是*通过考虑如何生成数据来为我们的数据创建合适的模型！此外，这个口头禅不仅仅是一个抽象的概念。我们可以采用先验预测分布形式的具体表示。如果我们重新审视贝叶斯建模的 3 个步骤，我们可以将它们重新构建为，编写先验预测分布，添加数据以对其进行约束，检查结果是否有意义。\n",
    "\n",
    "必要时进行迭代。\n",
    "\n",
    "::: \n",
    "\n",
    "另一个有用的计算量是**后验预测分布**：\n",
    "\n",
    "```{math} \n",
    ":label: eq:post_pred_dist \n",
    "\n",
    "p(\\tilde{\\boldsymbol{Y}} \\mid \\boldsymbol{Y}) = \\int_{\\boldsymbol{\\Theta}} p(\\tilde{\\boldsymbol{Y}} \\mid \\boldsymbol{\\theta}) \\, p(\\boldsymbol{\\theta} \\mid \\boldsymbol{Y}) \\, d\\boldsymbol{\\theta} \n",
    "\n",
    "``` \n",
    "\n",
    "这是预期的、未来的数据 $\\tilde{\\boldsymbol{Y}}$ 根据后验 $p(\\boldsymbol{\\theta} \\mid \\boldsymbol{Y})$ 的分布，这又是一个结果模型（先验和似然）和观测数据。用更常见的术语来说，这是模型在看到数据集 $\\boldsymbol{Y}$ 后期望看到的数据，即这些是模型的预测。从方程 {eq}`eq:post_pred_dist`，我们可以看到预测是通过对参数的后验分布进行积分（或边缘化）来计算的。因此，以这种方式计算的预测将包含我们估计的不确定性。\n",
    "\n",
    "::: {admonition} Bayesian posteriors in a Frequentist light \n",
    "\n",
    "因为后验仅来自模型和观测数据，所以我们不是基于未观察到的，而是基于潜在数据生成过程的潜在观察到的实现来做出陈述。对未观察到的推断通常由所谓的常客方法完成。然而，如果我们使用后验预测样本来检查我们的模型，我们（部分）接受了考虑未观察到但可能可观测数据的频率论思想。我们不仅对这个想法感到满意，而且我们将在本书中看到这个过程的许多示例。我们认为这是一个很棒的主意——让我们做更多这样的事情！\n",
    "\n",
    "::: \n",
    "\n",
    "(sampling_methods_intro)=\n",
    "\n",
    "## 1.2 一个 DIY 的采样器 \n",
    "\n",
    "方程 {eq}`eq:marginal_likelihood` 中积分的封闭形式表达式并不总是可能的，因此现代贝叶斯推断的大部分是使用我们称为 **Universal Inference Engines** 的数值方法完成的（参见第 {ref}`inference_methods `) 只是为了弥补我们生活在 $21^\\text{st}$ 世纪的事实，而我们仍然没有飞行汽车。\n",
    "\n",
    "\n",
    "无论如何，有许多经过良好测试的 Python 库提供了这样的数值方法，因此一般来说，贝叶斯从业者不太可能需要编写自己的通用推断引擎。\n",
    "\n",
    "到今天为止，编写自己的引擎通常只有两个很好的理由，要么设计一个改进旧引擎的新引擎，要么正在学习当前引擎的工作原理。由于我们在本章中学习，我们将编写一个代码，但对于本书的其余部分，我们将使用 Python 库中可用的引擎。\n",
    "\n",
    "有许多算法可以用作*通用推断引擎*。可能最广泛采用和最强大的是马尔可夫链蒙特卡洛方法（MCMC）系列。在非常高的水平上，所有 MCMC 方法都使用样本来近似后验分布。来自后验分布的样本是通过接受或拒绝来自称为提议分布的不同分布的样本来生成的。通过遵循某些规则 [^8] 并在某些假设下，我们有理论上的保证，我们将获得非常近似后验分布的样本。因此，MCMC 方法也称为采样器。所有这些方法都需要能够评估给定参数值的先验和似然。也就是说，即使我们不知道整个后部的样子，我们也可以逐点求其密度。\n",
    "\n",
    "一种这样的算法是 Metropolis-Hastings {cite:p}`Metropolis1953, Hastings1970, Rosenbluth2003`。这不是一个非常现代或特别有效的算法，但 Metropolis-Hastings 易于理解，也为理解更复杂和更强大的方法提供了基础。 [^9]\n",
    "\n",
    "Metropolis-Hasting 算法定义如下：\n",
    "\n",
    "1. 在$x_i$处初始化参数$\\boldsymbol{X}$的值\n",
    "\n",
    "2. 使用提议分布 [^10] $q(x_{i + 1} \\mid x_i)$ 从旧值 $x_i$ 生成新值 $x_{i + 1}$。\n",
    "\n",
    "3. 计算接受新值的概率为：\n",
    "\n",
    "```{math}    \n",
    ":label: acceptance_prob\n",
    " \n",
    "p_a (x_{i + 1} \\mid x_i) = \\min \\left (1, \\frac{p(x_{i + 1}) \\;     q(x_i \\mid x_{i + 1})} {p(x_i) \\; q (x_{i + 1} \\mid x_i)} \\right)\n",
    "```\n",
    "4. 如果 $p_a > R$ 其中 $R \\sim \\mathcal{U}(0, 1)$，则保存新值，否则保存旧值。\n",
    "\n",
    "5. 迭代 2 到 4 直到生成一个*足够大*的值样本。\n",
    "\n",
    "Metropolis 算法非常通用，可以在非贝叶斯应用中使用，但对于我们在本书中关心的内容，$p(x_i)$ 是在参数值 $x_i$ 处评估的后验密度。请注意，如果 $q$ 是对称分布，则 $q(x_i \\mid x_{i + 1})$ 和 $q(x_{i + 1} \\mid x_i)$ 将抵消（从概念上讲，这意味着它是我们同样可能从 $x_{i+1}$ 到 $x_i$ 或从 $x_{i}$ 到 $x_{i+1}$)，只留下后验的比率评估为两点。从方程 {eq}`acceptance_prob` 我们可以看到该算法将始终接受从低概率区域到较高概率区域的移动，并且将在概率上接受从高概率区域到低概率区域的移动。\n",
    "\n",
    "另一个重要的说明是 Metropolis-Hastings 算法不是优化方法！我们不关心找到具有最大概率的参数值，我们想*探索* $p$ 分布（后验）。如果我们注意到最多一次，则可以看出这一点，该方法仍然可以在后续步骤中移动到概率较低的区域。\n",
    "\n",
    "为了使事情更具体，让我们尝试求解 Beta-Binomial 模型。这可能是贝叶斯统计中最常见的示例，它用于对二元、互斥的结果进行建模，例如 0 或 1、正或负、正面或反面、垃圾邮件或火腿、热狗或非热狗、健康或不健康等. Beta-Binomial 模型经常被用作第一个例子来介绍贝叶斯统计的基础知识，因为它是一个简单的模型，我们可以轻松求解和计算。在统计符号中，我们可以将 Beta-Binomial 模型写为：\n",
    "\n",
    "```{math} \n",
    ":label: eq:beta_binomial \n",
    "\n",
    "\\begin{split}\n",
    "\\theta \\sim &\\; \\text{Beta}(\\alpha, \\beta) \\\\\n",
    "Y \\sim &\\; \\text{Bin}(n=1, p=\\theta) \n",
    "\\end{split}\n",
    "```\n",
    "\n",
    "在方程 {eq}`eq:beta_binomial` 中，我们说参数 $\\theta$ 具有 $\\text{Beta}(\\alpha, \\beta)$ 作为其先验分布。我们假设数据按照二项式分布 $\\text{Bin}(n=1, p=\\theta)$ 分布，它代表我们的似然分布。在这个模型中，成功的数量$\\theta$ 可以表示诸如头部比例或垂死患者比例之类的数量，有时统计数据可能是一个非常黑暗的地方。该模型有一个解析解（参见 {ref}`conjugate_priors`）了解详细信息。为了这个例子，让我们假设我们不知道如何计算后验，因此我们将在 Python 代码中实现 Metropolis-Hastings 算法以获得近似答案。我们将在 SciPy 统计函数的帮助下完成：\n",
    "\n",
    "```{code-block} ipython3\n",
    ":name: metropolis_hastings_sampler\n",
    ":caption: metropolis_hastings_sampler\n",
    "\n",
    "def post(θ, Y, α=1, β=1):\n",
    "    if 0 <= θ <= 1:\n",
    "        prior = stats.beta(α, β).pdf(θ)\n",
    "        like  = stats.bernoulli(θ).pmf(Y).prod()\n",
    "        prob = like * prior\n",
    "    else:\n",
    "        prob = -np.inf\n",
    "    return prob\n",
    "```\n",
    "\n",
    "我们还需要数据，因此我们将为此目的生成一些随机的假数据。\n",
    "\n",
    "```{code-block} ipython3\n",
    ":name: metropolis_hastings_sampler_rvs\n",
    ":caption: metropolis_hastings_sampler_rvs\n",
    "\n",
    "Y = stats.bernoulli(0.7).rvs(20)\n",
    "```\n",
    "\n",
    "最后我们运行 Metropolis-Hastings 算法的实现：\n",
    "\n",
    "```{code-block} ipython3\n",
    ":name: metropolis_hastings\n",
    ":caption: metropolis_hastings\n",
    ":linenos:\n",
    "\n",
    "n_iters = 1000\n",
    "can_sd = 0.05\n",
    "α = β =  1\n",
    "θ = 0.5\n",
    "trace = {\"θ\":np.zeros(n_iters)}\n",
    "p2 = post(θ, Y, α, β)\n",
    "\n",
    "for iter in range(n_iters):\n",
    "    θ_can = stats.norm(θ, can_sd).rvs(1)\n",
    "    p1 = post(θ_can, Y, α, β)\n",
    "    pa = p1 / p2\n",
    "\n",
    "    if pa > stats.uniform(0, 1).rvs(1):\n",
    "        θ = θ_can\n",
    "        p2 = p1\n",
    "\n",
    "    trace[\"θ\"][iter] = θ\n",
    "```\n",
    "\n",
    "在代码块 [metropolis_hastings](metropolis_hastings) 的第 9 行，我们通过从标准差为“can_sd”的正态分布中采样来生成提议分布。在第 10 行，我们在新生成的值 `θ_can` 处评估后验，在第 11 行，我们计算接受概率。在第 17 行，我们在 `trace` 数组中保存了 `θ` 的值。\n",
    "\n",
    "这个值是新值还是我们重复上一个值，取决于第 13 行的比较结果。\n",
    "\n",
    "::: {admonition} Ambiguous MCMC jargon \n",
    "\n",
    "当我们使用马尔可夫链蒙特卡洛方法进行贝叶斯推断时，我们通常将它们称为 MCMC 采样器。在每次迭代中，我们从采样器中抽取一个随机样本，因此我们自然地将 MCMC 的输出称为 *samples* 或 *draws*。有些人区分样本是由一组抽奖组成的，其他人将样本和抽奖视为可互换的。\n",
    " \n",
    "由于 MCMC 是按顺序抽取样本的，我们也说我们得到了一个 *chain* 的抽取结果，或者简称为 MCMC 链。通常出于计算和诊断的原因需要绘制许多链（我们在第 [2] 章（第 1 章之二）中讨论了如何做到这一点）。所有输出链，无论是单数还是复数，通常都称为迹线或简单的后验。不幸的是，口语是不精确的，所以如果需要精确，最好的方法是查看代码以准确了解正在发生的事情。\n",
    "\n",
    "::: \n",
    "\n",
    "请注意，代码块 [metropolis_hastings](metropolis_hastings) 中实现的代码并非旨在提高效率，实际上生产级代码中会出现许多变化，例如计算对数规模的概率以避免下溢/溢出问题（参见第 {ref}`log_probabilities` 部分），或预先计算提案和统一值。这就是需要调整数学纯度以适应计算机现实的地方，以及为什么最好让专家来构建这些引擎。同样，“can_sd”的值是 Metropolis-Hastings 算法的参数，而不是贝叶斯模型的参数。理论上这个参数不应该影响算法的正确行为，但在实践中它非常重要，因为方法的效率肯定会受到它的值的影响（请参阅第 {ref}`inference_methods` 节进行深入讨论） .\n",
    "\n",
    "回到我们的示例，现在我们有了 MCMC 样本，我们想了解 *它的样子*。检查贝叶斯推断结果的一种常用方法是将每次迭代的采样值与直方图或其他可视化工具一起绘制，以表示分布。例如，我们可以使用代码块 [diy_trace_plot](diy_trace_plot) 中的代码来绘制 {numref}`fig:traceplot` [^11]：\n",
    "\n",
    "```{code-block} ipython3 \n",
    ":name: diy_trace_plot\n",
    ":caption: diy_trace_plot\n",
    "\n",
    "_, axes = plt.subplots(1,2, sharey=True) \n",
    "axes[1].hist(trace[\"θ\"], color=\"0.5\", orientation=\"horizontal\", density=True)\n",
    "```\n",
    "\n",
    "```{figure} figures/traceplot.png\n",
    ":name: fig:traceplot\n",
    ":width: 8.00in \n",
    " \n",
    "在左侧，我们在每次迭代中都有参数 $\\theta$ 的采样值。在右边，我们有 $\\theta$ 的采样值的直方图。旋转直方图，以便更容易看出两个图密切相关。左边的图显示了采样值的*序列*。这个序列就是我们的马尔可夫链。右图显示了采样值的分布。\n",
    "``` \n",
    "\n",
    "通常，计算一些数字摘要也很有用。在这里，我们将使用 Python 包 ArviZ {cite:p}`Kumar2019` 来计算这些统计信息：\n",
    "\n",
    "```{code-block} ipython3 \n",
    "az.summary(trace, kind=\"stats\", round_to=2)\n",
    "```\n",
    "\n",
    "```{list-table} Posterior summary\n",
    ":name: tab:posterior_summary \n",
    " * -   - **mean**   - **sd**   - **hdi_3%**   - **hdi_97%** * - $\\theta$   - 0.69   - 0.01   - 0.52   - 0.87\n",
    "```\n",
    "\n",
    "ArviZ 的函数“summary”计算我们参数 $\\theta$ 的 $94\\%$ 的平均值、标准差和最高密度区间 (HDI)。 HDI 是包含给定概率密度的最短间隔，对于这个特定示例 [^12] 为 $94\\%$。 {numref}`fig:plot_posterior`，使用 `az.plot_posterior(trace)` 生成，与 {numref}`tab:posterior_summary` 中的上述摘要非常相似。我们可以在代表整个后验分布的曲线顶部看到均值和 HDI。该曲线是使用 **kernel density estimator (KDE)** 计算的，类似于直方图的平滑版本。\n",
    "\n",
    "ArviZ 在其许多绘图中使用 KDE，甚至在内部进行一些计算。\n",
    "\n",
    "```{figure} figures/plot_posterior.png\n",
    ":name: fig:plot_posterior\n",
    ":width: 4in \n",
    " \n",
    "后验图可视化从代码块 [metropolis_hastings](metropolis_hastings) 生成的样本。后验分布使用 KDE 表示，HDI $94\\%$ 的均值和极限在图中表示。\n",
    "\n",
    "``` \n",
    "\n",
    "HDI 是贝叶斯统计中的常见选择，并且像 $50\\%$ 或 95% 这样的 *round* 值很常见。但是 ArviZ 使用 $94\\%$（或 0.94）作为默认值，如摘要 {numref}`tab:posterior_summary` 和 {numref}`fig:plot_posterior` 中所示。这种选择的原因是 94 接近*广泛使用的* 95，但差异足以作为友好的提醒，这些 *round* 值 {cite:p}`mcelreath_2020` 并没有什么特别之处。理想情况下，您应该选择一个适合您需要的值 {cite:p}`Lakens2018`，或者至少承认您使用的是默认值。\n",
    "\n",
    "(Automating_inference)=\n",
    "\n",
    "## 1.3 人工建模与自动推断\n",
    "\n",
    "我们可以利用 **概率编程语言 Probabilistic Programming Languages** (PPL) 的帮助，而不是编写自己的采样器并且必须使用 `scipy.stats` 方法定义自己的模型。这些工具允许用户使用代码表达贝叶斯模型，然后借助通用推断引擎以相当自动化的方式执行贝叶斯推断。简而言之，PPL 帮助从业者更多地关注模型构建，而不是数学和计算细节。\n",
    "\n",
    "在过去的几十年中，此类工具的可用性有助于提高贝叶斯方法的普及度和实用性。不幸的是，这些通用推断引擎方法并不是真正通用的，因为它们无法有效地解决每个贝叶斯模型。现代贝叶斯实践者的部分工作是能够理解和解决这些限制。\n",
    "\n",
    "在本书中，我们将使用 PyMC3 {cite:p}`Salvatier2016` 和 TensorFlow Probability {cite:p}`dillon2017tensorflow`。让我们使用 PyMC3 从方程 {eq}`eq:beta_binomial` 编写模型：\n",
    "\n",
    "```{code-block} ipython3 \n",
    ":name: beta_binom \n",
    ":caption: beta_binom \n",
    "\n",
    "# Declare a model in PyMC3 \n",
    "with pm.Model() as model:     \n",
    "   # Specify the prior distribution of unknown parameter\n",
    "    θ = pm.Beta(\"θ\", alpha=1, beta=1) \n",
    "   # Specify the likelihood distribution and condition on the observed data     \n",
    "    y_obs = pm.Binomial(\"y_obs\", n=1, p=θ, observed=Y) \n",
    "\n",
    "# Sample from the posterior distribution     \n",
    "idata = pm.sample(1000, return_inferencedata=True) \n",
    "``` \n",
    "您应该自己检查这段代码是否提供了与之前使用的 DIY 采样器基本相同的答案，但工作量要少得多。如果您不熟悉 PyMC3 的语法，现在只需关注代码注释中显示的每一行的意图。\n",
    "\n",
    "由于我们已经在 PyMC3 语法中定义了模型，我们还可以利用 `pm.model_to_graphviz(model)` 在代码块 [beta_binom](beta_binom) 中生成模型的图形表示（参见 {numref}`fig:BetaBinomModelGraphViz`）。\n",
    "\n",
    "```{figure} figures/BetaBinomModelGraphViz.png\n",
    ":name: fig:BetaBinomModelGraphViz\n",
    ":width: 2in \n",
    " \n",
    " A graphical representation of the model defined in Equation {eq}`eq:beta_binomial` and Code Block [beta_binom](beta_binom). The ovals represent our prior and likelihood, whereas the 20 in this case indicates the number of observations.\n",
    "\n",
    "方程 {eq}`eq:beta_binomial` 和代码块 [beta_binom](beta_binom) 中定义的模型的图形表示。椭圆代表我们的先验和可能性，而本例中的 20 表示观察次数。\n",
    "\n",
    "[fig:BetaBinomModelGraphViz]{#fig:BetaBinomModelGraphViz label=\"fig:BetaBinomModelGraphViz\"}\n",
    "```\n",
    "\n",
    "概率编程语言不仅可以评估随机变量的对数概率以获得后验分布，还可以模拟各种分布。例如，代码块 [predictive_distributions](predictive_distributions) 展示了如何使用 PyMC3 从先验预测分布生成 1000 个样本，从后验预测分布生成 1000 个样本。请注意，对于第一个函数，我们有一个以“模型”作为参数的函数，而对于第二个函数，我们必须同时传递“模型”和“跟踪”，这反映了先验预测分布可以仅从模型而后验预测分布我们需要一个模型和后验。从先验和后验预测分布生成的样本分别在顶部和底部子图中表示，来自 {numref}`fig:quartet`。\n",
    "\n",
    "```{code-block} ipython3 \n",
    ":name: predictive_distributions\n",
    ":caption: predictive_distributions \n",
    "\n",
    "pred_dists = (pm.sample_prior_predictive(1000, model)[\"y_obs\"],             pm.sample_posterior_predictive(idata, 1000, model)[\"y_obs\"])\n",
    "```\n",
    "\n",
    "Equations {eq}`eq:posterior_dist`, {eq}`eq:prior_pred_dist`, and {eq}`eq:post_pred_dist` clearly define the posterior, the prior predictive, and the posterior predictive distributions as different mathematical objects. The two later are distributions over data and the first one is a distribution over the parameters in a model.\n",
    "\n",
    "{numref}`fig:quartet` helps us visualize this difference and also includes the prior distribution for completeness.\n",
    "\n",
    "方程 {eq}`eq:posterior_dist`、{eq}`eq:prior_pred_dist` 和 {eq}`eq:post_pred_dist` 清楚地将后验、先验预测和后验预测分布定义为不同的数学对象。后面的两个是数据分布，第一个是模型中参数的分布。\n",
    "{numref}`fig:quartet` 帮助我们可视化这种差异，并且还包括完整性的先验分布。\n",
    "\n",
    "::: {admonition} Expressing models in multiple ways \n",
    "\n",
    "There are numerous methods to communicate the architecture of statistical models. These can be, in no particular order: \n",
    "\n",
    "-   Spoken and written language \n",
    "\n",
    "-   Conceptual diagrams: {numref}`fig:BetaBinomModelGraphViz`.\n",
    "\n",
    "-   Mathematical notation: Equation {eq}`eq:beta_binomial` \n",
    "\n",
    "-   Computer Code: Code Block [beta_binom](beta_binom) \n",
    "\n",
    "For a modern Bayesian practitioner it is useful to be literate across all these mediums. They are formats you see presented in talks, scientific papers, hand sketches when discussing with colleagues, code examples on the internet, etc. With fluency across these mediums you will be better able to understand concepts presented one way, and then apply them in another way. For example, read paper and then implement a model, or hear about a technique in a talk and then be able to write a blog post on it. For you personally fluency will likely speed up your learning and increase your ability to communicate with others.\n",
    "\n",
    "Ultimately this helps achieve what general statistics community always strives for a better shared understanding of the world.\n",
    "\n",
    "有许多方法可以传达统计模型的架构。这些可以是，没有特定的顺序：\n",
    "\n",
    "- 口语和书面语言\n",
    "\n",
    "- 概念图：{numref}`fig:BetaBinomModelGraphViz`。\n",
    "\n",
    "- 数学符号：方程 {eq}`eq:beta_binomial`\n",
    "\n",
    "- 计算机代码：代码块 [beta_binom](beta_binom)\n",
    "\n",
    "对于现代贝叶斯实践者来说，了解所有这些媒介是很有用的。它们是您在会谈、科学论文、与同事讨论时的手绘草图、互联网上的代码示例等中看到的格式。通过这些媒体流利，您将能够更好地理解以一种方式呈现的概念，然后将它们应用到另一种方式中大大地。例如，阅读论文然后实现一个模型，或者在演讲中听到一种技术，然后能够在上面写一篇博客文章。对于您个人而言，流利程度可能会加快您的学习速度并提高您与他人交流的能力。\n",
    "\n",
    "最终，这有助于实现一般统计界一直在努力更好地共享对世界的理解。\n",
    "\n",
    "::: \n",
    "\n",
    "```{figure} figures/Bayesian_quartet_distributions.png\n",
    ":name: fig:quartet\n",
    ":width: 8.00in \n",
    " \n",
    " From top plot to bottom plot we show: (1) samples from the prior distribution of the parameter $\\theta$; (2) samples from the prior predictive distribution, where we are plotting the probability distribution of the total number of successes; (3) posterior samples of the parameter $\\theta$; (4) posterior predictive distribution of the total number of successes. The x-axis and y-axis scales are shared between the first and third plots and then between the second and fourth plots.\n",
    "\n",
    "从上图到下图，我们展示了：（1）来自参数 $\\theta$ 的先验分布的样本； (2) 来自先验预测分布的样本，我们正在绘制成功总数的概率分布； (3) 参数$\\theta$的后验样本； (4) 成功总数的后验预测分布。 x 轴和 y 轴刻度在第一个和第三个图之间共享，然后在第二个和第四个图之间共享。\n",
    "``` \n",
    "\n",
    "As we already mentioned, posterior predictive distributions take into account the uncertainty about our estimates.\n",
    "\n",
    "{numref}`fig:predictions_distributions` shows that the predictions using the mean are less spread than predictions from the posterior predictive distribution. This result is not only valid for the mean, we would get a similar picture if we change the mean to any other point-estimate.\n",
    "\n",
    "正如我们已经提到的，后验预测分布考虑了我们估计的不确定性。\n",
    "\n",
    "{numref}`fig:predictions_distributions` 表明使用均值的预测比来自后验预测分布的预测分布更少。这个结果不仅对均值有效，如果我们将均值更改为任何其他点估计，我们会得到类似的图像。\n",
    "\n",
    "```{figure} figures/predictions_distributions.png\n",
    ":name: fig:predictions_distributions\n",
    ":width: 8.00in \n",
    " \n",
    " Predictions for the Beta-Binomial model, using the posterior mean (gray histogram) vs predictions using the entire posterior, i.e. the posterior predictive distribution (blue histogram).\n",
    "``` \n",
    "\n",
    "(make_prior_count)=\n",
    "\n",
    "## 1.4 量化先验信息的几种选择\n",
    "\n",
    " Having to choose a prior distribution is portrayed both as a burden and as a blessing. We choose to affirm that is a necessity, if you are not choosing your priors someone else is doing it for you. Letting others decide for you is not always a bad thing. Many of these non-Bayesian methods can be very useful and efficient if applied in the correct context, and with awareness of their limitations. However, we firmly believe there is an advantage for the practitioner in knowing the model assumptions and have the flexibility to alter them. Priors are just one form of assumption.\n",
    "\n",
    " We also understand that prior elicitation can be a source of doubts, anxiety, and even frustration for many practitioners, especially for, but not necessarily only for, newcomers. Asking what is the best-ever prior for a given problem, is a common and totally valid question. But it is difficult to give a straight satisfying answer other than, there is no such thing. At best there are some useful defaults that we can use as starting points in an iterative modeling workflow.\n",
    "\n",
    " In this section we discuss a few general approaches for selecting prior distributions. This discussion follows more or less an *informativeness gradient* from \"blank slates\\\" which include no information, to highly informative, which put as much information as possible into the priors.\n",
    "\n",
    "As with the other sections in this chapter, this discussion is more on the theoretical side. In the following chapters we will discuss how to choose priors in more practical settings.\n",
    "\n",
    "\n",
    "不得不选择先验分布被描述为一种负担和一种祝福。我们选择确认这是必要的，如果你没有选择你的先验，其他人正在为你做这件事。让别人替你做决定并不总是一件坏事。如果在正确的上下文中应用并且意识到它们的局限性，许多这些非贝叶斯方法可能非常有用和有效。然而，我们坚信从业者了解模型假设并灵活地改变它们是有优势的。先验只是假设的一种形式。\n",
    "\n",
    "我们也明白，对于许多从业者来说，先前的启发可能是怀疑、焦虑甚至沮丧的根源，尤其是对于新人，但不一定仅限于新人。询问给定问题的最佳先验是什么，是一个常见且完全有效的问题。但是除了没有这样的事情之外，很难给出一个直接令人满意的答案。充其量，我们可以使用一些有用的默认值作为迭代建模工作流程的起点。\n",
    "\n",
    "在本节中，我们将讨论一些选择先验分布的一般方法。这个讨论或多或少遵循一个*信息梯度*，从不包含任何信息的“空白板”到信息丰富的，将尽可能多的信息放入先验中。\n",
    "\n",
    "与本章的其他部分一样，这个讨论更多地是在理论方面。在接下来的章节中，我们将讨论如何在更实际的环境中选择先验。\n",
    "\n",
    "(conjugate_priors)=\n",
    "\n",
    "### 1.4.1 共轭先验 \n",
    "\n",
    "A prior is conjugate to a likelihood if the posterior belongs to the same family of distributions as the prior. For example, if the likelihood is Poisson and the prior Gamma, then the posterior will also be a Gamma distribution [^13].\n",
    "\n",
    " From a purely mathematical perspective, **conjugate priors** are the most convenient choice as they allow us to calculate the posterior distribution analytically with \"pen and paper\\\", no complex computation required [^14]. From a modern computational perspective, conjugate priors are generally not better than alternatives, the main reason being that modern computational methods allow us to perform inference with virtually any choice of priors and not just those that are mathematically convenient. Nevertheless, conjugate priors can be useful when learning Bayesian inference and also under some situations when there is a need to use analytical expressions for the posterior (see Section {ref}`conjugate_case_study` for an example). As is such, we will briefly discuss analytical priors using the Beta Binomial model.\n",
    "\n",
    " As the name suggests, the conjugate prior for the binomial distribution is the Beta distribution: \n",
    "\n",
    "如果后验与先验属于同一分布族，则先验与似然共轭。例如，如果似然是 Poisson 和先验 Gamma，那么后验也将是 Gamma 分布 [^13]。\n",
    "\n",
    "从纯数学的角度来看，**共轭先验**是最方便的选择，因为它们允许我们用“纸笔”分析地计算后验分布，不需要复杂的计算 [^14]。从现代计算的角度来看，共轭先验通常并不比替代方法好，主要原因是现代计算方法允许我们使用几乎任何选择的先验进行推断，而不仅仅是那些在数学上方便的选择。尽管如此，共轭先验在学习贝叶斯推断时以及在某些需要对后验使用分析表达式的情况下可能很有用（请参阅第 {ref}`conjugate_case_study` 节中的示例）。因此，我们将简要讨论使用 Beta 二项式模型的分析先验。\n",
    "\n",
    "顾名思义，二项分布的共轭先验是 Beta 分布：\n",
    "\n",
    "```{math} \n",
    "p(\\theta \\mid Y) \\propto \\overbrace{\\frac{N!}{y!(N-y)!} \\theta^y (1 - \\theta)^{N-y}}^{\\text{binomial-likelihood}} \\: \\overbrace{\\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}\\, \\theta^{\\alpha-1}(1-\\theta)^{\\beta-1}}^{\\text{beta.prior}} \n",
    "```\n",
    " \n",
    "\n",
    "Because all the terms not depending on $\\theta$ are constant we can drop them and we get: \n",
    "\n",
    "因为所有不依赖于 $\\theta$ 的项都是不变的，所以我们可以删除它们，我们得到：\n",
    "\n",
    "```{math} \n",
    "p(\\theta \\mid Y) \\propto \\overbrace{\\theta^y (1 - \\theta)^{N-y}}^{\\text{binomial-likelihood}} \\: \\overbrace{ \\theta^{\\alpha-1}(1-\\theta)^{\\beta-1}}^{\\text{beta.prior}}\n",
    "```\n",
    "\n",
    "Reordering: \n",
    "\n",
    "重新排序：\n",
    "\n",
    "```{math} \n",
    ":label: eq:kernel_beta \n",
    "p(\\theta \\mid Y) \\propto \\theta^{\\alpha-1+y}(1-\\theta)^{\\beta-1+N-y} \n",
    "``` \n",
    "\n",
    "If we want to ensure that the posterior is a proper probability distribution function, we need to add a normalization constant ensuring that the integral of the PDF is 1 (see Section {ref}`cont_rvs`). Notice that expression {eq}`eq:kernel_beta` looks like the kernel of a Beta distribution, thus by adding the normalization constant of a Beta distribution we arrive to the conclusion that the posterior distribution for a Beta-Binomial model is: \n",
    "\n",
    "如果我们想确保后验是一个正确的概率分布函数，我们需要添加一个归一化常数，确保 PDF 的积分为 1（参见第 {ref}`cont_rvs` 节）。请注意，表达式 {eq}`eq:kernel_beta` 看起来像 Beta 分布的内核，因此通过添加 Beta 分布的归一化常数，我们得出结论，Beta-Binomial 模型的后验分布为：\n",
    "\n",
    "```{math} \n",
    ":label: eq:beta_posterior \n",
    "p(\\theta \\mid Y) \\propto \\frac{\\Gamma(\\alpha_{post}+\\beta_{post})}{\\Gamma(\\alpha_{post})\\Gamma(\\beta_{post})} \\theta^{\\alpha_{post}-1}(1-\\theta)^{\\beta_{post}-1} = \\text{Beta}(\\alpha_{post}, \\beta_{post}) \n",
    "``` \n",
    "\n",
    "where $\\alpha_{post} = \\alpha+y$ and $\\beta_{post} = \\beta+N-y$.\n",
    "\n",
    " As the posterior of a Beta-Binomial model is a Beta distribution we can use a Beta-posterior as the prior for a future analysis. This means that we will get the same result if we update the prior one data-point at a time or if we use the entire dataset at once. For example, the first four panels of {numref}`fig:beta_binomial_update` show how different priors get updated as we move from 0 to 1, 2, and 3 trials. The result is the same if we follow this succession or if we *jump* from 0 to 3 trials (or, in fact, $n$ trials).\n",
    "\n",
    "其中 $\\alpha_{post} = \\alpha+y$ 和 $\\beta_{post} = \\beta+N-y$。\n",
    "由于 Beta-Binomial 模型的后验是 Beta 分布，我们可以使用 Beta-posterior 作为未来分析的先验。这意味着，如果我们一次更新前一个数据点或一次使用整个数据集，我们将获得相同的结果。例如，{numref}`fig:beta_binomial_update` 的前四个子图显示了当我们从 0 到 1、2 和 3 试验时，不同的先验是如何更新的。如果我们遵循这个顺序，或者如果我们从 0 次试验*跳*到 3 次试验（或者，实际上是 $n$ 次试验），结果是相同的。\n",
    "\n",
    " There are a lot of other interesting things to see from {numref}`fig:beta_binomial_update`. For instance, as the number of trials increases, the width of the posterior gets lower and lower, i.e.\n",
    "\n",
    "the uncertainty gets lower and lower. Panels 3 and 5 show the results for 2 trials with 1 success and 12 trials with 6 success, for these cases, the sampling proportion estimator $\\hat \\theta = \\frac{y}{n}$ (black dot) is the same 0.5 for both cases (the posterior mode is also 0.5), although the width of the posteriors are concentrated in panel 5 reflecting that the number of observations is larger and thus uncertainty lower. Finally, we can see how different priors converge to the same posterior distribution as the number of observations increase.\n",
    "\n",
    "In the limit of infinite data, the posteriors (irrespective of priors used to compute those posteriors) will have all its density at $\\hat \\theta = \\frac{y}{n}$.\n",
    "\n",
    "从 {numref}`fig:beta_binomial_update` 可以看到很多其他有趣的事情。例如，随着试验次数的增加，后部的宽度越来越小，即\n",
    "\n",
    "不确定性越来越低。子图 3 和 5 显示了 2 次试验成功 1 次和 12 次试验成功 6 次的结果，对于这些情况，抽样比例估计量 $\\hat \\theta = \\frac{y}{n}$（黑点）是相同的两种情况下均为 0.5（后验模式也是 0.5），尽管后验的宽度集中在子图 5 中，这反映了观察的数量更大，因此不确定性更低。最后，我们可以看到随着观察次数的增加，不同的先验如何收敛到相同的后验分布。\n",
    "\n",
    "在无限数据的限制下，后验（与用于计算这些后验的先验无关）将在 $\\hat \\theta = \\frac{y}{n}$ 处具有所有密度。\n",
    "\n",
    "```{code-block} ipython3\n",
    ":name: binomial_update\n",
    ":caption: binomial_update\n",
    "\n",
    "_, axes = plt.subplots(2,3, sharey=True, sharex=True)\n",
    "axes = np.ravel(axes)\n",
    "\n",
    "n_trials = [0, 1, 2, 3, 12, 180]\n",
    "success = [0, 1, 1, 1, 6, 59]\n",
    "data = zip(n_trials, success)\n",
    "\n",
    "beta_params = [(0.5, 0.5), (1, 1), (10, 10)]\n",
    "θ = np.linspace(0, 1, 1500)\n",
    "for idx, (N, y) in enumerate(data):\n",
    "    s_n = (\"s\" if (N > 1) else \"\")\n",
    "    for jdx, (a_prior, b_prior) in enumerate(beta_params):\n",
    "        p_theta_given_y = stats.beta.pdf(θ, a_prior + y, b_prior + N - y)\n",
    "\n",
    "        axes[idx].plot(θ, p_theta_given_y, lw=4, color=viridish[jdx])\n",
    "        axes[idx].set_yticks([])\n",
    "        axes[idx].set_ylim(0, 12)\n",
    "        axes[idx].plot(np.divide(y, N), 0, color=\"k\", marker=\"o\", ms=12)\n",
    "        axes[idx].set_title(f\"{N:4d} trial{s_n} {y:4d} success\")\n",
    "```\n",
    "\n",
    "```{figure} figures/beta_binomial_update.png\n",
    ":name: fig:beta_binomial_update\n",
    ":width: 8.00in \n",
    " \n",
    "从 3 个不同的先验开始连续更新先验并增加试验次数（也可能增加成功次数）。黑点代表采样比例估计器$\\hat \\theta = \\frac{y}{n}$。\n",
    "``` \n",
    "\n",
    "The mean of the Beta distribution is $\\frac{\\alpha}{\\alpha + \\beta}$, thus the prior mean is: \n",
    "\n",
    "```{math} \n",
    "\\mathbb{E}[\\theta]  = \\frac{\\alpha}{\\alpha + \\beta}\n",
    "```\n",
    "\n",
    "and the posterior mean is: \n",
    "\n",
    "```{math} \n",
    ":label: eq:beta_binom_mean \n",
    "\n",
    "\\mathbb{E}[\\theta \\mid Y]  = \\frac{\\alpha + y}{\\alpha + \\beta + n}\n",
    "``` \n",
    "\n",
    "We can see that if the value of $n$ is small in relation with the values of $\\alpha$ and $\\beta$ then the posterior mean will be closer to the prior mean. That is, the prior contributes more to the result than the data. If we have the opposite situation the posterior mean will be closer to the sampling proportion estimator $\\hat \\theta = \\frac{y}{n}$, in fact in the limit of $n \\rightarrow \\infty$ the posterior mean will exactly match the sample proportion no matter which prior values we choose for $\\alpha$ and $\\beta$.\n",
    "\n",
    " For the Beta Binomial model the posterior mode is: \n",
    "\n",
    "```{math} \n",
    ":label: eq:beta_binom_mode \n",
    "\n",
    "\\operatorname*{argmax}_{\\theta}{[\\theta \\mid Y]}  = \\frac{\\alpha + y - 1}{\\alpha + \\beta + n - 2} \n",
    "``` \n",
    "\n",
    "We can see that when the prior is Beta$(\\alpha\\!=\\!1, \\beta\\!=\\!1)$ (Uniform) the posterior mode is numerically equivalent to the sampling proportion estimator $\\hat \\theta = \\frac{y}{n}$. The posterior mode is often called the **maximum a posteriori** (MAP) value. This result is not exclusive for the Beta-Binomial model. In fact the results from many non-Bayesian methods can be understood as the MAP from Bayesian methods under some particular priors [^15].\n",
    "\n",
    " Compare Equation {eq}`eq:beta_binom_mean` to the sampling proportion $\\frac{y}{n}$. The Bayesian estimator is adding $\\alpha$ to the number of successes and $\\alpha + \\beta$ to the number of trials. Which makes $\\beta$ the number of failures. In this sense we can think of the prior parameters as *pseudo counts* or if you want prior data. A prior $\\text{Beta}(1, 1)$ is equivalent to having two trials with 1 success and 1 failure. Conceptually, the shape of the Beta distribution is controlled by parameter $\\alpha$ and $\\beta$, the observed data updates the prior so that it shifts the shape of the Beta distribution closer and more narrowly to the majority of observations. For values of $\\alpha < 1$ and/or $\\beta < 1$ the prior interpretations becomes a little bit weird as a literal interpretation would say that the prior $\\text{Beta}(0.5, 0.5)$ corresponds to 1 trial with half failure and half success or maybe one trial with undetermined outcome. Spooky! \n",
    "\n",
    "(objective-priors)=\n",
    "\n",
    "### 1.4.2 客观性先验 \n",
    "\n",
    "In the absence of prior information, it sounds reasonable to follow the *principle of indifference* also known as the *principle of insufficient reason*. This principle basically says that if you do not have information about a problem then you do not have any reason to believe one outcome is more likely than any other. In the context of Bayesian statistics this principle has motivated the study and use of **objective priors**. These are systematic ways of generating priors that have the least possible influence on a given analysis. The champions of ascetic statistics favor objective priors as these priors eliminate the *subjectivity* from prior elicitation. Of course this does not remove other sources of subjectivity such as the choice of the likelihood, the data selection process, the choice of the problem being modeled or investigated, and a long *et cetera*.\n",
    "\n",
    " One procedure to obtain objective priors is known as Jeffreys' prior (JP). These type of priors are often referred as *non-informative* even when priors are always informative in some way. A better description is to say that JPs have the property of being invariant under **reparametrization**, i.e. writing an expression in a different but mathematically equivalent way. Let us explain what this exactly means with an example. Suppose Alice has a binomial likelihood with unknown parameter $\\theta$, she chooses a prior and computes a posterior.\n",
    "\n",
    "Alice's friend Bob is interested on the same problem but instead of the number of success $\\theta$, Bob is interested on the **odds** of the success, i.e. $\\kappa$, with $\\kappa = \\frac{\\theta}{1-\\theta}$. Bob has two choices: uses Alice's posterior over $\\theta$ to compute $\\kappa$ [^16] or choose a prior over $\\kappa$ to compute the posterior by himself. JPs guarantee that if both Alice and Bob use JPs then no matter which of the two choices Bob takes in order to compute the posteriors, he will get the same result. In this sense we say the results are invariant to the chosen parameterization. A corollary of this explanation could be, that unless we use JPs there is no guarantee that two (or more) parameterization of a model will necessarily lead to posteriors that are coherent.\n",
    "\n",
    " For the one-dimensional case JP for $\\theta$ is \n",
    "\n",
    "\n",
    "在没有先验信息的情况下，遵循*无差异原则*（也称为*不充分理由原则*）听起来是合理的。这个原则基本上是说，如果你没有关于某个问题的信息，那么你没有任何理由相信一个结果比任何其他结果更有可能发生。在贝叶斯统计的背景下，这一原则激发了**客观先验**的研究和使用。这些是生成对给定分析影响最小的先验的系统方法。苦行统计的拥护者偏爱客观先验，因为这些先验消除了先验的*主观性*。当然，这并没有消除其他主观性来源，例如似然的选择、数据选择过程、正在建模或研究的问题的选择，以及长长的*等等*。\n",
    "\n",
    "获得客观先验的一种程序称为 Jeffreys 的先验 (JP)。这些类型的先验通常被称为*非信息性*，即使先验总是以某种方式提供信息。更好的描述是说 JP 具有在**重新参数化**下保持不变的属性，即以不同但在数学上等效的方式编写表达式。让我们用一个例子来解释这究竟意味着什么。假设 Alice 具有未知参数 $\\theta$ 的二项似然，她选择先验并计算后验。\n",
    "\n",
    "Alice 的朋友 Bob 对同样的问题感兴趣，但不是成功的次数 $\\theta$，Bob 感兴趣的是成功的 **odds**，即 $\\kappa$，$\\kappa = \\frac{\\ theta}{1-\\theta}$。 Bob 有两个选择：使用 Alice 在 $\\theta$ 上的后验来计算 $\\kappa$ [^16] 或选择 $\\kappa$ 上的先验来自己计算后验。 JP 保证如果 Alice 和 Bob 都使用 JP，那么无论 Bob 为计算后验而采取的两种选择中的哪一种，他都会得到相同的结果。从这个意义上说，我们说结果对于选择的参数化是不变的。这种解释的一个推论可能是，除非我们使用 JP，否则不能保证模型的两个（或更多）参数化必然会导致后验一致。\n",
    "\n",
    "对于 $\\theta$ 的一维情况 JP 是\n",
    "\n",
    "```{math} \n",
    ":label: eq:Jeffreys_prior0 \n",
    "\n",
    "p(\\theta) \\propto \\sqrt{I(\\theta)} \n",
    "``` \n",
    "\n",
    "where $I(\\theta)$ is the expected Fisher information: \n",
    "\n",
    "```{math} \n",
    ":label: eq:Jeffreys_prior \n",
    "I(\\theta) = - \\mathbb{E_{Y}}\\left[\\frac{d^2}{d\\theta^2} \\log p(Y \\mid \\theta)\\right] \n",
    "``` \n",
    "\n",
    "Once the likelihood function $p(Y \\mid \\theta)$ has been decided by the practitioner, then the JP gets automatically determined, eliminating any discussion over prior choices, until that annoying person at the back of the conference room objects your choice of a JP in the first place.\n",
    "\n",
    " For a detailed derivation of the JPs for both Alice and Bob problem see Section {ref}`Jeffreys_prior_derivation`. If you want to skip those details here we have the JP for Alice: \n",
    "\n",
    "一旦从业者确定了似然函数 $p(Y \\mid \\theta)$，那么 JP 就会自动确定，消除对先前选择的任何讨论，直到会议室后面那个讨厌的人反对您的选择首先是JP。\n",
    "\n",
    "有关 Alice 和 Bob 问题的 JP 的详细推导，请参阅第 {ref}`Jeffreys_prior_derivation` 部分。如果你想在这里跳过这些细节，我们有 Alice 的 JP：\n",
    "\n",
    "```{math} \n",
    "\\begin{aligned}\n",
    " p(\\theta) \\propto \\theta^{-0.5} (1-\\theta)^{-0.5}\n",
    "\\end{aligned}\n",
    "```\n",
    "\n",
    "This turns to be the kernel of the $\\text{Beta}(0.5, 0.5)$ distribution.\n",
    "\n",
    "Which is a u-shaped distribution as shown in the left-top panel of {numref}`fig:Jeffrey_priors`.\n",
    "\n",
    " For Bob the JP is: \n",
    "\n",
    "这变成了 $\\text{Beta}(0.5, 0.5)$ 发行版的内核。\n",
    "这是一个 u 形分布，如 {numref}`fig:Jeffrey_priors` 的左上子图所示。\n",
    "对于 Bob 来说，JP 是：\n",
    "\n",
    "```{math} \n",
    ":label: fig:bob_prior \n",
    "p(\\kappa) \\propto \\kappa^{-0.5} (1 + \\kappa)^{-1} \n",
    "``` \n",
    "\n",
    "This is a half-u-shaped distribution, defined in the $[0, \\infty)$ interval, see top-right panel in {numref}`fig:Jeffrey_priors`. Saying this is a half-u-shaped may sound a little bit weird. Actually it is not that weird when we find that this is the kernel of a close cousin of the Beta distribution, the Beta-prime distribution with parameters $\\alpha=\\beta=0.5$.\n",
    "\n",
    "这是一个半 u 形分布，定义在 $[0, \\infty)$ 区间中，参见 {numref}`fig:Jeffrey_priors` 中的右上角子图。说这是一个半 U 形可能听起来有点奇怪。实际上，当我们发现这是 Beta 分布的近亲，即参数为 $\\alpha=\\beta=0.5$ 的 Beta-prime 分布的内核时，这并不奇怪。\n",
    "\n",
    "```{figure} figures/Jeffrey_priors.png\n",
    ":name: fig:Jeffrey_priors\n",
    ":width: 8.00in \n",
    " \n",
    " Top: Jeffreys' prior (unnormalized) for the binomial likelihood parameterized in term of the number of success $\\theta$ (left) or in term of the odds $\\kappa$ (right). Bottom: Jeffreys' posteriors (unnormalized) for the binomial likelihood parameterized in term of the number of success $\\theta$ (left) or in term of the odds $\\kappa$ (right). The arrows between the posteriors indicate that the posterior are inter-convertible by applying the change of variable rule (see Section {ref}`transformations` for details).\n",
    " \n",
    " 上图：根据成功次数 $\\theta$（左）或几率 $\\kappa$（右）参数化的二项式似然的 Jeffreys 的先验（未归一化）。底部：根据成功次数 $\\theta$（左）或几率 $\\kappa$（右）参数化的二项式似然性的 Jeffreys 后验（未归一化）。后验之间的箭头表示后验通过应用变量规则的变化是可相互转换的（有关详细信息，请参阅第 {ref}`transformations` 节）。\n",
    "``` \n",
    "\n",
    "Notice that as the expectation in Equation {eq}`eq:Jeffreys_prior` is with respect to $Y \\mid \\theta$, that is an expectation over the sample space. This means that in order to obtain a JP we need to average over all possible experimental outcomes. This is a violation of the likelihood principle [^17] as the inferences about $\\theta$ depends not just on the data at hand, but also on the set of potentially (but not yet) observed data.\n",
    "\n",
    " A JP can be improper prior, meaning that it does not integrate to 1. For example, the JP for the mean of a Gaussian distribution of known variance is uniform over the entire real line. Improper priors are fine as long as we verify that the combination of them with a likelihood produces a proper posterior distribution, that is one integrating to 1.\n",
    "\n",
    "Also notice that we can not draw random samples from improper priors (i.e., they are non-generative) this can invalidate many useful tools that allow us to reason about our model.\n",
    "\n",
    " JPs are not the only way to obtain an objective prior. Another possible route is to obtain a prior by maximizing the expected Kullback-Leibler divergence (see Section {ref}`DKL`) between the prior and posterior. These kind of priors are known as Bernardo reference priors. They are objective as these are the priors that *allow the data to bring* the maximal amount of information into the posterior distribution. Bernardo reference priors and Jeffreys' prior do not necessarily agree.\n",
    "\n",
    "Additionally, objective priors may not exist or be difficult to derive for complicated models.\n",
    "\n",
    "请注意，由于方程 {eq}`eq:Jeffreys_prior` 中的期望是关于 $Y \\mid \\theta$ 的，因此这是对样本空间的期望。这意味着为了获得 JP，我们需要对所有可能的实验结果进行平均。这违反了似然原则 [^17]，因为关于 $\\theta$ 的推论不仅取决于手头的数据，还取决于可能（但尚未）观测数据集。\n",
    "\n",
    "JP 可能是不正确的先验，这意味着它不会积分到 1。例如，已知方差的高斯分布的均值的 JP 在整个实线上是均匀的。只要我们验证它们与似然的组合会产生适当的后验分布，即积分为 1，不适当的先验就可以了。\n",
    "\n",
    "还要注意，我们不能从不正确的先验中抽取随机样本（即它们是非生成的），这会使许多有用的工具失效，这些工具使我们能够推断我们的模型。\n",
    "\n",
    "JP 并不是获得客观先验的唯一方法。另一种可能的途径是通过最大化先验和后验之间的预期 Kullback-Leibler 散度（参见 {ref}`DKL` 部分）来获得先验。这种先验被称为 Bernardo 参考先验。它们是客观的，因为这些是*允许数据将*最大量的信息带入后验分布的先验。 Bernardo 参考先验和 Jeffreys 的先验不一定一致。\n",
    "\n",
    "此外，对于复杂的模型，客观先验可能不存在或难以推导。\n",
    "\n",
    "(maximum-entropy-priors)=\n",
    "\n",
    "### 1.4.3 最大熵先验 \n",
    "\n",
    "Yet another way to justify a choice of priors is to pick the prior with the highest entropy. If we are totally indifferent about the plausible values then such prior turns out to be the Uniform distribution over the range on plausible values [^18]. But what about when we are not completely indifferent about the plausible values a parameter can take? For example, we may know our parameter is restricted to the $[0, \\infty)$ interval. Can we obtain a prior that has maximum entropy while also satisfying a given constraint? Yes we can and that is exactly the idea behind maximum entropy priors. In the literature it is common to find the word MaxEnt when people talk about the maximum entropy principle.\n",
    "\n",
    "另一种证明先验选择合理性的方法是选择具有最高熵的先验。如果我们对合理值完全漠不关心，那么这种先验结果是合理值范围内的均匀分布 [^18]。但是，当我们对参数可以取的合理值不是完全无动于衷时呢？例如，我们可能知道我们的参数仅限于 $[0, \\infty)$ 区间。我们能否获得具有最大熵同时满足给定约束的先验？是的，我们可以，这正是最大熵先验背后的想法。在文献中，当人们谈论最大熵原理时，通常会找到 MaxEnt 这个词。\n",
    "\n",
    " In order to obtain a maximum entropy prior we need to solve an optimization problem taking into account a set of constraints.\n",
    "\n",
    "Mathematically this can be done using what is known as Lagrangian multipliers. Instead of a formal proof we are going to use a couple code examples to gain some intuition.\n",
    "\n",
    " {numref}`fig:max_entropy` shows 3 distributions obtained by entropy maximization. The purple distribution is obtained under no constraint, and we are happy to find that this is indeed the Uniform distribution as expected from the discussion about entropy in Section {ref}`entropy`. If we do not know anything about the problem all events are equally likely a priori. The second distribution, in cyan, is obtained under the constraint that we know the mean value of the distribution. In this example the mean value is 1.5). Under this constraint we get an Exponential-like distribution. The last one in yellow-green was obtained under the restriction that the value 3 and 4 are known to appear with a probability of 0.8. If you check Code Block [max_ent_priors](max_ent_priors) you will see all distributions were computed under two constraints that probabilities can only take values in the interval $[0, 1]$ and that the total probability must be 1. As these are general constraints for valid probability distribution we can think of them as *intrinsic* or even *ontological* constraints. For that reason we say that the purple distribution in {numref}`fig:max_entropy` was obtained under no-constraint.\n",
    "\n",
    "为了获得最大熵先验，我们需要解决一个考虑一组约束的优化问题。\n",
    "\n",
    "从数学上讲，这可以使用所谓的拉格朗日乘数来完成。我们将使用几个代码示例来获得一些直觉，而不是正式的证明。\n",
    "\n",
    "{numref}`fig:max_entropy` 显示了通过熵最大化获得的 3 个分布。紫色分布是在没有约束的情况下获得的，我们很高兴地发现这确实是第 {ref}`entropy` 节中关于熵的讨论所预期的均匀分布。如果我们对问题一无所知，那么所有事件都同样可能是先验的。青色的第二个分布是在我们知道分布的平均值的约束下获得的。在本例中，平均值为 1.5)。在这个约束下，我们得到一个类似指数的分布。最后一个黄绿色是在已知值 3 和 4 出现概率为 0.8 的限制下获得的。如果您检查代码块 [max_ent_priors](max_ent_priors)，您将看到所有分布都是在两个约束条件下计算的，即概率只能在区间 $[0, 1]$ 中取值，并且总概率必须为 1。因为这些是通用的有效概率分布的约束，我们可以将它们视为 *intrinsic* 甚至 *ontological* 约束。出于这个原因，我们说 {numref}`fig:max_entropy` 中的紫色分布是在无约束条件下获得的。\n",
    " \n",
    "\n",
    "```{code-block} ipython3\n",
    ":name: max_ent_priors\n",
    ":caption: max_ent_priors\n",
    "cons = [[{\"type\": \"eq\", \"fun\": lambda x: np.sum(x) - 1}],\n",
    "        [{\"type\": \"eq\", \"fun\": lambda x: np.sum(x) - 1},\n",
    "         {\"type\": \"eq\", \"fun\": lambda x: 1.5 - np.sum(x * np.arange(1, 7))}],\n",
    "        [{\"type\": \"eq\", \"fun\": lambda x: np.sum(x) - 1},\n",
    "         {\"type\": \"eq\", \"fun\": lambda x: np.sum(x[[2, 3]]) - 0.8}]]\n",
    "\n",
    "max_ent = []\n",
    "for i, c in enumerate(cons):\n",
    "    val = minimize(lambda x: -entropy(x), x0=[1/6]*6, bounds=[(0., 1.)] * 6,\n",
    "                   constraints=c)['x']\n",
    "    max_ent.append(entropy(val))\n",
    "    plt.plot(np.arange(1, 7), val, 'o--', color=viridish[i], lw=2.5)\n",
    "plt.xlabel(\"$t$\")\n",
    "plt.ylabel(\"$p(t)$\")\n",
    "```\n",
    "\n",
    "```{figure} figures/max_entropy.png\n",
    ":name: fig:max_entropy\n",
    ":width: 8.00in \n",
    " \n",
    " Discrete distributions obtained by maximizing the entropy under different constraints. We are using the function `entropy` from `scipy.stats` to estimate these distributions. Notice how adding constraints can drastically change the distribution.\n",
    " \n",
    " 通过在不同约束下最大化熵获得的离散分布。我们使用来自 scipy.stats 的函数 entropy 来估计这些分布。请注意添加约束如何极大地改变分布。\n",
    "``` \n",
    "\n",
    "We can think of the maximum entropy principle as the procedure of choosing the flattest distribution, and by extension the flattest prior distribution, under a given constraint. In {numref}`fig:max_entropy` the Uniform distribution is the flattest distribution, but notice that the distribution in green is also the flattest distribution once we include the restriction that the values 3 and 4 have a 80% chance of arising.\n",
    "\n",
    "Notice how the values 3 and 4 have both a probability of 0.4, even when you have infinite other ways to combine their probabilities to obtain the target value of 0.8, like 0+0.8, 0.7+0.1, 0.312+0.488 and so on.\n",
    "\n",
    "Also notice something similar is true for the values 1, 2, 5 and 6, they have a total probability of 0.2 which is evenly distributed (0.05 for each value). Now take a look at the Exponential-like curve, which certainly does not look very flat, but once again notice that other choices will be less flat and more concentrated, for example, obtaining 1 and 2 with $50\\%$ chance each (and thus zero change for the values 3 to 6), which will also have 1.5 as the expected value.\n",
    "\n",
    "我们可以将最大熵原理视为在给定约束下选择最平坦分布的过程，并通过扩展最平坦的先验分布。在 {numref}`fig:max_entropy` 中，均匀分布是最平坦的分布，但请注意，一旦我们包含值 3 和 4 有 80% 出现机会的限制，绿色分布也是最平坦的分布。\n",
    "请注意值 3 和 4 的概率都是 0.4，即使您有无数其他方法可以组合它们的概率以获得目标值 0.8，例如 0+0.8、0.7+0.1、0.312+0.488 等等。\n",
    "另请注意，值 1、2、5 和 6 也有类似的情况，它们的总概率为 0.2，这是均匀分布的（每个值 0.05）。现在看一下类似指数的曲线，它看起来肯定不是很平坦，但再次注意到其他选择将不那么平坦且更集中，例如，分别以 $50\\%$ 的机会获得 1 和 2（因此为零将值 3 更改为 6)，这也将具有 1.5 作为预期值。\n",
    "\n",
    "```python\n",
    "ite = 100_000\n",
    "entropies = np.zeros((3, ite))\n",
    "for idx in range(ite):\n",
    "    rnds = np.zeros(6)\n",
    "    total = 0\n",
    "    x_ = np.random.choice(np.arange(1, 7), size=6, replace=False)\n",
    "    for i in x_[:-1]:\n",
    "        rnd = np.random.uniform(0, 1-total)\n",
    "        rnds[i-1] = rnd\n",
    "        total = rnds.sum()\n",
    "    rnds[-1] = 1 - rnds[:-1].sum()\n",
    "    H = entropy(rnds)\n",
    "    entropies[0, idx] = H\n",
    "    if abs(1.5 - np.sum(rnds * x_)) < 0.01:\n",
    "        entropies[1, idx] = H\n",
    "    prob_34 = sum(rnds[np.argwhere((x_ == 3) | (x_ == 4)).ravel()])\n",
    "    if abs(0.8 - prob_34) < 0.01:\n",
    "        entropies[2, idx] = H\n",
    "```\n",
    "\n",
    "\n",
    "{numref}`fig:max_entropy_vs_random_dist` shows the distribution of entropies computed for randomly generated samples under the exact same conditions as the 3 distributions in {numref}`fig:max_entropy`. The dotted vertical line represents the entropy of the curves in {numref}`fig:max_entropy_vs_random_dist`. While this is not a proof, this experiment seems to suggest that there is no distribution with higher entropy than the distributions in {numref}`fig:max_entropy_vs_random_dist`, which is in total agreement with what the theory tells us.\n",
    "\n",
    "{numref}`fig:max_entropy_vs_random_dist` 显示了在与 {numref}`fig:max_entropy` 中的 3 个分布完全相同的条件下为随机生成的样本计算的熵分布。垂直虚线表示 {numref}`fig:max_entropy_vs_random_dist` 中曲线的熵。虽然这不是证据，但这个实验似乎表明没有比 {numref}`fig:max_entropy_vs_random_dist` 中的分布具有更高熵的分布，这与理论告诉我们的完全一致。\n",
    "\n",
    "```{figure} figures/max_entropy_vs_random_dist.png\n",
    ":name: fig:max_entropy_vs_random_dist\n",
    ":width: 8.00in \n",
    " \n",
    " The distribution of entropy for a set of randomly generated distributions. The dotted vertical line indicates the value for the distributions with maximum entropy, computed with Code Block [max_ent_priors](max_ent_priors). We can see that none of the randomly generated distributions have an entropy larger that the distributions with maximum entropy, while this is no formal proof, this is certainly reassuring.\n",
    " \n",
    " 一组随机生成的分布的熵分布。垂直虚线表示具有最大熵的分布的值，使用代码块 [max_ent_priors](max_ent_priors) 计算。我们可以看到，没有一个随机生成的分布的熵大于具有最大熵的分布，虽然这没有正式的证据，但这当然是令人放心的。\n",
    "``` \n",
    "\n",
    "The distributions with the largest entropy under the following constraints are [^19]: \n",
    "\n",
    "-   No constraints: Uniform (continuous or discrete, according to the     type of variable) \n",
    "\n",
    "-   A positive mean, with support $[0, \\infty)$: Exponential \n",
    "\n",
    "-   An absolute value mean, with support $(-\\infty, \\infty)$: Laplace     (also known as double Exponential) \n",
    "\n",
    "-   A given mean and variance, with support $(-\\infty, \\infty)$: Normal     distribution \n",
    "\n",
    "-   A given mean and variance, with support $[-\\pi, \\pi]$: Von Mises \n",
    "\n",
    "-   Only two unordered outcomes and a constant mean: Binomial, or the     Poisson if we have rare events (the Poisson can be seen as a special     case of the binomial) \n",
    "\n",
    "It is interesting to note that many of the generalized linear models like the ones described in Chapter [3](chap2) are traditionally defined using maximum entropy distributions, given the constraints of the models. Similar to objective priors, MaxEnt prior may not exist or are difficult to derive.\n",
    "\n",
    "在以下约束下具有最大熵的分布是 [^19]：\n",
    "\n",
    "- 无约束：统一（连续或离散，取决于变量的类型）\n",
    "\n",
    "- 正均值，支持 $[0, \\infty)$：指数\n",
    "\n",
    "- 绝对值均值，支持 $(-\\infty, \\infty)$：拉普拉斯（也称为双指数）\n",
    "\n",
    "- 给定的均值和方差，支持 $(-\\infty, \\infty)$：正态分布\n",
    "\n",
    "- 给定的均值和方差，支持 $[-\\pi, \\pi]$：Von Mises\n",
    "\n",
    "- 只有两个无序的结果和一个恒定的平均值：二项式，或者泊松，如果我们有罕见的事件（泊松可以看作是二项式的一个特例）\n",
    "\n",
    "有趣的是，考虑到模型的约束，许多广义线性模型（如第 [3] 章（chap2）中描述的模型）传统上是使用最大熵分布定义的。与客观先验类似，MaxEnt 先验可能不存在或难以推导。\n",
    "\n",
    "(weakly-informative-priors-and-regularization-priors)=\n",
    "\n",
    "### 1.4.4 弱信息性先验和正则化先验\n",
    "\n",
    "In previous sections we used general procedures to generate vague, non-informative priors designed to not put *too much* information into our analysis. These procedures to generate priors also provide a \"somehow\\\" automated way of generating priors. These two features may sound appealing, and in fact they are for a large number of Bayesian practitioners and theorists.\n",
    "\n",
    " But in this book we will not rely too much on these kinds of priors. We believe prior elicitation (as other modeling decisions) should be context dependent, meaning that details from specific problems and even idiosyncrasies of a given scientific field could inform our choice of priors. While MaxEnt priors can incorporate some of these restrictions it is possible to move a little bit closer to the informative end of the informativeness prior spectrum. We can do this with so called weakly informative priors.\n",
    " \n",
    " 在前面的部分中，我们使用一般程序来生成模糊的、无信息的先验，旨在不将*太多*信息放入我们的分析中。这些生成先验的过程还提供了一种“以某种方式”自动生成先验的方式。这两个特征听起来很吸引人，实际上它们适用于大量贝叶斯实践者和理论家。\n",
    " \n",
    "但在本书中，我们不会过分依赖这些先验。我们认为先验启发（与其他建模决策一样）应该取决于上下文，这意味着来自特定问题的细节甚至给定科学领域的特质都可以为我们选择先验提供信息。虽然 MaxEnt 先验可以包含其中一些限制，但可以稍微靠近信息性先验频谱的信息端。我们可以用所谓的弱信息先验来做到这一点。\n",
    "\n",
    " What constitutes a weakly informative priors is usually not mathematically well defined as JPs or MaxEnt are. Instead they are more *empirical* and *model-driven*, that is they are defined through a combination of relevant domain expertise and the model itself. For many problems, we often have information about the values a parameter can take. This information can be derived from the physical meaning of the parameter. We know heights have to be positive. We may even know the plausible range a parameter can take from previous experiments or observations. We may have strong reasons to justify a value should be close to zero or above some predefined lower-bound. We can use this information to weakly inform our analysis while keeping a good dose of ignorance to us from *to pushing too much*.\n",
    "\n",
    "构成弱信息先验的内容通常在数学上没有像 JP 或 MaxEnt 那样得到很好的定义。相反，它们更*经验*和*模型驱动*，也就是说，它们是通过相关领域专业知识和模型本身的组合来定义的。对于许多问题，我们经常有关于参数可以取值的信息。该信息可以从参数的物理意义中推导出来。我们知道高度必须是积极的。我们甚至可以从以前的实验或观察中知道参数的合理范围。我们可能有充分的理由证明一个值应该接近零或高于某个预定义的下限。我们可以使用这些信息来为我们的分析提供微弱的信息，同时对我们保持一定程度的无知，从*到推动太多*。\n",
    "\n",
    " Using the Beta-Binomial example again, {numref}`fig:prior_informativeness_spectrum` shows four alternative priors. Two of them are the JP and maximum entropy prior from previous sections. One is what could called a weakly informative prior that gives preference to a value of $\\theta=0.5$ while still being broad or relatively vague about other values. The last is an informative prior, narrowly centered around $\\theta=0.8$ [^20]. Using informative priors is a valid option if we have good-quality information from theory, previous experiments, observational data, etc. As informative priors are very strong priors conveying a lot of information they generally require a stronger justification than other priors. As Carl Sagan used to say \"Extraordinary claims require extraordinary evidence\" {cite:p}`Deming2016`. It is important to remember that informativeness of the prior depends on model and model context. An uninformative prior in one context can become highly informative in another {cite:p}`LikehoodandPrior`. For instance if modeling the mean height of adult humans in meters, a prior of $\\mathcal{N}(2,1)$ can be considered uninformative, but if estimating the height of giraffes that same prior becomes highly informative as in reality giraffe heights differ greatly than human heights.\n",
    "\n",
    "再次使用 Beta-Binomial 示例，{numref}`fig:prior_informativeness_spectrum` 显示了四个替代先验。其中两个是前几节中的 JP 和最大熵先验。一种是可以称为弱信息先验，它优先考虑 $\\theta=0.5$ 的值，同时对其他值仍然很宽泛或相对模糊。最后一个是信息丰富的先验，以 $\\theta=0.8$ [^20] 为中心。如果我们从理论、先前的实验、观察数据等中获得高质量的信息，则使用信息先验是一个有效的选择。由于信息先验是非常强大的先验，可以传达大量信息，它们通常需要比其他先验更强的理由。正如卡尔·萨根 (Carl Sagan) 常说的“非凡的主张需要非凡的证据”{cite:p}`Deming2016`。重要的是要记住，先验的信息量取决于模型和模型上下文。在一个上下文中的无信息先验可以在另一个 {cite:p}`LikehoodandPrior` 中变得非常有用。例如，如果以米为单位对成年人的平均身高进行建模，则 $\\mathcal{N}(2,1)$ 的先验可以被认为是无信息的，但如果估计长颈鹿的高度，则相同的先验变得像现实中的长颈鹿一样提供大量信息身高与人类身高相差很大。\n",
    "\n",
    "```{figure} figures/prior_informativeness_spectrum.png\n",
    ":name: fig:prior_informativeness_spectrum\n",
    ":width: 8.00in \n",
    " \n",
    " Prior informativeness spectrum: While Jeffreys and MaxEnt priors are uniquely defined for a binomial likelihood, weakly informative and informative priors are not and instead depend on previous information and practitioner's modeling decisions.\n",
    " \n",
    " 先验信息谱：虽然 Jeffreys 和 MaxEnt 先验是为二项似然唯一定义的，但弱信息和信息先验不是而是取决于先前的信息和从业者的建模决策。\n",
    "``` \n",
    "\n",
    "Because weakly-informative priors work to keep the posterior distribution within certain reasonable bounds, they are also known as regularizing priors. Regularization is a procedure of adding information with the aim of solving an ill-posed problem or to reduce the chance of overfitting and priors offer a principled way of performing regularization.\n",
    "\n",
    " In this book, more often than not, we will use weakly-informative priors. Sometimes the prior will be used in a model without too much justification, simply because the focus of the example may be related to other aspects of the Bayesian modeling workflow. But we will also show some examples of using prior predictive checks to help us calibrate our priors.\n",
    " \n",
    " 因为弱信息先验可以将后验分布保持在一定的合理范围内，所以它们也被称为正则化先验。正则化是一种添加信息的过程，目的是解决不适定问题或减少过度拟合的机会，先验提供了一种执行正则化的原则方法。\n",
    " \n",
    "在本书中，我们通常会使用弱信息先验。有时会在没有太多理由的情况下在模型中使用先验，仅仅是因为示例的重点可能与贝叶斯建模工作流程的其他方面有关。但我们还将展示一些使用先验预测检查来帮助我们校准先验的示例。\n",
    "\n",
    "::: {admonition} Overfitting \n",
    "\n",
    "Overfitting occurs when a model generates predictions very close to the limited dataset used to fit it, but it fails to fit additional data and/or predict future observations reasonably well. That is it fails to generalize its predictions to a wider set of possible observations. The counterpart of overfitting is underfitting, which is when a model fails to adequately capture the underlying structure of the data. We will discuss more about there topics in Sections {ref}`model_cmp` and {ref}`information_criterion`.\n",
    "\n",
    "当模型生成的预测非常接近用于拟合它的有限数据集时，就会发生过度拟合，但它无法拟合额外的数据和/或不能很好地预测未来的观察结果。也就是说，它未能将其预测推广到更广泛的可能观察结果。过拟合的对应物是欠拟合，即模型未能充分捕捉数据的底层结构。我们将在 {ref}`model_cmp` 和 {ref}`information_criterion` 部分讨论有关这些主题的更多信息。\n",
    "\n",
    "::: \n",
    "\n",
    "(using-prior-predictive-distributions-to-assess-priors)=\n",
    "\n",
    "### 1.4.5 使用先验预测分布来评估先验 \n",
    "\n",
    "When evaluating the choice of priors, the prior predictive distribution shown in {ref}`Automating_inference` is a handy tool. By sampling from the prior predictive distribution, the computer does the work of translating choices made in the parameter space into samples in the observed variable space. Thinking in terms of observed values is generally easier than thinking in terms of the model's parameters which makes model evaluation easier. Following a Beta Binomial model, instead of judging whether a particular value of $\\theta$ is plausible, prior predictive distributions allow us to judge whether a particular number of successes is plausible. This becomes even more useful for complex models where parameters get transformed through many mathematical operations or multiple priors interact with each other. Lastly, computing the prior predictive could help us ensure our model has been properly written and is able to run in our probabilistic programming language and can even help us to debug our model. In the following chapters, we will see more concrete examples of how to reason about prior predictive samples and use them to choose reasonable priors.\n",
    "\n",
    "在评估先验选择时，{ref}`Automating_inference` 中显示的先验预测分布是一个方便的工具。通过从先前的预测分布中采样，计算机将在参数空间中做出的选择转换为观察到的变量空间中的样本。考虑观察值通常比考虑模型参数更容易，这使得模型评估更容易。遵循 Beta 二项式模型，而不是判断 $\\theta$ 的特定值是否合理，先验预测分布允许我们判断特定数量的成功是否合理。这对于参数通过许多数学运算或多个先验相互交互的复杂模型变得更加有用。最后，计算先验预测可以帮助我们确保我们的模型已经正确编写并且能够在我们的概率编程语言中运行，甚至可以帮助我们调试我们的模型。在接下来的章节中，我们将看到更具体的示例，说明如何推断先验预测样本并使用它们来选择合理的先验。\n",
    "\n",
    "(exercises1)=\n",
    "\n",
    "## 1.5 练习\n",
    "\n",
    "Problems are labeled Easy (E), Medium (M), and Hard (H).\n",
    "\n",
    "**1E1.** As we discussed, models are artificial representations used to help define and understand an object or process.\n",
    "\n",
    "However, no model is able to perfectly replicate what it represents and thus is deficient in some way. In this book we focus on a particular type of models, statistical models. What are other types of models you can think of? How do they aid understanding of the thing that is being modeled? How are they deficient? \n",
    "\n",
    "**1E2.** Match each of these verbal descriptions to their corresponding mathematical expression: \n",
    "\n",
    "1.  The probability of a parameter given the observed data \n",
    "\n",
    "2.  The distribution of parameters before seeing any data \n",
    "\n",
    "3.  The plausibility of the observed data given a parameter value \n",
    "\n",
    "4.  The probability of an unseen observation given the observed data \n",
    "\n",
    "5.  The probability of an unseen observation before seeing any data \n",
    "\n",
    "**1E3.** From the following expressions, which one corresponds to the sentence, The probability of being sunny given that it is July 9th of 1816? \n",
    "\n",
    "1.  $p(\\text{sunny})$ \n",
    "\n",
    "2.  $p(\\text{sunny} \\mid \\text{July})$ \n",
    "\n",
    "3.  $p(\\text{sunny} \\mid \\text{July 9th of 1816})$ \n",
    "\n",
    "4.  $p(\\text{July 9th of 1816} \\mid \\text{sunny})$ \n",
    "\n",
    "5.  $p(\\text{sunny}, \\text{July 9th of 1816}) / p(\\text{July 9th of 1816})$ \n",
    "\n",
    "**1E4.** Show that the probability of choosing a human at random and picking the Pope is not the same as the probability of the Pope being human. In the animated series Futurama, the (Space) Pope is a reptile. How does this change your previous calculations? \n",
    "\n",
    "**1E5.** Sketch what the distribution of possible observed values could be for the following cases: \n",
    "\n",
    "1.  The number of people visiting your local cafe assuming Poisson     distribution \n",
    "\n",
    "2.  The weight of adult dogs in kilograms assuming a Uniform     distribution \n",
    "\n",
    "3.  The weight of adult elephants in kilograms assuming Normal     distribution \n",
    "\n",
    "4.  The weight of adult humans in pounds assuming skew Normal     distribution \n",
    "\n",
    "**1E6.** For each example in the previous exercise, use SciPy to specify the distribution in Python. Pick parameters that you believe are reasonable, take a random sample of size 1000, and plot the resulting distribution. Does this distribution look reasonable given your domain knowledge? If not adjust the parameters and repeat the process until they seem reasonable.\n",
    "\n",
    "**1E7.** Compare priors $\\text{Beta}(0.5, 0.5)$, $\\text{Beta}(1, 1)$, $\\text{Beta}(1, 4)$. How do the priors differ in terms of shape? \n",
    "\n",
    "**1E8**. Rerun Code Block [binomial_update](binomial_update) but using two Beta-priors of your choice. Hint: you may what to try priors with $\\alpha \\neq \\beta$ like $\\text{Beta}(2, 5)$.\n",
    "\n",
    "**1E9.** Try to come up with new constraints in order to obtain new Max-Ent distributions (Code Block [max_ent_priors](max_ent_priors)) \n",
    "\n",
    "**1E10.** In Code Block [metropolis_hastings](metropolis_hastings), change the value of `can_sd` and run the Metropolis-Hastings sampler. Try values like 0.001 and 1.\n",
    "\n",
    "1. Compute the mean, SD, and HDI and compare the values with those in     the book (computed using `can_sd=0.05`). How different are the     estimates? \n",
    "\n",
    "2.  Use the function `az.plot_posterior`.\n",
    "\n",
    "**1E11.** You need to estimate the weights of blue whales, humans, and mice. You assume they are normally distributed, and you set the same prior $\\mathcal{HN}(200\\text{kg})$ for the variance. What type of prior is this for adult blue whales? Strongly informative, weakly informative, or non-informative? What about for mice and for humans? How does informativeness of the prior correspond to our real world intuitions about these animals? \n",
    "\n",
    "**1E12.** Use the following function to explore different combinations of priors (change the parameters `a` and `b`) and data (change heads and trials). Summarize your observations.\n",
    "\n",
    "```python\n",
    "def posterior_grid(grid=10, a=1, b=1, heads=6, trials=9):\n",
    "    grid = np.linspace(0, 1, grid)\n",
    "    prior = stats.beta(a, b).pdf(grid)\n",
    "    likelihood = stats.binom.pmf(heads, trials, grid)\n",
    "    posterior = likelihood * prior\n",
    "    posterior /= posterior.sum()\n",
    "    _, ax = plt.subplots(1, 3, sharex=True, figsize=(16, 4))\n",
    "    ax[0].set_title(f\"heads = {heads}\\ntrials = {trials}\")\n",
    "    for i, (e, e_n) in enumerate(zip(\n",
    "            [prior, likelihood, posterior],\n",
    "            [\"prior\", \"likelihood\", \"posterior\"])):\n",
    "        ax[i].set_yticks([])\n",
    "        ax[i].plot(grid, e, \"o-\", label=e_n)\n",
    "        ax[i].legend(fontsize=14)\n",
    "\n",
    "\n",
    "interact(posterior_grid,\n",
    "    grid=ipyw.IntSlider(min=2, max=100, step=1, value=15),\n",
    "    a=ipyw.FloatSlider(min=1, max=7, step=1, value=1),\n",
    "    b=ipyw.FloatSlider(min=1, max=7, step=1, value=1),\n",
    "    heads=ipyw.IntSlider(min=0, max=20, step=1, value=6),\n",
    "    trials=ipyw.IntSlider(min=0, max=20, step=1, value=9))\n",
    "```\n",
    "\n",
    "**1E13.** Between the prior, prior predictive, posterior, and posterior predictive distributions which distribution would help answer each of these questions. Some items may have multiple answers.\n",
    "\n",
    "1. How do we think is the distribution of parameters values before     seeing any data? \n",
    "\n",
    "2.  What observed values do we think we could see before seeing any     data? \n",
    "\n",
    "3.  After estimating parameters using a model what do we predict we will     observe next? \n",
    "\n",
    "4.  What parameter values explain the observed data after conditioning     on that data? \n",
    "\n",
    "5.  Which can be used to calculate numerical summaries, such as the     mean, of the parameters? \n",
    "\n",
    "6.  Which can can be used to to visualize a Highest Density Interval? \n",
    "\n",
    "**1M14.** Equation {eq}`eq:posterior_dist` contains the marginal likelihood in the denominator, which is difficult to calculate.\n",
    "\n",
    "In Equation {eq}`eq:proportional_bayes` we show that knowing the posterior up to a proportional constant is sufficient for inference.\n",
    "\n",
    "Show why the marginal likelihood is not needed for the Metropolis-Hasting method to work. Hint: this is a pen and paper exercise, try by expanding Equation {eq}`acceptance_prob`.\n",
    "\n",
    "**1M15.** In the following definition of a probabilistic model, identify the prior, the likelihood, and the posterior: \n",
    "\n",
    "```{math} \n",
    "\\begin{split} \n",
    "Y \\sim \\mathcal{N}(\\mu, \\sigma)\\\\ \n",
    "\\mu \\sim \\mathcal{N}(0, 1)\\\\ \n",
    "\\sigma \\sim \\mathcal{HN}(1)\\\\ \n",
    "\\end{split}\n",
    "```\n",
    "\n",
    "**1M16.** In the previous model, how many parameters will the posterior have? Compare your answer with that from the model in the coin-flipping problem in Equation {eq}`eq:beta_binomial`.\n",
    "\n",
    "**1M17.** Suppose that we have two coins; when we toss the first coin, half of the time it lands tails and half of the time on heads. The other coin is a loaded coin that always lands on heads. If we choose one of the coins at random and observe a head, what is the probability that this coin is the loaded one? \n",
    "\n",
    "**1M18.** Modify Code Block [metropolis_hastings_sampler_rvs](metropolis_hastings_sampler_rvs) to generate random samples from a Poisson distribution with parameters of your choosing.\n",
    "\n",
    "Then modify Code Blocks [metropolis_hastings_sampler](metropolis_hastings_sampler) and [metropolis_hastings](metropolis_hastings) to generate MCMC samples estimating your chosen parameters. Test how the number of samples, MCMC iterations, and initial starting point affect convergence to your true chosen parameter.\n",
    "\n",
    "**1M19.** Assume we are building a model to estimate the mean and standard deviation of adult human heights in centimeters. Build a model that will make these estimation. Start with Code Block [beta_binom](beta_binom) and change the likelihood and priors as needed. After doing so then \n",
    "\n",
    "1.  Sample from the prior predictive. Generate a visualization and     numerical summary of the prior predictive distribution \n",
    "\n",
    "2.  Using the outputs from (a) to justify your choices of priors and     likelihoods \n",
    "\n",
    "**1M20.** From domain knowledge you have that a given parameter can not be negative, and has a mean that is roughly between 3 and 10 units, and a standard deviation of around 2. Determine two prior distribution that satisfy these constraints using Python. This may require trial and error by drawing samples and verifying these criteria have been met using both plots and numerical summaries.\n",
    "\n",
    "**1M21.** A store is visited by $n$ customers on a given day.\n",
    "\n",
    "The number of customers that make a purchase $Y$ is distributed as $\\text{Bin}(n, \\theta)$, where $\\theta$ is the probability that a customer makes a purchase. Assume we know $\\theta$ and the prior for $n$ is $\\text{Pois}(4.5)$.\n",
    "\n",
    "1. Use PyMC3 to compute the posterior distribution of $n$ for all     combinations of $Y \\in {0, 5, 10}$ and $\\theta \\in {0.2, 0.5}$. Use     `az.plot_posterior` to plot the results in a single plot.\n",
    "\n",
    "2. Summarize the effect of $Y$ and $\\theta$ on the posterior \n",
    "\n",
    "**1H22.** Modify Code Block [metropolis_hastings_sampler_rvs](metropolis_hastings_sampler_rvs) to generate samples from a Normal Distribution, noting your choice of parameters for the mean and standard deviation. Then modify Code Blocks [metropolis_hastings_sampler](metropolis_hastings_sampler) and [metropolis_hastings](metropolis_hastings) to sample from a Normal model and see if you can recover your chosen parameters.\n",
    "\n",
    " **1H23.** Make a model that estimates the proportion of the number of sunny versus cloudy days in your area. Use the past 5 days of data from your personal observations. Think through the data collection process. How hard is it to remember the past 5 days. What if needed the past 30 days of data? Past year? Justify your choice of priors. Obtain a posterior distribution that estimates the proportion of sunny versus cloudy days. Generate predictions for the next 10 days of weather.\n",
    "\n",
    "Communicate your answer using both numerical summaries and visualizations.\n",
    "\n",
    " **1H24.** You planted 12 seedlings and 3 germinate. Let us call $\\theta$ the probability that a seedling germinates. Assuming $\\text{Beta}(1, 1)$ prior distribution for $\\theta$.\n",
    "\n",
    "1. Use pen and paper to compute the posterior mean and standard     deviation. Verify your calculations using SciPy.\n",
    "\n",
    "2. Use SciPy to compute the equal-tailed and highest density $94\\%$     posterior intervals.\n",
    "\n",
    "3. Use SciPy to compute the posterior predictive probability that at     least one seedling will germinate if you plant another 12 seedlings.\n",
    "\n",
    " After obtaining your results with SciPy repeat this exercise using PyMC3 and ArviZ \n",
    "\n",
    "[^1]: If you want to be more general you can even say that everything is     a probability distribution as a quantity you assume to know with     arbitrary precision that can be described by a Dirac delta function.\n",
    "\n",
    "[^2]: Some authors call these quantities latent variables and reserve     the name parameter to identify fixed, but unknown, quantities.\n",
    "\n",
    "[^3]: Alternatively you can think of this in terms of certainty or     information, depending if you are a glass half empty or glass half     full person.\n",
    "\n",
    "[^4]: Sometimes the word *distribution* will be implicit, this commonly occurs when discussing these topics.\n",
    "\n",
    "[^5]: Here we are using experiment in the broad sense of any procedure     to collect or generate data.\n",
    "\n",
    "[^6]: <https://xkcd.com/2117/> \n",
    "\n",
    "[^7]: Technically we should talk about the expectation of a random     variable. See Section {ref}`expectations` for details.\n",
    "\n",
    "[^8]: See detailed balance at Sections {ref}`markov_chains` and {ref}`sec_metropolis_hastings`.\n",
    "\n",
    "[^9]: For a more extensive discussion about inference methods you should     read Section [{ref}`inference_methods` and references     therein.\n",
    "\n",
    "[^10]: This is sometimes referred to as a kernel in other Universal     Inference Engines.\n",
    "\n",
    "[^11]: You can use ArviZ `plot_trace` function to get a similar plot.  This is how we will do in the rest of the book.\n",
    "\n",
    "[^12]: Notice that in principle the number of possible intervals     containing a given proportion of the total density is infinite.\n",
    "\n",
    "[^13]: For more examples check     <https://en.wikipedia.org/wiki/Conjugate_prior#Table_of_conjugate_distributions> \n",
    "\n",
    "[^14]: Except, the ones happening in your brain.\n",
    "\n",
    "[^15]: For example, a regularized linear regression with a L2     regularization is the same as using a Gaussian prior on the     coefficient.\n",
    "\n",
    "[^16]: For example, if we have samples from the posterior, then we can     plug those samples of $\\theta$ into     $\\kappa = \\frac{\\theta}{1-\\theta}$.\n",
    "\n",
    "[^17]: <https://en.wikipedia.org/wiki/Likelihood_principle> \n",
    "\n",
    "[^18]: See Section {ref}`entropy` for more details.\n",
    "\n",
    "[^19]: Wikipedia has a longer list at     <https://en.wikipedia.org/wiki/Maximum_entropy_probability_distribution#Other_examples> \n",
    "\n",
    "[^20]: Even when the definition of such priors will require more context     than the one provided, we still think the example conveys a useful     intuition, that will be refined as we progress through this book."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md:myst"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
