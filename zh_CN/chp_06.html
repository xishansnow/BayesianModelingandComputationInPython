
<!DOCTYPE html>

<html>
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>第六章: 时间序列 — Bayesian Modeling and Computation in Python</title>
<link href="../_static/css/theme.css" rel="stylesheet"/>
<link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet"/>
<link href="../_static/vendor/fontawesome/5.13.0/css/all.min.css" rel="stylesheet"/>
<link as="font" crossorigin="" href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2" rel="preload" type="font/woff2"/>
<link href="../_static/pygments.css" rel="stylesheet" type="text/css">
<link href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" rel="stylesheet" type="text/css">
<link href="../_static/togglebutton.css" rel="stylesheet" type="text/css">
<link href="../_static/copybutton.css" rel="stylesheet" type="text/css">
<link href="../_static/mystnb.css" rel="stylesheet" type="text/css">
<link href="../_static/sphinx-thebe.css" rel="stylesheet" type="text/css"/>
<link href="../_static/sphinx-codeautolink.css" rel="stylesheet" type="text/css"/>
<link href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" rel="stylesheet" type="text/css"/>
<link href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" rel="stylesheet" type="text/css"/>
<link as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js" rel="preload"/>
<script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
<script src="../_static/jquery.js"></script>
<script src="../_static/underscore.js"></script>
<script src="../_static/doctools.js"></script>
<script src="../_static/togglebutton.js"></script>
<script src="../_static/clipboard.min.js"></script>
<script src="../_static/copybutton.js"></script>
<script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
<script src="../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
<script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
<script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
<script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
<script async="async" src="../_static/sphinx-thebe.js"></script>
<link href="../_static/favicon.ico" rel="shortcut icon">
<link href="../genindex.html" rel="index" title="Index"/>
<link href="../search.html" rel="search" title="Search"/>
<link href="chp_07.html" rel="next" title="第七章：贝叶斯加性回归树"/>
<link href="chp_05.html" rel="prev" title="第五章: 样条"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="None" name="docsearch:language"/>
<!-- Google Analytics -->
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-702QMHG8ST"></script>
<script>
                    window.dataLayer = window.dataLayer || [];
                    function gtag(){ dataLayer.push(arguments); }
                    gtag('js', new Date());
                    gtag('config', 'G-702QMHG8ST');
                </script>
</link></link></link></link></link></link></head>
<body data-offset="80" data-spy="scroll" data-target="#bd-toc-nav">
<div class="container-fluid" id="banner"></div>
<div class="container-xl">
<div class="row">
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
<div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
<h1 class="site-logo" id="site-title">Bayesian Modeling and Computation in Python</h1>
</a>
</div><form action="../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="icon fas fa-search"></i>
<input aria-label="Search this book..." autocomplete="off" class="form-control" id="search-input" name="q" placeholder="Search this book..." type="search"/>
</form><nav aria-label="Main" class="bd-links" id="bd-docs-nav">
<div class="bd-toc-item active">
<ul class="current nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="dedication.html">
   贡献
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="foreword.html">
   序言
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="preface.html">
   前言
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="symbollist.html">
   符号表
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chp_01.html">
   第一章: 贝叶斯推断
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chp_02.html">
   第二章: 贝叶斯模型的探索性分析
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chp_03.html">
   第三章：线性模型与概率编程语言
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chp_04.html">
   第四章：扩展线性模型
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chp_05.html">
   第五章: 样条
  </a>
</li>
<li class="toctree-l1 current active">
<a class="current reference internal" href="#">
   第六章: 时间序列
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chp_07.html">
   第七章：贝叶斯加性回归树
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chp_08.html">
   第八章：近似贝叶斯计算
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chp_09.html">
   第九章: 端到端的贝叶斯工作流
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chp_10.html">
   第十章: 概率编程语言
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chp_11.html">
   第十一章: 附加主题
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="glossary.html">
   词汇表
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="references.html">
   References
  </a>
</li>
</ul>
</div>
</nav> <!-- To handle the deprecated key -->
<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>
</div>
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
<div class="topbar container-xl fixed-top">
<div class="topbar-contents row">
<div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
<div class="col pl-md-4 topbar-main">
<button aria-controls="site-navigation" aria-expanded="true" aria-label="Toggle navigation" class="navbar-toggler ml-0" data-placement="left" data-target=".site-navigation" data-toggle="tooltip" id="navbar-toggler" title="Toggle navigation" type="button">
<i class="fas fa-bars"></i>
<i class="fas fa-arrow-left"></i>
<i class="fas fa-arrow-up"></i>
</button>
<!-- Source interaction buttons -->
<div class="dropdown-buttons-trigger">
<button aria-label="Connect with source repository" class="btn btn-secondary topbarbtn" id="dropdown-buttons-trigger"><i class="fab fa-github"></i></button>
<div class="dropdown-buttons sourcebuttons">
<a class="repository-button" href="https://github.com/BayesianModelingandComputationInPython/BookCode_Edition1"><button class="btn btn-secondary topbarbtn" data-placement="left" data-toggle="tooltip" title="Source repository" type="button"><i class="fab fa-github"></i>repository</button></a>
<a class="issues-button" href="https://github.com/BayesianModelingandComputationInPython/BookCode_Edition1/issues/new?title=Issue%20on%20page%20%2Fzh_CN/chp_06.html&amp;body=Your%20issue%20content%20here."><button class="btn btn-secondary topbarbtn" data-placement="left" data-toggle="tooltip" title="Open an issue" type="button"><i class="fas fa-lightbulb"></i>open issue</button></a>
</div>
</div>
<!-- Full screen (wrap in <a> to have style consistency -->
<a class="full-screen-button"><button aria-label="Fullscreen mode" class="btn btn-secondary topbarbtn" data-placement="bottom" data-toggle="tooltip" onclick="toggleFullScreen()" title="Fullscreen mode" type="button"><i class="fas fa-expand"></i></button></a>
<!-- Launch buttons -->
</div>
<!-- Table of contents -->
<div class="d-none d-md-block col-md-2 bd-toc show noprint">
<div class="tocsection onthispage pt-5 pb-3">
<i class="fas fa-list"></i> Contents
            </div>
<nav aria-label="Page" id="bd-toc-nav">
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#an-overview-of-time-series-problems">
   6.1 时间序列问题概览
  </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#time-series-analysis-as-a-regression-problem">
   6.2 将时间序列视为回归问题
  </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#design-matrices-for-time-series">
     6.2.1 时间序列的设计矩阵
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#chp4-gam">
     6.2.2 基函数和广义可加模型
    </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#chap4-ar">
   6.3 自回归模型
  </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id20">
     6.3.1 基础的自回归模型
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#latent-ar-process-and-smoothing">
     6.3.2 隐自回归过程和平滑
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#s-ar-i-ma-x">
     6.3.3 自回归移动平均 (S)AR(I)MA(X)
    </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#state-space-models">
   6.4 状态空间模型
  </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#lgssm-time-series">
     6.4.1 线性高斯状态空间模型与卡尔曼滤波
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#arim">
     6.4.2 表示为状态空间模型的 ARIM
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#bayesian-structural-time-series">
     6.4.3 贝叶斯结构时间序列
    </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#other-time-series-models">
   6.5 其他时间序列模型
  </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#model-criticism-and-choosing-priors">
   6.6 模型评判和先验选择
  </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#priors-for-time-series-models">
     6.6.1 时间序列模型的先验
    </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#exercises6">
   6.7 练习
  </a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="row" id="main-content">
<div class="col-12 col-md-9 pl-md-3 pr-md-0">
<!-- Table of contents that is only displayed when printing the page -->
<div class="onlyprint" id="jb-print-docs-body">
<h1>第六章: 时间序列</h1>
<!-- Table of contents -->
<div id="print-main-content">
<div id="jb-print-toc">
<div>
<h2> Contents </h2>
</div>
<nav aria-label="Page">
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#an-overview-of-time-series-problems">
   6.1 时间序列问题概览
  </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#time-series-analysis-as-a-regression-problem">
   6.2 将时间序列视为回归问题
  </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#design-matrices-for-time-series">
     6.2.1 时间序列的设计矩阵
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#chp4-gam">
     6.2.2 基函数和广义可加模型
    </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#chap4-ar">
   6.3 自回归模型
  </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id20">
     6.3.1 基础的自回归模型
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#latent-ar-process-and-smoothing">
     6.3.2 隐自回归过程和平滑
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#s-ar-i-ma-x">
     6.3.3 自回归移动平均 (S)AR(I)MA(X)
    </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#state-space-models">
   6.4 状态空间模型
  </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#lgssm-time-series">
     6.4.1 线性高斯状态空间模型与卡尔曼滤波
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#arim">
     6.4.2 表示为状态空间模型的 ARIM
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#bayesian-structural-time-series">
     6.4.3 贝叶斯结构时间序列
    </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#other-time-series-models">
   6.5 其他时间序列模型
  </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#model-criticism-and-choosing-priors">
   6.6 模型评判和先验选择
  </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#priors-for-time-series-models">
     6.6.1 时间序列模型的先验
    </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#exercises6">
   6.7 练习
  </a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div>
<div class="tex2jax_ignore mathjax_ignore section" id="chap4">
<span id="id1"></span><h1>第六章: 时间序列<a class="headerlink" href="#chap4" title="Permalink to this headline">¶</a></h1>
<style>p{text-indent:2em;2}</style>
<p>“很难做出预测，尤其是关于未来的预测”。</p>
<p>据称，荷兰政治家 <code class="docutils literal notranslate"><span class="pre">Karl</span> <span class="pre">Kristian</span> <span class="pre">Steincke</span></code> 在 <span class="math notranslate nohighlight">\(1940\)</span> 年代 <a class="footnote-reference brackets" href="#id56" id="id2">1</a> 的某个时候说过的这句话确实如此，即便今天仍然如此，特别是你在研究时间序列问题和预报问题的时候。</p>
<p>时间序列分析有很多应用，从面向未来的预报、到了解历史趋势中的潜在因素等。在本章中，我们将讨论涉及此问题域的一些贝叶斯方法。</p>
<ul class="simple">
<li><p>首先，将时间序列建模视为一个回归问题，并且从时间戳中解析设计矩阵。</p></li>
<li><p>然后，我们将探索使用自回归方法对时间相关性进行建模。</p></li>
<li><p>将上述模型进一步扩展到更一般性的状态空间模型和贝叶斯结构的时间序列模型，并在线性高斯情况下引入一种专门的推断方法：卡尔曼滤波器。</p></li>
<li><p>本章其余部分简要总结了模型比较问题，以及在为时间序列模型选择先验时需要考虑的因素。</p></li>
</ul>
<div class="section" id="an-overview-of-time-series-problems">
<span id="id3"></span><h2>6.1 时间序列问题概览<a class="headerlink" href="#an-overview-of-time-series-problems" title="Permalink to this headline">¶</a></h2>
<p>在许多现实生活的应用中，我们按时间顺序观测数据，每次观测时都会生成时间戳。除了观测本身之外，时间戳信息在以下情况中可以提供相当丰富的信息：</p>
<ul class="simple">
<li><p>存在一个<strong>时间趋势</strong>，例如，地区人口、全球 GDP 、美国的年二氧化碳排放量等。通常这是一种整体模式，可以直观地将其标记为“增长”或“下降”。</p></li>
<li><p>有一些与时间相关的循环模式，称为<strong>季节性（ seasonality ）</strong> <a class="footnote-reference brackets" href="#id57" id="id4">2</a>。例如，</p>
<ul>
<li><p>每月温度的变化（夏季较高，冬季较低）；</p></li>
<li><p>每月降雨量（在世界许多地区，冬季较低，夏季较高）；</p></li>
<li><p>给定办公楼的每日咖啡消耗量（较高平日，周末减少）；</p></li>
<li><p>每小时的自行车租赁数量（白天比晚上多）。</p></li>
</ul>
</li>
<li><p>当前数据点以某种方式提供了有关下一个数据点的信息。换句话说，**噪声( Noise )<strong>或</strong>残差( Residuals )**是相关的 <a class="footnote-reference brackets" href="#id58" id="id5">3</a>。例如，</p>
<ul>
<li><p>帮助台每天解决的案例数量；</p></li>
<li><p>股票的价格；</p></li>
<li><p>每小时的温度；</p></li>
<li><p>每小时的降雨量。</p></li>
</ul>
</li>
</ul>
<p>因此，可以考虑将时间序列分解为：</p>
<div class="math notranslate nohighlight" id="equation-eq-generic-time-series">
<span class="eqno">(46)<a class="headerlink" href="#equation-eq-generic-time-series" title="Permalink to this equation">¶</a></span>\[ y_t = \text{Trend}_t + \text{Seasonality}_t + \text{Residuals}_t\]</div>
<p>大多数经典的时间序列模型都是基于此分解。在本章中，我们将讨论呈现出某种程度<code class="docutils literal notranslate"><span class="pre">时间趋势</span></code>和<code class="docutils literal notranslate"><span class="pre">季节性</span></code>的时间序列建模方法，并探索捕获其中<code class="docutils literal notranslate"><span class="pre">有规则</span></code>和<code class="docutils literal notranslate"><span class="pre">无规则</span></code>模式的方法。</p>
</div>
<div class="section" id="time-series-analysis-as-a-regression-problem">
<span id="id6"></span><h2>6.2 将时间序列视为回归问题<a class="headerlink" href="#time-series-analysis-as-a-regression-problem" title="Permalink to this headline">¶</a></h2>
<p>我们将首先在一些教程中频繁出现和使用的演示数据集上，使用线性回归模型对时间序列建模。它在《机器学习中的高斯过程》一书中被用作示例<span id="id7">Rasmussen and Williams [<a class="reference internal" href="references.html#id91">52</a>]</span>。自 <span class="math notranslate nohighlight">\(1950\)</span> 年代后期以来，夏威夷的莫纳罗亚天文台每隔一小时就测定一次大气二氧化碳浓度。在许多示例中，该观测结果被汇总为月均值，如 <a class="reference internal" href="#fig-fig1-co2-by-month"><span class="std std-numref">Fig. 102</span></a> 所示。我们使用代码 <a class="reference internal" href="#load-co2-data"><span class="std std-ref">load_co2_data</span></a> 将数据加载到 Python 中，并将数据集拆分为训练集和测试集。仅使用训练集拟合模型，并根据测试集来评估预测结果。</p>
<div class="figure align-default" id="fig-fig1-co2-by-month">
<a class="reference internal image-reference" href="../_images/fig1_co2_by_month.png"><img alt="../_images/fig1_co2_by_month.png" src="../_images/fig1_co2_by_month.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 102 </span><span class="caption-text">从 <span class="math notranslate nohighlight">\(1966\)</span> 年 <span class="math notranslate nohighlight">\(1\)</span> 月到 <span class="math notranslate nohighlight">\(2019\)</span> 年 <span class="math notranslate nohighlight">\(2\)</span> 月，莫纳罗亚的月度 <span class="math notranslate nohighlight">\(\text{CO}_2\)</span> 测量值，分为训练集（黑色显示）和测试集（蓝色显示）。我们可以在数据中看到强劲的上升趋势和季节性模式。</span><a class="headerlink" href="#fig-fig1-co2-by-month" title="Permalink to this image">¶</a></p>
</div>
<div class="literal-block-wrapper docutils container" id="load-co2-data">
<div class="code-block-caption"><span class="caption-number">Listing 73 </span><span class="caption-text">load_co2_data</span><a class="headerlink" href="#load-co2-data" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">co2_by_month</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">"../data/monthly_mauna_loa_co2.csv"</span><span class="p">)</span>
<span class="n">co2_by_month</span><span class="p">[</span><span class="s2">"date_month"</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">co2_by_month</span><span class="p">[</span><span class="s2">"date_month"</span><span class="p">])</span>
<span class="n">co2_by_month</span><span class="p">[</span><span class="s2">"CO2"</span><span class="p">]</span> <span class="o">=</span> <span class="n">co2_by_month</span><span class="p">[</span><span class="s2">"CO2"</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.float32" title="numpy.float32"><span class="n">np</span><span class="o">.</span><span class="n">float32</span></a><span class="p">)</span>
<span class="n">co2_by_month</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s2">"date_month"</span><span class="p">,</span> <span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">num_forecast_steps</span> <span class="o">=</span> <span class="mi">12</span> <span class="o">*</span> <span class="mi">10</span>  <span class="c1"># Forecast the final ten years, given previous data</span>
<span class="n">co2_by_month_training_data</span> <span class="o">=</span> <span class="n">co2_by_month</span><span class="p">[:</span><span class="o">-</span><span class="n">num_forecast_steps</span><span class="p">]</span>
<span class="n">co2_by_month_testing_data</span> <span class="o">=</span> <span class="n">co2_by_month</span><span class="p">[</span><span class="o">-</span><span class="n">num_forecast_steps</span><span class="p">:]</span>
</pre></div>
</div>
</div>
<p>在这里，我们有一个每月大气 <span class="math notranslate nohighlight">\(\text{CO}_2\)</span> 浓度 <span class="math notranslate nohighlight">\(y_t\)</span> 的观测向量，其中 <span class="math notranslate nohighlight">\(t = [0, \dots, 636]\)</span> ；其中每个元素都与时间戳相关联。一年中的月份可以解析为 <span class="math notranslate nohighlight">\([1, 2, 3,\dots, 12, 1, 2,\dots]\)</span> 的向量。对于线性回归，我们可以将似然函数陈述如下：</p>
<div class="math notranslate nohighlight" id="equation-eq-regression-model">
<span class="eqno">(47)<a class="headerlink" href="#equation-eq-regression-model" title="Permalink to this equation">¶</a></span>\[Y \sim \mathcal{N}(\mathbf{X} \beta, \sigma)\]</div>
<p>考虑到季节性的影响，我们使用年预测变量的月份来索引回归系数的向量。这里使用代码 <a class="reference internal" href="#generate-design-matrix"><span class="std std-ref">generate_design_matrix</span></a>，将预测变量独热编码为具有 <code class="docutils literal notranslate"><span class="pre">shape</span> <span class="pre">=</span> <span class="pre">(637,</span> <span class="pre">12)</span></code> 的设计矩阵。在设计矩阵中，添加一个线性预测变量以捕获数据中的上升趋势，进而得到时间序列的设计矩阵。</p>
<p>你可以在 <a class="reference internal" href="#fig-fig2-sparse-design-matrix"><span class="std std-numref">Fig. 103</span></a> 中看到设计矩阵的子集。</p>
<div class="figure align-default" id="fig-fig2-sparse-design-matrix">
<a class="reference internal image-reference" href="../_images/fig2_sparse_design_matrix.png"><img alt="../_images/fig2_sparse_design_matrix.png" src="../_images/fig2_sparse_design_matrix.png" style="width: 5.2in;"/></a>
<p class="caption"><span class="caption-number">Fig. 103 </span><span class="caption-text">为时间序列的简单回归模型设计具有年度线性分量和月份分量的矩阵。设计矩阵转置为 <span class="math notranslate nohighlight">\(feature * timestamps\)</span> ，以便更易于可视化。在图中，第一行（索引 <span class="math notranslate nohighlight">\(0\)</span>）包含 <span class="math notranslate nohighlight">\(0\)</span> 到 <span class="math notranslate nohighlight">\(1\)</span> 之间的连续值，表示时间和线性增长。其余行（索引 <span class="math notranslate nohighlight">\(1 - 12\)</span> ）是月份信息的独热编码。颜色编码从代表黑色的 <span class="math notranslate nohighlight">\(1\)</span> 到 代表浅灰色的 <span class="math notranslate nohighlight">\(0\)</span> 。</span><a class="headerlink" href="#fig-fig2-sparse-design-matrix" title="Permalink to this image">¶</a></p>
</div>
<div class="literal-block-wrapper docutils container" id="generate-design-matrix">
<div class="code-block-caption"><span class="caption-number">Listing 74 </span><span class="caption-text">generate_design_matrix</span><a class="headerlink" href="#generate-design-matrix" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">trend_all</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.linspace.html#numpy.linspace" title="numpy.linspace"><span class="n">np</span><span class="o">.</span><span class="n">linspace</span></a><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">co2_by_month</span><span class="p">))[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span>
<span class="n">trend_all</span> <span class="o">=</span> <span class="n">trend_all</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.float32" title="numpy.float32"><span class="n">np</span><span class="o">.</span><span class="n">float32</span></a><span class="p">)</span>
<span class="n">trend</span> <span class="o">=</span> <span class="n">trend_all</span><span class="p">[:</span><span class="o">-</span><span class="n">num_forecast_steps</span><span class="p">,</span> <span class="p">:]</span>

<span class="n">seasonality_all</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span>
   <span class="n">co2_by_month</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">month</span><span class="p">)</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.float32" title="numpy.float32"><span class="n">np</span><span class="o">.</span><span class="n">float32</span></a><span class="p">)</span>
<span class="n">seasonality</span> <span class="o">=</span> <span class="n">seasonality_all</span><span class="p">[:</span><span class="o">-</span><span class="n">num_forecast_steps</span><span class="p">,</span> <span class="p">:]</span>

<span class="n">_</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.subplots.html#matplotlib.pyplot.subplots" title="matplotlib.pyplot.subplots"><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span></a><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">X_subset</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.concatenate.html#numpy.concatenate" title="numpy.concatenate"><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span></a><span class="p">([</span><span class="n">trend</span><span class="p">,</span> <span class="n">seasonality</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)[</span><span class="o">-</span><span class="mi">50</span><span class="p">:]</span>
<span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">X_subset</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="admonition- admonition">
<p class="admonition-title">解析到设计矩阵的时间戳</p>
<p>时间戳的处理可能很乏味，并且容易出错，尤其是在涉及不同时区的时候。我们可以从时间戳中解析出的典型周期性信息包括（按解析顺序排列）：</p>
<ul class="simple">
<li><p>小时的秒数 (1, 2, …, 60)</p></li>
<li><p>一天中的小时（1、2、…、24）</p></li>
<li><p>星期几（周一、周二、…、周日）</p></li>
<li><p>一个月中的某天（1、2、…、31）</p></li>
<li><p>一年中的月份（1、2、…、12）</p></li>
<li><p>节日效应（元旦、复活节、国际劳动节、圣诞节等）</p></li>
</ul>
<p>所有上述信息都可以用独热编码解析为一个设计矩阵。</p>
<p>类似于 “一周中的某天” 和 “一个月中的某天” 等时间戳的效应通常与人类活动密切相关。例如，</p>
<ul class="simple">
<li><p>公共交通乘客的数量通常表现出强烈的工作日效应；</p></li>
<li><p>发薪日之后，消费者支出可能会更高，这通常是在月底左右。</p></li>
</ul>
<p>在本章中，<strong>我们主要考虑定期记录的时间戳</strong>。</p>
</div>
<p>我们现在可以使用 <code class="docutils literal notranslate"><span class="pre">tfd.JointDistributionCoroutine</span></code> 建立第一个面向回归问题的时间序列模型，其作法和第 <a class="reference internal" href="chp_03.html#chap2"><span class="std std-ref">3</span></a> 章中介绍的 <code class="docutils literal notranslate"><span class="pre">tfd.JointDistributionCoroutine</span></code> API 和 TFP 贝叶斯建模方法相同。</p>
<div class="literal-block-wrapper docutils container" id="regression-model-for-timeseries">
<div class="code-block-caption"><span class="caption-number">Listing 75 </span><span class="caption-text">regression_model_for_timeseries</span><a class="headerlink" href="#regression-model-for-timeseries" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tfd</span> <span class="o">=</span> <span class="n">tfp</span><span class="o">.</span><span class="n">distributions</span>
<span class="n">root</span> <span class="o">=</span> <span class="n">tfd</span><span class="o">.</span><span class="n">JointDistributionCoroutine</span><span class="o">.</span><span class="n">Root</span>

<span class="nd">@tfd</span><span class="o">.</span><span class="n">JointDistributionCoroutine</span>
<span class="k">def</span> <span class="nf">ts_regression_model</span><span class="p">():</span>
    <span class="n">intercept</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">root</span><span class="p">(</span><span class="n">tfd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">100.</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">"intercept"</span><span class="p">))</span>
    <span class="n">trend_coeff</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">root</span><span class="p">(</span><span class="n">tfd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">10.</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">"trend_coeff"</span><span class="p">))</span>
    <span class="n">seasonality_coeff</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">root</span><span class="p">(</span>
        <span class="n">tfd</span><span class="o">.</span><span class="n">Sample</span><span class="p">(</span><span class="n">tfd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">),</span>
                   <span class="n">sample_shape</span><span class="o">=</span><span class="n">seasonality</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                   <span class="n">name</span><span class="o">=</span><span class="s2">"seasonality_coeff"</span><span class="p">))</span>
    <span class="n">noise</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">root</span><span class="p">(</span><span class="n">tfd</span><span class="o">.</span><span class="n">HalfCauchy</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">5.</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">"noise_sigma"</span><span class="p">))</span>
    <span class="n">y_hat</span> <span class="o">=</span> <span class="p">(</span><span class="n">intercept</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">+</span>
             <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">"ij,...-&gt;...i"</span><span class="p">,</span> <span class="n">trend</span><span class="p">,</span> <span class="n">trend_coeff</span><span class="p">)</span> <span class="o">+</span>
             <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">"ij,...j-&gt;...i"</span><span class="p">,</span> <span class="n">seasonality</span><span class="p">,</span> <span class="n">seasonality_coeff</span><span class="p">))</span>
    <span class="n">observed</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Independent</span><span class="p">(</span>
        <span class="n">tfd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">noise</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">]),</span>
        <span class="n">reinterpreted_batch_ndims</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">"observed"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>正如在前面章节中提到的，与 PyMC3 相比，TFP 提供了较低级别的 API 。虽然与低级模块和分量交互更灵活，但与其他概率编程语言相比，通常需要更多代码，并且需要在模型中使用 <code class="docutils literal notranslate"><span class="pre">tfp</span></code> 进行额外的 <code class="docutils literal notranslate"><span class="pre">shape</span></code> 形状处理。例如，在代码 <a class="reference internal" href="#regression-model-for-timeseries"><span class="std std-ref">regression_model_for_timeseries</span></a> 中，我们使用 <code class="docutils literal notranslate"><span class="pre">einsum</span></code> 而不是 <code class="docutils literal notranslate"><span class="pre">matmul</span></code> 以便代码能够处理任意的 <em>批形状</em>（详情参阅第 <a class="reference internal" href="chp_10.html#shape-ppl"><span class="std std-ref">10.8.1 PPL 中的形状处理</span></a> 节）。</p>
<p>代码 <a class="reference internal" href="#regression-model-for-timeseries"><span class="std std-ref">regression_model_for_timeseries</span></a> 提供了一个回归模型 <code class="docutils literal notranslate"><span class="pre">ts_regression_model</span></code>。它具有和 <code class="docutils literal notranslate"><span class="pre">tfd.Distribution</span></code> 类似的功能，要抽取先验和先验预测样本，我们可以调用 <code class="docutils literal notranslate"><span class="pre">.sample(.)</span></code> 方法（参见代码 <a class="reference internal" href="#prior-predictive"><span class="std std-ref">prior_predictive</span></a>，结果显示在 <a class="reference internal" href="#fig-fig3-prior-predictive1"><span class="std std-numref">Fig. 104</span></a> 中）。</p>
<div class="literal-block-wrapper docutils container" id="prior-predictive">
<div class="code-block-caption"><span class="caption-number">Listing 76 </span><span class="caption-text">prior_predictive</span><a class="headerlink" href="#prior-predictive" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Draw 100 prior and prior predictive samples</span>
<span class="n">prior_samples</span> <span class="o">=</span> <span class="n">ts_regression_model</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>  
<span class="n">prior_predictive_timeseries</span> <span class="o">=</span> <span class="n">prior_samples</span><span class="o">.</span><span class="n">observed</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.subplots.html#matplotlib.pyplot.subplots" title="matplotlib.pyplot.subplots"><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span></a><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">co2_by_month</span><span class="o">.</span><span class="n">index</span><span class="p">[:</span><span class="o">-</span><span class="n">num_forecast_steps</span><span class="p">],</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">prior_predictive_timeseries</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.5</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">"Year"</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">autofmt_xdate</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="figure align-default" id="fig-fig3-prior-predictive1">
<a class="reference internal image-reference" href="../_images/fig3_prior_predictive1.png"><img alt="../_images/fig3_prior_predictive1.png" src="../_images/fig3_prior_predictive1.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 104 </span><span class="caption-text">来自简单回归模型的先验预测样本，用于模拟 Mauna Loa 时间序列中的月 <span class="math notranslate nohighlight">\(\text{CO}_2\)</span> 测量值。每条线是一个模拟的时间序列。由于使用了无信息先验，造成先验预测结果的分布范围很广。</span><a class="headerlink" href="#fig-fig3-prior-predictive1" title="Permalink to this image">¶</a></p>
</div>
<p>在代码 <a class="reference internal" href="#inference-of-regression-model"><span class="std std-ref">inference_of_regression_model</span></a> 中，我们运行回归模型的推断，并将结果格式化为 <code class="docutils literal notranslate"><span class="pre">az.InferenceData</span></code> 对象。</p>
<div class="literal-block-wrapper docutils container" id="inference-of-regression-model">
<div class="code-block-caption"><span class="caption-number">Listing 77 </span><span class="caption-text">inference_of_regression_model</span><a class="headerlink" href="#inference-of-regression-model" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">run_mcmc</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">function</span><span class="p">(</span>
    <span class="n">tfp</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">mcmc</span><span class="o">.</span><span class="n">windowed_adaptive_nuts</span><span class="p">,</span>
    <span class="n">autograph</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">jit_compile</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">mcmc_samples</span><span class="p">,</span> <span class="n">sampler_stats</span> <span class="o">=</span> <span class="n">run_mcmc</span><span class="p">(</span>
    <span class="mi">1000</span><span class="p">,</span> <span class="n">ts_regression_model</span><span class="p">,</span> <span class="n">n_chains</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">num_adaptation_steps</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
    <span class="n">observed</span><span class="o">=</span><span class="n">co2_by_month_training_data</span><span class="p">[</span><span class="s2">"CO2"</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="o">...</span><span class="p">])</span>

<span class="n">regression_idata</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="https://arviz-devs.github.io/arviz/api/generated/arviz.from_dict.html#arviz.from_dict" title="arviz.from_dict"><span class="n">az</span><span class="o">.</span><span class="n">from_dict</span></a><span class="p">(</span>
    <span class="n">posterior</span><span class="o">=</span><span class="p">{</span>
        <span class="c1"># TFP mcmc returns (num_samples, num_chains, ...), we swap</span>
        <span class="c1"># the first and second axis below for each RV so the shape</span>
        <span class="c1"># is what ArviZ expects.</span>
        <span class="n">k</span><span class="p">:</span><a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.swapaxes.html#numpy.swapaxes" title="numpy.swapaxes"><span class="n">np</span><span class="o">.</span><span class="n">swapaxes</span></a><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">mcmc_samples</span><span class="o">.</span><span class="n">_asdict</span><span class="p">()</span><span class="o">.</span><span class="n">items</span><span class="p">()},</span>
    <span class="n">sample_stats</span><span class="o">=</span><span class="p">{</span>
        <span class="n">k</span><span class="p">:</span><a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.swapaxes.html#numpy.swapaxes" title="numpy.swapaxes"><span class="n">np</span><span class="o">.</span><span class="n">swapaxes</span></a><span class="p">(</span><span class="n">sampler_stats</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">"target_log_prob"</span><span class="p">,</span> <span class="s2">"diverging"</span><span class="p">,</span> <span class="s2">"accept_ratio"</span><span class="p">,</span> <span class="s2">"n_steps"</span><span class="p">]})</span>
</pre></div>
</div>
</div>
<p>如果要依据推断结果来抽取后验预测样本，我们可以使用 <code class="docutils literal notranslate"><span class="pre">.sample_distributions</span></code> 方法先抽取后验样本，并基于后验样本的条件化生成后验预测样本。本例中，我们还希望能够为时间序列中的<code class="docutils literal notranslate"><span class="pre">趋势性</span></code>和<code class="docutils literal notranslate"><span class="pre">季节性</span></code>分量绘制后验预测样本。为了可视化模型的预测能力，我们在代码 <a class="reference internal" href="#posterior-predictive-with-component"><span class="std std-ref">posterior_predictive_with_component</span></a> 中构建了后验预测分布，结果显示在趋势性和季节性分量的 <a class="reference internal" href="#fig-fig4-posterior-predictive-components1"><span class="std std-numref">Fig. 105</span></a> 中，以及整体模型拟合和预测的 <a class="reference internal" href="#fig-fig5-posterior-predictive1"><span class="std std-numref">Fig. 106</span></a> 。</p>
<div class="literal-block-wrapper docutils container" id="posterior-predictive-with-component">
<div class="code-block-caption"><span class="caption-number">Listing 78 </span><span class="caption-text">posterior_predictive_with_component</span><a class="headerlink" href="#posterior-predictive-with-component" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># We can draw posterior predictive sample with jd.sample_distributions()</span>
<span class="c1"># But since we want to also plot the posterior predictive distribution for </span>
<span class="c1"># each components, conditioned on both training and testing data, we</span>
<span class="c1"># construct the posterior predictive distribution as below:</span>
<span class="n">nchains</span> <span class="o">=</span> <span class="n">regression_idata</span><span class="o">.</span><span class="n">posterior</span><span class="o">.</span><span class="n">dims</span><span class="p">[</span><span class="s2">"chain"</span><span class="p">]</span>

<span class="n">trend_posterior</span> <span class="o">=</span> <span class="n">mcmc_samples</span><span class="o">.</span><span class="n">intercept</span> <span class="o">+</span> \
    <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">"ij,...-&gt;i..."</span><span class="p">,</span> <span class="n">trend_all</span><span class="p">,</span> <span class="n">mcmc_samples</span><span class="o">.</span><span class="n">trend_coeff</span><span class="p">)</span>
<span class="n">seasonality_posterior</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span>
    <span class="s2">"ij,...j-&gt;i..."</span><span class="p">,</span> <span class="n">seasonality_all</span><span class="p">,</span> <span class="n">mcmc_samples</span><span class="o">.</span><span class="n">seasonality_coeff</span><span class="p">)</span>

<span class="n">y_hat</span> <span class="o">=</span> <span class="n">trend_posterior</span> <span class="o">+</span> <span class="n">seasonality_posterior</span>
<span class="n">posterior_predictive_dist</span> <span class="o">=</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">mcmc_samples</span><span class="o">.</span><span class="n">noise_sigma</span><span class="p">)</span>
<span class="n">posterior_predictive_samples</span> <span class="o">=</span> <span class="n">posterior_predictive_dist</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="figure align-default" id="fig-fig4-posterior-predictive-components1">
<a class="reference internal image-reference" href="../_images/fig4_posterior_predictive_components1.png"><img alt="../_images/fig4_posterior_predictive_components1.png" src="../_images/fig4_posterior_predictive_components1.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 105 </span><span class="caption-text">时间序列回归模型的趋势分量和季节性分量的后验预测样本。</span><a class="headerlink" href="#fig-fig4-posterior-predictive-components1" title="Permalink to this image">¶</a></p>
</div>
<div class="figure align-default" id="fig-fig5-posterior-predictive1">
<a class="reference internal image-reference" href="../_images/fig5_posterior_predictive1.png"><img alt="../_images/fig5_posterior_predictive1.png" src="../_images/fig5_posterior_predictive1.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 106 </span><span class="caption-text">来自时间序列简单回归模型的后验预测样本（灰色），实际数据为黑色和蓝色。虽然训练集的整体拟合（绘制为黑色）是合理的，但预测结果（样本外预测）很差，因为数据中隐含的加速趋势超过了线性关系。</span><a class="headerlink" href="#fig-fig5-posterior-predictive1" title="Permalink to this image">¶</a></p>
</div>
<p>查看 <a class="reference internal" href="#fig-fig5-posterior-predictive1"><span class="std std-numref">Fig. 106</span></a> 中的样本外预测，我们注意到：</p>
<ol class="simple">
<li><p>当对未来预测时，线性趋势表现不佳，给出的预测始终低于实际观测值。具体来说，大气中的二氧化碳不会以恒定的斜率线性增加 <a class="footnote-reference brackets" href="#id59" id="id8">4</a></p></li>
<li><p>不确定性的范围几乎是恒定的（有时也称为预测锥），但直觉上判断，当预测更远的未来时，似乎不确定性应当增加才对。</p></li>
</ol>
<div class="section" id="design-matrices-for-time-series">
<span id="id9"></span><h3>6.2.1 时间序列的设计矩阵<a class="headerlink" href="#design-matrices-for-time-series" title="Permalink to this headline">¶</a></h3>
<p>在上面的回归模型中，使用了一个相当简单的设计矩阵。通过向设计矩阵添加额外信息，可以获得更好的模型来捕获我们对时间序列的理解。</p>
<p>更好的趋势分量通常是提高预测性能最重要的方面，因为季节性分量<em>通常</em>是平稳的 <a class="footnote-reference brackets" href="#id60" id="id10">5</a>，具有易于估计的参数。重申：存在一种重复的模式导致了一种重复的测量。因此，大多数时间序列建模都包含如何设计一个能够捕获趋势中非平稳性的隐过程。</p>
<p>一种非常成功的方法是对趋势分量使用局部线性过程。基本上，它是一个在某个范围内呈线性的平滑趋势，截距和系数在观测到的时间跨度内缓慢变化或漂移。这种应用程序的一个典型例子是 Facebook Prophet <a class="footnote-reference brackets" href="#id61" id="id11">6</a>，其中使用 <em>半平滑阶跃线性函数</em> 对趋势 <span id="id12">[<a class="reference internal" href="references.html#id125">53</a>]</span> 进行建模。通过允许斜率在某些特定断点处发生变化，我们可以生成能够比直线更好捕获长期趋势的趋势线。这类似于我们在第 <a class="reference internal" href="chp_05.html#expanding-feature-space"><span class="std std-ref">5.2 扩展特征空间</span></a> 中讨论的指示函数的想法。在时间序列上下文中，我们在公式 <a class="reference internal" href="#equation-eq-step-linear-function">(48)</a> 中以数学方式表达了这个想法。</p>
<div class="math notranslate nohighlight" id="equation-eq-step-linear-function">
<span class="eqno">(48)<a class="headerlink" href="#equation-eq-step-linear-function" title="Permalink to this equation">¶</a></span>\[g(t) = (k + \mathbf{A}\delta) t + (m + \mathbf{A} \gamma)\]</div>
<p>其中 <span class="math notranslate nohighlight">\(k\)</span> 是（全局）增长率，<span class="math notranslate nohighlight">\(\delta\)</span> 是每个变化点的调整率向量，<span class="math notranslate nohighlight">\(m\)</span> 是（全局）截距。<span class="math notranslate nohighlight">\(\mathbf{A}\)</span> 是一个 <code class="docutils literal notranslate"><span class="pre">shape=(n_t,</span> <span class="pre">n_s)</span></code> 的矩阵，其中 <span class="math notranslate nohighlight">\(n_s\)</span> 是变化点的数量。在时间 <span class="math notranslate nohighlight">\(t\)</span>，<span class="math notranslate nohighlight">\(\mathbf{A}\)</span> 累积斜率的漂移效应 <span class="math notranslate nohighlight">\(\delta\)</span>。 <span class="math notranslate nohighlight">\(\gamma\)</span> 设置为 <span class="math notranslate nohighlight">\(-s_j \times \delta_j\)</span>（其中 <span class="math notranslate nohighlight">\(s_j\)</span> 是 <span class="math notranslate nohighlight">\(n_s\)</span> 个变化点的时间位置）以使趋势线连续。</p>
<p>通常为 <span class="math notranslate nohighlight">\(\delta\)</span> 选择一个正则化的先验，如 <span class="math notranslate nohighlight">\(\text{Laplace}\)</span>，以表示我们不希望看到斜率发生突然的或较大的变化。你可以在代码 <a class="reference internal" href="#step-linear-function-for-trend"><span class="std std-ref">step_linear_function_for_trend</span></a> 中查看随机生成的阶跃线性函数的示例,以及在 <a class="reference internal" href="#fig-fig6-step-linear-function"><span class="std std-numref">Fig. 107</span></a> 中的分解。</p>
<div class="literal-block-wrapper docutils container" id="step-linear-function-for-trend">
<div class="code-block-caption"><span class="caption-number">Listing 79 </span><span class="caption-text">step_linear_function_for_trend</span><a class="headerlink" href="#step-linear-function-for-trend" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_changepoints</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">n_tp</span> <span class="o">=</span> <span class="mi">500</span>
<span class="n">t</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.linspace.html#numpy.linspace" title="numpy.linspace"><span class="n">np</span><span class="o">.</span><span class="n">linspace</span></a><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_tp</span><span class="p">)</span>
<span class="n">s</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.linspace.html#numpy.linspace" title="numpy.linspace"><span class="n">np</span><span class="o">.</span><span class="n">linspace</span></a><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_changepoints</span> <span class="o">+</span> <span class="mi">2</span><span class="p">)[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">A</span> <span class="o">=</span> <span class="p">(</span><span class="n">t</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">s</span><span class="p">)</span>

<span class="n">k</span><span class="p">,</span> <span class="n">m</span> <span class="o">=</span> <span class="mf">2.5</span><span class="p">,</span> <span class="mi">40</span>
<span class="n">delta</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/random/generated/numpy.random.laplace.html#numpy.random.laplace" title="numpy.random.laplace"><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">laplace</span></a><span class="p">(</span><span class="mf">.1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n_changepoints</span><span class="p">)</span>
<span class="n">growth</span> <span class="o">=</span> <span class="p">(</span><span class="n">k</span> <span class="o">+</span> <span class="n">A</span> <span class="o">@</span> <span class="n">delta</span><span class="p">)</span> <span class="o">*</span> <span class="n">t</span>
<span class="n">offset</span> <span class="o">=</span> <span class="n">m</span> <span class="o">+</span> <span class="n">A</span> <span class="o">@</span> <span class="p">(</span><span class="o">-</span><span class="n">s</span> <span class="o">*</span> <span class="n">delta</span><span class="p">)</span>
<span class="n">trend</span> <span class="o">=</span> <span class="n">growth</span> <span class="o">+</span> <span class="n">offset</span>
</pre></div>
</div>
</div>
<div class="figure align-default" id="fig-fig6-step-linear-function">
<a class="reference internal image-reference" href="../_images/fig6_step_linear_function.png"><img alt="../_images/fig6_step_linear_function.png" src="../_images/fig6_step_linear_function.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 107 </span><span class="caption-text">作为时间序列模型趋势分量的阶跃线性函数，使用代码 <a class="reference internal" href="#step-linear-function-for-trend"><span class="std std-ref">step_linear_function_for_trend</span></a> 生成。第一个子图是设计矩阵 <span class="math notranslate nohighlight">\(\mathbf{A}\)</span>，其颜色编码相同，黑色代表 <span class="math notranslate nohighlight">\(1\)</span>，浅灰色代表 <span class="math notranslate nohighlight">\(0\)</span>。最后一个子图是公式 <a class="reference internal" href="#equation-eq-step-linear-function">(48)</a> 中可以在时间序列模型中用作趋势的结果函数 <span class="math notranslate nohighlight">\(g(t)\)</span> 。中间两个子图是公式 <a class="reference internal" href="#equation-eq-step-linear-function">(48)</a> 中两个分量的分解。请注意两者是如何结合使结果趋势连续的。</span><a class="headerlink" href="#fig-fig6-step-linear-function" title="Permalink to this image">¶</a></p>
</div>
<p>在实践中，我们通常会先验地指定有多少变化点，因此可以静态生成 <span class="math notranslate nohighlight">\(\mathbf{A}\)</span>。一种常见的方法是指定比你认为时间序列实际显示的更多的变化点，并在 <span class="math notranslate nohighlight">\(\delta\)</span> 上放置一个更稀疏的先验以将后验调节到 0。自动变化点检测也是可能的 <span id="id13">[<a class="reference internal" href="references.html#id126">54</a>]</span>。</p>
</div>
<div class="section" id="chp4-gam">
<span id="id14"></span><h3>6.2.2 基函数和广义可加模型<a class="headerlink" href="#chp4-gam" title="Permalink to this headline">¶</a></h3>
<p>在代码 <a class="reference internal" href="#regression-model-for-timeseries"><span class="std std-ref">regression_model_for_timeseries</span></a> 中定义的回归模型中，我们使用稀疏索引矩阵对季节性分量进行建模。另一种方法是使用基样条（ 参见第 <a class="reference internal" href="chp_05.html#chap3-5"><span class="std std-ref">5</span></a> 章 ）之类的基函数，或 Facebook Prophet 模型中的傅里叶基函数。作为设计矩阵的基函数可能会提供一些很好的属性，如正交性（参见<strong>设计矩阵的数学性质</strong>），这使得数值求解线性公式更稳定 <span id="id15">[<a class="reference internal" href="references.html#id160">55</a>]</span>。</p>
<p>傅里叶基函数是正弦和余弦函数的集合，可用于逼近任意平滑的季节性效应 <span id="id16">[<a class="reference internal" href="references.html#id127">56</a>]</span>：</p>
<div class="math notranslate nohighlight" id="equation-eq-fourier-basis-functions">
<span class="eqno">(49)<a class="headerlink" href="#equation-eq-fourier-basis-functions" title="Permalink to this equation">¶</a></span>\[s(t) = \sum^N_{n=1} \left[a_n \text{cos}\left(\frac{2 \pi nt}{P} \right) + b_n \text{sin}\left(\frac{2 \pi nt}{P}\right) \right]\]</div>
<p>其中 <span class="math notranslate nohighlight">\(P\)</span> 是时间序列具有的常规周期（例如，对于年度数据，<span class="math notranslate nohighlight">\(P = 365.25\)</span> 或对于每周数据，当时间变量以天为单位时，<span class="math notranslate nohighlight">\(P = 7\)</span>）。我们可以使用代码 <a class="reference internal" href="#fourier-basis-as-seasonality"><span class="std std-ref">fourier_basis_as_seasonality</span></a> 中所示的公式静态生成它们，并在 <a class="reference internal" href="#fig-fig7-fourier-basis"><span class="std std-numref">Fig. 108</span></a> 中将其可视化。</p>
<div class="literal-block-wrapper docutils container" id="fourier-basis-as-seasonality">
<div class="code-block-caption"><span class="caption-number">Listing 80 </span><span class="caption-text">fourier_basis_as_seasonality</span><a class="headerlink" href="#fourier-basis-as-seasonality" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">gen_fourier_basis</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">365.25</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/constants.html#numpy.pi" title="numpy.pi"><span class="n">np</span><span class="o">.</span><span class="n">pi</span></a> <span class="o">*</span> <span class="p">(</span><a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.arange.html#numpy.arange" title="numpy.arange"><span class="n">np</span><span class="o">.</span><span class="n">arange</span></a><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">t</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">/</span> <span class="n">p</span>
    <span class="k">return</span> <a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.concatenate.html#numpy.concatenate" title="numpy.concatenate"><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span></a><span class="p">((</span><a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.cos.html#numpy.cos" title="numpy.cos"><span class="n">np</span><span class="o">.</span><span class="n">cos</span></a><span class="p">(</span><span class="n">x</span><span class="p">),</span> <a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.sin.html#numpy.sin" title="numpy.sin"><span class="n">np</span><span class="o">.</span><span class="n">sin</span></a><span class="p">(</span><span class="n">x</span><span class="p">)),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">n_tp</span> <span class="o">=</span> <span class="mi">500</span>
<span class="n">p</span> <span class="o">=</span> <span class="mi">12</span>
<span class="n">t_monthly</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.asarray.html#numpy.asarray" title="numpy.asarray"><span class="n">np</span><span class="o">.</span><span class="n">asarray</span></a><span class="p">([</span><span class="n">i</span> <span class="o">%</span> <span class="n">p</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_tp</span><span class="p">)])</span>
<span class="n">monthly_X</span> <span class="o">=</span> <span class="n">gen_fourier_basis</span><span class="p">(</span><span class="n">t_monthly</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="figure align-default" id="fig-fig7-fourier-basis">
<a class="reference internal image-reference" href="../_images/fig7_fourier_basis.png"><img alt="../_images/fig7_fourier_basis.png" src="../_images/fig7_fourier_basis.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 108 </span><span class="caption-text"><span class="math notranslate nohighlight">\(n=3\)</span> 的傅立叶基函数。总共有 <span class="math notranslate nohighlight">\(6\)</span> 个预测变量，我们通过将其余的设置为半透明来突出显示第一个。</span><a class="headerlink" href="#fig-fig7-fourier-basis" title="Permalink to this image">¶</a></p>
</div>
<p>使用上述傅里叶基函数生成的设计矩阵拟合季节性需要估计 <span class="math notranslate nohighlight">\(2N\)</span> 个参数 <span class="math notranslate nohighlight">\(\beta = [a_1, b_1, \dots , a_N , b_N]\)</span>。</p>
<p>像 Facebook Prophet 这样的回归模型也被称为广义可加模型 (GAM)，因为其结果变量 <span class="math notranslate nohighlight">\(Y_t\)</span> 线性依赖于未知的平滑基函数 <a class="footnote-reference brackets" href="#id62" id="id17">7</a>。我们之前在第 <a class="reference internal" href="chp_05.html#chap3-5"><span class="std std-ref">5</span></a> 章中也讨论了其他 GAM。</p>
<div class="admonition- admonition">
<p class="admonition-title">设计矩阵的数学性质</p>
<p>设计矩阵的数学性质在线性最小二乘问题设置中得到了相当广泛的研究，我们想要求解 <span class="math notranslate nohighlight">\(min \mid Y - \mathbf{X} \beta \mid ^{2}\)</span> 的 <span class="math notranslate nohighlight">\(\beta\)</span>。通过检查矩阵 <span class="math notranslate nohighlight">\(\mathbf{X}^T \mathbf{X}\)</span> 的性质，我们通常可以了解 <span class="math notranslate nohighlight">\(\beta\)</span> 解的稳定程度，甚至可能得到一个解。其中一个性质是条件数，它表明 <span class="math notranslate nohighlight">\(\beta\)</span> 的解是否容易出现较大的数值误差。例如，如果设计矩阵包含高相关（多重共线性）的列，则条件数会很大，并且矩阵 <span class="math notranslate nohighlight">\(\mathbf{X}^T \mathbf{X}\)</span> 是病态的。类似原理也适用于贝叶斯建模。无论你采用何种建模方法，在分析工作流程中做深入的探索性分析都是非常有用的。基函数作为设计矩阵通常需要具备良好的条件。</p>
</div>
<p>用于每月二氧化碳测量结果的类似 Facebook Prophet 的广义可加模型见代码 <a class="reference internal" href="#gam"><span class="std std-ref">gam</span></a> 。我们为 <code class="docutils literal notranslate"><span class="pre">k</span></code> 和 <code class="docutils literal notranslate"><span class="pre">m</span></code> 分配了弱信息先验，以表达我们对月指标总体呈上升趋势的认知。这里得到了与实际观测非常接近的先验预测样本（参见 <a class="reference internal" href="#fig-fig8-prior-predictive2"><span class="std std-numref">Fig. 109</span></a>）。</p>
<div class="literal-block-wrapper docutils container" id="gam">
<div class="code-block-caption"><span class="caption-number">Listing 81 </span><span class="caption-text">gam</span><a class="headerlink" href="#gam" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Generate trend design matrix</span>
<span class="n">n_changepoints</span> <span class="o">=</span> <span class="mi">12</span>
<span class="n">n_tp</span> <span class="o">=</span> <span class="n">seasonality_all</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">t</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.linspace.html#numpy.linspace" title="numpy.linspace"><span class="n">np</span><span class="o">.</span><span class="n">linspace</span></a><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_tp</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.float32" title="numpy.float32"><span class="n">np</span><span class="o">.</span><span class="n">float32</span></a><span class="p">)</span>
<span class="n">s</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.linspace.html#numpy.linspace" title="numpy.linspace"><span class="n">np</span><span class="o">.</span><span class="n">linspace</span></a><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="n">t</span><span class="p">),</span> <span class="n">n_changepoints</span> <span class="o">+</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.float32" title="numpy.float32"><span class="n">np</span><span class="o">.</span><span class="n">float32</span></a><span class="p">)[</span><span class="mi">1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">A</span> <span class="o">=</span> <span class="p">(</span><span class="n">t</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">s</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.float32" title="numpy.float32"><span class="n">np</span><span class="o">.</span><span class="n">float32</span></a><span class="p">)</span>
<span class="c1"># Generate seasonality design matrix</span>
<span class="c1"># Set n=6 here so that there are 12 columns (same as `seasonality_all`)</span>
<span class="n">X_pred</span> <span class="o">=</span> <span class="n">gen_fourier_basis</span><span class="p">(</span><a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.where.html#numpy.where" title="numpy.where"><span class="n">np</span><span class="o">.</span><span class="n">where</span></a><span class="p">(</span><span class="n">seasonality_all</span><span class="p">)[</span><span class="mi">1</span><span class="p">],</span>
                           <span class="n">p</span><span class="o">=</span><span class="n">seasonality_all</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                           <span class="n">n</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>
<span class="n">n_pred</span> <span class="o">=</span> <span class="n">X_pred</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="nd">@tfd</span><span class="o">.</span><span class="n">JointDistributionCoroutine</span>
<span class="k">def</span> <span class="nf">gam</span><span class="p">():</span>
    <span class="n">beta</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">root</span><span class="p">(</span><span class="n">tfd</span><span class="o">.</span><span class="n">Sample</span><span class="p">(</span>
        <span class="n">tfd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">),</span> <span class="n">sample_shape</span><span class="o">=</span><span class="n">n_pred</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">"beta"</span><span class="p">))</span>
    <span class="n">seasonality</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">"ij,...j-&gt;...i"</span><span class="p">,</span> <span class="n">X_pred</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>

    <span class="n">k</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">root</span><span class="p">(</span><span class="n">tfd</span><span class="o">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="mf">10.</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">"k"</span><span class="p">))</span>
    <span class="n">m</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">root</span><span class="p">(</span><span class="n">tfd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span>
        <span class="n">co2_by_month_training_data</span><span class="p">[</span><span class="s2">"CO2"</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">scale</span><span class="o">=</span><span class="mf">5.</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">"m"</span><span class="p">))</span>
    <span class="n">tau</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">root</span><span class="p">(</span><span class="n">tfd</span><span class="o">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="mf">10.</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">"tau"</span><span class="p">))</span>
    <span class="n">delta</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Sample</span><span class="p">(</span>
        <span class="n">tfd</span><span class="o">.</span><span class="n">Laplace</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="n">tau</span><span class="p">),</span> <span class="n">sample_shape</span><span class="o">=</span><span class="n">n_changepoints</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">"delta"</span><span class="p">)</span>

    <span class="n">growth_rate</span> <span class="o">=</span> <span class="n">k</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">"ij,...j-&gt;...i"</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">delta</span><span class="p">)</span>
    <span class="n">offset</span> <span class="o">=</span> <span class="n">m</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">"ij,...j-&gt;...i"</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="o">-</span><span class="n">s</span> <span class="o">*</span> <span class="n">delta</span><span class="p">)</span>
    <span class="n">trend</span> <span class="o">=</span> <span class="n">growth_rate</span> <span class="o">*</span> <span class="n">t</span> <span class="o">+</span> <span class="n">offset</span>

    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">seasonality</span> <span class="o">+</span> <span class="n">trend</span>
    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">y_hat</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="n">co2_by_month_training_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>

    <span class="n">noise_sigma</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">root</span><span class="p">(</span><span class="n">tfd</span><span class="o">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="mf">5.</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">"noise_sigma"</span><span class="p">))</span>
    <span class="n">observed</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Independent</span><span class="p">(</span>
        <span class="n">tfd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">noise_sigma</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">]),</span>
        <span class="n">reinterpreted_batch_ndims</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">"observed"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="figure align-default" id="fig-fig8-prior-predictive2">
<a class="reference internal image-reference" href="../_images/fig8_prior_predictive2.png"><img alt="../_images/fig8_prior_predictive2.png" src="../_images/fig8_prior_predictive2.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 109 </span><span class="caption-text">从代码 <a class="reference internal" href="#gam"><span class="std std-ref">gam</span></a> 生成的、来自类 Facebook Prophet 广义加法模型的先验预测样本，与趋势分量相关的参数具有弱信息先验。每条线是一个模拟时间序列。预测样本与实际观测值的范围相似，尤其是将此图与 <a class="reference internal" href="#fig-fig3-prior-predictive1"><span class="std std-numref">Fig. 104</span></a> 进行比较时表现更明显。</span><a class="headerlink" href="#fig-fig8-prior-predictive2" title="Permalink to this image">¶</a></p>
</div>
<p>经过推断，我们可以生成后验预测样本，如 <a class="reference internal" href="#fig-fig9-posterior-predictive2"><span class="std std-numref">Fig. 110</span></a> 所示，预测性能优于 <a class="reference internal" href="#fig-fig5-posterior-predictive1"><span class="std std-numref">Fig. 106</span></a> 中的简单回归模型。</p>
<p>请注意，在 <span id="id18">Taylor and Letham [<a class="reference internal" href="references.html#id125">53</a>]</span> 中预测的生成过程与此处的生成模型不同，因为阶跃线性函数与预定的变化点均匀分布。对于预测而言，在每个时间点，建议首先确定该时间点是否为变化点，然后从后验分布 <span class="math notranslate nohighlight">\(\delta_{new} \sim \text{Laplace}(0, \tau)\)</span> 中生成新的 <code class="docutils literal notranslate"><span class="pre">delta</span></code>。在这里，我们为了简化生成过程，简单地使用上一时段的线性趋势。</p>
<div class="figure align-default" id="fig-fig9-posterior-predictive2">
<a class="reference internal image-reference" href="../_images/fig9_posterior_predictive2.png"><img alt="../_images/fig9_posterior_predictive2.png" src="../_images/fig9_posterior_predictive2.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 110 </span><span class="caption-text">来自代码 <a class="reference internal" href="#gam"><span class="std std-ref">gam</span></a> 的类 Facebook Prophet 模型的后验预测样本以灰色显示，实际数据以黑色和蓝色显示。</span><a class="headerlink" href="#fig-fig9-posterior-predictive2" title="Permalink to this image">¶</a></p>
</div>
</div>
</div>
<div class="section" id="chap4-ar">
<span id="id19"></span><h2>6.3 自回归模型<a class="headerlink" href="#chap4-ar" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id20">
<h3>6.3.1 基础的自回归模型<a class="headerlink" href="#id20" title="Permalink to this headline">¶</a></h3>
<p>时间序列的一个特征是观测值的顺序依赖性。这通常会引入在时间上与先前观测（或观测误差）相关的结构化误差，其中比较典型的是自回归性。在自回归模型中，时间 <span class="math notranslate nohighlight">\(t\)</span> 处的分布被先前观测值的线性函数参数化。考虑一个具有高斯似然的一阶自回归模型（ 通常写为 <span class="math notranslate nohighlight">\(AR(1)\)</span> ）：</p>
<div class="math notranslate nohighlight" id="equation-eq-ar1">
<span class="eqno">(50)<a class="headerlink" href="#equation-eq-ar1" title="Permalink to this equation">¶</a></span>\[y_t \sim \mathcal{N}(\alpha + \rho y_{t-1}, \sigma)\]</div>
<p><span class="math notranslate nohighlight">\(y_t\)</span> 遵循在该位置处的高斯分布，并且是 <span class="math notranslate nohighlight">\(y_{t-1}\)</span> 的线性函数。在 Python 中，可以用一个 <code class="docutils literal notranslate"><span class="pre">for</span></code> 循环来编写这样一个自回归模型。例如，在代码 <a class="reference internal" href="#ar1-with-forloop"><span class="std std-ref">ar1_with_forloop</span></a> 中，我们使用 <span class="math notranslate nohighlight">\(\alpha = 0\)</span> 的 <code class="docutils literal notranslate"><span class="pre">tfd.JointDistributionCoroutine</span></code> 创建了一个 AR(1) 过程，并以 <span class="math notranslate nohighlight">\(\sigma = 1\)</span> 和 不同的 <span class="math notranslate nohighlight">\(\rho\)</span> 值做条件化抽取了随机样本，其结果显示在 <a class="reference internal" href="#fig-fig10-ar1-process"><span class="std std-numref">Fig. 111</span></a> 中。</p>
<div class="literal-block-wrapper docutils container" id="ar1-with-forloop">
<div class="code-block-caption"><span class="caption-number">Listing 82 </span><span class="caption-text">ar1_with_forloop</span><a class="headerlink" href="#ar1-with-forloop" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_t</span> <span class="o">=</span> <span class="mi">200</span>

<span class="nd">@tfd</span><span class="o">.</span><span class="n">JointDistributionCoroutine</span>
<span class="k">def</span> <span class="nf">ar1_with_forloop</span><span class="p">():</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">root</span><span class="p">(</span><span class="n">tfd</span><span class="o">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="mf">1.</span><span class="p">))</span>
    <span class="n">rho</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">root</span><span class="p">(</span><span class="n">tfd</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">))</span>
    <span class="n">x0</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="n">sigma</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="n">x0</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_t</span><span class="p">):</span>
        <span class="n">x_i</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">rho</span><span class="p">,</span> <span class="n">sigma</span><span class="p">)</span>
        <span class="n">x</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x_i</span><span class="p">)</span>

<span class="n">nplot</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.subplots.html#matplotlib.pyplot.subplots" title="matplotlib.pyplot.subplots"><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span></a><span class="p">(</span><span class="n">nplot</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">rho</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axes</span><span class="p">,</span> <a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.linspace.html#numpy.linspace" title="numpy.linspace"><span class="n">np</span><span class="o">.</span><span class="n">linspace</span></a><span class="p">(</span><span class="o">-</span><span class="mf">1.01</span><span class="p">,</span> <span class="mf">1.01</span><span class="p">,</span> <span class="n">nplot</span><span class="p">)):</span>
    <span class="n">test_samples</span> <span class="o">=</span> <span class="n">ar1_with_forloop</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="n">rho</span><span class="p">))</span>
    <span class="n">ar1_samples</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">test_samples</span><span class="p">[</span><span class="mi">2</span><span class="p">:])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ar1_samples</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s2">"$\rho$=</span><span class="si">%.2f</span><span class="s2">"</span> <span class="o">%</span> <span class="n">rho</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">loc</span><span class="o">=</span><span class="s2">"upper left"</span><span class="p">,</span>
              <span class="n">borderaxespad</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="figure align-default" id="fig-fig10-ar1-process">
<a class="reference internal image-reference" href="../_images/fig10_ar1_process.png"><img alt="../_images/fig10_ar1_process.png" src="../_images/fig10_ar1_process.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 111 </span><span class="caption-text"><span class="math notranslate nohighlight">\(\sigma = 1\)</span> 和不同 <span class="math notranslate nohighlight">\(\rho\)</span> 值时 AR(1) 过程的随机样本。请注意，当 <span class="math notranslate nohighlight">\(\mid \rho \mid &gt; 1\)</span> 时，AR(1) 过程是非平稳的。</span><a class="headerlink" href="#fig-fig10-ar1-process" title="Permalink to this image">¶</a></p>
</div>
<p>使用 <code class="docutils literal notranslate"><span class="pre">for</span></code> 循环生成时间序列随机变量非常简单，但现在每个时间点都是一个随机变量，使其应用起来非常困难（ 例如，难以适应大规模的时间点数据 ）。如果可能，我们更喜欢编写使用向量化操作的模型。上面的模型可以在不使用 <code class="docutils literal notranslate"><span class="pre">for</span></code> 循环的情况下，通过 TFP 中的自回归分布 <code class="docutils literal notranslate"><span class="pre">tfd.Autoregressive</span></code> 来重写模型，它采用<code class="docutils literal notranslate"><span class="pre">distribution_fn</span></code> 函数来表示公式 <a class="reference internal" href="#equation-eq-ar1">(50)</a> ，该函数输入 <span class="math notranslate nohighlight">\(y_{t -1}\)</span> 并返回 <span class="math notranslate nohighlight">\(y_t\)</span> 的分布。但 TFP 中的自回归分布仅保留了过程的最终状态，即初始值 <span class="math notranslate nohighlight">\(y_0\)</span> 迭代 <span class="math notranslate nohighlight">\(t\)</span> 步骤后，随机变量 <span class="math notranslate nohighlight">\(y_t\)</span> 的分布。为了获得自回归过程中的所有时间步，我们需要使用后移运算符（也称为滞后运算符）<span class="math notranslate nohighlight">\(\mathbf{B}\)</span> 表达公式 <a class="reference internal" href="#equation-eq-ar1">(50)</a>，该运算符会对所有 <span class="math notranslate nohighlight">\(t &gt; 0\)</span> 移动时间序列 <span class="math notranslate nohighlight">\(\mathbf{B} y_t = y_{t-1}\)</span> 。用后移运算符 <span class="math notranslate nohighlight">\(\mathbf{B}\)</span> 重新表示公式 <a class="reference internal" href="#equation-eq-ar1">(50)</a> 为 <span class="math notranslate nohighlight">\(Y \sim \mathcal{N}(\rho \mathbf{B} Y, \sigma)\)</span> 。从概念上讲，你可以将其视为对向量化似然 <code class="docutils literal notranslate"><span class="pre">Normal(ρ</span> <span class="pre">*</span> <span class="pre">y[:-1],</span> <span class="pre">σ).log_prob(y[1:])</span></code> 的估计。在代码 <a class="reference internal" href="#ar1-without-forloop"><span class="std std-ref">ar1_without_forloop</span></a> 中，我们用 <code class="docutils literal notranslate"><span class="pre">tfd.Autoregressive</span></code> API 为 <code class="docutils literal notranslate"><span class="pre">n_t</span></code> 步骤构建了相同的生成式 AR(1) 模型。请注意，我们并没有在代码 <a class="reference internal" href="#ar1-without-forloop"><span class="std std-ref">ar1_without_forloop</span></a> 中通过生成输出结果 <span class="math notranslate nohighlight">\(y_{t-1}\)</span> 来显式地构造后移运算符 <span class="math notranslate nohighlight">\(\mathbf{B}\)</span> ，而是使用了 Python 函数 <code class="docutils literal notranslate"><span class="pre">ar1_fun</span></code> 完成后移操作并为下一时间步生成分布。</p>
<div class="literal-block-wrapper docutils container" id="ar1-without-forloop">
<div class="code-block-caption"><span class="caption-number">Listing 83 </span><span class="caption-text">ar1_without_forloop</span><a class="headerlink" href="#ar1-without-forloop" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@tfd</span><span class="o">.</span><span class="n">JointDistributionCoroutine</span>
<span class="k">def</span> <span class="nf">ar1_without_forloop</span><span class="p">():</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">root</span><span class="p">(</span><span class="n">tfd</span><span class="o">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="mf">1.</span><span class="p">))</span>
    <span class="n">rho</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">root</span><span class="p">(</span><span class="n">tfd</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">ar1_fun</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
        <span class="c1"># We apply the backshift operation here</span>
        <span class="n">x_tm1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="mi">1</span><span class="p">]),</span> <span class="n">x</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">loc</span> <span class="o">=</span> <span class="n">x_tm1</span> <span class="o">*</span> <span class="n">rho</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Independent</span><span class="p">(</span><span class="n">tfd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">sigma</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">]),</span>
                               <span class="n">reinterpreted_batch_ndims</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">dist</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Autoregressive</span><span class="p">(</span>
        <span class="n">distribution_fn</span><span class="o">=</span><span class="n">ar1_fun</span><span class="p">,</span>
        <span class="n">sample0</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">n_t</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">rho</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span>
        <span class="n">num_steps</span><span class="o">=</span><span class="n">n_t</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>现在我们以 AR(1) 过程作为似然函数来扩展上述类 Facebook Prophet 的广义可加模型。但在这样做之前，先将代码 <a class="reference internal" href="#gam"><span class="std std-ref">gam</span></a> 中的 <code class="docutils literal notranslate"><span class="pre">GAM</span></code> 重写为代码 <a class="reference internal" href="#gam-alternative"><span class="std std-ref">gam_alternative</span></a>。</p>
<div class="literal-block-wrapper docutils container" id="gam-alternative">
<div class="code-block-caption"><span class="caption-number">Listing 84 </span><span class="caption-text">gam_alternative</span><a class="headerlink" href="#gam-alternative" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">gam_trend_seasonality</span><span class="p">():</span>
    <span class="n">beta</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">root</span><span class="p">(</span><span class="n">tfd</span><span class="o">.</span><span class="n">Sample</span><span class="p">(</span>
        <span class="n">tfd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">),</span> <span class="n">sample_shape</span><span class="o">=</span><span class="n">n_pred</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">"beta"</span><span class="p">))</span>
    <span class="n">seasonality</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">"ij,...j-&gt;...i"</span><span class="p">,</span> <span class="n">X_pred</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>

    <span class="n">k</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">root</span><span class="p">(</span><span class="n">tfd</span><span class="o">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="mf">10.</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">"k"</span><span class="p">))</span>
    <span class="n">m</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">root</span><span class="p">(</span><span class="n">tfd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span>
        <span class="n">co2_by_month_training_data</span><span class="p">[</span><span class="s2">"CO2"</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">scale</span><span class="o">=</span><span class="mf">5.</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">"m"</span><span class="p">))</span>
    <span class="n">tau</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">root</span><span class="p">(</span><span class="n">tfd</span><span class="o">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="mf">10.</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">"tau"</span><span class="p">))</span>
    <span class="n">delta</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Sample</span><span class="p">(</span>
        <span class="n">tfd</span><span class="o">.</span><span class="n">Laplace</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="n">tau</span><span class="p">),</span> <span class="n">sample_shape</span><span class="o">=</span><span class="n">n_changepoints</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">"delta"</span><span class="p">)</span>

    <span class="n">growth_rate</span> <span class="o">=</span> <span class="n">k</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">"ij,...j-&gt;...i"</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">delta</span><span class="p">)</span>
    <span class="n">offset</span> <span class="o">=</span> <span class="n">m</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">"ij,...j-&gt;...i"</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="o">-</span><span class="n">s</span> <span class="o">*</span> <span class="n">delta</span><span class="p">)</span>
    <span class="n">trend</span> <span class="o">=</span> <span class="n">growth_rate</span> <span class="o">*</span> <span class="n">t</span> <span class="o">+</span> <span class="n">offset</span>
    <span class="n">noise_sigma</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">root</span><span class="p">(</span><span class="n">tfd</span><span class="o">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="mf">5.</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">"noise_sigma"</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">seasonality</span><span class="p">,</span> <span class="n">trend</span><span class="p">,</span> <span class="n">noise_sigma</span>

<span class="k">def</span> <span class="nf">generate_gam</span><span class="p">(</span><span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>

    <span class="nd">@tfd</span><span class="o">.</span><span class="n">JointDistributionCoroutine</span>
    <span class="k">def</span> <span class="nf">gam</span><span class="p">():</span>
        <span class="n">seasonality</span><span class="p">,</span> <span class="n">trend</span><span class="p">,</span> <span class="n">noise_sigma</span> <span class="o">=</span> <span class="k">yield from</span> <span class="n">gam_trend_seasonality</span><span class="p">()</span>
        <span class="n">y_hat</span> <span class="o">=</span> <span class="n">seasonality</span> <span class="o">+</span> <span class="n">trend</span>
        <span class="k">if</span> <span class="n">training</span><span class="p">:</span>
            <span class="n">y_hat</span> <span class="o">=</span> <span class="n">y_hat</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="n">co2_by_month_training_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>

        <span class="c1"># likelihood</span>
        <span class="n">observed</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Independent</span><span class="p">(</span>
            <span class="n">tfd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">noise_sigma</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">]),</span>
            <span class="n">reinterpreted_batch_ndims</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="s2">"observed"</span>
        <span class="p">)</span>

    <span class="k">return</span> <span class="n">gam</span>

<span class="n">gam</span> <span class="o">=</span> <span class="n">generate_gam</span><span class="p">()</span>
</pre></div>
</div>
</div>
<p>比较代码 <a class="reference internal" href="#gam-alternative"><span class="std std-ref">gam_alternative</span></a> 和代码 <a class="reference internal" href="#gam"><span class="std std-ref">gam</span></a>，可以看到两个主要区别：</p>
<ol class="simple">
<li><p>我们将趋势和季节性分量（及其先验）的构造拆分成了独立函数，并且在 <code class="docutils literal notranslate"><span class="pre">tfd.JointDistributionCoroutine</span></code> 的模型块中，使用了 <code class="docutils literal notranslate"><span class="pre">yield</span> <span class="pre">from</span></code> 语句，从而在不同代码中能够获得相同的 <code class="docutils literal notranslate"><span class="pre">tfd.JointDistributionCoroutine</span> </code> 模型；</p></li>
<li><p>我们将 <code class="docutils literal notranslate"><span class="pre">tfd.JointDistributionCoroutine</span></code> 包装在另一个 Python 函数中，这样更容易在训练集和测试集上实现条件化。</p></li>
</ol>
<p>代码 <a class="reference internal" href="#gam-alternative"><span class="std std-ref">gam_alternative</span></a> 是一种更加模块化的方法。我们可以通过改变似然函数部分来写出一个具有 AR(1) 似然函数的 GAM。这就是在代码 <a class="reference internal" href="#gam-with-ar-likelihood"><span class="std std-ref">gam_with_ar_likelihood</span></a> 中所做的。</p>
<div class="literal-block-wrapper docutils container" id="gam-with-ar-likelihood">
<div class="code-block-caption"><span class="caption-number">Listing 85 </span><span class="caption-text">gam_with_ar_likelihood</span><a class="headerlink" href="#gam-with-ar-likelihood" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">generate_gam_ar_likelihood</span><span class="p">(</span><span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>

    <span class="nd">@tfd</span><span class="o">.</span><span class="n">JointDistributionCoroutine</span>
    <span class="k">def</span> <span class="nf">gam_with_ar_likelihood</span><span class="p">():</span>
        <span class="n">seasonality</span><span class="p">,</span> <span class="n">trend</span><span class="p">,</span> <span class="n">noise_sigma</span> <span class="o">=</span> <span class="k">yield from</span> <span class="n">gam_trend_seasonality</span><span class="p">()</span>
        <span class="n">y_hat</span> <span class="o">=</span> <span class="n">seasonality</span> <span class="o">+</span> <span class="n">trend</span>
        <span class="k">if</span> <span class="n">training</span><span class="p">:</span>
            <span class="n">y_hat</span> <span class="o">=</span> <span class="n">y_hat</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="n">co2_by_month_training_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>

        <span class="c1"># Likelihood</span>
        <span class="n">rho</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">root</span><span class="p">(</span><span class="n">tfd</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">"rho"</span><span class="p">))</span>
        <span class="k">def</span> <span class="nf">ar_fun</span><span class="p">(</span><span class="n">y</span><span class="p">):</span>
            <span class="n">loc</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="mi">1</span><span class="p">]),</span> <span class="n">y</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]],</span>
                            <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">rho</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">+</span> <span class="n">y_hat</span>
            <span class="k">return</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Independent</span><span class="p">(</span>
                <span class="n">tfd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">noise_sigma</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">]),</span>
                <span class="n">reinterpreted_batch_ndims</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">observed</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Autoregressive</span><span class="p">(</span>
            <span class="n">distribution_fn</span><span class="o">=</span><span class="n">ar_fun</span><span class="p">,</span>
            <span class="n">sample0</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">y_hat</span><span class="p">),</span>
            <span class="n">num_steps</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="s2">"observed"</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">gam_with_ar_likelihood</span>

<span class="n">gam_with_ar_likelihood</span> <span class="o">=</span> <span class="n">generate_gam_ar_likelihood</span><span class="p">()</span>
</pre></div>
</div>
</div>
<p>在这里考虑 AR(1) 模型的另一种方法，是将线性回归概念扩展为在设计矩阵中包含一个观测相关列，并将该列的元素 <span class="math notranslate nohighlight">\(x_i\)</span> 设置为 <span class="math notranslate nohighlight">\(y_{i-1}\)</span>。然后，自回归系数 <span class="math notranslate nohighlight">\(\rho\)</span> 与任何其他回归系数没有什么不同，这只是告诉我们，先前观测对当前观测的期望的线性贡献是什么 <a class="footnote-reference brackets" href="#id63" id="id21">8</a>。在这个模型中，我们通过检查 <span class="math notranslate nohighlight">\(\rho\)</span> 的后验分布发现这种影响几乎可以忽略不计（ 参见 <a class="reference internal" href="#fig-fig11-ar1-likelihood-rho"><span class="std std-numref">Fig. 112</span></a> ）：</p>
<div class="figure align-default" id="fig-fig11-ar1-likelihood-rho">
<a class="reference internal image-reference" href="../_images/fig11_ar1_likelihood_rho.png"><img alt="../_images/fig11_ar1_likelihood_rho.png" src="../_images/fig11_ar1_likelihood_rho.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 112 </span><span class="caption-text">在代码 <a class="reference internal" href="#gam-with-ar-likelihood"><span class="std std-ref">gam_with_ar_likelihood</span></a> 中定义的类 Facebook Prophet 的 GAM 模型的似然函数参数的后验分布。最左边的子图是具有正态似然的模型中的 <span class="math notranslate nohighlight">\(\sigma\)</span>，中间和最右边的子图是具有 AR(1) 似然的模型中的 <span class="math notranslate nohighlight">\(\sigma\)</span> 和 <span class="math notranslate nohighlight">\(\rho\)</span>。两个模型都返回了相似的 <span class="math notranslate nohighlight">\(\sigma\)</span> 估计值，<span class="math notranslate nohighlight">\(\rho\)</span> 估计值以 <span class="math notranslate nohighlight">\(0\)</span> 为中心。</span><a class="headerlink" href="#fig-fig11-ar1-likelihood-rho" title="Permalink to this image">¶</a></p>
</div>
<p>除了采用 AR(k) 似然函数这种方式之外，我们还可以通过在线性预测中添加隐自回归分量，来达到将自回归包含在时间序列模型中的目的。这就是代码 <a class="reference internal" href="#gam-with-latent-ar"><span class="std std-ref">gam_with_latent_ar</span></a> 中的 <code class="docutils literal notranslate"><span class="pre">gam_with_latent_ar</span></code> 隐自回归模型。</p>
<div class="literal-block-wrapper docutils container" id="gam-with-latent-ar">
<div class="code-block-caption"><span class="caption-number">Listing 86 </span><span class="caption-text">gam_with_latent_ar</span><a class="headerlink" href="#gam-with-latent-ar" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">generate_gam_ar_latent</span><span class="p">(</span><span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>

    <span class="nd">@tfd</span><span class="o">.</span><span class="n">JointDistributionCoroutine</span>
    <span class="k">def</span> <span class="nf">gam_with_latent_ar</span><span class="p">():</span>
        <span class="n">seasonality</span><span class="p">,</span> <span class="n">trend</span><span class="p">,</span> <span class="n">noise_sigma</span> <span class="o">=</span> <span class="k">yield from</span> <span class="n">gam_trend_seasonality</span><span class="p">()</span>
        
        <span class="c1"># Latent AR(1)</span>
        <span class="n">ar_sigma</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">root</span><span class="p">(</span><span class="n">tfd</span><span class="o">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="mf">.1</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">"ar_sigma"</span><span class="p">))</span>
        <span class="n">rho</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">root</span><span class="p">(</span><span class="n">tfd</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">"rho"</span><span class="p">))</span>
        <span class="k">def</span> <span class="nf">ar_fun</span><span class="p">(</span><span class="n">y</span><span class="p">):</span>
            <span class="n">loc</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="mi">1</span><span class="p">]),</span> <span class="n">y</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]],</span>
                            <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">rho</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span>
            <span class="k">return</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Independent</span><span class="p">(</span>
                <span class="n">tfd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">ar_sigma</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">]),</span>
                <span class="n">reinterpreted_batch_ndims</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">temporal_error</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Autoregressive</span><span class="p">(</span>
            <span class="n">distribution_fn</span><span class="o">=</span><span class="n">ar_fun</span><span class="p">,</span>
            <span class="n">sample0</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">trend</span><span class="p">),</span>
            <span class="n">num_steps</span><span class="o">=</span><span class="n">trend</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
            <span class="n">name</span><span class="o">=</span><span class="s2">"temporal_error"</span><span class="p">)</span>

        <span class="c1"># Linear prediction</span>
        <span class="n">y_hat</span> <span class="o">=</span> <span class="n">seasonality</span> <span class="o">+</span> <span class="n">trend</span> <span class="o">+</span> <span class="n">temporal_error</span>
        <span class="k">if</span> <span class="n">training</span><span class="p">:</span>
            <span class="n">y_hat</span> <span class="o">=</span> <span class="n">y_hat</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="n">co2_by_month_training_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>

        <span class="c1"># Likelihood</span>
        <span class="n">observed</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Independent</span><span class="p">(</span>
            <span class="n">tfd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">noise_sigma</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">]),</span>
            <span class="n">reinterpreted_batch_ndims</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="s2">"observed"</span>
        <span class="p">)</span>

    <span class="k">return</span> <span class="n">gam_with_latent_ar</span>

<span class="n">gam_with_latent_ar</span> <span class="o">=</span> <span class="n">generate_gam_ar_latent</span><span class="p">()</span>
</pre></div>
</div>
</div>
<p>通过显式的隐自回归过程，我们将一个与观测数据大小相同的随机变量添加到模型中。由于它现在是添加到线性预测 <span class="math notranslate nohighlight">\(\hat{Y}\)</span> 中的显式分量，因此可以将自回归过程解释为趋势分量的补充，甚至是其一部分。</p>
<p>我们可以在完成推断后，可视化隐自回归分量，类似于时间序列模型的趋势和季节性分量（参见 <a class="reference internal" href="#fig-fig12-posterior-predictive-ar1"><span class="std std-numref">Fig. 113</span></a>）。</p>
<div class="figure align-default" id="fig-fig12-posterior-predictive-ar1">
<a class="reference internal image-reference" href="../_images/fig12_posterior_predictive_ar1.png"><img alt="../_images/fig12_posterior_predictive_ar1.png" src="../_images/fig12_posterior_predictive_ar1.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 113 </span><span class="caption-text">在代码 <a class="reference internal" href="#gam-with-latent-ar"><span class="std std-ref">gam_with_latent_ar</span></a> 中指定的基于 GAM 的时间序列模型 <code class="docutils literal notranslate"><span class="pre">gam_with_latent_ar</span></code> 的趋势、季节性和 AR(1) 分量的后验预测样本。</span><a class="headerlink" href="#fig-fig12-posterior-predictive-ar1" title="Permalink to this image">¶</a></p>
</div>
<p>解释显式隐自回归过程的另一种方法是认为它捕获了时间相关的残差，因此我们预期 <span class="math notranslate nohighlight">\(\sigma_{noise}\)</span> 的后验估计较没有此分量的模型更小。在 <a class="reference internal" href="#fig-fig13-ar1-likelihood-rho2"><span class="std std-numref">Fig. 114</span></a> 中，我们展示了模型 <code class="docutils literal notranslate"><span class="pre">gam_with_latent_ar</span></code> 的 <span class="math notranslate nohighlight">\(\sigma_{noise}\)</span>、<span class="math notranslate nohighlight">\(\sigma_{AR}\)</span> 和 <span class="math notranslate nohighlight">\(\rho\)</span> 的后验分布。与模型 <code class="docutils literal notranslate"><span class="pre">gam_with_ar_likelihood</span></code> 相比，确实得到了 <span class="math notranslate nohighlight">\(\sigma_{noise}\)</span> 的较低估计，而 <span class="math notranslate nohighlight">\(\rho\)</span> 的估计则要高得多。</p>
<div class="figure align-default" id="fig-fig13-ar1-likelihood-rho2">
<a class="reference internal image-reference" href="../_images/fig13_ar1_likelihood_rho2.png"><img alt="../_images/fig13_ar1_likelihood_rho2.png" src="../_images/fig13_ar1_likelihood_rho2.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 114 </span><span class="caption-text">代码 <a class="reference internal" href="#gam-with-latent-ar"><span class="std std-ref">gam_with_latent_ar</span></a> 中 <code class="docutils literal notranslate"><span class="pre">gam_with_latent_ar</span></code> 模型的 AR(1) 潜在分量的 <span class="math notranslate nohighlight">\(\sigma_{noise}\)</span>、<span class="math notranslate nohighlight">\(\sigma_{AR}\)</span> 和 <span class="math notranslate nohighlight">\(\rho\)</span> 的后验分布。注意不要与 <a class="reference internal" href="#fig-fig11-ar1-likelihood-rho"><span class="std std-numref">Fig. 112</span></a> 混淆，其中我们展示了来自 <span class="math notranslate nohighlight">\(2\)</span> 个不同 GAM 的参数的后验分布。</span><a class="headerlink" href="#fig-fig13-ar1-likelihood-rho2" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="section" id="latent-ar-process-and-smoothing">
<span id="id22"></span><h3>6.3.2 隐自回归过程和平滑<a class="headerlink" href="#latent-ar-process-and-smoothing" title="Permalink to this headline">¶</a></h3>
<p>隐过程在捕获时间观测序列中的微妙趋势方面非常强大。它甚至可以逼近任意函数。为了看到这一点，让我们考虑使用包含隐 (GRW) 分量的时间序列模型对玩具数据进行建模，如公式 <a class="reference internal" href="#equation-eq-gw-formulation1">(51)</a> 所示。</p>
<div class="math notranslate nohighlight" id="equation-eq-gw-formulation1">
<span class="eqno">(51)<a class="headerlink" href="#equation-eq-gw-formulation1" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{split}
z_i &amp; \sim \mathcal{N}(z_{i-1}, \sigma_{z}^2) \: \text{ for } i=1,\dots,N \\
y_i &amp; \sim \mathcal{N}(z_i,  \sigma_{y}^2)
\end{split}\end{split}\]</div>
<p>这里的 GRW 等同于 <span class="math notranslate nohighlight">\(\rho = 1\)</span> 时的 AR(1) 过程。</p>
<p>通过在公式 <a class="reference internal" href="#equation-eq-gw-formulation1">(51)</a> 中对 <span class="math notranslate nohighlight">\(\sigma_{z}\)</span> 和 <span class="math notranslate nohighlight">\(\sigma_{y}\)</span> 设置不同先验，我们可以强调在 GRW 中应解释多少观测数据中的方差，以及其中有多少是独立同分布的噪声。我们还可以计算比率 <span class="math notranslate nohighlight">\(\alpha = \frac{\sigma_{y}^2}{\sigma_{z}^2 + \sigma_{y}^2}\)</span> ，其中 <span class="math notranslate nohighlight">\(\alpha\)</span> 在 <span class="math notranslate nohighlight">\([0, 1]\)</span> 区间内，可以解释为平滑度。因此，我们可以将公式 <a class="reference internal" href="#equation-eq-gw-formulation1">(51)</a> 中的模型等价地表示为公式 <a class="reference internal" href="#equation-eq-gw-formulation2">(52)</a>。</p>
<div class="math notranslate nohighlight" id="equation-eq-gw-formulation2">
<span class="eqno">(52)<a class="headerlink" href="#equation-eq-gw-formulation2" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{split}
z_i &amp; \sim \mathcal{N}(z_{i-1}, (1 - \alpha) \sigma^2) \: \text{ for } i=1,\dots,N \\
y_i &amp; \sim \mathcal{N}(z_i,   \alpha \sigma^2)
\end{split}\end{split}\]</div>
<p>我们在公式 <a class="reference internal" href="#equation-eq-gw-formulation2">(52)</a> 中的隐 GRW 模型可以用代码 <a class="reference internal" href="#gw-tfp"><span class="std std-ref">gw_tfp</span></a> 编写。通过在 <span class="math notranslate nohighlight">\(\alpha\)</span> 上放置信息先验，我们可以控制希望在隐 GRW 中看到多少 “平滑”（较大的 <span class="math notranslate nohighlight">\(\alpha\)</span> 给出更平滑的近似值）。让我们用从任意函数模拟的一些含噪声观测来拟合模型 <code class="docutils literal notranslate"><span class="pre">smoothing_grw</span></code>。数据在 <a class="reference internal" href="#fig-fig14-smoothing-with-gw"><span class="std std-numref">Fig. 115</span></a> 中显示为黑色实心点，拟合的隐随机游走显示在同一图中。</p>
<div class="literal-block-wrapper docutils container" id="gw-tfp">
<div class="code-block-caption"><span class="caption-number">Listing 87 </span><span class="caption-text">gw_tfp</span><a class="headerlink" href="#gw-tfp" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@tfd</span><span class="o">.</span><span class="n">JointDistributionCoroutine</span>
<span class="k">def</span> <span class="nf">smoothing_grw</span><span class="p">():</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">root</span><span class="p">(</span><span class="n">tfd</span><span class="o">.</span><span class="n">Beta</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mf">1.</span><span class="p">))</span>
    <span class="n">variance</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">root</span><span class="p">(</span><span class="n">tfd</span><span class="o">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="mf">10.</span><span class="p">))</span>
    <span class="n">sigma0</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">variance</span> <span class="o">*</span> <span class="n">alpha</span><span class="p">)</span>
    <span class="n">sigma1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">variance</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">))</span>
    <span class="n">z</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Sample</span><span class="p">(</span><span class="n">tfd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="n">sigma0</span><span class="p">),</span> <span class="n">num_steps</span><span class="p">)</span>
    <span class="n">observed</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Independent</span><span class="p">(</span>
        <span class="n">tfd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span> <span class="n">sigma1</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="figure align-default" id="fig-fig14-smoothing-with-gw">
<a class="reference internal image-reference" href="../_images/fig14_smoothing_with_gw.png"><img alt="../_images/fig14_smoothing_with_gw.png" src="../_images/fig14_smoothing_with_gw.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 115 </span><span class="caption-text">来自 <span class="math notranslate nohighlight">\(y \sim \text{Normal}(f(x), 1)\)</span> 的模拟观测结果 <span class="math notranslate nohighlight">\(f(x) = e^{1 + x^{0.5} - e^{\frac{x}{15} }}\)</span>，以及推断的隐高斯随机游走。灰色半透明区域是隐高斯随机游走 <span class="math notranslate nohighlight">\(z\)</span> 的后验 <span class="math notranslate nohighlight">\(94\%\)</span> HDI 区间，后验均值图为蓝色虚线。</span><a class="headerlink" href="#fig-fig14-smoothing-with-gw" title="Permalink to this image">¶</a></p>
</div>
<p>自回归过程还有一些其他有趣的性质，与高斯过程 <span id="id23">[<a class="reference internal" href="references.html#id91">52</a>]</span> 有关。例如，你可能会发现<em>单独的</em>自回归模型无法捕获长期趋势。尽管模型似乎很适合观测结果，但在预测时，你会观察到预测值很快就回归到了最后几个时间步的均值。与使用具有恒定平均函数 <a class="footnote-reference brackets" href="#id64" id="id24">9</a> 的高斯过程所观测到的相同。</p>
<p>作为额外趋势分量的自回归分量可能会给模型推断带来一些挑战。例如，规模化可能是一个问题，因为我们正在添加一个时间观测序列具有相同形状的随机变量。当趋势分量和自回归过程都灵活时，我们可能会得到一个无法识别的模型，因为自回归过程本身已经有能力近似观测数据的潜在趋势（平滑函数）了。</p>
</div>
<div class="section" id="s-ar-i-ma-x">
<span id="sarimax"></span><h3>6.3.3 自回归移动平均 (S)AR(I)MA(X)<a class="headerlink" href="#s-ar-i-ma-x" title="Permalink to this headline">¶</a></h3>
<p>许多经典时间序列模型共享相似的类自回归模式，在此类模式中，时间 <span class="math notranslate nohighlight">\(t\)</span> 处有一些隐参数依赖于自身的观测值或 <span class="math notranslate nohighlight">\(t-k\)</span> 处的另外一个参数。其中两个典型的例子是：</p>
<ul class="simple">
<li><p>自回归条件异方差 (ARCH) 模型，其中残差的规模随时间变化；</p></li>
<li><p>移动平均 (MA) 模型，它将先前残差的线性组合添加到时间系列均值中。</p></li>
</ul>
<p>这些经典时间序列模型中可以组合成更复杂的模型，其中一种扩展是 SARIMAX 模型。虽然命名可能看起来很吓人，但基本概念在很大程度上是自回归和移动平均模型的直接组合。</p>
<p>用移动平均扩展自回归模型，我们得到一般性的 ARMA 模型：</p>
<div class="math notranslate nohighlight" id="equation-eq-arma">
<span class="eqno">(53)<a class="headerlink" href="#equation-eq-arma" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{split}
y_t &amp; = \alpha + \sum_{i=1}^{p}\phi_i y_{t-i} + \sum_{j=1}^{q}\theta_j \epsilon_{t-j} + \epsilon_t \\
\epsilon_t &amp; \sim \mathcal{N}(0, \sigma^2)
\end{split}\end{split}\]</div>
<p>其中 <span class="math notranslate nohighlight">\(p\)</span> 是自回归模型的阶数，<span class="math notranslate nohighlight">\(q\)</span> 是移动平均模型的阶数。通常，我们将模型记为 <span class="math notranslate nohighlight">\(ARMA(p, q)\)</span> 。同样，对于季节性 ARMA，我们有：</p>
<div class="math notranslate nohighlight" id="equation-eq-sarma">
<span class="eqno">(54)<a class="headerlink" href="#equation-eq-sarma" title="Permalink to this equation">¶</a></span>\[\begin{split}
y_t = \alpha + \sum_{i=1}^{p}\phi_i y_{t-period-i} + \sum_{j=1}^{q}\theta_j \epsilon_{t-period-j} + \epsilon_t
\end{split}\]</div>
<p>在 ARIMA 模型中，积分部分是指时间序列的统计量：积分阶数。表示为 <span class="math notranslate nohighlight">\(I(d)\)</span>，如果一个时间序列重复差分 <span class="math notranslate nohighlight">\(d\)</span> 次后仍然产生平稳序列，则称其被积分至 <span class="math notranslate nohighlight">\(d\)</span> 阶。遵从 <span id="id25">Box <em>et al.</em> [<a class="reference internal" href="references.html#id130">57</a>]</span> ，我们将反复获取时间观测序列的差作为预处理步骤，来解释 <span class="math notranslate nohighlight">\(ARIMA(p,d,q)\)</span> 模型的 <span class="math notranslate nohighlight">\(I(d)\)</span> 部分，并对差分序列结果建模为一个带 <span class="math notranslate nohighlight">\(ARMA(p,q)\)</span> 的平稳过程。该运算本身在 Python 中也相当标准。我们可以使用 <code class="docutils literal notranslate"><span class="pre">numpy.diff</span></code>，其中计算的第一个差分是沿给定轴的 <code class="docutils literal notranslate"><span class="pre">delta_y[i]</span> <span class="pre">=</span> <span class="pre">y[i]</span> <span class="pre">-</span> <span class="pre">y[i-1]</span></code>，通过在给定轴上递归重复相同运算来计算更高阶的差分结果数组。</p>
<p>如果我们有一个额外的回归量 <span class="math notranslate nohighlight">\(\mathbf{X}\)</span>，在上面模型中 <span class="math notranslate nohighlight">\(\alpha\)</span> 被线性预测 <span class="math notranslate nohighlight">\(\mathbf{X} \beta\)</span> 替换。如果 <span class="math notranslate nohighlight">\(d &gt; 0\)</span>，我们将对 <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> 应用相同的差分运算。</p>
<p>此外请注意，我们可以有季节性（ <code class="docutils literal notranslate"><span class="pre">SARIMA</span></code> ）或外生回归（ <code class="docutils literal notranslate"><span class="pre">ARIMAX</span></code> ），但不能同时有。</p>
<div class="admonition-s-ar-i-ma-x admonition">
<p class="admonition-title">(S)AR(I)MA(X) 的概念</p>
<p>通常，ARIMA 模型表示为 <span class="math notranslate nohighlight">\(ARIMA(p,d,q)\)</span>，也就是说，我们有一个包含 <span class="math notranslate nohighlight">\(p\)</span> 阶自回归、<span class="math notranslate nohighlight">\(d\)</span> 度积分 、 <span class="math notranslate nohighlight">\(q\)</span> 阶移动平均的模型。例如，<span class="math notranslate nohighlight">\(ARIMA(1,0,0)\)</span> 只是一个 AR(1)。</p>
<p>我们将季节性 ARIMA 模型表示为 <span class="math notranslate nohighlight">\(\text{SARIMA}(p,d,q)(P,D,Q)_{s}\)</span>，其中 <span class="math notranslate nohighlight">\(s\)</span> 表示每个季节的周期数，大写的 <span class="math notranslate nohighlight">\(P\)</span>、<span class="math notranslate nohighlight">\(D\)</span>、<span class="math notranslate nohighlight">\(Q\)</span> 是 ARIMA 模型 <span class="math notranslate nohighlight">\(p\)</span>、<span class="math notranslate nohighlight">\(d\)</span>、<span class="math notranslate nohighlight">\(q\)</span> 的季节性计数器部分。有时季节性 ARIMA 也表示为 <span class="math notranslate nohighlight">\(\text{SARIMA}(p,d,q)(P,D,Q,s)\)</span>。</p>
<p>如果有外生回归量，我们记为 <span class="math notranslate nohighlight">\(\text{ARIMAX}(p,d,q)\mathbf{X}[k]\)</span> ，其中 <span class="math notranslate nohighlight">\(\mathbf{X}[k]\)</span> 表示包含 <span class="math notranslate nohighlight">\(k\)</span> 列的设计矩阵 <span class="math notranslate nohighlight">\(\mathbf{X}\)</span>。</p>
</div>
<p>作为本章的第二个例子，我们将使用不同的 ARIMA 对美国从 <span class="math notranslate nohighlight">\(1948\)</span> 年到 <span class="math notranslate nohighlight">\(1979\)</span> 年的月活产率时间序列进行建模<span id="id26">[<a class="reference internal" href="references.html#id132">58</a>]</span>。数据显示在 <a class="reference internal" href="#fig-fig15-birth-by-month"><span class="std std-numref">Fig. 116</span></a> 中。</p>
<div class="figure align-default" id="fig-fig15-birth-by-month">
<a class="reference internal image-reference" href="../_images/fig15_birth_by_month.png"><img alt="../_images/fig15_birth_by_month.png" src="../_images/fig15_birth_by_month.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 116 </span><span class="caption-text">美国的月活产婴儿（1948-1979 年）。 <span class="math notranslate nohighlight">\(Y\)</span> 轴显示出生人数（以千计）。</span><a class="headerlink" href="#fig-fig15-birth-by-month" title="Permalink to this image">¶</a></p>
</div>
<p>我们从 <span class="math notranslate nohighlight">\(\text{SARIMA}(1, 1, 1)(1, 1, 1)_{12}\)</span> 模型开始。首先，在代码 <a class="reference internal" href="#sarima-preprocess"><span class="std std-ref">sarima_preprocess</span></a> 中加载和预处理时间观测序列。</p>
<div class="literal-block-wrapper docutils container" id="sarima-preprocess">
<div class="code-block-caption"><span class="caption-number">Listing 88 </span><span class="caption-text">sarima_preprocess</span><a class="headerlink" href="#sarima-preprocess" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">us_monthly_birth</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">"../data/monthly_birth_usa.csv"</span><span class="p">)</span>
<span class="n">us_monthly_birth</span><span class="p">[</span><span class="s2">"date_month"</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">us_monthly_birth</span><span class="p">[</span><span class="s2">"date_month"</span><span class="p">])</span>
<span class="n">us_monthly_birth</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s2">"date_month"</span><span class="p">,</span> <span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># y ~ Sarima(1,1,1)(1,1,1)[12]</span>
<span class="n">p</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">q</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">P</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">Q</span><span class="p">,</span> <span class="n">period</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">12</span><span class="p">)</span>
<span class="c1"># Time series data: us_monthly_birth.shape = (372,)</span>
<span class="n">observed</span> <span class="o">=</span> <span class="n">us_monthly_birth</span><span class="p">[</span><span class="s2">"birth_in_thousands"</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="c1"># Integrated to seasonal order $D$</span>
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">D</span><span class="p">):</span>
    <span class="n">observed</span> <span class="o">=</span> <span class="n">observed</span><span class="p">[</span><span class="n">period</span><span class="p">:]</span> <span class="o">-</span> <span class="n">observed</span><span class="p">[:</span><span class="o">-</span><span class="n">period</span><span class="p">]</span>
<span class="c1"># Integrated to order $d$</span>
<span class="n">observed</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.diff.html#numpy.diff" title="numpy.diff"><span class="n">np</span><span class="o">.</span><span class="n">diff</span></a><span class="p">(</span><span class="n">observed</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">d</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>在撰写本文时，TFP 没有 ARMA 分布的专门实现。为了运行 SARIMA 模型的推断，TFP 需要一个 Python 的 <code class="docutils literal notranslate"><span class="pre">callable</span></code> 来表示对数后验密度函数（直到某个常数 <span id="id27">[<a class="reference internal" href="references.html#id133">30</a>]</span>）。在这种情况下，我们可以通过实现似然函数 <span class="math notranslate nohighlight">\(\text{SARMA}(1, 1)(1, 1)_{12}\)</span> 来得到它（ 因为 <span class="math notranslate nohighlight">\(\text{I}\)</span> 部分已经通过差分处理实现 ）。我们在代码 <a class="reference internal" href="#sarima-likelihood"><span class="std std-ref">sarima_likelihood</span></a> 使用 <code class="docutils literal notranslate"><span class="pre">tf.while_loop</span></code> 构造残差时间序列 <span class="math notranslate nohighlight">\(\epsilon_t\)</span> 并在 <span class="math notranslate nohighlight">\(\text{Normal}\)</span> 分布 <a class="footnote-reference brackets" href="#id65" id="id28">10</a> 上进行估值。从编程角度来看，这里的最大挑战是确保当我们对时间序列进行索引时，张量形状是正确的。为了避免额外的控制流来检查索引是否有效（ 例如，当 <span class="math notranslate nohighlight">\(t=0\)</span> 时，我们不能索引到 <span class="math notranslate nohighlight">\(t-1\)</span> 和 <span class="math notranslate nohighlight">\(t-period-1\)</span> )，我们用零来填充时间序列。</p>
<div class="literal-block-wrapper docutils container" id="sarima-likelihood">
<div class="code-block-caption"><span class="caption-number">Listing 89 </span><span class="caption-text">sarima_likelihood</span><a class="headerlink" href="#sarima-likelihood" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">likelihood</span><span class="p">(</span><span class="n">mu0</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">phi</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">sphi</span><span class="p">,</span> <span class="n">stheta</span><span class="p">):</span>
    <span class="n">batch_shape</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">mu0</span><span class="p">)</span>
    <span class="n">y_extended</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span>
        <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([[</span><span class="n">r</span><span class="p">],</span> <span class="n">batch_shape</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mu0</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">"...,j-&gt;j..."</span><span class="p">,</span>
                  <span class="n">tf</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">mu0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">observed</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span>
                  <span class="n">observed</span><span class="p">)],</span>
        <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">eps_t</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">y_extended</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">observed</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">arma_onestep</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">eps_t</span><span class="p">):</span>
        <span class="n">t_shift</span> <span class="o">=</span> <span class="n">t</span> <span class="o">+</span> <span class="n">r</span>
        <span class="c1"># AR</span>
        <span class="n">y_past</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">y_extended</span><span class="p">,</span> <span class="n">t_shift</span> <span class="o">-</span> <span class="p">(</span><a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.arange.html#numpy.arange" title="numpy.arange"><span class="n">np</span><span class="o">.</span><span class="n">arange</span></a><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">ar</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">"...p,p...-&gt;..."</span><span class="p">,</span> <span class="n">phi</span><span class="p">,</span> <span class="n">y_past</span><span class="p">)</span>
        <span class="c1"># MA</span>
        <span class="n">eps_past</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">eps_t</span><span class="p">,</span> <span class="n">t_shift</span> <span class="o">-</span> <span class="p">(</span><a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.arange.html#numpy.arange" title="numpy.arange"><span class="n">np</span><span class="o">.</span><span class="n">arange</span></a><span class="p">(</span><span class="n">q</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">ma</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">"...q,q...-&gt;..."</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">eps_past</span><span class="p">)</span>
        <span class="c1"># Seasonal AR</span>
        <span class="n">sy_past</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">y_extended</span><span class="p">,</span> <span class="n">t_shift</span> <span class="o">-</span> <span class="p">(</span><a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.arange.html#numpy.arange" title="numpy.arange"><span class="n">np</span><span class="o">.</span><span class="n">arange</span></a><span class="p">(</span><span class="n">P</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">period</span><span class="p">)</span>
        <span class="n">sar</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">"...p,p...-&gt;..."</span><span class="p">,</span> <span class="n">sphi</span><span class="p">,</span> <span class="n">sy_past</span><span class="p">)</span>
        <span class="c1"># Seasonal MA</span>
        <span class="n">seps_past</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">eps_t</span><span class="p">,</span> <span class="n">t_shift</span> <span class="o">-</span> <span class="p">(</span><a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.arange.html#numpy.arange" title="numpy.arange"><span class="n">np</span><span class="o">.</span><span class="n">arange</span></a><span class="p">(</span><span class="n">Q</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">period</span><span class="p">)</span>
        <span class="n">sma</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">"...q,q...-&gt;..."</span><span class="p">,</span> <span class="n">stheta</span><span class="p">,</span> <span class="n">seps_past</span><span class="p">)</span>

        <span class="n">mu_at_t</span> <span class="o">=</span> <span class="n">ar</span> <span class="o">+</span> <span class="n">ma</span> <span class="o">+</span> <span class="n">sar</span> <span class="o">+</span> <span class="n">sma</span> <span class="o">+</span> <span class="n">mu0</span>
        <span class="n">eps_update</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">y_extended</span><span class="p">,</span> <span class="n">t_shift</span><span class="p">)</span> <span class="o">-</span> <span class="n">mu_at_t</span>
        <span class="n">epsilon_t_next</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tensor_scatter_nd_update</span><span class="p">(</span>
            <span class="n">eps_t</span><span class="p">,</span> <span class="p">[[</span><span class="n">t_shift</span><span class="p">]],</span> <span class="n">eps_update</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="o">...</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">epsilon_t_next</span>

    <span class="n">t</span><span class="p">,</span> <span class="n">eps_output_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">while_loop</span><span class="p">(</span>
        <span class="k">lambda</span> <span class="n">t</span><span class="p">,</span> <span class="o">*</span><span class="n">_</span><span class="p">:</span> <span class="n">t</span> <span class="o">&lt;</span> <span class="n">observed</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
        <span class="n">arma_onestep</span><span class="p">,</span>
        <span class="n">loop_vars</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">eps_t</span><span class="p">),</span>
        <span class="n">maximum_iterations</span><span class="o">=</span><span class="n">observed</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">eps_output</span> <span class="o">=</span> <span class="n">eps_output_</span><span class="p">[</span><span class="n">r</span><span class="p">:]</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span>
        <span class="n">tfd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="o">...</span><span class="p">])</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">eps_output</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>添加未知参数的先验（ 当前情况下为 <code class="docutils literal notranslate"><span class="pre">mu0</span></code>、<code class="docutils literal notranslate"><span class="pre">sigma</span></code>、<code class="docutils literal notranslate"><span class="pre">phi</span></code>、<code class="docutils literal notranslate"><span class="pre">theta</span></code>、<code class="docutils literal notranslate"><span class="pre">sphi</span></code> 和 <code class="docutils literal notranslate"><span class="pre">stheta</span></code> ），我们可以生成用于推断的后验密度函数。这显示在代码 <a class="reference internal" href="#sarima-posterior"><span class="std std-ref">sarima_posterior</span></a> 中，我们从代码 <a class="reference internal" href="#sarima-posterior"><span class="std std-ref">sarima_posterior</span></a> <a class="footnote-reference brackets" href="#id66" id="id29">11</a> 中采样得到 <code class="docutils literal notranslate"><span class="pre">target_log_prob_fn</span></code>。</p>
<div class="literal-block-wrapper docutils container" id="sarima-posterior">
<div class="code-block-caption"><span class="caption-number">Listing 90 </span><span class="caption-text">sarima_posterior</span><a class="headerlink" href="#sarima-posterior" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@tfd</span><span class="o">.</span><span class="n">JointDistributionCoroutine</span>
<span class="k">def</span> <span class="nf">sarima_priors</span><span class="p">():</span>
    <span class="n">mu0</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">root</span><span class="p">(</span><span class="n">tfd</span><span class="o">.</span><span class="n">StudentT</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">2.5</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">'mu0'</span><span class="p">))</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">root</span><span class="p">(</span><span class="n">tfd</span><span class="o">.</span><span class="n">HalfStudentT</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">'sigma'</span><span class="p">))</span>

    <span class="n">phi</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">root</span><span class="p">(</span><span class="n">tfd</span><span class="o">.</span><span class="n">Sample</span><span class="p">(</span><span class="n">tfd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="n">p</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">'phi'</span><span class="p">))</span>
    <span class="n">theta</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">root</span><span class="p">(</span><span class="n">tfd</span><span class="o">.</span><span class="n">Sample</span><span class="p">(</span><span class="n">tfd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="n">q</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">'theta'</span><span class="p">))</span>
    <span class="n">sphi</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">root</span><span class="p">(</span><span class="n">tfd</span><span class="o">.</span><span class="n">Sample</span><span class="p">(</span><span class="n">tfd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="n">P</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">'sphi'</span><span class="p">))</span>
    <span class="n">stheta</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">root</span><span class="p">(</span><span class="n">tfd</span><span class="o">.</span><span class="n">Sample</span><span class="p">(</span><span class="n">tfd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="n">Q</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">'stheta'</span><span class="p">))</span>

<span class="n">target_log_prob_fn</span> <span class="o">=</span> <span class="k">lambda</span> <span class="o">*</span><span class="n">x</span><span class="p">:</span> <span class="n">sarima_priors</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="o">*</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">likelihood</span><span class="p">(</span><span class="o">*</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>时间序列的预处理以解释代码 <a class="reference internal" href="#sarima-preprocess"><span class="std std-ref">sarima_preprocess</span></a> 中的 <em>积分</em> 部分，代码 <a class="reference internal" href="#sarima-likelihood"><span class="std std-ref">sarima_likelihood</span></a> 中实现的似然函数可以重构为一个可灵活生成不同SARIMA 似然函数的 Python 语言 helper 类。例如，<a class="reference internal" href="#tab-loo-sarima"><span class="std std-numref">Table 13</span></a> 显示了代码 <a class="reference internal" href="#sarima-posterior"><span class="std std-ref">sarima_posterior</span></a> 中的 $<span class="math notranslate nohighlight">\(\text{SARIMA}(1,1,1)(1,1,1)_{12}\)</span> 模型与相似的 <span class="math notranslate nohighlight">\(\text{SARIMA}(0,1,2)(1,1,1)_{12}\)</span> 模型之间的比较。</p>
<table class="table" id="tab-loo-sarima">
<caption><span class="caption-number">Table 13 </span><span class="caption-text">使用 LOO（对数标度）对不同 SARIMA 模型进行模型比较的汇总数据。</span><a class="headerlink" href="#tab-loo-sarima" title="Permalink to this table">¶</a></caption>
<colgroup>
<col style="width: 13%"/>
<col style="width: 13%"/>
<col style="width: 13%"/>
<col style="width: 13%"/>
<col style="width: 13%"/>
<col style="width: 13%"/>
<col style="width: 13%"/>
<col style="width: 13%"/>
</colgroup>
<tbody>
<tr class="row-odd"><td></td>
<td><p><strong>rank</strong></p></td>
<td><p><strong>loo</strong></p></td>
<td><p><strong>p_loo</strong></p></td>
<td><p><strong>d_loo</strong></p></td>
<td><p><strong>weight</strong></p></td>
<td><p><strong>se</strong></p></td>
<td><p><strong>dse</strong></p></td>
</tr>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\(\text{SARIMA}(0,1,2)(1,1,1)_{12}\)</span></p></td>
<td><p>0</p></td>
<td><p>-1235.60</p></td>
<td><p>7.51</p></td>
<td><p>0.00</p></td>
<td><p>0.5</p></td>
<td><p>15.41</p></td>
<td><p>0.00</p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\(\text{SARIMA}(1,1,1)(1,1,1)_{12}\)</span></p></td>
<td><p>1</p></td>
<td><p>-1235.97</p></td>
<td><p>8.30</p></td>
<td><p>0.37</p></td>
<td><p>0.5</p></td>
<td><p>15.47</p></td>
<td><p>6.29</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="state-space-models">
<span id="id30"></span><h2>6.4 状态空间模型<a class="headerlink" href="#state-space-models" title="Permalink to this headline">¶</a></h2>
<p>在代码 <a class="reference internal" href="#sarima-likelihood"><span class="std std-ref">sarima_likelihood</span></a>的 ARMA 对数似然函数中，我们对时间步进行迭代以便以观测为条件构建一些隐变量。实际上，除非模型非常具体和简单（例如，每两个连续时间步长之间的马尔可夫依赖关系可以将生成过程简化为向量化操作，而非迭代），否则这种递归模式是表达时间序列模型的一种非常自然的方式。这种模式的一个强大而通用的形式是<strong>状态空间模型（ Status Space Model ）</strong>，该模型是一个离散时间过程，其中假设在每个时间步，一些隐状态 <span class="math notranslate nohighlight">\(X_t\)</span> 由前一步 <span class="math notranslate nohighlight">\(X_{t-1}\)</span> 演变而来（ 马尔可夫序列 ），而观测值 <span class="math notranslate nohighlight">\(Y_t\)</span> 则是从 <span class="math notranslate nohighlight">\(X_t\)</span> 所在的隐状态空间到观测空间的某种投影 <a class="footnote-reference brackets" href="#id67" id="id31">12</a> ：</p>
<div class="math notranslate nohighlight" id="equation-eq-state-space-model">
<span class="eqno">(55)<a class="headerlink" href="#equation-eq-state-space-model" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{split}
X_0 &amp; \sim p(X_0) \\
\text{for t in 0...T:} \\
 Y_t &amp; \sim p^{\psi}(Y_t \mid X_t) \\
 X_{t+1} &amp; \sim p^{\theta}(X_{t+1} \mid X_{t})
\end{split}\end{split}\]</div>
<p>其中 <span class="math notranslate nohighlight">\(p(X_0)\)</span> 是时间步 <span class="math notranslate nohighlight">\(0\)</span> 处隐状态的先验分布，<span class="math notranslate nohighlight">\(p^{\theta}(X_{t+1} \mid X_t)\)</span> 是由参数向量 <span class="math notranslate nohighlight">\(\theta\)</span> 参数化的转移概率， 其中 <span class="math notranslate nohighlight">\(\theta\)</span> 描述了系统动力学。<span class="math notranslate nohighlight">\(p^{\psi}(Y_t \mid X_t)\)</span> 是由参数向量 <span class="math notranslate nohighlight">\(\psi\)</span> 参数化的观测概率，描述了时间 <span class="math notranslate nohighlight">\(t\)</span> 时隐状态条件下的测量值。</p>
<div class="admonition- admonition">
<p class="admonition-title">实现高效计算的状态空间模型</p>
<p>使用 <code class="docutils literal notranslate"><span class="pre">tf.while_loop</span></code> 或 <code class="docutils literal notranslate"><span class="pre">tf.scan</span></code>  等 API 实现的状态空间模型和数学公式之间存在某种调谐。与使用 Python 的 <code class="docutils literal notranslate"><span class="pre">for</span></code> 循环或 <code class="docutils literal notranslate"><span class="pre">while</span></code> 循环不同，在 TFP 中，需要将循环体编译成一个函数，该函数采用相同的张量结构作为输入和输出。这种函数风格的实现方式有助于显式表示 “在每个时间步隐状态是如何转换的？” 以及 “隐状态如果转换到为观测结果的？”。值得注意的是，实现状态空间模型及其相关推断算法（ 如卡尔曼滤波器 ）也涉及在何处放置初始计算的设计决策。在上式中，我们在初始隐条件上放置了一个先验，并且第一个观测值直接来自初始状态的测量值。不过，在第 <span class="math notranslate nohighlight">\(0\)</span> 步中，对隐状态进行转换同样有效，然后通过修改先验分布进行第一次观测，这两种方法是等效的。</p>
<p>然而，在为时间序列问题实现滤波器时，在形状处理上有一些微妙的技巧。主要挑战是时间维度的放置位置。一个明显选择是将其放置在轴 <span class="math notranslate nohighlight">\(0\)</span> 上，因为使用 <code class="docutils literal notranslate"><span class="pre">t</span></code> 作为时间索引来执行 <code class="docutils literal notranslate"><span class="pre">time_series[t]</span></code> 是很自然的事情。使用 <code class="docutils literal notranslate"><span class="pre">tf.scan</span></code> 或 <code class="docutils literal notranslate"><span class="pre">theano.scan</span></code> 等循环结构在时间序列上实现循环时，会自动将时间维度放在轴 <span class="math notranslate nohighlight">\(0\)</span> 上。但是，这与通常作为引导轴的批处理维有冲突。例如，如果我们想对 <span class="math notranslate nohighlight">\(N\)</span> 批 <span class="math notranslate nohighlight">\(k\)</span> 维时间序列进行向量化，每个时间序列总共有 <span class="math notranslate nohighlight">\(T\)</span> 个时间戳，则数组的形状为 <code class="docutils literal notranslate"><span class="pre">[N,</span> <span class="pre">T,</span> <span class="pre">...]</span></code>，但 <code class="docutils literal notranslate"><span class="pre">tf.scan</span> </code> 的输出形状为 <code class="docutils literal notranslate"><span class="pre">[T,</span> <span class="pre">N,</span> <span class="pre">...]</span></code> 。目前，建模人员似乎不可避免地需要对 <code class="docutils literal notranslate"><span class="pre">scan</span></code> 的输出执行转置，以使其与输入张量的批处理维和时间维语义相匹配。</p>
</div>
<p>一旦有了时间序列问题的状态空间表示，我们就处在了一个序列分析框架中。该框架通常包括滤波和平滑等任务：</p>
<ul class="simple">
<li><p>滤波：</p>
<ul>
<li><p>以 <span class="math notranslate nohighlight">\(k\)</span> 时间步之前（含 <span class="math notranslate nohighlight">\(k\)</span> ）的观测作为条件，计算隐状态 <span class="math notranslate nohighlight">\(X_k\)</span> 的边缘分布：<span class="math notranslate nohighlight">\(p(X_k \mid y_{0:k}), k = 0,...,T \)</span> ；</p></li>
<li><p><span class="math notranslate nohighlight">\(\circ\)</span> 预测：隐状态的预测分布，将滤波分布扩展到未来 <span class="math notranslate nohighlight">\(n\)</span> 步：<span class="math notranslate nohighlight">\(p(X_k+n \mid y_{0:k}), k = 0,... ,T, n=1, 2,...\)</span></p></li>
</ul>
</li>
<li><p>平滑：</p>
<ul>
<li><p>类似于滤波，但我们尝试以所有观测为条件，计算隐状态 <span class="math notranslate nohighlight">\(X_k\)</span> 的边缘分布：<span class="math notranslate nohighlight">\(p(X_k \mid y_{0:T}), k = 0 ,...,T\)</span> 。</p></li>
</ul>
</li>
</ul>
<p>注意 <span class="math notranslate nohighlight">\(y_{0:\dots}\)</span> 的下标在滤波和平滑方面有所不同：滤波以 <span class="math notranslate nohighlight">\(y_{0:k}\)</span> 为条件，而平滑以 <span class="math notranslate nohighlight">\(y_{0:T}\)</span> 为条件。</p>
<p>事实上，从滤波和平滑的角度考虑时间序列建模有着悠久的传统。例如，我们计算上述 ARMA 过程的对数似然的方式，可以看作是一个滤波问题，其中观测数据被解构为一些隐含的不可观测状态。</p>
<div class="section" id="lgssm-time-series">
<span id="id32"></span><h3>6.4.1 线性高斯状态空间模型与卡尔曼滤波<a class="headerlink" href="#lgssm-time-series" title="Permalink to this headline">¶</a></h3>
<p>线性高斯状态空间模型也许是最著名的状态空间模型。在该模型中，有隐状态 <span class="math notranslate nohighlight">\(X_t\)</span> ，并且假设观测 <span class="math notranslate nohighlight">\(Y_t\)</span> 呈（多元）高斯分布，其中状态转移和测量都是线性函数：</p>
<div class="math notranslate nohighlight" id="equation-eq-lgssm">
<span class="eqno">(56)<a class="headerlink" href="#equation-eq-lgssm" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{split}
Y_t &amp; = \mathbf{H}_t X_t + \epsilon_t \\
X_t &amp; = \mathbf{F}_t X_{t-1} + \eta_t
\end{split}\end{split}\]</div>
<p>其中 <span class="math notranslate nohighlight">\(\epsilon_t \sim \mathcal{N}(0, \mathbf{R}_t)\)</span> 和 <span class="math notranslate nohighlight">\(\eta_t \sim \mathcal{N}(0, \mathbf{Q}_t)\)</span> 是噪声分量。</p>
<p>变量 (<span class="math notranslate nohighlight">\(\mathbf{H}_t\)</span>, <span class="math notranslate nohighlight">\(\mathbf{F}_t\)</span>) 是描述线性变换的矩阵，通常 <span class="math notranslate nohighlight">\(\mathbf{F}_t\)</span> 是方阵，<span class="math notranslate nohighlight">\(\mathbf{H} _t\)</span> 的秩低于 <span class="math notranslate nohighlight">\(\mathbf{F}_t\)</span>，它将状态从隐空间 “推进” 到测量空间。 <span class="math notranslate nohighlight">\(\mathbf{R}_t\)</span>, <span class="math notranslate nohighlight">\(\mathbf{Q}_t\)</span> 是协方差矩阵（正半定矩阵）。你还可以在章节 <a class="reference internal" href="chp_11.html#markov-chains"><span class="std std-ref">马尔可夫链</span></a> 中找到一些比较直观的转移矩阵示例。</p>
<p>由于 <span class="math notranslate nohighlight">\(\epsilon_t\)</span> 和 <span class="math notranslate nohighlight">\(\eta_t\)</span> 都是服从高斯分布的随机变量，因此上述线性函数实际上是对高斯随机变量做了仿射变换，导致 <span class="math notranslate nohighlight">\(X_t\)</span> 和 <span class="math notranslate nohighlight">\(Y_t\)</span> 也服从高斯分布。也就是说，先验（ <span class="math notranslate nohighlight">\(t-1\)</span> 时的状态 ）和后验（ <span class="math notranslate nohighlight">\(t\)</span> 时的状态 ）之间存在共轭性质，这使得获得贝叶斯滤波公式的解析解成为可能，即<strong>卡尔曼滤波器</strong>（Kalman，1960）。作为共轭贝叶斯模型最重要的应用之一，卡尔曼滤波器帮助人类登陆月球，并且至今在许多领域仍然被广泛使用。</p>
<p>为了直观地理解卡尔曼滤波器，首先看一下线性高斯状态空间模型从时间 <span class="math notranslate nohighlight">\(t-1\)</span> 到 <span class="math notranslate nohighlight">\(t\)</span> 的生成过程：</p>
<div class="math notranslate nohighlight" id="equation-eq-lgssm-generative">
<span class="eqno">(57)<a class="headerlink" href="#equation-eq-lgssm-generative" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{split}
X_t \sim p(X_t \mid X_{t-1}) &amp; \equiv \mathcal{N}(\mathbf{F}_{t} X_{t-1}, \mathbf{Q}_{t}) \\
Y_t \sim p(Y_t \mid X_t) &amp; \equiv \mathcal{N}(\mathbf{H}_t X_t, \mathbf{R}_t)
\end{split}\end{split}\]</div>
<p>其中 <span class="math notranslate nohighlight">\(X_t\)</span> 和 <span class="math notranslate nohighlight">\(Y_t\)</span> 的条件概率分布表示为 <span class="math notranslate nohighlight">\(p(.)\)</span>（ 此处使用 <span class="math notranslate nohighlight">\(\equiv\)</span> 表示该条件分布为多元高斯分布 ）。请注意，<span class="math notranslate nohighlight">\(X_t\)</span> 仅取决于上一个时间步的状态 <span class="math notranslate nohighlight">\(X_{t-1}\)</span> ，而不取决于历史观测。这意味着，生成过程可以首先生成一个隐时间序列 <span class="math notranslate nohighlight">\(X_t,\ t = 0...T\)</span> ， 然后再将整个隐时间序列投射到观测空间中。在贝叶斯滤波上下文中，<span class="math notranslate nohighlight">\(Y_t\)</span> 是可观测的，因此被用于更新状态 <span class="math notranslate nohighlight">\(X_t\)</span>，类似于在静态模型中用（观测数据的）似然去更新先验：</p>
<div class="math notranslate nohighlight" id="equation-eq-kalman-fitler">
<span class="eqno">(58)<a class="headerlink" href="#equation-eq-kalman-fitler" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{split}
X_0 \sim p(X_0 \mid m_0, \mathbf{P}_0) &amp; \equiv \mathcal{N}(m_0, \mathbf{P}_0) \\
X_{t \mid t-1} \sim p(X_{t \mid t-1} \mid Y_{0:t-1}) &amp; \equiv \mathcal{N}(m_{t \mid t-1}, \mathbf{P}_{t \mid t-1}) \\
X_{t \mid t} \sim p(X_{t \mid t} \mid Y_{0:t}) &amp; \equiv \mathcal{N}(m_{t \mid t}, \mathbf{P}_{t \mid t}) \\
Y_t \sim p(Y_t \mid Y_{0:t-1}) &amp; \equiv \mathcal{N}(\mathbf{H}_t m_{t \mid t-1}, \mathbf{S}_t)
\end{split}\end{split}\]</div>
<p>其中 <span class="math notranslate nohighlight">\(m_t\)</span> 和 <span class="math notranslate nohighlight">\(\mathbf{P}_t\)</span> 表示隐状态 <span class="math notranslate nohighlight">\(X_t\)</span> 的均值和协方差矩阵。 <span class="math notranslate nohighlight">\(X_{t \mid t-1}\)</span> 是参数 <span class="math notranslate nohighlight">\(m_{t \mid t-1}\)</span> （预测均值）和 <span class="math notranslate nohighlight">\(\mathbf{P}_{t \mid t-1}\)</span> （预测协方差）下预测隐状态，而 <span class="math notranslate nohighlight">\(X_{t \mid t}\)</span> 是参数 <span class="math notranslate nohighlight">\(m_{t \mid t}\)</span> 和 <span class="math notranslate nohighlight">\(\mathbf{P}_{t \mid t}\)</span>下的滤波后隐状态。</p>
<p>公式 <a class="reference internal" href="#equation-eq-kalman-fitler">(58)</a> 中的下标容易让人感到困惑，因此需要有一个如下的高层视图：从上一个时间步开始，我们有一个滤波状态 <span class="math notranslate nohighlight">\(X_{t-1 \mid t-1} \)</span>，在应用转移矩阵 <span class="math notranslate nohighlight">\(\mathbf{F}_{t}\)</span> 后，我们得到一个预测状态 <span class="math notranslate nohighlight">\(X_{t \mid t-1}\)</span>，结合当前时间步的观测，我们得到滤波后的新状态 <span class="math notranslate nohighlight">\(X_{t \mid t}\)</span> 。</p>
<p>公式 <a class="reference internal" href="#equation-eq-kalman-fitler">(58)</a> 中，上述分布的参数是利用卡尔曼滤波的预测和更新步骤计算的：</p>
<ul>
<li><p>预测步骤：</p>
<div class="math notranslate nohighlight" id="equation-eq-kalman-fitler-preddict-step">
<span class="eqno">(59)<a class="headerlink" href="#equation-eq-kalman-fitler-preddict-step" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{split}
m_{t \mid t-1} &amp; = \mathbf{F}_{t} m_{t-1 \mid t-1} \\
\mathbf{P}_{t \mid t-1} &amp; = \mathbf{F}_{t} \mathbf{P}_{t-1 \mid t-1} \mathbf{F}_{t}^T + \mathbf{Q}_{t}
\end{split}\end{split}\]</div>
</li>
<li><p>更新步骤</p>
<div class="math notranslate nohighlight" id="equation-eq-kalman-fitler-update-step">
<span class="eqno">(60)<a class="headerlink" href="#equation-eq-kalman-fitler-update-step" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{split}
z_t &amp; = Y_t - \mathbf{H}_t m_{t \mid t-1} \\
\mathbf{S}_t &amp; = \mathbf{H}_t \mathbf{P}_{t \mid t-1} \mathbf{H}_t^T + \mathbf{R}_t \\
\mathbf{K}_t &amp; = \mathbf{P}_{t \mid t-1} \mathbf{H}_t^T \mathbf{S}_t^{-1} \\
m_{t \mid t} &amp; = m_{t \mid t-1} + \mathbf{K}_t z_t \\
\mathbf{P}_{t \mid t} &amp; = \mathbf{P}_{t \mid t-1} - \mathbf{K}_t \mathbf{S}_t \mathbf{K}_t^T
\end{split}\end{split}\]</div>
</li>
</ul>
<p>卡尔曼滤波方程的推导主要使用了多元高斯联合分布。在实践中，还有一些技巧来确保计算在数值上是稳定的。例如，避免逆矩阵 <span class="math notranslate nohighlight">\(\mathbf{S}_t\)</span> ，在计算 <span class="math notranslate nohighlight">\(\mathbf{P}_{t\mid t}\)</span> 时使用 Jordan 范数更新，以确保结果是正定矩阵 <span id="id33">[<a class="reference internal" href="references.html#id134">59</a>]</span>。在 TFP 中，线性高斯状态空间模型和卡尔曼滤波器可以通过分布<code class="docutils literal notranslate"><span class="pre">tfd.LinearGaussianStateSpaceModel</span></code> 方便地实现。</p>
<p>线性高斯状态空间模型的实际挑战之一是将未知参数表示为高斯隐状态。我们将用一个简单的线性增长时间序列作为第一个示例进行演示（ 参见《贝叶斯滤波和平滑》 <span id="id34">[<a class="reference internal" href="references.html#id129">60</a>]</span> 的第 3 章 ）：</p>
<div class="literal-block-wrapper docutils container" id="linear-growth-model">
<div class="code-block-caption"><span class="caption-number">Listing 91 </span><span class="caption-text">linear_growth_model</span><a class="headerlink" href="#linear-growth-model" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">theta0</span><span class="p">,</span> <span class="n">theta1</span> <span class="o">=</span> <span class="mf">1.2</span><span class="p">,</span> <span class="mf">2.6</span>
<span class="n">sigma</span> <span class="o">=</span> <span class="mf">0.4</span>
<span class="n">num_timesteps</span> <span class="o">=</span> <span class="mi">100</span>

<span class="n">time_stamp</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="n">num_timesteps</span><span class="p">)[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span>
<span class="n">yhat</span> <span class="o">=</span> <span class="n">theta0</span> <span class="o">+</span> <span class="n">theta1</span> <span class="o">*</span> <span class="n">time_stamp</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">yhat</span><span class="p">,</span> <span class="n">sigma</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
</pre></div>
</div>
</div>
<p>你可能会将代码 <a class="reference internal" href="#linear-growth-model"><span class="std std-ref">linear_growth_model</span></a> 识别为简单的线性回归。要将其作为使用卡尔曼滤波器的滤波问题来处理，需要假设测量噪声 <span class="math notranslate nohighlight">\(\sigma\)</span> 已知，未知参数 <span class="math notranslate nohighlight">\(\theta_0\)</span> 和 <span class="math notranslate nohighlight">\(\theta_1\)</span> 服从高斯先验分布。</p>
<p>在状态空间形式中，有隐状态：</p>
<div class="math notranslate nohighlight" id="equation-eq-linear-growth-state">
<span class="eqno">(61)<a class="headerlink" href="#equation-eq-linear-growth-state" title="Permalink to this equation">¶</a></span>\[\begin{split}X_t = \left[\begin{array}{ccc}
  \theta_0 \\
  \theta_1 \\
\end{array}\right]\end{split}\]</div>
<p>由于隐状态不随时间变化，转移矩阵 <span class="math notranslate nohighlight">\(F_t\)</span> 是一个没有转移噪声的单位矩阵。观测矩阵描述了从隐空间到测量空间的“推进”，它是线性函数的矩阵形式 <a class="footnote-reference brackets" href="#id68" id="id35">13</a> ：</p>
<div class="math notranslate nohighlight" id="equation-eq-linear-growth-observed-state">
<span class="eqno">(62)<a class="headerlink" href="#equation-eq-linear-growth-observed-state" title="Permalink to this equation">¶</a></span>\[\begin{split}y_t = \theta_0 + \theta_1 * t = \left[\begin{array}{ccc}
  1, t \\
\end{array}\right]\left[\begin{array}{ccc}
  \theta_0 \\
  \theta_1 \\
\end{array}\right]\end{split}\]</div>
<p>用 <code class="docutils literal notranslate"><span class="pre">tfd.LinearGaussianStateSpaceModel</span></code> API 表示，我们有：</p>
<div class="literal-block-wrapper docutils container" id="tfd-lgssm-linear-growth">
<div class="code-block-caption"><span class="caption-number">Listing 92 </span><span class="caption-text">tfd_lgssm_linear_growth</span><a class="headerlink" href="#tfd-lgssm-linear-growth" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># X_0</span>
<span class="n">initial_state_prior</span> <span class="o">=</span> <span class="n">tfd</span><span class="o">.</span><span class="n">MultivariateNormalDiag</span><span class="p">(</span>
    <span class="n">loc</span><span class="o">=</span><span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span> <span class="n">scale_diag</span><span class="o">=</span><span class="p">[</span><span class="mf">5.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">])</span>
<span class="c1"># F_t</span>
<span class="n">transition_matrix</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">_</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">LinearOperatorIdentity</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="c1"># eta_t ~ Normal(0, Q_t)</span>
<span class="n">transition_noise</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">_</span><span class="p">:</span> <span class="n">tfd</span><span class="o">.</span><span class="n">MultivariateNormalDiag</span><span class="p">(</span>
    <span class="n">loc</span><span class="o">=</span><span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span> <span class="n">scale_diag</span><span class="o">=</span><span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">])</span>
<span class="c1"># H_t</span>
<span class="n">H</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">tf</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">time_stamp</span><span class="p">),</span> <span class="n">time_stamp</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">observation_matrix</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">LinearOperatorFullMatrix</span><span class="p">(</span>
    <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">t</span><span class="p">)])</span>
<span class="c1"># epsilon_t ~ Normal(0, R_t)</span>
<span class="n">observation_noise</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">_</span><span class="p">:</span> <span class="n">tfd</span><span class="o">.</span><span class="n">MultivariateNormalDiag</span><span class="p">(</span>
    <span class="n">loc</span><span class="o">=</span><span class="p">[</span><span class="mf">0.</span><span class="p">],</span> <span class="n">scale_diag</span><span class="o">=</span><span class="p">[</span><span class="n">sigma</span><span class="p">])</span>

<span class="n">linear_growth_model</span> <span class="o">=</span> <span class="n">tfd</span><span class="o">.</span><span class="n">LinearGaussianStateSpaceModel</span><span class="p">(</span>
    <span class="n">num_timesteps</span><span class="o">=</span><span class="n">num_timesteps</span><span class="p">,</span>
    <span class="n">transition_matrix</span><span class="o">=</span><span class="n">transition_matrix</span><span class="p">,</span>
    <span class="n">transition_noise</span><span class="o">=</span><span class="n">transition_noise</span><span class="p">,</span>
    <span class="n">observation_matrix</span><span class="o">=</span><span class="n">observation_matrix</span><span class="p">,</span>
    <span class="n">observation_noise</span><span class="o">=</span><span class="n">observation_noise</span><span class="p">,</span>
    <span class="n">initial_state_prior</span><span class="o">=</span><span class="n">initial_state_prior</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>我们可以应用卡尔曼滤波器获得 <span class="math notranslate nohighlight">\(\theta_0\)</span> 和 <span class="math notranslate nohighlight">\(\theta_1\)</span> 的后验分布：</p>
<div class="literal-block-wrapper docutils container" id="tfd-lgssm-linear-growth-filter">
<div class="code-block-caption"><span class="caption-number">Listing 93 </span><span class="caption-text">tfd_lgssm_linear_growth_filter</span><a class="headerlink" href="#tfd-lgssm-linear-growth-filter" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Run the Kalman filter</span>
<span class="p">(</span>
    <span class="n">log_likelihoods</span><span class="p">,</span>
    <span class="n">mt_filtered</span><span class="p">,</span> <span class="n">Pt_filtered</span><span class="p">,</span>
    <span class="n">mt_predicted</span><span class="p">,</span> <span class="n">Pt_predicted</span><span class="p">,</span>
    <span class="n">observation_means</span><span class="p">,</span> <span class="n">observation_cov</span>  <span class="c1"># observation_cov is S_t</span>
<span class="p">)</span> <span class="o">=</span> <span class="n">linear_growth_model</span><span class="o">.</span><span class="n">forward_filter</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>我们可以在 <a class="reference internal" href="#fig-fig16-linear-growth-lgssm"><span class="std std-numref">Fig. 117</span></a> 中将卡尔曼滤波器的结果（即迭代地观测每个时间步长）与分析结果（即观测的完整时间序列）进行比较。</p>
<div class="figure align-default" id="fig-fig16-linear-growth-lgssm">
<a class="reference internal image-reference" href="../_images/fig16_linear_growth_lgssm.png"><img alt="../_images/fig16_linear_growth_lgssm.png" src="../_images/fig16_linear_growth_lgssm.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 117 </span><span class="caption-text">线性增长时间序列模型，使用卡尔曼滤波器进行推断。在第一个子图中，展示了观测数据（用虚线连接的灰点）和来自卡尔曼滤波器的单步预测（ 黑色实线中的 <span class="math notranslate nohighlight">\(H_t m_{t \mid t-1}\)</span> ）。在观测每个时间步之后，将隐状态 <span class="math notranslate nohighlight">\(X_t\)</span> 的后验分布与使用中间和最右侧子图中的所有数据的解析解（黑色实线）进行比较。</span><a class="headerlink" href="#fig-fig16-linear-growth-lgssm" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="section" id="arim">
<span id="arima-expressed-as-a-state-space-model"></span><h3>6.4.2 表示为状态空间模型的 ARIM<a class="headerlink" href="#arim" title="Permalink to this headline">¶</a></h3>
<p>状态空间模型是一种概括了许多经典时间序列模型的统一方法。但如何以状态空间形式表达传统模型可能并不总是很明显。在本节中，我们将了解如何表达更复杂的线性高斯状态空间模型：ARMA 和 ARIMA。</p>
<p>回想上面的 <span class="math notranslate nohighlight">\(ARMA(p,q)\)</span> 公式 <a class="reference internal" href="#equation-eq-arma">(53)</a>，我们有自回归系数参数 <span class="math notranslate nohighlight">\(\phi_i\)</span>、移动平均系数 <span class="math notranslate nohighlight">\(\theta_j\)</span> 和噪声参数 <span class="math notranslate nohighlight">\(\sigma\)</span> 。使用 <span class="math notranslate nohighlight">\(\sigma\)</span> 来参数化观测噪声的分布 <span class="math notranslate nohighlight">\(R_t\)</span> 很具有吸引力。</p>
<p>然而，在 <span class="math notranslate nohighlight">\(ARMA(p,q)\)</span> 公式 <a class="reference internal" href="#equation-eq-arma">(53)</a> 中，利用先前步骤的噪声所做的移动平均，要求我们 “记录” 当前噪声。唯一的解决办法是将其形式化为转移噪声，使其成为隐状态 <span class="math notranslate nohighlight">\(X_t\)</span> 的一部分。我们将 <span class="math notranslate nohighlight">\(ARMA(p,q)\)</span> 公式 <a class="reference internal" href="#equation-eq-arma">(53)</a> 重新表述为：</p>
<div class="math notranslate nohighlight" id="equation-eq-arma-pre-lgssm">
<span class="eqno">(63)<a class="headerlink" href="#equation-eq-arma-pre-lgssm" title="Permalink to this equation">¶</a></span>\[y_t = \sum_{i=1}^{r}\phi_i y_{t-i} + \sum_{i=1}^{r-1}\theta_i \epsilon_{t-i} + \epsilon_t\]</div>
<p>其中公式 <a class="reference internal" href="#equation-eq-arma">(53)</a> 中的常数项 <span class="math notranslate nohighlight">\(\alpha\)</span> 被省略，<span class="math notranslate nohighlight">\(r = \max(p, q+1)\)</span>。我们在需要时用零来填充（ pad ）参数 <span class="math notranslate nohighlight">\(\phi\)</span> 和 <span class="math notranslate nohighlight">\(\theta\)</span> ，以便其具有相同的大小 <span class="math notranslate nohighlight">\(r\)</span>。因此状态方程中的 <span class="math notranslate nohighlight">\(X_t\)</span> 分量为：</p>
<div class="math notranslate nohighlight" id="equation-eq-arma-lgssm-state-fn">
<span class="eqno">(64)<a class="headerlink" href="#equation-eq-arma-lgssm-state-fn" title="Permalink to this equation">¶</a></span>\[\begin{split}\mathbf{F}_t = \mathbf{F} = \left[\begin{array}{cccc}
\phi_1 &amp; 1 &amp; \cdots &amp; 0 \\
\vdots  &amp; \vdots  &amp; \ddots &amp; \vdots  \\
\phi_{r-1} &amp; 0 &amp; \cdots &amp; 1  \\
\phi_r &amp; 0 &amp; \cdots &amp; 0 
\end{array}\right], \\
\mathbf{A} = \left[\begin{array}{c}
1\\
\theta_1 \\
\vdots \\
\theta_{r-1} \\
\end{array}\right],
\eta'_{t+1} \sim \mathcal{N}(0, \sigma^2), \eta_t = \mathbf{A} \eta'_{t+1}\end{split}\]</div>
<p>隐状态为：</p>
<div class="math notranslate nohighlight" id="equation-eq-arma-lgssm-state">
<span class="eqno">(65)<a class="headerlink" href="#equation-eq-arma-lgssm-state" title="Permalink to this equation">¶</a></span>\[\begin{split}X_t = \left[\begin{array}{ccc}
y_t \\
\phi_2 y_{t-1} + \dots + \phi_r y_{t-r+1} + \theta_1 \eta'_t + \dots + \theta_{r-1} \eta'_{t-r+2} \\
\phi_3 y_{t-1} + \dots + \phi_r y_{t-r+2} + \theta_2 \eta'_t + \dots + \theta_{r-1} \eta'_{t-r+3} \\
\vdots \\
\phi_r y_{t-1} + \theta_{r-1} \eta'_t
\end{array}\right]\end{split}\]</div>
<p>观测矩阵只是一个索引矩阵 <span class="math notranslate nohighlight">\(\mathbf{H}_t = [1, 0, 0, \dots, 0]\)</span>，观测公式为 <span class="math notranslate nohighlight">\(y_t = \mathbf{H}_t X_t\)</span> <a class="footnote-reference brackets" href="#id69" id="id36">14</a> 。</p>
<p>例如，状态空间表示中的 <span class="math notranslate nohighlight">\(ARMA(2,1)\)</span> 模型是：</p>
<div class="math notranslate nohighlight" id="equation-eq-arma-lgssm-state-full">
<span class="eqno">(66)<a class="headerlink" href="#equation-eq-arma-lgssm-state-full" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{split}
\left[\begin{array}{ccc}
y_{t+1}\\
\phi_2 y_t + \theta_1 \eta'_{t+1}\\
\end{array}\right] &amp; =  
\left[\begin{array}{ccc}
\phi_1 &amp; 1\\
\phi_2 &amp; 0\\
\end{array}\right]
\left[\begin{array}{ccc}
y_t\\
\phi_2 y_{t-1} + \theta_1 \eta'_t\\
\end{array}\right] + \left[\begin{array}{ccc}
1\\
\theta_1\\
\end{array}\right] \eta'_{t+1}\\
\eta'_{t+1} &amp; \sim \mathcal{N}(0, \sigma^2)
\end{split}\end{split}\]</div>
<p>你可能注意到状态转移与上面定义的略有不同，因为转换噪声不是从多元高斯分布中抽取的。 <span class="math notranslate nohighlight">\(\eta\)</span> 的协方差矩阵是 <span class="math notranslate nohighlight">\(\mathbf{Q}_t = \mathbf{A} \sigma^2 \mathbf{A}^T\)</span> ，在这种情况下会产生奇异的随机变量 <span class="math notranslate nohighlight">\(\eta\)</span> 。但无论如何，我们可以在 TFP 中定义模型了。例如，在代码 <a class="reference internal" href="#tfd-lgssm-arma-simulate"><span class="std std-ref">tfd_lgssm_arma_simulate</span></a> 中，我们定义了一个 <span class="math notranslate nohighlight">\(ARMA(2,1)\)</span> 模型，其中 <span class="math notranslate nohighlight">\(\phi = [-0.1, 0.5]\)</span> 、 <span class="math notranslate nohighlight">\(\theta = -0.25\)</span> 、 <span class="math notranslate nohighlight">\(\sigma = 1.25\)</span> ，并抽取了一个随机时间序列。</p>
<div class="literal-block-wrapper docutils container" id="tfd-lgssm-arma-simulate">
<div class="code-block-caption"><span class="caption-number">Listing 94 </span><span class="caption-text">tfd_lgssm_arma_simulate</span><a class="headerlink" href="#tfd-lgssm-arma-simulate" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">num_timesteps</span> <span class="o">=</span> <span class="mi">300</span>
<span class="n">phi1</span> <span class="o">=</span> <span class="o">-</span><span class="mf">.1</span>
<span class="n">phi2</span> <span class="o">=</span> <span class="mf">.5</span>
<span class="n">theta1</span> <span class="o">=</span> <span class="o">-</span><span class="mf">.25</span>
<span class="n">sigma</span> <span class="o">=</span> <span class="mf">1.25</span>

<span class="c1"># X_0</span>
<span class="n">initial_state_prior</span> <span class="o">=</span> <span class="n">tfd</span><span class="o">.</span><span class="n">MultivariateNormalDiag</span><span class="p">(</span>
   <span class="n">scale_diag</span><span class="o">=</span><span class="p">[</span><span class="n">sigma</span><span class="p">,</span> <span class="n">sigma</span><span class="p">])</span>
<span class="c1"># F_t</span>
<span class="n">transition_matrix</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">_</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">LinearOperatorFullMatrix</span><span class="p">(</span>
   <span class="p">[[</span><span class="n">phi1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="n">phi2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="c1"># eta_t ~ Normal(0, Q_t)</span>
<span class="n">R_t</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="n">sigma</span><span class="p">],</span> <span class="p">[</span><span class="n">sigma</span><span class="o">*</span><span class="n">theta1</span><span class="p">]])</span>
<span class="n">Q_t_tril</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">R_t</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">R_t</span><span class="p">)],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">transition_noise</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">_</span><span class="p">:</span> <span class="n">tfd</span><span class="o">.</span><span class="n">MultivariateNormalTriL</span><span class="p">(</span>
   <span class="n">scale_tril</span><span class="o">=</span><span class="n">Q_t_tril</span><span class="p">)</span>
<span class="c1"># H_t</span>
<span class="n">observation_matrix</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">LinearOperatorFullMatrix</span><span class="p">(</span>
   <span class="p">[[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]])</span>
<span class="c1"># epsilon_t ~ Normal(0, 0)</span>
<span class="n">observation_noise</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">_</span><span class="p">:</span> <span class="n">tfd</span><span class="o">.</span><span class="n">MultivariateNormalDiag</span><span class="p">(</span>
   <span class="n">loc</span><span class="o">=</span><span class="p">[</span><span class="mf">0.</span><span class="p">],</span> <span class="n">scale_diag</span><span class="o">=</span><span class="p">[</span><span class="mf">0.</span><span class="p">])</span>

<span class="n">arma</span> <span class="o">=</span> <span class="n">tfd</span><span class="o">.</span><span class="n">LinearGaussianStateSpaceModel</span><span class="p">(</span>
   <span class="n">num_timesteps</span><span class="o">=</span><span class="n">num_timesteps</span><span class="p">,</span>
   <span class="n">transition_matrix</span><span class="o">=</span><span class="n">transition_matrix</span><span class="p">,</span>
   <span class="n">transition_noise</span><span class="o">=</span><span class="n">transition_noise</span><span class="p">,</span>
   <span class="n">observation_matrix</span><span class="o">=</span><span class="n">observation_matrix</span><span class="p">,</span>
   <span class="n">observation_noise</span><span class="o">=</span><span class="n">observation_noise</span><span class="p">,</span>
   <span class="n">initial_state_prior</span><span class="o">=</span><span class="n">initial_state_prior</span>
   <span class="p">)</span>

<span class="n">sim_ts</span> <span class="o">=</span> <span class="n">arma</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>  <span class="c1"># Simulate from the model</span>
</pre></div>
</div>
</div>
<p>添加适当先验并做一些重写可以更好地处理形状，我们在代码 <a class="reference internal" href="#tfd-lgssm-arma-with-prior"><span class="std std-ref">tfd_lgssm_arma_with_prior</span></a> 中得到一个完整的生成式 <span class="math notranslate nohighlight">\(ARMA(2,1)\)</span> 模型。</p>
<p>由于使用了 <code class="docutils literal notranslate"><span class="pre">tfd.JointDistributionCoroutine</span></code> 模型，因此对（模拟的）数据 <code class="docutils literal notranslate"><span class="pre">sim_ts</span></code> 和推断进行调整非常简单。请注意，未知参数并非隐状态 <span class="math notranslate nohighlight">\(X_t\)</span> 的一部分，因此不能像卡尔曼滤波一样做贝叶斯滤波推导，而是使用标准的 MCMC 方法进行推断。我们在 <a class="reference internal" href="#fig-fig17-arma-lgssm-inference-result"><span class="std std-numref">Fig. 118</span></a> 中展示了后验样本的轨迹图。</p>
<div class="literal-block-wrapper docutils container" id="tfd-lgssm-arma-with-prior">
<div class="code-block-caption"><span class="caption-number">Listing 95 </span><span class="caption-text">tfd_lgssm_arma_with_prior</span><a class="headerlink" href="#tfd-lgssm-arma-with-prior" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@tfd</span><span class="o">.</span><span class="n">JointDistributionCoroutine</span>
<span class="k">def</span> <span class="nf">arma_lgssm</span><span class="p">():</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">root</span><span class="p">(</span><span class="n">tfd</span><span class="o">.</span><span class="n">HalfStudentT</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">"sigma"</span><span class="p">))</span>
    <span class="n">phi</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">root</span><span class="p">(</span><span class="n">tfd</span><span class="o">.</span><span class="n">Sample</span><span class="p">(</span><span class="n">tfd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="mi">2</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">"phi"</span><span class="p">))</span>
    <span class="n">theta</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">root</span><span class="p">(</span><span class="n">tfd</span><span class="o">.</span><span class="n">Sample</span><span class="p">(</span><span class="n">tfd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">"theta"</span><span class="p">))</span>
    <span class="c1"># Prior for initial state</span>
    <span class="n">init_scale_diag</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">sigma</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span> <span class="n">sigma</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">]],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">initial_state_prior</span> <span class="o">=</span> <span class="n">tfd</span><span class="o">.</span><span class="n">MultivariateNormalDiag</span><span class="p">(</span>
        <span class="n">scale_diag</span><span class="o">=</span><span class="n">init_scale_diag</span><span class="p">)</span>
    
    <span class="n">F_t</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">phi</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
                     <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">tf</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">phi</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">]),</span>
                                <span class="n">tf</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">phi</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">])],</span>
                               <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">]],</span>
                    <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">transition_matrix</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">_</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">LinearOperatorFullMatrix</span><span class="p">(</span><span class="n">F_t</span><span class="p">)</span>
    
    <span class="n">transition_scale_tril</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span>
        <span class="p">[</span><span class="n">sigma</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span> <span class="n">theta</span> <span class="o">*</span> <span class="n">sigma</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">]],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span>
    <span class="n">scale_tril</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span>
        <span class="p">[</span><span class="n">transition_scale_tril</span><span class="p">,</span>
         <span class="n">tf</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">transition_scale_tril</span><span class="p">)],</span>
        <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">transition_noise</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">_</span><span class="p">:</span> <span class="n">tfd</span><span class="o">.</span><span class="n">MultivariateNormalTriL</span><span class="p">(</span>
        <span class="n">scale_tril</span><span class="o">=</span><span class="n">scale_tril</span><span class="p">)</span>
    
    <span class="n">observation_matrix</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">LinearOperatorFullMatrix</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]])</span>
    <span class="n">observation_noise</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">tfd</span><span class="o">.</span><span class="n">MultivariateNormalDiag</span><span class="p">(</span>
        <span class="n">loc</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">scale_diag</span><span class="o">=</span><span class="p">[</span><span class="mf">0.</span><span class="p">])</span>

    <span class="n">arma</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">tfd</span><span class="o">.</span><span class="n">LinearGaussianStateSpaceModel</span><span class="p">(</span>
            <span class="n">num_timesteps</span><span class="o">=</span><span class="n">num_timesteps</span><span class="p">,</span>
            <span class="n">transition_matrix</span><span class="o">=</span><span class="n">transition_matrix</span><span class="p">,</span>
            <span class="n">transition_noise</span><span class="o">=</span><span class="n">transition_noise</span><span class="p">,</span>
            <span class="n">observation_matrix</span><span class="o">=</span><span class="n">observation_matrix</span><span class="p">,</span>
            <span class="n">observation_noise</span><span class="o">=</span><span class="n">observation_noise</span><span class="p">,</span>
            <span class="n">initial_state_prior</span><span class="o">=</span><span class="n">initial_state_prior</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="s2">"arma"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="figure align-default" id="fig-fig17-arma-lgssm-inference-result">
<a class="reference internal image-reference" href="../_images/fig17_arma_lgssm_inference_result.png"><img alt="../_images/fig17_arma_lgssm_inference_result.png" src="../_images/fig17_arma_lgssm_inference_result.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 118 </span><span class="caption-text">代码 <a class="reference internal" href="#tfd-lgssm-arma-with-prior"><span class="std std-ref">tfd_lgssm_arma_with_prior</span></a> 中的 <span class="math notranslate nohighlight">\(ARMA(2,1)\)</span> 模型 <code class="docutils literal notranslate"><span class="pre">arma_lgssm</span></code> 的 MCMC 采样结果，以代码 <a class="reference internal" href="#tfd-lgssm-arma-simulate"><span class="std std-ref">tfd_lgssm_arma_simulate</span></a> 中生成的模拟数据 <code class="docutils literal notranslate"><span class="pre">sim_ts</span></code> 为条件。参数的真实值在后验密度图中绘制为垂线，在轨迹图中绘制为水平线。</span><a class="headerlink" href="#fig-fig17-arma-lgssm-inference-result" title="Permalink to this image">¶</a></p>
</div>
<p>结合通过预处理观测时间序列以解释积分部分的方法，我们现在已经可以将该形式用于 <span class="math notranslate nohighlight">\(d&gt;0\)</span> 的 ARIMA 建模了。状态空间模型的表达形式为我们提供了一个很重要的优势：我们可以更直接更直观地写下生成过程，而无需在数据预处理步骤中的重复 <span class="math notranslate nohighlight">\(d\)</span> 次差分。</p>
<p>例如，考虑用 <span class="math notranslate nohighlight">\(d=1\)</span> 扩展上面的 <span class="math notranslate nohighlight">\(ARMA(2,1)\)</span> 模型，有 <span class="math notranslate nohighlight">\(\Delta y_t = y_t - y_{t-1}\)</span>，这意味着 <span class="math notranslate nohighlight">\(y_t = y_{t-1} + \Delta y_t\)</span>，我们可以将观测矩阵定义为 <span class="math notranslate nohighlight">\(\mathbf{H}_t = [1, 1, 0]\)</span> ，其中隐状态 <span class="math notranslate nohighlight">\(X_t\)</span> 和状态转移矩阵为：</p>
<div class="math notranslate nohighlight" id="equation-eq-arima-lgssm-state-transition">
<span class="eqno">(67)<a class="headerlink" href="#equation-eq-arima-lgssm-state-transition" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{split}
\left[\begin{array}{ccc}
y_{t-1} + \Delta y_t \\
\phi_1 \Delta y_t + \phi_2 \Delta y_{t-1} + \eta'_{t+1} + \theta_1 \eta'_t\\
\phi_2 \Delta y_t + \theta_1 \eta'_{t+1}\\
\end{array}\right] &amp; =  
\left[\begin{array}{ccc}
1 &amp; 1 &amp; 0 \\
0 &amp; \phi_1 &amp; 1\\
0 &amp; \phi_2 &amp; 0\\
\end{array}\right]
\left[\begin{array}{ccc}
y_{t-1}\\
\Delta y_t \\
\phi_2 \Delta y_{t-1} + \theta_1 \eta'_t\\
\end{array}\right] + \left[\begin{array}{ccc}
0 \\
1 \\
\theta_1\\
\end{array}\right] \eta'_{t+1}
\end{split}\end{split}\]</div>
<p>如你所见，虽然参数化导致更大的隐状态向量 <span class="math notranslate nohighlight">\(X_t\)</span>，但参数的数量保持不变。此外，该模型是在 <span class="math notranslate nohighlight">\(y_t\)</span> 而不是 <span class="math notranslate nohighlight">\(\Delta y_t\)</span> 中生成的。</p>
<p>上述方法在指定初始状态 <span class="math notranslate nohighlight">\(X_0\)</span> 的分布时可能存在挑战，因为第一个元素 ( <span class="math notranslate nohighlight">\(y_0\)</span> ) 现在是非平稳的。在实践中，我们可以在中心化处理（减去均值）之后，围绕时间序列的初始值分配一个信息先验。你可以在 <span id="id37">Durbin and Koopman [<a class="reference internal" href="references.html#id131">61</a>]</span> 中找到有关此主题的更多讨论，以及对状态空间模型的深入介绍。</p>
</div>
<div class="section" id="bayesian-structural-time-series">
<span id="id38"></span><h3>6.4.3 贝叶斯结构时间序列<a class="headerlink" href="#bayesian-structural-time-series" title="Permalink to this headline">¶</a></h3>
<p>时间序列模型的线性高斯状态空间表达形式具有另一个优点，即它很容易与其他线性高斯状态空间模型一起扩展。为了将两个模型组合在一起，我们可以对隐空间中的两个正态随机变量做连接。我们使用两个协方差矩阵生成一个块对角矩阵，连接事件轴上的均值。在测量空间中，该操作相当于对两个正态随机变量求和。</p>
<p>更具体地说，我们有：</p>
<div class="math notranslate nohighlight" id="equation-eq-combining-lgssm">
<span class="eqno">(68)<a class="headerlink" href="#equation-eq-combining-lgssm" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{split}
\mathbf{F}_t &amp; = \left[\begin{array}{ccc}
\mathbf{F}_{\mathbf{1}, t} &amp; 0 \\
0 &amp; \mathbf{F}_{\mathbf{2}, t}\\
\end{array}\right], 
\mathbf{Q}_t = \left[\begin{array}{ccc}
\mathbf{Q}_{\mathbf{1}, t} &amp; 0 \\
0 &amp; \mathbf{Q}_{\mathbf{2}, t}\\
\end{array}\right],
X_t = \left[\begin{array}{ccc}
X_{1,t} \\
X_{2,t}\\
\end{array}\right] \\
\mathbf{H}_t &amp; = \left[\begin{array}{ccc}
\mathbf{H}_{\mathbf{1}, t} &amp; \mathbf{H}_{\mathbf{2}, t} \\
\end{array}\right],
\mathbf{R}_t = \mathbf{R}_{\mathbf{1}, t} + \mathbf{R}_{\mathbf{2}, t}\\
\end{split}\end{split}\]</div>
<p>如果我们有一个不是线性高斯的时间序列模型 <span class="math notranslate nohighlight">\(\mathcal{M}\)</span>。我们还可以将其合并到状态空间模型中。为此，我们将每个时间步的来自 <span class="math notranslate nohighlight">\(\mathcal{M}\)</span> 的预测 <span class="math notranslate nohighlight">\(\hat{\psi}_t\)</span> 视为静态“已知”值，并添加到观测噪声分布 <span class="math notranslate nohighlight">\(\epsilon_t \sim N( \hat{\mu}_t + \hat{\psi}_t, R_t)\)</span>。</p>
<p>从概念上讲，我们可以将其理解为从 <span class="math notranslate nohighlight">\(Y_t\)</span> 中减去 <span class="math notranslate nohighlight">\(\mathcal{M}\)</span> 的预测并对结果进行建模，因此卡尔曼滤波器和其他线性高斯状态空间模型属性仍然成立。</p>
<p>这种<em>可组合性</em>功能可以轻松构建由多个较小的线性高斯状态空间模型分量构建的时间序列模型。我们可以为趋势、季节性和误差项提供单独的状态空间表示，并将它们组合成通常称为<em>结构时间序列</em>模型或动态线性模型的模型。 TFP 提供了一种非常方便的方法来构建贝叶斯结构化时间序列，它使用 <code class="docutils literal notranslate"><span class="pre">tfp.sts</span></code> 模块，以及用于解构分量、进行预测、推断和其他诊断的辅助函数。</p>
<p>例如，我们可以使用具有局部线性趋势分量和季节性分量的结构化时间序列对每月出生数据进行建模，以解释代码 <a class="reference internal" href="#tfp-sts-example2"><span class="std std-ref">tfp_sts_example2</span></a> 中的每月模式。</p>
<div class="literal-block-wrapper docutils container" id="tfp-sts-example2">
<div class="code-block-caption"><span class="caption-number">Listing 96 </span><span class="caption-text">tfp_sts_example2</span><a class="headerlink" href="#tfp-sts-example2" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">generate_bsts_model</span><span class="p">(</span><span class="n">observed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Args:</span>
<span class="sd">        observed: Observed time series, tfp.sts use it to generate prior.</span>
<span class="sd">    """</span>
    <span class="c1"># Trend</span>
    <span class="n">trend</span> <span class="o">=</span> <span class="n">tfp</span><span class="o">.</span><span class="n">sts</span><span class="o">.</span><span class="n">LocalLinearTrend</span><span class="p">(</span><span class="n">observed_time_series</span><span class="o">=</span><span class="n">observed</span><span class="p">)</span>
    <span class="c1"># Seasonal</span>
    <span class="n">seasonal</span> <span class="o">=</span> <span class="n">tfp</span><span class="o">.</span><span class="n">sts</span><span class="o">.</span><span class="n">Seasonal</span><span class="p">(</span><span class="n">num_seasons</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">observed_time_series</span><span class="o">=</span><span class="n">observed</span><span class="p">)</span>
    <span class="c1"># Full model</span>
    <span class="k">return</span> <span class="n">tfp</span><span class="o">.</span><span class="n">sts</span><span class="o">.</span><span class="n">Sum</span><span class="p">([</span><span class="n">trend</span><span class="p">,</span> <span class="n">seasonal</span><span class="p">],</span> <span class="n">observed_time_series</span><span class="o">=</span><span class="n">observed</span><span class="p">)</span>

<span class="n">observed</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">us_monthly_birth</span><span class="p">[</span><span class="s2">"birth_in_thousands"</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">birth_model</span> <span class="o">=</span> <span class="n">generate_bsts_model</span><span class="p">(</span><span class="n">observed</span><span class="o">=</span><span class="n">observed</span><span class="p">)</span>

<span class="c1"># Generate the posterior distribution conditioned on the observed</span>
<span class="n">target_log_prob_fn</span> <span class="o">=</span> <span class="n">birth_model</span><span class="o">.</span><span class="n">joint_log_prob</span><span class="p">(</span><span class="n">observed_time_series</span><span class="o">=</span><span class="n">observed</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>我们可以检查 <code class="docutils literal notranslate"><span class="pre">birth_model</span></code> 中的每个分量：</p>
<div class="literal-block-wrapper docutils container" id="tfp-sts-model">
<div class="code-block-caption"><span class="caption-number">Listing 97 </span><span class="caption-text">tfp_sts_model</span><a class="headerlink" href="#tfp-sts-model" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">birth_model</span><span class="o">.</span><span class="n">components</span>
</pre></div>
</div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>[&lt;tensorflow_probability.python.sts.local_linear_trend.LocalLinearTrend at ...&gt;,
 &lt;tensorflow_probability.python.sts.seasonal.Seasonal at ...&gt;]
</pre></div>
</div>
<p>每个分量都由一些超参数参数化，这些超参数是我们想要进行推断的未知参数。它们不是隐状态 <span class="math notranslate nohighlight">\(X_t\)</span> 的一部分，但可能参数化生成 <span class="math notranslate nohighlight">\(X_t\)</span> 的先验。例如，我们可以检查季节性分量的参数：</p>
<div class="literal-block-wrapper docutils container" id="tfp-sts-model-component">
<div class="code-block-caption"><span class="caption-number">Listing 98 </span><span class="caption-text">tfp_sts_model_component</span><a class="headerlink" href="#tfp-sts-model-component" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">birth_model</span><span class="o">.</span><span class="n">components</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">parameters</span>
</pre></div>
</div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>[Parameter(name='drift_scale', prior=&lt;tfp.distributions.LogNormal 
'Seasonal_LogNormal' batch_shape=[] event_shape=[] dtype=float32&gt;,
bijector=&lt;tensorflow_probability.python.bijectors.chain.Chain object at ...&gt;)]
</pre></div>
</div>
<p>这里 STS 模型的季节性分量包含 12 个隐状态（每个月一个），但该分量仅包含 1 个参数（参数化隐状态的超参数）。你可能已经从上一节中的示例中注意到未知参数的处理方式是如何不同的。在线性增长模型中，未知参数是隐状态 <span class="math notranslate nohighlight">\(X_t\)</span> 的一部分，在 ARIMA 模型中，未知参数参数化 <span class="math notranslate nohighlight">\(\mathbf{F}_t\)</span> 和 <span class="math notranslate nohighlight">\(\mathbf{Q}_t\)</span>。对于后一种情况，我们不能使用卡尔曼滤波器来推断这些参数。</p>
<p>相反，隐状态被有效地边缘化了，但我们仍然可以通过运行以后验分布为条件的卡尔曼滤波器（表示为蒙特卡洛样本）在推断后恢复它们。参数化的概念描述可以在 <a class="reference internal" href="#fig-fig18-bsts-lgssm"><span class="std std-numref">Fig. 119</span></a> 中找到：</p>
<div class="figure align-default" id="fig-fig18-bsts-lgssm">
<a class="reference internal image-reference" href="../_images/fig18_bsts_lgssm.png"><img alt="../_images/fig18_bsts_lgssm.png" src="../_images/fig18_bsts_lgssm.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 119 </span><span class="caption-text">贝叶斯结构时间序列（蓝色框）与线性高斯状态空间模型（红色框）之间的关系。此处显示的线性高斯状态空间模型是一个包含局部线性趋势分量、季节性分量和自回归分量的示例。</span><a class="headerlink" href="#fig-fig18-bsts-lgssm" title="Permalink to this image">¶</a></p>
</div>
<p>因此，对结构时间序列模型进行推断在概念上可以理解为从要推断的参数生成线性高斯状态空间模型，运行卡尔曼滤波器以获得数据似然性，并结合以当前为条件的先验对数似然参数的值。不幸的是，遍历每个数据点的操作在计算上是相当昂贵的（尽管卡尔曼滤波器已经是一种非常有效的算法），因此在运行长时间序列时，拟合结构时间序列可能无法很好地扩展。</p>
<p>在对结构化时间序列模型进行推断之后，我们可以使用来自 <code class="docutils literal notranslate"><span class="pre">tfp.sts</span></code> 的一些有用的实用函数来预测和检查每个带有代码 <a class="reference internal" href="#tfp-sts-example2-result"><span class="std std-ref">tfp_sts_example2_result</span></a> 的推断分量。结果显示在 <a class="reference internal" href="#fig-fig19-bsts-lgssm-result"><span class="std std-numref">Fig. 120</span></a> 中。</p>
<div class="literal-block-wrapper docutils container" id="tfp-sts-example2-result">
<div class="code-block-caption"><span class="caption-number">Listing 99 </span><span class="caption-text">tfp_sts_example2_result</span><a class="headerlink" href="#tfp-sts-example2-result" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Using a subset of posterior samples.</span>
<span class="n">parameter_samples</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="o">-</span><span class="mi">100</span><span class="p">:,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">mcmc_samples</span><span class="p">]</span>

<span class="c1"># Get structual compoenent.</span>
<span class="n">component_dists</span> <span class="o">=</span> <span class="n">tfp</span><span class="o">.</span><span class="n">sts</span><span class="o">.</span><span class="n">decompose_by_component</span><span class="p">(</span>
    <span class="n">birth_model</span><span class="p">,</span>
    <span class="n">observed_time_series</span><span class="o">=</span><span class="n">observed</span><span class="p">,</span>
    <span class="n">parameter_samples</span><span class="o">=</span><span class="n">parameter_samples</span><span class="p">)</span>

<span class="c1"># Get forecast for n_steps.</span>
<span class="n">n_steps</span> <span class="o">=</span> <span class="mi">36</span>
<span class="n">forecast_dist</span> <span class="o">=</span> <span class="n">tfp</span><span class="o">.</span><span class="n">sts</span><span class="o">.</span><span class="n">forecast</span><span class="p">(</span>
    <span class="n">birth_model</span><span class="p">,</span>
    <span class="n">observed_time_series</span><span class="o">=</span><span class="n">observed</span><span class="p">,</span>
    <span class="n">parameter_samples</span><span class="o">=</span><span class="n">parameter_samples</span><span class="p">,</span>
    <span class="n">num_steps_forecast</span><span class="o">=</span><span class="n">n_steps</span><span class="p">)</span>
<span class="n">birth_dates</span> <span class="o">=</span> <span class="n">us_monthly_birth</span><span class="o">.</span><span class="n">index</span>
<span class="n">forecast_date</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">date_range</span><span class="p">(</span>
    <span class="n">start</span><span class="o">=</span><span class="n">birth_dates</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.timedelta64" title="numpy.timedelta64"><span class="n">np</span><span class="o">.</span><span class="n">timedelta64</span></a><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s2">"M"</span><span class="p">),</span>
    <span class="n">end</span><span class="o">=</span><span class="n">birth_dates</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.timedelta64" title="numpy.timedelta64"><span class="n">np</span><span class="o">.</span><span class="n">timedelta64</span></a><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">n_steps</span><span class="p">,</span> <span class="s2">"M"</span><span class="p">),</span>
    <span class="n">freq</span><span class="o">=</span><span class="s2">"M"</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.subplots.html#matplotlib.pyplot.subplots" title="matplotlib.pyplot.subplots"><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span></a><span class="p">(</span>
    <span class="mi">1</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">component_dists</span><span class="o">.</span><span class="n">keys</span><span class="p">()),</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">9</span><span class="p">),</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">us_monthly_birth</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">"observed"</span><span class="p">)</span>

<span class="n">forecast_mean</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.squeeze.html#numpy.squeeze" title="numpy.squeeze"><span class="n">np</span><span class="o">.</span><span class="n">squeeze</span></a><span class="p">(</span><span class="n">forecast_dist</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
<span class="n">line</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">forecast_date</span><span class="p">,</span> <span class="n">forecast_mean</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span>
               <span class="n">label</span><span class="o">=</span><span class="s2">"forecast mean"</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">"C4"</span><span class="p">)</span>

<span class="n">forecast_std</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.squeeze.html#numpy.squeeze" title="numpy.squeeze"><span class="n">np</span><span class="o">.</span><span class="n">squeeze</span></a><span class="p">(</span><span class="n">forecast_dist</span><span class="o">.</span><span class="n">stddev</span><span class="p">())</span>
<span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">forecast_date</span><span class="p">,</span>
                <span class="n">forecast_mean</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">forecast_std</span><span class="p">,</span>
                <span class="n">forecast_mean</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">forecast_std</span><span class="p">,</span>
                <span class="n">color</span><span class="o">=</span><span class="n">line</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get_color</span><span class="p">(),</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

<span class="k">for</span> <span class="n">ax_</span><span class="p">,</span> <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">dist</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="n">component_dists</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
    <span class="n">comp_mean</span><span class="p">,</span> <span class="n">comp_std</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.squeeze.html#numpy.squeeze" title="numpy.squeeze"><span class="n">np</span><span class="o">.</span><span class="n">squeeze</span></a><span class="p">(</span><span class="n">dist</span><span class="o">.</span><span class="n">mean</span><span class="p">()),</span> <a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.squeeze.html#numpy.squeeze" title="numpy.squeeze"><span class="n">np</span><span class="o">.</span><span class="n">squeeze</span></a><span class="p">(</span><span class="n">dist</span><span class="o">.</span><span class="n">stddev</span><span class="p">())</span>
    <span class="n">line</span> <span class="o">=</span> <span class="n">ax_</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">birth_dates</span><span class="p">,</span> <span class="n">dist</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">lw</span><span class="o">=</span><span class="mf">2.</span><span class="p">)</span>
    <span class="n">ax_</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">birth_dates</span><span class="p">,</span>
                     <span class="n">comp_mean</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">comp_std</span><span class="p">,</span>
                     <span class="n">comp_mean</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">comp_std</span><span class="p">,</span>
                     <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
    <span class="n">ax_</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">key</span><span class="o">.</span><span class="n">name</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="figure align-default" id="fig-fig19-bsts-lgssm-result">
<a class="reference internal image-reference" href="../_images/fig19_bsts_lgssm_result.png"><img alt="../_images/fig19_bsts_lgssm_result.png" src="../_images/fig19_bsts_lgssm_result.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 120 </span><span class="caption-text">使用带有代码 <a class="reference internal" href="#tfp-sts-example2-result"><span class="std std-ref">tfp_sts_example2_result</span></a> 的 <code class="docutils literal notranslate"><span class="pre">tfp.sts</span></code> API 推断美国（1948-1979 年）每月活产的结果和预测。上子图：36 个月预测；底部 2 个子图：结构时间序列的分解。</span><a class="headerlink" href="#fig-fig19-bsts-lgssm-result" title="Permalink to this image">¶</a></p>
</div>
</div>
</div>
<div class="section" id="other-time-series-models">
<span id="id39"></span><h2>6.5 其他时间序列模型<a class="headerlink" href="#other-time-series-models" title="Permalink to this headline">¶</a></h2>
<p>虽然结构时间序列和线性高斯状态空间模型是时间序列模型的强大且富有表现力的类别，但它们当然不能满足我们的所有需求。例如，一些有趣的扩展包括非线性高斯状态空间模型，其中转移函数和测量函数是可微分的非线性函数。扩展卡尔曼滤波器可用于推断这些模型 <span id="id40">[<a class="reference internal" href="references.html#id161">62</a>]</span> 的 <span class="math notranslate nohighlight">\(X_t\)</span> 。有用于推断非高斯非线性模型 <span id="id41">[<a class="reference internal" href="references.html#id161">62</a>]</span> 的 Unscented Kalman 滤波器，以及作为状态空间模型 <span id="id42">[<a class="reference internal" href="references.html#id38">63</a>]</span> 的一般滤波方法的粒子滤波器。</p>
<p>另一类广泛使用的时间序列模型是隐马尔可夫模型，它是具有离散状态空间的状态空间模型。还有一些专门的算法可以对这些模型进行推断，例如，用于计算边缘后验似然的前向后向算法，以及用于计算后验模式的 Viterbi 算法。</p>
<p>此外，还有作为连续时间模型的常微分公式 (ODE) 和随机微分公式 (SDE)。</p>
<p>在 <a class="reference internal" href="#table-ts-model-type"><span class="std std-numref">Table 14</span></a> 中，我们通过对随机性和时间的处理来划分模型的空间。虽然我们不会详细介绍这些模型，但它们是经过深入研究的主题，在 Python 计算生态系统中具有易于使用的实现。</p>
<table class="table" id="table-ts-model-type">
<caption><span class="caption-number">Table 14 </span><span class="caption-text">按随机性和时间处理分类的各种时间序列模型</span><a class="headerlink" href="#table-ts-model-type" title="Permalink to this table">¶</a></caption>
<colgroup>
<col style="width: 33%"/>
<col style="width: 33%"/>
<col style="width: 33%"/>
</colgroup>
<tbody>
<tr class="row-odd"><td></td>
<td><p><strong>Deterministic dynamics</strong></p></td>
<td><p><strong>Stochastic dynamics</strong></p></td>
</tr>
<tr class="row-even"><td><p><strong>Discrete time</strong></p></td>
<td><p>automata / discretized ODEs</p></td>
<td><p>state space models</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Continuous time</strong></p></td>
<td><p>ODEs</p></td>
<td><p>SDEs</p></td>
</tr>
</tbody>
</table>
<p>`</p>
</div>
<div class="section" id="model-criticism-and-choosing-priors">
<span id="id43"></span><h2>6.6 模型评判和先验选择<a class="headerlink" href="#model-criticism-and-choosing-priors" title="Permalink to this headline">¶</a></h2>
<p>在 <span id="id44">Box <em>et al.</em> [<a class="reference internal" href="references.html#id130">57</a>]</span> <a class="footnote-reference brackets" href="#id70" id="id45">15</a> 的开创性时间序列书中，他们概述了时间序列建模的五个重要实际问题：</p>
<ul class="simple">
<li><p>预测</p></li>
<li><p>传递函数的估计</p></li>
<li><p>异常干预事件对系统的影响分析</p></li>
<li><p>多元时间序列分析</p></li>
<li><p>离散控制系统</p></li>
</ul>
<p>在实践中，大多数时间序列问题旨在执行某种预测（或即时预测，你试图在瞬时时间 <span class="math notranslate nohighlight">\(t\)</span> 推断一些由于获取测量延迟而尚不可用的观测量），这建立了一个自然的时间序列分析问题中的模型批评标准。虽然我们在本章中没有围绕贝叶斯决策理论进行具体处理，但值得引用 <span id="id46">West and Harrison [<a class="reference internal" href="references.html#id134">59</a>]</span> 的内容：</p>
<blockquote>
<div><p>良好的建模需要认真思考，而良好的预测需要对预测在决策系统中的作用有一个综合的认识。</p>
</div></blockquote>
<p>在实践中，对时间序列模型推断的批评和对预测的评估应与决策过程紧密结合，尤其是如何将不确定性纳入决策。尽管如此，预测绩效可以单独评估。</p>
<p>通常这是通过收集新数据或保留一些保留数据集来完成的，就像我们在本章中对 <span class="math notranslate nohighlight">\(\text{CO}_2\)</span> 示例所做的那样，并使用标准指标将观测结果与预测结果进行比较。一种流行的选择是平均绝对百分比误差 (MAPE)，它简单地计算：</p>
<div class="math notranslate nohighlight" id="equation-eq-mape">
<span class="eqno">(69)<a class="headerlink" href="#equation-eq-mape" title="Permalink to this equation">¶</a></span>\[MAPE = \frac{1}{n} \sum_{i=1}^{n} \frac{|\text{forecast}_i - \text{observed}_i|}{\text{observed}_i}\]</div>
<p>然而，MAPE 存在一些已知的偏差，例如，在低值观测期间的大误差会显着影响 MAPE。</p>
<p>此外，当观测范围差异很大时，很难跨多个时间序列比较 MAPE。</p>
<p>基于交叉验证的模型评估方法仍然适用并推荐用于时间序列模型。但是，如果目标是估计未来时间点的预测性能，则将 LOO 用于单个时间序列将是有问题的。一次简单地忽略一个观测结果并不尊重数据（或模型）的时间结构。例如，如果你删除一个点 <span class="math notranslate nohighlight">\(t\)</span> 并将其余点用于预测，你将使用点 <span class="math notranslate nohighlight">\(t_{-1}, t_{-2}, ...\)</span> 这可能与之前的观测结果一样好（在某种程度上）通知未来的，但你也将使用点 <span class="math notranslate nohighlight">\(t_{+1}, t_{+2}, ...\)</span>，也就是说你将使用未来来预测过去。因此，我们可以计算 LOO，但对得到的数字的解释将是荒谬的，因此会产生误导。我们不需要留下一个（或一些）时间点，而是需要某种形式的保留未来交叉验证（LFO-CV，参见例如 <span id="id47">Bürkner <em>et al.</em> [<a class="reference internal" href="references.html#id123">64</a>]</span>。作为粗略的草图，在初始模型推断之后，为了近似提前 1 步预测，我们将迭代保留时间序列或未来观测结果并评估对数预测密度，并重新拟合模型，包括 Pareto <span class="math notranslate nohighlight">\(k\)</span> 估计超过某个阈值时的特定时间点 [^ 16]. 因此，LFO-CV 不是指一个特定的预测任务，而是指各种可能的交叉验证方法，这些方法都涉及对未来时间点的某种形式的预测。</p>
<div class="section" id="priors-for-time-series-models">
<span id="id48"></span><h3>6.6.1 时间序列模型的先验<a class="headerlink" href="#priors-for-time-series-models" title="Permalink to this headline">¶</a></h3>
<p>在 <a class="reference internal" href="#chp4-gam"><span class="std std-ref">6.2.2 基函数和广义可加模型</span></a> 部分中，我们使用了正则化先验，拉普拉斯先验，用于阶跃线性函数的斜率。正如我们所提到的，这是为了表达我们的先验知识，即斜率的变化通常很小且接近于零，因此产生的潜在趋势更平滑。
正则化先验或稀疏先验的另一个常见用途是模拟假期或特殊日子效果。通常每个假期都有自己的系数，我们想表达一个先验，表明某些假期可能会对时间序列产生巨大影响，但大多数假期就像任何其他普通日子一样。我们可以用马蹄形先验 <span id="id49">[<a class="reference internal" href="references.html#id166">65</a>, <a class="reference internal" href="references.html#id168">66</a>]</span> 将这种直觉形式化，如公式 <a class="reference internal" href="#equation-eq-horse-shoe">(70)</a> 所示：</p>
<div class="math notranslate nohighlight" id="equation-eq-horse-shoe">
<span class="eqno">(70)<a class="headerlink" href="#equation-eq-horse-shoe" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{split}
\lambda_t^2 \sim&amp; \mathcal{H}\text{C}(1.) \\
\beta_t \sim&amp; \mathcal{N}(0, \lambda_t^2 \tau^2)
\end{split}\end{split}\]</div>
<p>马蹄形先验中的全局参数 <span class="math notranslate nohighlight">\(\tau\)</span> 将假日效应的系数全局拉向零。同时，局部尺度 <span class="math notranslate nohighlight">\(\lambda_t\)</span> 的重尾让收缩产生了一些影响。我们可以通过改变 <span class="math notranslate nohighlight">\(\tau\)</span> 的值来适应不同程度的稀疏性：<span class="math notranslate nohighlight">\(\tau\)</span> 越接近于零，假期效应 <span class="math notranslate nohighlight">\(\beta_t\)</span> 的收缩越多，趋向于零，而较大的 <span class="math notranslate nohighlight">\(\tau\)</span>我们有一个更分散的先验 <span id="id50">[<a class="reference internal" href="references.html#id167">67</a>]</span> <a class="footnote-reference brackets" href="#id71" id="id51">17</a>。例如，在 <span id="id52">Riutort-Mayol <em>et al.</em> [<a class="reference internal" href="references.html#id169">68</a>]</span> 的案例研究 2 中，他们为一年中的每一天（包括闰日为 366 天）添加了一个特殊的日效应，并在对其进行正则化之前使用马蹄形。</p>
<p>时间序列模型先验的另一个重要考虑因素是观测噪声的先验。大多数时间序列数据本质上是非重复测量。我们根本无法及时返回并在确切条件下进行另一次观测（即，我们无法量化<strong>偶然</strong>不确定性）。这意味着我们的模型需要先验信息才能“确定”噪声是来自测量还是来自隐过程（即 <strong>epistemic</strong> 不确定性）。例如，在具有隐自回归分量或局部线性趋势模型的时间序列模型中，我们可以将更多信息先验放在观测噪声上，以将其调节为更小的值。这将“推动”趋势或自回归分量以过度拟合潜在的漂移模式，并且我们可能对趋势有更好的预测（短期内预测准确性更高）。风险在于我们对潜在趋势过于自信，从长远来看，这可能会导致预测不佳。在时间序列很可能是非平稳的实际应用程序中，我们应该准备好相应地调整先验。</p>
</div>
</div>
<div class="section" id="exercises6">
<span id="id53"></span><h2>6.7 练习<a class="headerlink" href="#exercises6" title="Permalink to this headline">¶</a></h2>
<p><strong>6E1.</strong> As we explained in Box <em>Parsing timestamp to design matrix</em> above, date information could be formatted into a design matrix for regression model to account for the periodic pattern in a time series. Try generating the following design matrix for the year 2021.</p>
<p>Hint: use Code Block <a class="reference internal" href="#timerange-2021"><span class="std std-ref">timerange_2021</span></a> to generate all time stamps for 2021:</p>
<div class="literal-block-wrapper docutils container" id="timerange-2021">
<div class="code-block-caption"><span class="caption-number">Listing 100 </span><span class="caption-text">timerange_2021</span><a class="headerlink" href="#timerange-2021" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">datetime_index</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">date_range</span><span class="p">(</span><span class="n">start</span><span class="o">=</span><span class="s2">"2021-01-01"</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s2">"2021-12-31"</span><span class="p">,</span> <span class="n">freq</span><span class="o">=</span><span class="s1">'D'</span><span class="p">)</span>
</pre></div>
</div>
</div>
<ul class="simple">
<li><p>A design matrix for day of the month effect.</p></li>
<li><p>A design matrix for weekday vs weekend effect.</p></li>
<li><p>Company G pay their employee on the 25th of every month, and if the  25th falls on a weekend, the payday is moved up to the Friday  before. Try to create a design matrix to encode the pay day of 2021.</p></li>
<li><p>A design matrix for the US Federal holiday effect <a class="footnote-reference brackets" href="#id72" id="id54">18</a> in 2021.</p></li>
</ul>
<p>Create the design matrix so that each holiday has their individual  coefficient.</p>
<p><strong>6E2.</strong> In the previous exercise , the design matrix for holiday effect treat each holiday separately. What if we consider all holiday effects to be the same? What is the shape of the design matrix if we do so? Reason about how does it affects the fit of the regression time series model.</p>
<p><strong>6E3.</strong> Fit a linear regression to the <code class="docutils literal notranslate"><span class="pre">"monthly_mauna_loa_co2.csv"</span></code> dataset:</p>
<ul class="simple">
<li><p>A plain regression with an intercept and slope, using linear time as  predictor.</p></li>
<li><p>A covariate adjusted regression like the square root predictor in  the baby example in Chapter <a class="reference internal" href="chp_04.html#chap3"><span class="std std-ref">4</span></a> Code Block  <a class="reference internal" href="chp_04.html#babies-transformed"><span class="std std-ref">babies_transformed</span></a>.</p></li>
</ul>
<p>Explain what these models are missing compared to Code Block <a class="reference internal" href="#regression-model-for-timeseries"><span class="std std-ref">regression_model_for_timeseries</span></a>.</p>
<p><strong>6E4.</strong> Explain in your own words the difference between regression, autoregressive and state space architectures. In which situation would each be particularly useful.</p>
<p><strong>6M5.</strong> Does using basis function as design matrix actually have better condition number than sparse matrix? Compare the condition number of the following design matrix of the same rank using <code class="docutils literal notranslate"><span class="pre">numpy.linalg.cond</span></code>:</p>
<ul class="simple">
<li><p>Dummy coded design matrix <code class="docutils literal notranslate"><span class="pre">seasonality_all</span></code> from Code Block  <a class="reference internal" href="#generate-design-matrix"><span class="std std-ref">generate_design_matrix</span></a>.</p></li>
<li><p>Fourier basis function design matrix <code class="docutils literal notranslate"><span class="pre">X_pred</span></code> from Code Block  <a class="reference internal" href="#gam"><span class="std std-ref">gam</span></a>.</p></li>
<li><p>An array of the same shape as <code class="docutils literal notranslate"><span class="pre">seasonality_all</span></code> with values drawn  from a Normal distribution.</p></li>
<li><p>An array of the same shape as <code class="docutils literal notranslate"><span class="pre">seasonality_all</span></code> with values drawn  from a Normal distribution <em>and</em> one of the column being identical  to another.</p></li>
</ul>
<p><strong>6M6.</strong> The <code class="docutils literal notranslate"><span class="pre">gen_fourier_basis</span></code> function from Code Block <a class="reference internal" href="#fourier-basis-as-seasonality"><span class="std std-ref">fourier_basis_as_seasonality</span></a> takes a time index <code class="docutils literal notranslate"><span class="pre">t</span></code> as the first input. There are a few different ways to represent the time index, for example, if we are observing some data monthly from 2019 January for 36 months, we can code the time index in 2 equivalent ways as shown below in Code Block <a class="reference internal" href="#exercise-chap4-e6"><span class="std std-ref">exercise_chap4_e6</span></a>:</p>
<div class="literal-block-wrapper docutils container" id="exercise-chap4-e6">
<div class="code-block-caption"><span class="caption-number">Listing 101 </span><span class="caption-text">exercise_chap4_e6</span><a class="headerlink" href="#exercise-chap4-e6" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">nmonths</span> <span class="o">=</span> <span class="mi">36</span>
<span class="n">day0</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Timestamp</span><span class="p">(</span><span class="s1">'2019-01-01'</span><span class="p">)</span>
<span class="n">time_index</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">date_range</span><span class="p">(</span>
    <span class="n">start</span><span class="o">=</span><span class="n">day0</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="n">day0</span> <span class="o">+</span> <a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.timedelta64" title="numpy.timedelta64"><span class="n">np</span><span class="o">.</span><span class="n">timedelta64</span></a><span class="p">(</span><span class="n">nmonths</span><span class="p">,</span> <span class="s1">'M'</span><span class="p">),</span> 
    <span class="n">freq</span><span class="o">=</span><span class="s1">'M'</span><span class="p">)</span>

<span class="n">t0</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.arange.html#numpy.arange" title="numpy.arange"><span class="n">np</span><span class="o">.</span><span class="n">arange</span></a><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">time_index</span><span class="p">))</span>
<span class="n">design_matrix0</span> <span class="o">=</span> <span class="n">gen_fourier_basis</span><span class="p">(</span><span class="n">t0</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>
<span class="n">t1</span> <span class="o">=</span> <span class="n">time_index</span><span class="o">.</span><span class="n">month</span> <span class="o">-</span> <span class="mi">1</span>
<span class="n">design_matrix1</span> <span class="o">=</span> <span class="n">gen_fourier_basis</span><span class="p">(</span><span class="n">t1</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>

<a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.testing.assert_array_almost_equal.html#numpy.testing.assert_array_almost_equal" title="numpy.testing.assert_array_almost_equal"><span class="n">np</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_array_almost_equal</span></a><span class="p">(</span><span class="n">design_matrix0</span><span class="p">,</span> <span class="n">design_matrix1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>What if we are observing the data daily? How would you change the Code Block <a class="reference internal" href="#exercise-chap4-e6"><span class="std std-ref">exercise_chap4_e6</span></a> to:</p>
<ul class="simple">
<li><p>Make <code class="docutils literal notranslate"><span class="pre">time_index</span></code> represent day of the year instead of month of the  year.</p></li>
<li><p>Modify the function signature to <code class="docutils literal notranslate"><span class="pre">gen_fourier_basis</span></code> in line 8 and 10 so that the resulting design matrices coded for the month of the year effect.</p></li>
<li><p>How does the new <code class="docutils literal notranslate"><span class="pre">design_matrix0</span></code> and <code class="docutils literal notranslate"><span class="pre">design_matrix1</span></code> differ? How is the differences would impact the model fitting? Hint: validate your reasoning by multiplying them with the same random regression coefficient.</p></li>
</ul>
<p><strong>6E7.</strong> In Section <a class="reference internal" href="#chap4-ar"><span class="std std-ref">6.3 自回归模型</span></a> we introduced the backshift operator <span class="math notranslate nohighlight">\(\mathbf{B}\)</span>. You might have already noticed that applying the operation <span class="math notranslate nohighlight">\(\mathbf{B}\)</span> on a time series is the same as performing a matrix multiplication. We can generate a matrix <span class="math notranslate nohighlight">\(\mathbf{B}\)</span> explicitly in Python. Modify Code Block <a class="reference internal" href="#ar1-without-forloop"><span class="std std-ref">ar1_without_forloop</span></a> to use an explicit <span class="math notranslate nohighlight">\(\mathbf{B}\)</span> constructed in NumPy or TensorFlow.</p>
<p><strong>6E8.</strong> The step linear function as defined in Equation <a class="reference internal" href="#equation-eq-step-linear-function">(48)</a> and Code Block <a class="reference internal" href="#step-linear-function-for-trend"><span class="std std-ref">step_linear_function_for_trend</span></a> rely on a key regression coefficient <span class="math notranslate nohighlight">\(\delta\)</span>. Rewrite the definition so that it has a similar form compare to other linear regression:</p>
<div class="math notranslate nohighlight">
\[g(t) = \mathbf{A}^\prime \delta^\prime \]</div>
<p>Find the appropriate expression of design matrix <span class="math notranslate nohighlight">\(\mathbf{A}^\prime\)</span> and coefficient <span class="math notranslate nohighlight">\(\delta^\prime\)</span>.</p>
<p><strong>6E9.</strong> As we have seen in past chapters, a great way to understand your data generating process is to write it down. In this exercise we will generate synthetic data which will reinforce the mapping of “real world” ideas to code. Assume we start with a linear trend that is <code class="docutils literal notranslate"><span class="pre">y</span> <span class="pre">=</span> <span class="pre">2x,</span> <span class="pre">x</span> <span class="pre">=</span> <span class="pre">np.arange(90)</span></code>, and iid noise at each time point draw from a <span class="math notranslate nohighlight">\(\mathcal{N}(0, 1)\)</span>. Assume that this time series starts on Sunday June 6 2021. Generate 4 synthetic datasets that include:</p>
<ol class="simple">
<li><p>An additive weekend effect where weekends have 2x more volume than weekdays.</p></li>
<li><p>An additive sinusoidal effect of sin(2x).</p></li>
<li><p>An additive AR(1) latent process with autoregressive coefficient of  your choice and a noise scale <span class="math notranslate nohighlight">\(\sigma = 0.2\)</span>.</p></li>
<li><p>A time series with weekend and sinusoidal effect from (1) and (2),  and an AR(1) process on the mean of the time series with the same  autoregressive coefficient as in (3)</p></li>
</ol>
<p><strong>6E10.</strong> Adapt the model in Code Block <a class="reference internal" href="#gam-with-ar-likelihood"><span class="std std-ref">gam_with_ar_likelihood</span></a> to model the generated time series in <strong>6E9</strong> (4).</p>
<p><strong>6E11.</strong> Inspection of the inference result (MCMC trace and diagnostic) of models in this chapter using <code class="docutils literal notranslate"><span class="pre">ArviZ</span></code>. For example, look at:</p>
<ul class="simple">
<li><p>Trace plot</p></li>
<li><p>Rank plot</p></li>
<li><p>Summary of posterior sample</p></li>
</ul>
<p>Which model contains problematic chains (divergence, low ESS, large <span class="math notranslate nohighlight">\(\hat R\)</span>)? Could you find ways to improve the inference for those models?</p>
<p><strong>6M12.</strong> Generate a sinusoidal time series with 200 time points in Python, and fit it with a AR(2) model. Do that in TFP by modifying Code Block <a class="reference internal" href="#ar1-without-forloop"><span class="std std-ref">ar1_without_forloop</span></a> and in PyMC3 with <code class="docutils literal notranslate"><span class="pre">pm.AR</span></code> API.</p>
<p><strong>6M13.</strong> This is an exercise of posterior predictive check for AR models. Generate the prediction distribution at each time step <span class="math notranslate nohighlight">\(t\)</span> for the AR2 model in Exercise <strong>6M11</strong>. Note that for each time step <span class="math notranslate nohighlight">\(t\)</span> you need to condition on all the observations up to time step <span class="math notranslate nohighlight">\(t-1\)</span>. Does the one-step-ahead predictive distribution match the observed time series?</p>
<p><strong>6M14.</strong> Make forecast for 50 time steps using the AR2 models from Exercise <strong>6M11</strong>. Does the forecast also look like a sinusoidal signal?</p>
<p><strong>6H15.</strong> Implement the generative process for the <span class="math notranslate nohighlight">\(\text{SARIMA}(1, 1, 1)(1, 1, 1)_{12}\)</span> model, and make forecast.</p>
<p><strong>6M16.</strong> Implement and inference a <span class="math notranslate nohighlight">\(ARIMAX(1,1,1)X[4]\)</span> model for the monthly birth dataset in this chapter, with the design matrix generated from a Fourier basis functions with <span class="math notranslate nohighlight">\(N=2\)</span>.</p>
<p><strong>6H17.</strong> Derive the Kalman filter equations. Hint: first work out the joint distribution of <span class="math notranslate nohighlight">\(X_t\)</span> and <span class="math notranslate nohighlight">\(X_{t-1}\)</span>, and then follow with the joint distribution of <span class="math notranslate nohighlight">\(Y_t\)</span> and <span class="math notranslate nohighlight">\(X_t\)</span>. If you are still stuck take at look at Chapter 4 in Särkkä’s book <span id="id55">[<a class="reference internal" href="references.html#id129">60</a>]</span>.</p>
<p><strong>6M18.</strong> Inspect the output of <code class="docutils literal notranslate"><span class="pre">linear_growth_model.forward_filter</span></code> by indexing to a given time step:</p>
<ul class="simple">
<li><p>Identify the input and output of one Kalman filter step;</p></li>
<li><p>Compute one step of the Kalman filter predict and update step using  the input;</p></li>
<li><p>Assert that your computation is the same as the indexed output.</p></li>
</ul>
<p><strong>6M19.</strong> Study the documentation and implementation of <code class="docutils literal notranslate"><span class="pre">tfp.sts.Seasonal</span></code>, and answer the following questions:</p>
<ul class="simple">
<li><p>How many hyperparameters does a seasonal SSM contains?</p></li>
<li><p>How does it parameterized the latent states and what kind of  regularization effect does the prior has? Hint: draw connection to  the Gaussian Random Walk prior in Chapter <a class="reference internal" href="chp_05.html#chap3-5"><span class="std std-ref">5</span></a>.</p></li>
</ul>
<p><strong>6M20.</strong> Study the documentation and implementation of <code class="docutils literal notranslate"><span class="pre">tfp.sts.LinearRegression</span></code> and <code class="docutils literal notranslate"><span class="pre">tfp.sts.Seasonal</span></code>, and reason about the differences of SSM they represent when modeling a day of the week pattern:</p>
<ul class="simple">
<li><p>How is the day of the week coefficient represented? Are they part of  the latent states?</p></li>
<li><p>How is the model fit different between the two SSMs? Validate your  reasoning with simulations.</p></li>
</ul>
<hr class="docutils"/>
<p><a class="reference external" href="https://github.com/asael697/bayesforecast">https://github.com/asael697/bayesforecast</a>.</p>
<hr class="footnotes docutils"/>
<dl class="footnote brackets">
<dt class="label" id="id56"><span class="brackets"><a class="fn-backref" href="#id2">1</a></span></dt>
<dd><p><a class="reference external" href="https://quoteinvestigator.com/2013/10/20/no-predict/">https://quoteinvestigator.com/2013/10/20/no-predict/</a></p>
</dd>
<dt class="label" id="id57"><span class="brackets"><a class="fn-backref" href="#id4">2</a></span></dt>
<dd><p>There is also a subtlety that not all periodic patterns in the  time series should be considered seasonal. A useful distinction to  make is between cyclic and seasonal behavior. You can find a nice  summary in <a class="reference external" href="https://robjhyndman.com/hyndsight/cyclicts/">https://robjhyndman.com/hyndsight/cyclicts/</a>.</p>
</dd>
<dt class="label" id="id58"><span class="brackets"><a class="fn-backref" href="#id5">3</a></span></dt>
<dd><p>This makes the observation not iid and not exchangeable. You can  also see in Chapter <a class="reference internal" href="chp_04.html#chap3"><span class="std std-ref">4</span></a> where we define residuals</p>
</dd>
<dt class="label" id="id59"><span class="brackets"><a class="fn-backref" href="#id8">4</a></span></dt>
<dd><p>Which, it is unfortunate for our model and for our planet.</p>
</dd>
<dt class="label" id="id60"><span class="brackets"><a class="fn-backref" href="#id10">5</a></span></dt>
<dd><p>A series is stationary if its characteristic properties such as  means and covariances remain invariant across time.</p>
</dd>
<dt class="label" id="id61"><span class="brackets"><a class="fn-backref" href="#id11">6</a></span></dt>
<dd><p><a class="reference external" href="https://facebook.github.io/prophet/">https://facebook.github.io/prophet/</a>.</p>
</dd>
<dt class="label" id="id62"><span class="brackets"><a class="fn-backref" href="#id17">7</a></span></dt>
<dd><p>A demo of the design matrix used in Facebook Prophet could be  found in <a class="reference external" href="http://prophet.mbrouns.com">http://prophet.mbrouns.com</a> from a PyMCon 2020  presentation.</p>
</dd>
<dt class="label" id="id63"><span class="brackets"><a class="fn-backref" href="#id21">8</a></span></dt>
<dd><p>That is why is called autoregressive, it applies a linear  regression to itself. Hence the similar naming to the  autocorrelation diagnostic introduced in Section <a class="reference internal" href="chp_02.html#autocorr-plot"><span class="std std-ref">2.4.5 自相关图</span></a>.</p>
</dd>
<dt class="label" id="id64"><span class="brackets"><a class="fn-backref" href="#id24">9</a></span></dt>
<dd><p>Actually, the AR example in this section <em>is</em> a Gaussian Process.</p>
</dd>
<dt class="label" id="id65"><span class="brackets"><a class="fn-backref" href="#id28">10</a></span></dt>
<dd><p>The Stan implementation of SARIMA can be found in e.g.</p>
</dd>
<dt class="label" id="id66"><span class="brackets"><a class="fn-backref" href="#id29">11</a></span></dt>
<dd><p>For brevity, we omitted the MCMC sampling code here. You can find  the details in the accompanying Jupyter Notebook.</p>
</dd>
<dt class="label" id="id67"><span class="brackets"><a class="fn-backref" href="#id31">12</a></span></dt>
<dd><p>It might be useful to first consider “space” here being some  multi-dimensional Euclidean spaces, so <span class="math notranslate nohighlight">\(X_t\)</span> and <span class="math notranslate nohighlight">\(Y_t\)</span> is some  multi-dimensional array/tensor when we do computations in Python.</p>
</dd>
<dt class="label" id="id68"><span class="brackets"><a class="fn-backref" href="#id35">13</a></span></dt>
<dd><p>This also gives a nice example of a non-stationary observation  matrix <span class="math notranslate nohighlight">\(\mathbf{H}\)</span>.</p>
</dd>
<dt class="label" id="id69"><span class="brackets"><a class="fn-backref" href="#id36">14</a></span></dt>
<dd><p>Note that this is not the only way to express ARMA model in a  state-space form, for more detail see lecture note  <a class="reference external" href="http://www-stat.wharton.upenn.edu/~stine/stat910/lectures/14_state_space.pdf">http://www-stat.wharton.upenn.edu/~stine/stat910/lectures/14_state_space.pdf</a>.</p>
</dd>
<dt class="label" id="id70"><span class="brackets"><a class="fn-backref" href="#id45">15</a></span></dt>
<dd><p>Nothing more puts George E. P. Box’s famous quote: “All models  are wrong, but some are useful” into perspective, than reading  through his seminal book and working on forecasting problems.</p>
</dd>
<dt class="label" id="id71"><span class="brackets"><a class="fn-backref" href="#id51">17</a></span></dt>
<dd><p>Note that in practice we usually parameterize Equation  <a class="reference internal" href="#equation-eq-horse-shoe">(70)</a> a little bit differently.</p>
</dd>
<dt class="label" id="id72"><span class="brackets"><a class="fn-backref" href="#id54">18</a></span></dt>
<dd><p><a class="reference external" href="https://en.wikipedia.org/wiki/Federal_holidays_in_the_United_States#List_of_federal_holidays">https://en.wikipedia.org/wiki/Federal_holidays_in_the_United_States#List_of_federal_holidays</a></p>
</dd>
</dl>
</div>
</div>
<script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./zh_CN"
        },
        predefinedOutput: true
    }
    </script>
<script>kernelName = 'python3'</script>
</div>
<!-- Previous / next buttons -->
<div class="prev-next-area">
<a class="left-prev" href="chp_05.html" id="prev-link" title="previous page">
<i class="fas fa-angle-left"></i>
<div class="prev-next-info">
<p class="prev-next-subtitle">previous</p>
<p class="prev-next-title">第五章: 样条</p>
</div>
</a>
<a class="right-next" href="chp_07.html" id="next-link" title="next page">
<div class="prev-next-info">
<p class="prev-next-subtitle">next</p>
<p class="prev-next-title">第七章：贝叶斯加性回归树</p>
</div>
<i class="fas fa-angle-right"></i>
</a>
</div>
</div>
</div>
<footer class="footer">
<p>
    
      By Martin, Kumar, Lao<br/>
    
        © Copyright 2021.<br/>
</p>
</footer>
</main>
</div>
</div>
<script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>
</body>
</html>