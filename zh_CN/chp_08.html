
<!DOCTYPE html>

<html>
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>第八章：近似贝叶斯计算 — Bayesian Modeling and Computation in Python</title>
<link href="../_static/css/theme.css" rel="stylesheet"/>
<link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet"/>
<link href="../_static/vendor/fontawesome/5.13.0/css/all.min.css" rel="stylesheet"/>
<link as="font" crossorigin="" href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2" rel="preload" type="font/woff2"/>
<link href="../_static/pygments.css" rel="stylesheet" type="text/css">
<link href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" rel="stylesheet" type="text/css">
<link href="../_static/togglebutton.css" rel="stylesheet" type="text/css">
<link href="../_static/copybutton.css" rel="stylesheet" type="text/css">
<link href="../_static/mystnb.css" rel="stylesheet" type="text/css">
<link href="../_static/sphinx-thebe.css" rel="stylesheet" type="text/css"/>
<link href="../_static/sphinx-codeautolink.css" rel="stylesheet" type="text/css"/>
<link href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" rel="stylesheet" type="text/css"/>
<link href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" rel="stylesheet" type="text/css"/>
<link as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js" rel="preload"/>
<script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
<script src="../_static/jquery.js"></script>
<script src="../_static/underscore.js"></script>
<script src="../_static/doctools.js"></script>
<script src="../_static/togglebutton.js"></script>
<script src="../_static/clipboard.min.js"></script>
<script src="../_static/copybutton.js"></script>
<script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
<script src="../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
<script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
<script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
<script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
<script async="async" src="../_static/sphinx-thebe.js"></script>
<link href="../_static/favicon.ico" rel="shortcut icon">
<link href="../genindex.html" rel="index" title="Index"/>
<link href="../search.html" rel="search" title="Search"/>
<link href="chp_09.html" rel="next" title="第九章: 端到端的贝叶斯工作流"/>
<link href="chp_07.html" rel="prev" title="第七章：贝叶斯加性回归树"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="None" name="docsearch:language"/>
<!-- Google Analytics -->
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-702QMHG8ST"></script>
<script>
                    window.dataLayer = window.dataLayer || [];
                    function gtag(){ dataLayer.push(arguments); }
                    gtag('js', new Date());
                    gtag('config', 'G-702QMHG8ST');
                </script>
</link></link></link></link></link></link></head>
<body data-offset="80" data-spy="scroll" data-target="#bd-toc-nav">
<div class="container-fluid" id="banner"></div>
<div class="container-xl">
<div class="row">
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
<div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
<h1 class="site-logo" id="site-title">Bayesian Modeling and Computation in Python</h1>
</a>
</div><form action="../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="icon fas fa-search"></i>
<input aria-label="Search this book..." autocomplete="off" class="form-control" id="search-input" name="q" placeholder="Search this book..." type="search"/>
</form><nav aria-label="Main" class="bd-links" id="bd-docs-nav">
<div class="bd-toc-item active">
<ul class="current nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="dedication.html">
   贡献
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="foreword.html">
   序言
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="preface.html">
   前言
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="symbollist.html">
   符号表
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chp_01.html">
   第一章: 贝叶斯推断
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chp_02.html">
   第二章: 贝叶斯模型的探索性分析
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chp_03.html">
   第三章：线性模型与概率编程语言
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chp_04.html">
   第四章：扩展线性模型
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chp_05.html">
   第五章: 样条
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chp_06.html">
   第六章: 时间序列
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chp_07.html">
   第七章：贝叶斯加性回归树
  </a>
</li>
<li class="toctree-l1 current active">
<a class="current reference internal" href="#">
   第八章：近似贝叶斯计算
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chp_09.html">
   第九章: 端到端的贝叶斯工作流
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chp_10.html">
   第十章: 概率编程语言
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chp_11.html">
   第十一章: 附加主题
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="glossary.html">
   词汇表
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="references.html">
   References
  </a>
</li>
</ul>
</div>
</nav> <!-- To handle the deprecated key -->
<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>
</div>
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
<div class="topbar container-xl fixed-top">
<div class="topbar-contents row">
<div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
<div class="col pl-md-4 topbar-main">
<button aria-controls="site-navigation" aria-expanded="true" aria-label="Toggle navigation" class="navbar-toggler ml-0" data-placement="left" data-target=".site-navigation" data-toggle="tooltip" id="navbar-toggler" title="Toggle navigation" type="button">
<i class="fas fa-bars"></i>
<i class="fas fa-arrow-left"></i>
<i class="fas fa-arrow-up"></i>
</button>
<!-- Source interaction buttons -->
<div class="dropdown-buttons-trigger">
<button aria-label="Connect with source repository" class="btn btn-secondary topbarbtn" id="dropdown-buttons-trigger"><i class="fab fa-github"></i></button>
<div class="dropdown-buttons sourcebuttons">
<a class="repository-button" href="https://github.com/BayesianModelingandComputationInPython/BookCode_Edition1"><button class="btn btn-secondary topbarbtn" data-placement="left" data-toggle="tooltip" title="Source repository" type="button"><i class="fab fa-github"></i>repository</button></a>
<a class="issues-button" href="https://github.com/BayesianModelingandComputationInPython/BookCode_Edition1/issues/new?title=Issue%20on%20page%20%2Fzh_CN/chp_08.html&amp;body=Your%20issue%20content%20here."><button class="btn btn-secondary topbarbtn" data-placement="left" data-toggle="tooltip" title="Open an issue" type="button"><i class="fas fa-lightbulb"></i>open issue</button></a>
</div>
</div>
<!-- Full screen (wrap in <a> to have style consistency -->
<a class="full-screen-button"><button aria-label="Fullscreen mode" class="btn btn-secondary topbarbtn" data-placement="bottom" data-toggle="tooltip" onclick="toggleFullScreen()" title="Fullscreen mode" type="button"><i class="fas fa-expand"></i></button></a>
<!-- Launch buttons -->
</div>
<!-- Table of contents -->
<div class="d-none d-md-block col-md-2 bd-toc show noprint">
<div class="tocsection onthispage pt-5 pb-3">
<i class="fas fa-list"></i> Contents
            </div>
<nav aria-label="Page" id="bd-toc-nav">
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#life-beyond-likelihood">
   8.1 超越似然
  </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#fitting-a-gaussian-the-abc-way">
   8.3 用近似贝叶斯计算拟合一个高斯
  </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#epsilon">
   8.4 选择距离函数、 阈值
   <span class="math notranslate nohighlight">
    \(\epsilon\)
   </span>
   和统计量
  </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#choosing-the-distance">
     8.4.1 选择距离函数
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#choosing-epsilon">
     8.4.2 选择阈值
     <span class="math notranslate nohighlight">
      \(\epsilon\)
     </span>
</a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#choosing-summary-statistics">
     8.4.3 选择统计量
    </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#g-and-k">
   8.5
   <code class="docutils literal notranslate">
<span class="pre">
     g-and-k
    </span>
</code>
   分布
  </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#abc-ma">
   8.6 移动平均模型的近似
  </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#model-comparison-in-the-abc-context">
   8.7 在近似贝叶斯计算的场景中做模型比较
  </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#marginal-likelihood-and-loo">
     8.7.1 贝叶斯因子法
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#model-choice-via-random-forest">
     8.7.2 随机森林法
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#model-choice-for-ma-model">
     8.7.3 移动平均模型的模型选择
    </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#choosing-priors-for-abc">
   8.8 为近似贝叶斯计算选择先验
  </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#exercises8">
   8.9 练习
  </a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="row" id="main-content">
<div class="col-12 col-md-9 pl-md-3 pr-md-0">
<!-- Table of contents that is only displayed when printing the page -->
<div class="onlyprint" id="jb-print-docs-body">
<h1>第八章：近似贝叶斯计算</h1>
<!-- Table of contents -->
<div id="print-main-content">
<div id="jb-print-toc">
<div>
<h2> Contents </h2>
</div>
<nav aria-label="Page">
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#life-beyond-likelihood">
   8.1 超越似然
  </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#fitting-a-gaussian-the-abc-way">
   8.3 用近似贝叶斯计算拟合一个高斯
  </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#epsilon">
   8.4 选择距离函数、 阈值
   <span class="math notranslate nohighlight">
    \(\epsilon\)
   </span>
   和统计量
  </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#choosing-the-distance">
     8.4.1 选择距离函数
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#choosing-epsilon">
     8.4.2 选择阈值
     <span class="math notranslate nohighlight">
      \(\epsilon\)
     </span>
</a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#choosing-summary-statistics">
     8.4.3 选择统计量
    </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#g-and-k">
   8.5
   <code class="docutils literal notranslate">
<span class="pre">
     g-and-k
    </span>
</code>
   分布
  </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#abc-ma">
   8.6 移动平均模型的近似
  </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#model-comparison-in-the-abc-context">
   8.7 在近似贝叶斯计算的场景中做模型比较
  </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#marginal-likelihood-and-loo">
     8.7.1 贝叶斯因子法
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#model-choice-via-random-forest">
     8.7.2 随机森林法
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#model-choice-for-ma-model">
     8.7.3 移动平均模型的模型选择
    </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#choosing-priors-for-abc">
   8.8 为近似贝叶斯计算选择先验
  </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#exercises8">
   8.9 练习
  </a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div>
<div class="tex2jax_ignore mathjax_ignore section" id="chap8">
<span id="id1"></span><h1>第八章：近似贝叶斯计算<a class="headerlink" href="#chap8" title="Permalink to this headline">¶</a></h1>
<style>p{text-indent:2em;2}</style>
<p>在本章中，我们讨论近似贝叶斯计算（ Approximate Bayesian Computation ， ABC ）。近似贝叶斯计算中的 “近似” 指缺乏显式的似然函数，而非 MCMC 或变分推理等后验近似推断方法。近似贝叶斯计算方法的另一个常见并且更明确的名称是无似然方法。尽管有很多学者认为这两个术语之间存在区别，不能作为可以互换的概念，但无似然方法这个名称还是更容易让初识的人理解。</p>
<p>当我们没有明确的似然表达式时，近似贝叶斯计算方法可能很有用，但需要有一个能够生成合成数据的参数化<em>模拟器</em>。这个模拟器有一个或多个未知参数，我们想知道哪一组参数生成的合成数据<em>足够接近</em>观测数据。然后我们再计算这组参数的后验分布。</p>
<p>近似贝叶斯计算方法在生物科学中变得越来越普遍，特别是在系统生物学、流行病学、生态学和群体遗传学等子领域<span id="id2">[<a class="reference internal" href="references.html#id77">84</a>]</span>。但其也可用于其他领域，因为它们提供了一种解决许多实际问题的灵活方式。</p>
<p>应用的多样性也反映在近似贝叶斯计算的 Python 软件包中 <span id="id3">[<a class="reference internal" href="references.html#id56">85</a>, <a class="reference internal" href="references.html#id55">86</a>, <a class="reference internal" href="references.html#id57">87</a>]</span> 。不过，额外的近似层也带来了一系列困难，主要是：在缺乏似然的情况下，<em>足够接近</em>到底指什么？如何能够实际计算一个近似的后验？</p>
<p>我们将在本章中从一般性角度讨论这些挑战。我们强烈建议有兴趣将近似贝叶斯计算方法应用于自身问题的读者，用自己领域知识中的例子来补充本章内容。</p>
<div class="section" id="life-beyond-likelihood">
<span id="id4"></span><h2>8.1 超越似然<a class="headerlink" href="#life-beyond-likelihood" title="Permalink to this headline">¶</a></h2>
<p>根据贝叶斯定理（ 公式 <a class="reference internal" href="chp_01.html#equation-eq-posterior-dist">(1)</a> ），要计算后验，需要两个基本成分：先验和似然。但是，对于某些特定问题，可能无法以封闭形式表达似然，或者计算似然的成本过高。这对于贝叶斯热爱者来说，似乎进入了一条死胡同。但是，如果能够以某种方式生成合成数据，情况可能就会有所不同，特别是当这种合成数据能够与真实的观测数据足够相似时，似乎能够用该生成过程来近似真实数据的似然。这种合成数据生成器通常被称为<strong>模拟器</strong>。从近似贝叶斯计算方法角度来看，模拟器就是一个黑盒子，我们在一侧输入参数值，并从另一侧获取模拟数据。这里的复杂性在于：不确定哪些输入参数足以生成与观测数据相似的合成数据。</p>
<p>所有近似贝叶斯计算方法共有的基本概念是用 <span class="math notranslate nohighlight">\(\delta\)</span> 函数替换似然，该函数计算某种距离，或者更一般地说， 观测数据 <span class="math notranslate nohighlight">\(Y\)</span> 与（参数化模拟器 <span class="math notranslate nohighlight">\(Sim\)</span> 生成的）合成数据 <span class="math notranslate nohighlight">\(\hat Y\)</span> 之间的某种差异。</p>
<div class="math notranslate nohighlight">
\[\hat Y \sim Sim(\theta)\]</div>
<div class="math notranslate nohighlight">
\[p(\theta \mid Y) 
  \underset{\sim}{\propto} 
  \delta(Y, \hat Y \mid \epsilon)\; p(\boldsymbol{\theta})\]</div>
<p>我们的目标是使用函数 <span class="math notranslate nohighlight">\(\delta\)</span> 来获得足够好的近似似然：</p>
<div class="math notranslate nohighlight">
\[\lim_{\epsilon \to 0} \delta(Y, \hat Y \mid \epsilon) = p(Y \mid \boldsymbol{\theta})\]</div>
<p>我们引入了一个容差参数 <span class="math notranslate nohighlight">\(\epsilon\)</span>，因为对于大多数问题，生成与观测数据 <span class="math notranslate nohighlight">\(Y\)</span> 相等的合成数据集 <span class="math notranslate nohighlight">\(\hat Y\)</span> 几乎不可能 <a class="footnote-reference brackets" href="#id54" id="id5">1</a> 。 <span class="math notranslate nohighlight">\(\epsilon\)</span> 的值越大，我们就越能容忍 <span class="math notranslate nohighlight">\(Y\)</span> 和 <span class="math notranslate nohighlight">\(\hat Y\)</span> 之间的接近程度。一般来说，对于一个给定问题，较大的 <span class="math notranslate nohighlight">\(\epsilon\)</span> 值意味着对后验更粗略的近似，我们将在后面看到这方面的例子。</p>
<p>在实践中，随着数据样本大小（或维度）的增加，我们找到足够小的 <span class="math notranslate nohighlight">\(\delta\)</span> 值将越来越困难 <a class="footnote-reference brackets" href="#id55" id="id6">2</a> 。一个简单的解决方案是增加 <span class="math notranslate nohighlight">\(\epsilon\)</span> 的值，但这意味着增加了近似误差。更好的解决方案可能是计算一个或多个统计量 <span class="math notranslate nohighlight">\(S\)</span> 之间的距离，而不是模拟数据集和真实数据集之间的距离。</p>
<div class="math notranslate nohighlight">
\[\delta\left(S(Y), S(\hat Y) \mid \epsilon\right)\]</div>
<p>我们必须知道，使用统计量会给近似贝叶斯计算带来额外的误差源，除非该统计量对于模型参数 <span class="math notranslate nohighlight">\(\theta\)</span> 来说是充分统计量。不幸的是，并非所有情况都能满足这种要求。但不充分的统计量在实践中仍然非常有用，并且经常被从业者使用。</p>
<p>在本章中，我们将探讨一些不同的距离和统计量，重点关注一些经过验证的方法。但一定要清楚，近似贝叶斯计算设计许多不同领域、不同类型的模拟数据，因此这些方法很难一概而论。此外，文献进展非常迅速，因此本书将专注于构建必要的知识、技能和工具。</p>
<div class="admonition- admonition">
<p class="admonition-title">充分统计量</p>
<p>如果除了某个统计量之外，从同一样本计算的其他统计量无法提供有关该样本的更多信息，则该统计量对于模型参数而言是充分的，被称为充分统计量。换句话说，该统计量 <em>足以</em> 总结你的样本而不会丢失信息。</p>
<p>例如，给定来自具有期望值 <span class="math notranslate nohighlight">\(\mu\)</span> 和已知有限方差的高斯分布的独立同分布样本，样本的均值对于参数 <span class="math notranslate nohighlight">\(\mu\)</span> 来说是一个<strong>充分统计量</strong>。请注意，均值无法说明离散度，因此其仅对参数 <span class="math notranslate nohighlight">\(\mu\)</span> 是充分的。</p>
<p>众所周知，对于独立同分布数据，具有充分统计量且维度与 <span class="math notranslate nohighlight">\(\theta\)</span> 相同的唯一分布来自于<strong>指数族分布</strong> <span id="id7">[<a class="reference internal" href="references.html#id153">88</a>, <a class="reference internal" href="references.html#id152">89</a>, <a class="reference internal" href="references.html#id151">90</a>, <a class="reference internal" href="references.html#id150">91</a>]</span> 。对于其他类型的分布，充分统计量的维度会随着样本量的增加而增加。</p>
</div>
<p id="approximating-the-approximated-posterior">ABC_行近似贝叶斯计算的最基础方法。我们将用 <a class="reference internal" href="#fig-abc-rejection"><span class="std std-numref">Fig. 134</span></a> 以及对算法抽象描述来逐步解释，如下所示。</p>
<ol class="simple">
<li><p>从先验分布中采样 <span class="math notranslate nohighlight">\(\theta\)</span> 的值。</p></li>
<li><p>将该值传递给模拟器并生成合成数据。</p></li>
<li><p>如果合成数据的<em>距离</em> <span class="math notranslate nohighlight">\(\delta\)</span> 比 <span class="math notranslate nohighlight">\(\epsilon\)</span> 更近，则保存建议的 <span class="math notranslate nohighlight">\(\theta\)</span>，否则拒绝它。</p></li>
<li><p>重复直到获得所需数量的样本。</p></li>
</ol>
<div class="figure align-default" id="fig-abc-rejection">
<a class="reference internal image-reference" href="../_images/ABC_rejection.png"><img alt="../_images/ABC_rejection.png" src="../_images/ABC_rejection.png" style="width: 4.5in;"/></a>
<p class="caption"><span class="caption-number">Fig. 134 </span><span class="caption-text">近似贝叶斯计算拒绝采样器的一个步骤。</span><a class="headerlink" href="#fig-abc-rejection" title="Permalink to this image">¶</a></p>
<div class="legend">
<p>我们从先验分布（顶部）中采样一组 <span class="math notranslate nohighlight">\(\theta\)</span> 值。每个值都被传递给模拟器，模拟器生成合成数据集（虚线分布），我们对合成数据与观测数据（底部）的分布进行比较。在这个例子中，只有 <span class="math notranslate nohighlight">\(\theta_1\)</span> 能够生成一个与观测数据足够接近的合成数据集，因此 <span class="math notranslate nohighlight">\(\theta_0\)</span> 和 <span class="math notranslate nohighlight">\(\theta_2\)</span> 被拒绝。请注意，如果仅使用统计量，我们需要在第 <span class="math notranslate nohighlight">\(2\)</span> 步之后和第 <span class="math notranslate nohighlight">\(3\)</span> 步之前计算合成数据和观测数据的统计量信息。</p>
</div>
</div>
<p>近似贝叶斯计算拒绝采样器的主要缺点是，如果先验分布与后验分布相差太大，我们会花费大部分时间提出将被拒绝的值，因此，更好的办法是从更接近真实后验的分布中提出建议值。但通常，我们对后验的了解不够，无法手动执行此操作，但可以使用 <strong>序贯蒙特卡洛 (SMC)</strong> 方法来实现。</p>
<p>序贯蒙特卡洛是一种通用采样方法，就像 MCMC 方法一样。 但序贯蒙特卡洛也适用于执行近似贝叶斯计算，并被称为 “序贯蒙特卡洛-ABC（ SMC-ABC ）” 。如果你想了解更多关于序贯蒙特卡洛方法的细节，可以参阅章节 <a class="reference internal" href="chp_11.html#inference-methods"><span class="std std-ref">11.9 推断方法</span></a>，但要理解本章，暂时只需要知道贯序蒙特卡洛是通过在 <span class="math notranslate nohighlight">\(s\)</span> 个连续阶段中逐步增加辅助参数 <span class="math notranslate nohighlight">\(\beta\)</span> 的值 <span class="math notranslate nohighlight">\(\{\beta_0=0 &lt; \beta_1 &lt; ... &lt; \beta_s=1\}\)</span> 实现的。其作法是：从先验（ <span class="math notranslate nohighlight">\(\beta = 0\)</span> ）开始采样，直到到达后验（ <span class="math notranslate nohighlight">\(\beta = 1\)</span> ）。因此，可以将 <span class="math notranslate nohighlight">\(\beta\)</span> 视为一个 <em>逐渐开启似然</em> 的参数。 <span class="math notranslate nohighlight">\(\beta\)</span> 的中间值序列由序贯蒙特卡洛方法自动计算。数据相对于先验的信息越多和（/或）后验几何形态越复杂，则序贯蒙特卡洛采取的中间步骤就会越多。</p>
<p><a class="reference internal" href="#fig-smc-tempering"><span class="std std-numref">Fig. 135</span></a> 显示了一个假设的中间分布序列，从浅灰色的先验到蓝色的后验。</p>
<div class="figure align-default" id="fig-smc-tempering">
<a class="reference internal image-reference" href="../_images/smc_tempering.png"><img alt="../_images/smc_tempering.png" src="../_images/smc_tempering.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 135 </span><span class="caption-text">序贯蒙特卡洛采样器探索的褪火后验假设序列，从浅灰色的先验 ( <span class="math notranslate nohighlight">\(\beta = 0\)</span> ) 到蓝色的真实后验 ( <span class="math notranslate nohighlight">\(\beta = 1\)</span> )。开始时较低的 <span class="math notranslate nohighlight">\(\beta\)</span> 值有助于防止采样器卡在单一最值中。</span><a class="headerlink" href="#fig-smc-tempering" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="section" id="fitting-a-gaussian-the-abc-way">
<span id="id8"></span><h2>8.3 用近似贝叶斯计算拟合一个高斯<a class="headerlink" href="#fitting-a-gaussian-the-abc-way" title="Permalink to this headline">¶</a></h2>
<p>让我们用一个简单的例子来热热身，从均值为 <span class="math notranslate nohighlight">\(0\)</span> 和标准差为 <span class="math notranslate nohighlight">\(1\)</span> 的高斯分布数据中估计均值和标准差。对于这个问题，我们可以拟合模型：</p>
<div class="math notranslate nohighlight" id="equation-eq-gauss-model">
<span class="eqno">(73)<a class="headerlink" href="#equation-eq-gauss-model" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{split}
  \boldsymbol{\mu} \sim &amp;\; \mathcal{N}(0, 1) \\
  \boldsymbol{\sigma} \sim &amp;\; \mathcal{HN}(1) \\
  \boldsymbol{s} \sim &amp;\; \mathcal{N}(\boldsymbol{\mu}, \boldsymbol{\sigma})
\end{split}\end{split}\]</div>
<p>在 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 中编写此模型的方法见代码 <a class="reference internal" href="#gauss-nuts"><span class="std std-ref">gauss_nuts</span></a> 。</p>
<div class="literal-block-wrapper docutils container" id="gauss-nuts">
<div class="code-block-caption"><span class="caption-number">Listing 104 </span><span class="caption-text">gauss_nuts</span><a class="headerlink" href="#gauss-nuts" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">gauss</span><span class="p">:</span>     
  <span class="n">μ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s2">"μ"</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>     
  <span class="n">σ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s2">"σ"</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>     
  <span class="n">s</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s2">"s"</span><span class="p">,</span> <span class="n">μ</span><span class="p">,</span> <span class="n">σ</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">data</span><span class="p">)</span>     
  <span class="n">trace_g</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
</pre></div>
</div>
</div>
<p>使用 <code class="docutils literal notranslate"><span class="pre">SMC-ABC</span></code> 的等效模型见代码 <a class="reference internal" href="#gauss-abc"><span class="std std-ref">gauss_abc</span></a> 。</p>
<div class="literal-block-wrapper docutils container" id="gauss-abc">
<div class="code-block-caption"><span class="caption-number">Listing 105 </span><span class="caption-text">gauss_abc</span><a class="headerlink" href="#gauss-abc" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">gauss</span><span class="p">:</span>     
  <span class="n">μ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s2">"μ"</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>     
  <span class="n">σ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s2">"σ"</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>     
  <span class="n">s</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Simulator</span><span class="p">(</span><span class="s2">"s"</span><span class="p">,</span> <span class="n">normal_simulator</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="p">[</span><span class="n">μ</span><span class="p">,</span> <span class="n">σ</span><span class="p">],</span>
                        <span class="n">distance</span><span class="o">=</span><span class="s2">"gaussian"</span><span class="p">,</span>                      <span class="n">sum_stat</span><span class="o">=</span><span class="s2">"sort"</span><span class="p">,</span>                        <span class="n">epsilon</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>                      
                        <span class="n">observed</span><span class="o">=</span><span class="n">data</span><span class="p">)</span>
  <span class="n">trace_g</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample_smc</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s2">"ABC"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>我们可以看到代码 <a class="reference internal" href="#gauss-nuts"><span class="std std-ref">gauss_nuts</span></a> 和代码 <a class="reference internal" href="#gauss-abc"><span class="std std-ref">gauss_abc</span></a> 之间有两个重要的区别：</p>
<ul class="simple">
<li><p>使用了 <code class="docutils literal notranslate"><span class="pre">pm.Simulator</span></code> 分布</p></li>
<li><p>使用 <code class="docutils literal notranslate"><span class="pre">pm.sample_smc(kernel="ABC")</span></code> 代替了 <code class="docutils literal notranslate"><span class="pre">pm.sample()</span></code>。</p></li>
</ul>
<p>通过使用 <code class="docutils literal notranslate"><span class="pre">pm.Simulator</span></code> ，我们告诉 PyMC3，不会对似然使用封闭形式表达式，而是定义一个伪似然。此时需要传递一个生成合成数据的 Python 函数，本例中该函数为 <code class="docutils literal notranslate"><span class="pre">normal_simulator</span></code> 以及其参数 <code class="docutils literal notranslate"> <span class="pre">params=[μ,</span> <span class="pre">σ]</span></code> 。代码 <a class="reference internal" href="#normal-simulator"><span class="std std-ref">normal_simulator</span></a> 给出了此函数的定义，样本大小为 <span class="math notranslate nohighlight">\(1000\)</span> ，未知参数为 <span class="math notranslate nohighlight">\(\mu\)</span> 和 <span class="math notranslate nohighlight">\(\sigma\)</span> 。</p>
<div class="literal-block-wrapper docutils container" id="normal-simulator">
<div class="code-block-caption"><span class="caption-number">Listing 106 </span><span class="caption-text">normal_simulator</span><a class="headerlink" href="#normal-simulator" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">normal_simulator</span><span class="p">(</span><span class="n">μ</span><span class="p">,</span> <span class="n">σ</span><span class="p">):</span>
    <span class="k">return</span> <a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/random/generated/numpy.random.normal.html#numpy.random.normal" title="numpy.random.normal"><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span></a><span class="p">(</span><span class="n">μ</span><span class="p">,</span> <span class="n">σ</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>我们还需要向 <code class="docutils literal notranslate"><span class="pre">pm.Simulator</span></code> 传递其他可选参数，包括距离函数 <code class="docutils literal notranslate"><span class="pre">distance</span></code>、统计量信息 <code class="docutils literal notranslate"><span class="pre">sum_stat</span></code> 和阈值 <code class="docutils literal notranslate"><span class="pre">epsilon</span></code> 的值。此外，我们还要将观测数据以常规似然形式传递给 <code class="docutils literal notranslate"><span class="pre">pm.Simulator</span></code> 。</p>
<p>通过使用 <code class="docutils literal notranslate"><span class="pre">pm.sample_smc(kernel="ABC")</span></code><a class="footnote-reference brackets" href="#id56" id="id9">3</a> ， 我们告诉 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 在模型中寻找 <code class="docutils literal notranslate"><span class="pre">pm.Simulator</span></code> 并使用它来定义伪似然，其余的采样过程与序贯蒙特卡洛算法中描述的相同。当 <code class="docutils literal notranslate"><span class="pre">pm.Simulator</span></code> 存在时，其他采样器将无法运行。</p>
<p>本例中的 <code class="docutils literal notranslate"><span class="pre">normal_simulator</span></code> 函数原则上可以是任何我们想要的 Python 函数，实际上甚至可以是经过封装的非 Python 代码，例如 Fortran 或 C 代码。这就是近似贝叶斯计算方法的灵活性所在。在本例中，模拟器只是一个 <code class="docutils literal notranslate"><span class="pre">NumPy</span></code> 随机生成器函数的包装器。</p>
<p>与其他采样器一样，建议运行多个链，以便诊断采样器是否无法正常工作，PyMC3 将尝试自动执行此操作。 <a class="reference internal" href="#fig-trace-g"><span class="std std-numref">Fig. 136</span></a> 显示了使用两条链运行代码 <a class="reference internal" href="#gauss-abc"><span class="std std-ref">gauss_abc</span></a> 的结果。</p>
<p>可以看到，我们能够恢复真实参数，并且采样器没有出现任何明显的采样问题。</p>
<div class="figure align-default" id="fig-trace-g">
<a class="reference internal image-reference" href="../_images/trace_g.png"><img alt="../_images/trace_g.png" src="../_images/trace_g.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 136 </span><span class="caption-text">正如预期的 <span class="math notranslate nohighlight">\(\mu \approx 0\)</span> 和 <span class="math notranslate nohighlight">\(\sigma \approx 1\)</span> 一样，两条链都支持核密度估计和秩图反映的后验。请注意，这两条链中都是通过运行 <span class="math notranslate nohighlight">\(2000\)</span> 个并行 SMC 链获得的，如 SMC 算法中所述。</span><a class="headerlink" href="#fig-trace-g" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="section" id="epsilon">
<span id="choosing-the-distance-function-epsilon-and-the-summary-statistics"></span><h2>8.4 选择距离函数、 阈值 <span class="math notranslate nohighlight">\(\epsilon\)</span> 和统计量<a class="headerlink" href="#epsilon" title="Permalink to this headline">¶</a></h2>
<p>如何定义有效的距离度量、统计量和阈值 <span class="math notranslate nohighlight">\(\epsilon\)</span> 取决于待解决的问题。这意味着我们应该在获得结果之前进行一些试验和尝试，尤其是在遇到新问题时。像往常一样，事先对选择做充分的思考有助于减少备选的数量；不过我们也应该习惯于运行实验，因为它总是有助于更好地理解问题，并对超参数做出更明智的抉择。在接下来的部分中，我们将讨论一些比较通用的指南。</p>
<div class="section" id="choosing-the-distance">
<span id="id10"></span><h3>8.4.1 选择距离函数<a class="headerlink" href="#choosing-the-distance" title="Permalink to this headline">¶</a></h3>
<p>上例中，我们使用了默认距离函数 <code class="docutils literal notranslate"><span class="pre">distance="gaussian"</span></code> 来运行代码 <a class="reference internal" href="#gauss-abc"><span class="std std-ref">gauss_abc</span></a>，其定义为：</p>
<div class="math notranslate nohighlight" id="equation-eq-euclidean-abc">
<span class="eqno">(74)<a class="headerlink" href="#equation-eq-euclidean-abc" title="Permalink to this equation">¶</a></span>\[\sum_i - \frac{||X_{oi} - X_{si}||^2}{2 \epsilon_i^2}\]</div>
<p>其中 <span class="math notranslate nohighlight">\(X_{o}\)</span> 是观测数据，<span class="math notranslate nohighlight">\(X_{s}\)</span> 是模拟数据，<span class="math notranslate nohighlight">\(\epsilon\)</span> 是其缩放参数。我们称 <a class="reference internal" href="#equation-eq-euclidean-abc">(74)</a> 为高斯的，因为它在对数尺度上是高斯核 <a class="footnote-reference brackets" href="#id57" id="id11">4</a>。我们使用对数尺度来计算伪似然，就和在实际似然（和先验）中一样 <a class="footnote-reference brackets" href="#id58" id="id12">5</a>。 <span class="math notranslate nohighlight">\(||X_{oi} - X_{si}||^2\)</span> 是欧几里得距离（也称为 <span class="math notranslate nohighlight">\(L2\)</span> 范数），因此也可以将公式 <a class="reference internal" href="#equation-eq-euclidean-abc">(74)</a> 描述为加权欧几里得距离。这是目前比较流行的选择，其他选项还有：在 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 中被称为拉普拉斯距离的 <span class="math notranslate nohighlight">\(L1\)</span> 范数（绝对差的和）； <span class="math notranslate nohighlight">\(L-\infty\)</span> 范数（差的最大绝对值）；马氏距离：<span class="math notranslate nohighlight">\(\sqrt{(xo - xs )^{T}\Sigma(xo - xs)}\)</span>， <span class="math notranslate nohighlight">\(\Sigma\)</span> 为协方差矩阵。</p>
<p>高斯距离、拉普拉斯等可以应用于整个数据，或者应用于统计量。此外，还专门引入了一些能够避免统计量计算、但效果也很好的距离函数 <span id="id13">[<a class="reference internal" href="references.html#id48">92</a>, <a class="reference internal" href="references.html#id47">93</a>, <a class="reference internal" href="references.html#id46">94</a>]</span>。我们将介绍其中的 <code class="docutils literal notranslate"><span class="pre">Wasserstein</span> <span class="pre">距离</span></code> 和 <code class="docutils literal notranslate"><span class="pre">KL</span> <span class="pre">散度</span></code>。</p>
<p>在代码 <a class="reference internal" href="#gauss-abc"><span class="std std-ref">gauss_abc</span></a> 中，我们使用了 <code class="docutils literal notranslate"><span class="pre">sum_stat="sort"</span></code> <a class="footnote-reference brackets" href="#id59" id="id14">6</a>，这告诉 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 在计算公式 <a class="reference internal" href="#equation-eq-euclidean-abc">(74)</a> 之前对数据进行排序。这相当于计算 <code class="docutils literal notranslate"><span class="pre">一维</span> <span class="pre">2-Wasserstein</span> <span class="pre">距离</span></code>，如果使用 <span class="math notranslate nohighlight">\(L1\)</span> 范数，则将得到 <code class="docutils literal notranslate"><span class="pre">一维</span> <span class="pre">1-Wasserstein</span> <span class="pre">距离</span></code>。当然，也可以为大于 <span class="math notranslate nohighlight">\(1\)</span> 的维度定义 <code class="docutils literal notranslate"><span class="pre">Wasserstein</span> <span class="pre">距离</span></code>（ <span id="id15">[<a class="reference internal" href="references.html#id46">94</a>]</span>  ）。</p>
<p>在计算距离之前对数据排序，会使分布之间的比较更加公平。想象一下，如果有两个完全相等的样本，但是一个从低到高排序，另一个是高到低排序。此时应用公式 <a class="reference internal" href="#equation-eq-euclidean-abc">(74)</a> 这样的度量，会得出“两个样本不同”的结论。但如果先排序而后计算距离，会得出“两个样本相同”结论。这是一个非常极端的场景，但有助于阐明数据排序背后的直觉。此外，对数据进行排序的前提，是假设我们只关心数据分布，不关心数据顺序；否则的话，做排序处理会破坏数据中本来存在的结构。最典型的例子 <a class="reference internal" href="chp_06.html#chap4"><span class="std std-ref"> 第 6 章 </span></a> 中的<strong>时间序列</strong>。</p>
<p>为了避免定义和计算统计量而引入的另一个距离是使用 KL 散度（ 参见第 <a class="reference internal" href="chp_11.html#dkl"><span class="std std-ref">11.3 KL 散度</span></a> 部分 ）。通常使用以下表达式来近似计算 KL 散度 （ <span id="id16">[<a class="reference internal" href="references.html#id48">92</a>, <a class="reference internal" href="references.html#id47">93</a>]</span> ）：</p>
<div class="math notranslate nohighlight" id="equation-eq-kl-abc">
<span class="eqno">(75)<a class="headerlink" href="#equation-eq-kl-abc" title="Permalink to this equation">¶</a></span>\[\frac{d}{n}  \sum \left(- \frac{\log(\frac{\nu_d}{\rho_d})}{\epsilon} \right) + \log\left(\frac{n}{n-1}\right)\]</div>
<p>其中 <span class="math notranslate nohighlight">\(d\)</span> 是数据集的维度（变量或特征的数量），<span class="math notranslate nohighlight">\(n\)</span> 是观测数据点的数量。 <span class="math notranslate nohighlight">\(\nu_d\)</span> 包含观测数据到模拟数据的 <code class="docutils literal notranslate"><span class="pre">1-最近邻距离</span></code>，<span class="math notranslate nohighlight">\(\rho_d\)</span> 包含观测数据到自身的 <code class="docutils literal notranslate"><span class="pre">2-最近邻距离</span></code>（ 注意，如果你将数据集与其自身进行比较，则 <code class="docutils literal notranslate"><span class="pre">1-最近邻距离</span></code> 永远为零 ）。由于该方法涉及最近邻搜索的 <span class="math notranslate nohighlight">\(2n\)</span> 次操作，因此通常使用 <code class="docutils literal notranslate"><span class="pre">k-d</span> <span class="pre">树</span></code> 来实现 <span id="id17">[<a class="reference internal" href="references.html#id49">95</a>]</span> 。</p>
</div>
<div class="section" id="choosing-epsilon">
<span id="id18"></span><h3>8.4.2 选择阈值 <span class="math notranslate nohighlight">\(\epsilon\)</span><a class="headerlink" href="#choosing-epsilon" title="Permalink to this headline">¶</a></h3>
<p>在许多近似贝叶斯计算方法中，<span class="math notranslate nohighlight">\(\epsilon\)</span> 参数用作硬阈值，生成距离大于 <span class="math notranslate nohighlight">\(\epsilon\)</span> 的样本的参数 <span class="math notranslate nohighlight">\(\theta\)</span> 值将被拒绝。此外，<span class="math notranslate nohighlight">\(\epsilon\)</span> 可以是用户必须设置的递减值列表，或者算法自适应找到的结果 <a class="footnote-reference brackets" href="#id60" id="id19">7</a>。</p>
<p>在 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 中，<span class="math notranslate nohighlight">\(\epsilon\)</span> 采用的是距离函数的尺度，就像在公式 <a class="reference internal" href="#equation-eq-euclidean-abc">(74)</a> 中一样，所以不能用作硬阈值。我们可以根据需要设置 <span class="math notranslate nohighlight">\(\epsilon\)</span> 。我们可以选择一个标量值（ 相当于将所有 <span class="math notranslate nohighlight">\(i\)</span> 的 <span class="math notranslate nohighlight">\(\epsilon_i\)</span> 设置为相等 ）。这在评估数据上的距离而不是统计量上的距离时非常有用。在此情况下，合理猜测可能是数据的经验标准差。</p>
<p>如果我们改为使用统计量，那么可以将 <span class="math notranslate nohighlight">\(\epsilon\)</span> 设置为值列表。这通常是必要的，因为每个统计量可能具有不同的尺度。如果尺度差异太大，那么每个统计量的贡献将是不均衡的，甚至可能出现单个统计量主导距离计算的情况。在此情况下，<span class="math notranslate nohighlight">\(\epsilon\)</span> 的一个常用选择是在先验预测分布下的 <span class="math notranslate nohighlight">\(i^{\text{th}}\)</span> 个统计量的经验标准差，或中值绝对差，因为这样选择相对于异常值来说更为稳健。使用先验预测分布的问题之一是其可能比后验预测分布更宽，因此，为了找到一个合适的 <span class="math notranslate nohighlight">\(\epsilon\)</span> 值，我们可能希望将上述有依据的猜测作为上限，然后从这些值中尝试一些较低的值。然后我们可以根据计算成本、所需的精度/误差水平和采样器的效率等几个因素来选择 <span class="math notranslate nohighlight">\(\epsilon\)</span> 的最终值。一般来说，<span class="math notranslate nohighlight">\(\epsilon\)</span> 的值越低，近似值就越好。</p>
<p><a class="reference internal" href="#fig-trace-g-many-eps"><span class="std std-numref">Fig. 137</span></a> 显示了 <span class="math notranslate nohighlight">\(\mu\)</span> 和 <span class="math notranslate nohighlight">\(\sigma\)</span> 的几个 <span class="math notranslate nohighlight">\(\epsilon\)</span> 阈值设置以及 NUTS 采样的森林图（ 使用正常似然而不是模拟器 ）。</p>
<div class="figure align-default" id="fig-trace-g-many-eps">
<a class="reference internal image-reference" href="../_images/trace_g_many_eps.png"><img alt="../_images/trace_g_many_eps.png" src="../_images/trace_g_many_eps.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 137 </span><span class="caption-text"><span class="math notranslate nohighlight">\(\mu\)</span> 和 <span class="math notranslate nohighlight">\(\sigma\)</span> 的森林图，使用 <code class="docutils literal notranslate"><span class="pre">NUTS</span></code> 或近似贝叶斯计算获得，<span class="math notranslate nohighlight">\(\epsilon\)</span> 为 <span class="math notranslate nohighlight">\(1\)</span> 、<span class="math notranslate nohighlight">\(5\)</span> 和 <span class="math notranslate nohighlight">\(10\)</span> 的递增值。</span><a class="headerlink" href="#fig-trace-g-many-eps" title="Permalink to this image">¶</a></p>
</div>
<p>减小 <span class="math notranslate nohighlight">\(\epsilon\)</span> 的值并非毫无限制的，因为过低的值有时会使采样器非常低效，表明目标是一个没有太大意义的准确度水平。 <a class="reference internal" href="#fig-trace-g-eps-too-low"><span class="std std-numref">Fig. 138</span></a> 显示了当来自代码 <a class="reference internal" href="#gauss-abc"><span class="std std-ref">gauss_abc</span></a> 的模型以 <code class="docutils literal notranslate"><span class="pre">epsilon=0.1</span></code> 的值进行采样时，序贯蒙特卡洛采样器难以收敛，采样器非常失败。</p>
<div class="figure align-default" id="fig-trace-g-eps-too-low">
<a class="reference internal image-reference" href="../_images/trace_g_eps_too_low.png"><img alt="../_images/trace_g_eps_too_low.png" src="../_images/trace_g_eps_too_low.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 138 </span><span class="caption-text">模型<code class="docutils literal notranslate"><span class="pre">trace_g_001</span></code>的核密度估计和秩图，收敛失败表明 <span class="math notranslate nohighlight">\(\epsilon=0.1\)</span> 的取值对于该问题来说太苛刻了。</span><a class="headerlink" href="#fig-trace-g-eps-too-low" title="Permalink to this image">¶</a></p>
</div>
<p>为了能够为 <span class="math notranslate nohighlight">\(\epsilon\)</span> 确定一个好的值，可以使用一些非近似贝叶斯计算方法中的模型评价工具，例如贝叶斯 <span class="math notranslate nohighlight">\(p\)</span> 值和后验预测检查，如图 <a class="reference internal" href="#fig-bpv-g-many-eps-00"><span class="std std-numref">Fig. 139</span></a>、<a class="reference internal" href="#fig-bpv-g-many-eps-01"><span class="std std-numref">Fig. 140</span></a> 和 <a class="reference internal" href="#fig-ppc-g-many-eps"><span class="std std-numref">Fig. 141</span></a>。 <a class="reference internal" href="#fig-bpv-g-many-eps-00"><span class="std std-numref">Fig. 139</span></a> 包含值 <span class="math notranslate nohighlight">\(\epsilon=0.1\)</span> ，主要是为了展示校准不佳的模型。但在实践中，如果获得像 <a class="reference internal" href="#fig-trace-g-eps-too-low"><span class="std std-numref">Fig. 138</span></a> 中的秩图，我们应该停止分析计算得到的后验，并重新检查模型定义。此外，对于近似贝叶斯计算方法，还应检查超参数 <span class="math notranslate nohighlight">\(\epsilon\)</span> 的值、统计量或距离函数。</p>
<div class="figure align-default" id="fig-bpv-g-many-eps-00">
<a class="reference internal image-reference" href="../_images/bpv_g_many_eps_00.png"><img alt="../_images/bpv_g_many_eps_00.png" src="../_images/bpv_g_many_eps_00.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 139 </span><span class="caption-text"><span class="math notranslate nohighlight">\(\epsilon\)</span> 值递增的边缘贝叶斯 <span class="math notranslate nohighlight">\(p\)</span> 值分布。对于一个校准良好的模型，我们应该预期一个均匀分布。可以看到 <span class="math notranslate nohighlight">\(\epsilon=0.1\)</span> 的校准很糟糕，因为 <span class="math notranslate nohighlight">\(\epsilon\)</span> 的值也是如此。对于 <span class="math notranslate nohighlight">\(\epsilon\)</span> 的所有其他值，分布看起来更加均匀，并且均匀性水平随着 <span class="math notranslate nohighlight">\(\epsilon\)</span> 的增加而降低。<code class="docutils literal notranslate"><span class="pre">se</span></code> 值是预期均匀分布和核密度估计之间的（缩放的）平方差。</span><a class="headerlink" href="#fig-bpv-g-many-eps-00" title="Permalink to this image">¶</a></p>
</div>
<div class="figure align-default" id="fig-bpv-g-many-eps-01">
<a class="reference internal image-reference" href="../_images/bpv_g_many_eps_01.png"><img alt="../_images/bpv_g_many_eps_01.png" src="../_images/bpv_g_many_eps_01.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 140 </span><span class="caption-text">增加 <span class="math notranslate nohighlight">\(\epsilon\)</span> 值的贝叶斯 <span class="math notranslate nohighlight">\(p\)</span> 值。蓝色曲线是观测分布，灰色曲线是预期分布。对于一个校准良好的模型，我们期望分布集中在 <span class="math notranslate nohighlight">\(0.5\)</span> 左右。可以看到 <span class="math notranslate nohighlight">\(\epsilon=0.1\)</span> 的校准很糟糕，因为 <span class="math notranslate nohighlight">\(\epsilon\)</span> 的值太低了。可以看到 <span class="math notranslate nohighlight">\(\epsilon=1\)</span> 提供了最好的结果。</span><a class="headerlink" href="#fig-bpv-g-many-eps-01" title="Permalink to this image">¶</a></p>
</div>
<div class="figure align-default" id="fig-ppc-g-many-eps">
<a class="reference internal image-reference" href="../_images/ppc_g_many_eps.png"><img alt="../_images/ppc_g_many_eps.png" src="../_images/ppc_g_many_eps.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 141 </span><span class="caption-text"><span class="math notranslate nohighlight">\(\epsilon\)</span> 递增时的后验预测检查。蓝色曲线是观测分布，灰色曲线是预期分布。令人惊讶的是，从 <span class="math notranslate nohighlight">\(\epsilon=0.1\)</span> 中似乎得到了一个很好的调整，即便我们知道来自该后验的样本不可信。这是一个非常简单的例子，我们完全靠运气得到了正确答案。这是一个 <em>a too good to be true fit</em> 的例子。实际上这是最糟糕的！如果我们只考虑具有看起来合理的后验样本的模型（ 即不是 <span class="math notranslate nohighlight">\(\epsilon=0.1\)</span> ），则可以看到 <span class="math notranslate nohighlight">\(\epsilon=1\)</span> 提供了最好的结果。</span><a class="headerlink" href="#fig-ppc-g-many-eps" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="section" id="choosing-summary-statistics">
<span id="id20"></span><h3>8.4.3 选择统计量<a class="headerlink" href="#choosing-summary-statistics" title="Permalink to this headline">¶</a></h3>
<p>统计量的选择可能比距离函数的选择更难，并且会产生更大的影响。</p>
<p>出于此原因，许多研究都集中在这个主题上，从使用不需要统计量的距离 <span id="id21">[<a class="reference internal" href="references.html#id47">93</a>, <a class="reference internal" href="references.html#id46">94</a>]</span> 到选择统计量的策略 <span id="id22">[<a class="reference internal" href="references.html#id50">96</a>]</span>。</p>
<p>一个好的统计量提供了低维度和信息量之间的平衡。当我们没有足够统计量数据时，很容易通过添加大量统计量数据来进行过度补偿。直觉是信息越多越好。然而，增加统计量的数量实际上会降低近似后验 <span id="id23">[<a class="reference internal" href="references.html#id50">96</a>]</span> 的质量。对此的一种解释是，我们从计算数据上的距离转移到计算摘要上的距离以减少维度，通过增加我们正在违背该目的的摘要统计数据的数量。</p>
<p>在一些领域，如群体遗传学，近似贝叶斯计算方法非常普遍，人们开发了大量有用的统计量数据 <span id="id24">[<a class="reference internal" href="references.html#id53">97</a>, <a class="reference internal" href="references.html#id54">98</a>, <a class="reference internal" href="references.html#id51">99</a>]</span>。一般来说，查看你正在研究的应用领域的文献以了解其他人在做什么是一个好主意，因为他们已经尝试并测试了许多替代方案的机会很高。</p>
<p>如有疑问，我们可以遵循上一节中的相同建议来评估模型拟合，即秩图、贝叶斯 <span class="math notranslate nohighlight">\(p\)</span> 值、后验预测检查等，并在必要时尝试替代方案（参见图 <a class="reference internal" href="#fig-trace-g-eps-too-low"><span class="std std-numref">Fig. 138</span></a>， <a class="reference internal" href="#fig-bpv-g-many-eps-00"><span class="std std-numref">Fig. 139</span></a>、<a class="reference internal" href="#fig-bpv-g-many-eps-01"><span class="std std-numref">Fig. 140</span></a> 和 <a class="reference internal" href="#fig-ppc-g-many-eps"><span class="std std-numref">Fig. 141</span></a>）。</p>
</div>
</div>
<div class="section" id="g-and-k">
<span id="g-and-k-distribution"></span><h2>8.5 <code class="docutils literal notranslate"><span class="pre">g-and-k</span></code> 分布<a class="headerlink" href="#g-and-k" title="Permalink to this headline">¶</a></h2>
<p>一氧化碳 ( <span class="math notranslate nohighlight">\(CO\)</span> ) 是一种无色、无味的气体，大量吸入有害甚至致命。当某物燃烧时会产生这种气体，尤其是在氧气含量低的情况下。世界上许多城市通常会监测一氧化碳和其他气体，如二氧化氮 ( <span class="math notranslate nohighlight">\(NO_2\)</span> )，以评估空气污染程度和空气质量。在城市中，一氧化碳的主要来源是汽车以及其他燃料化石车辆或机械。 <a class="reference internal" href="#fig-co-ppm-bsas"><span class="std std-numref">Fig. 142</span></a> 显示了 <span class="math notranslate nohighlight">\(2010\)</span> 年至 <span class="math notranslate nohighlight">\(2018\)</span> 年布宜诺斯艾利斯市一个站点测量的每日 <span class="math notranslate nohighlight">\(CO\)</span> 水平的直方图。</p>
<p>正如我们所见，数据似乎略微向右偏。此外，数据显示了一些具有非常高的观测值。</p>
<p>底部子图省略了 <span class="math notranslate nohighlight">\(3\)</span> 到 <span class="math notranslate nohighlight">\(30\)</span> 之间的 <span class="math notranslate nohighlight">\(8\)</span> 个观测值。</p>
<div class="figure align-default" id="fig-co-ppm-bsas">
<a class="reference internal image-reference" href="../_images/co_ppm_bsas.png"><img alt="../_images/co_ppm_bsas.png" src="../_images/co_ppm_bsas.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 142 </span><span class="caption-text"><span class="math notranslate nohighlight">\(CO\)</span> 水平的直方图。顶部子图显示整个数据，底部子图忽略了大于 <span class="math notranslate nohighlight">\(3\)</span> 的值。</span><a class="headerlink" href="#fig-co-ppm-bsas" title="Permalink to this image">¶</a></p>
</div>
<p>为了拟合这些数据，我们将引入<code class="docutils literal notranslate"><span class="pre">单变量</span> <span class="pre">g-and-k</span> <span class="pre">分布</span></code>。这是一个 <span class="math notranslate nohighlight">\(4\)</span> 参数的分布，能够描述具有高偏度和/或高峰度的数据 <span id="id25">[<a class="reference internal" href="references.html#id40">100</a>, <a class="reference internal" href="references.html#id41">101</a>]</span>。<code class="docutils literal notranslate"><span class="pre">g-and-k</span> <span class="pre">分布</span></code>的密度函数没有封闭形式的表达式，并且通过其分位数函数（即累积分布函数的逆函数）来进行定义：</p>
<div class="math notranslate nohighlight" id="equation-eq-g-and-k">
<span class="eqno">(76)<a class="headerlink" href="#equation-eq-g-and-k" title="Permalink to this equation">¶</a></span>\[a + b \ \left(1 + c \ \text{tanh}\left[\frac{gz(x)}{2}\right]\right) \left(1+z(x)^2\right)^k z(x)\]</div>
<p>其中 <span class="math notranslate nohighlight">\(z\)</span> 是标准高斯累积分布函数的逆函数，<span class="math notranslate nohighlight">\(x \in (0,1)\)</span>。</p>
<p>（1）参数 <span class="math notranslate nohighlight">\(a\)</span> 、 <span class="math notranslate nohighlight">\(b\)</span> 、 <span class="math notranslate nohighlight">\(g\)</span> 和 <span class="math notranslate nohighlight">\(k\)</span> 分别为位置、尺度、偏度和峰度参数。如果 <span class="math notranslate nohighlight">\(g\)</span> 和 <span class="math notranslate nohighlight">\(k\)</span> 均为 <span class="math notranslate nohighlight">\(0\)</span>，则恢复了具有均值 <span class="math notranslate nohighlight">\(a\)</span> 和标准差 <span class="math notranslate nohighlight">\(b\)</span> 的高斯分布。</p>
<p>（2）<span class="math notranslate nohighlight">\(g &gt; 0\)</span> 给出正（右）偏度，<span class="math notranslate nohighlight">\(g &lt; 0\)</span> 给出负（左）偏度。参数 <span class="math notranslate nohighlight">\(k \geqslant 0\)</span> 给出的尾部比高斯分布长，而 <span class="math notranslate nohighlight">\(k &lt; 0\)</span> 的尾部比高斯分布短。</p>
<p>（3）<span class="math notranslate nohighlight">\(a\)</span> 和 <span class="math notranslate nohighlight">\(g\)</span> 可以取任何实数值。通常将 <span class="math notranslate nohighlight">\(b\)</span> 限制为正数并且 <span class="math notranslate nohighlight">\(k \geqslant -0.5\)</span> 或有时 <span class="math notranslate nohighlight">\(k \geqslant 0\)</span> （即尾部与高斯分布中的尾部一样重或更重）。</p>
<p>（4）此外，通常固定 <span class="math notranslate nohighlight">\(c=0.8\)</span>。</p>
<p>有了所有这些限制，我们可以保证得到一个严格递增的分位数函数 <span id="id26">[<a class="reference internal" href="references.html#id41">101</a>]</span>，而这正是连续分布函数的标志。</p>
<p>代码 <a class="reference internal" href="#gk-quantile"><span class="std std-ref">gk_quantile</span></a> 定义了 <code class="docutils literal notranslate"><span class="pre">g-and-k</span> <span class="pre">分位数分布</span></code>。我们省略了 <code class="docutils literal notranslate"><span class="pre">cdf</span></code> 和 <code class="docutils literal notranslate"><span class="pre">pdf</span></code> 的计算，因为涉及太多额外内容，而且在我们的例子中暂时用不到 <a class="footnote-reference brackets" href="#id61" id="id27">8</a>。</p>
<p>虽然 <code class="docutils literal notranslate"><span class="pre">g-and-k</span> <span class="pre">分布</span></code> 的概率密度函数可以用数值方法推算 <span id="id28">[<a class="reference internal" href="references.html#id41">101</a>, <a class="reference internal" href="references.html#id45">102</a>]</span>，但使用反演方法从 <code class="docutils literal notranslate"><span class="pre">g-and-k</span> <span class="pre">模型</span></code> 中进行模拟更直接和快捷 <span id="id29">[<a class="reference internal" href="references.html#id45">102</a>, <a class="reference internal" href="references.html#id42">103</a>]</span>。</p>
<p>为了实现反演方法，我们对 <span class="math notranslate nohighlight">\(x \sim \mathcal{U}(0, 1)\)</span> 进行采样并替换公式 <a class="reference internal" href="#equation-eq-g-and-k">(76)</a>。代码 <a class="reference internal" href="#gk-quantile"><span class="std std-ref">gk_quantile</span></a> 展示了如何在 Python 中执行此操作，<a class="reference internal" href="#fig-gk-quantile"><span class="std std-numref">Fig. 143</span></a> 展示了 <code class="docutils literal notranslate"><span class="pre">g-and-k</span> <span class="pre">分布</span></code> 的示例。</p>
<div class="literal-block-wrapper docutils container" id="gk-quantile">
<div class="code-block-caption"><span class="caption-number">Listing 107 </span><span class="caption-text">gk_quantile</span><a class="headerlink" href="#gk-quantile" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">g_and_k_quantile</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">quantile_normal</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html#scipy.stats.norm" title="scipy.stats.norm"><span class="n">stats</span><span class="o">.</span><span class="n">norm</span></a><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">ppf</span>

    <span class="k">def</span> <span class="nf">ppf</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
        <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">quantile_normal</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="mf">0.8</span> <span class="o">*</span> <a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.tanh.html#numpy.tanh" title="numpy.tanh"><span class="n">np</span><span class="o">.</span><span class="n">tanh</span></a><span class="p">(</span><span class="n">g</span><span class="o">*</span><span class="n">z</span><span class="o">/</span><span class="mi">2</span><span class="p">))</span> <span class="o">*</span> <span class="p">((</span><span class="mi">1</span> <span class="o">+</span> <span class="n">z</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">**</span><span class="n">k</span><span class="p">)</span> <span class="o">*</span> <span class="n">z</span>

    <span class="k">def</span> <span class="nf">rvs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">samples</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/random/generated/numpy.random.normal.html#numpy.random.normal" title="numpy.random.normal"><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span></a><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">samples</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">ppf</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="figure align-default" id="fig-gk-quantile">
<a class="reference internal image-reference" href="../_images/gk_quantile.png"><img alt="../_images/gk_quantile.png" src="../_images/gk_quantile.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 143 </span><span class="caption-text">第一行显示了分位数函数，也称为累积分布函数（ <code class="docutils literal notranslate"><span class="pre">CDF</span></code> ）的逆函数。给定一个分位数值，它会返回代表该分位数的变量值。例如，如果你有 <span class="math notranslate nohighlight">\(P(X &lt;= x_q) = q\)</span>，则将 <span class="math notranslate nohighlight">\(q\)</span> 传递给分位数函数可以得到 <span class="math notranslate nohighlight">\(x_q\)</span>。图中第二行显示了（近似的）概率密度函数。对于此示例，使用核密度估计可以直接从代码 <a class="reference internal" href="#gk-quantile"><span class="std std-ref">gk_quantile</span></a> 生成的随机样本中计算得到概率密度函数。</span><a class="headerlink" href="#fig-gk-quantile" title="Permalink to this image">¶</a></p>
</div>
<p>要使用 <code class="docutils literal notranslate"><span class="pre">SMC-ABC</span></code> 拟合 <code class="docutils literal notranslate"><span class="pre">g-k</span> <span class="pre">分布</span></code>，可以使用高斯距离和 <code class="docutils literal notranslate"><span class="pre">sum_stat="sort"</span></code>。或者，也可以考虑为这个问题量身定制的统计量。参数 <span class="math notranslate nohighlight">\(a\)</span> 、<span class="math notranslate nohighlight">\(b\)</span> 、 <span class="math notranslate nohighlight">\(g\)</span> 和 <span class="math notranslate nohighlight">\(k\)</span> 分别与位置、尺度、偏度和峰度相关联。因此，可以用这些量的稳健估计来作为新的专用统计量 <span id="id30">[<a class="reference internal" href="references.html#id42">103</a>]</span> ：</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{split}
sa &amp;= e4 \\
sb &amp;= e6 - e2 \\  
sg &amp;= (e6 + e2 - 2*e4)/sb \\ 
sk &amp;= (e7 - e5 + e3 - e1)/sb \\
\end{split}\end{split}\]</div>
<p>其中 <span class="math notranslate nohighlight">\(e1\)</span> 到 <span class="math notranslate nohighlight">\(e7\)</span> 是八分位数，即将样本分成八个子集的分位数。</p>
<p>如果注意，可以看到 <span class="math notranslate nohighlight">\(sa\)</span> 是中位数，<span class="math notranslate nohighlight">\(sb\)</span> 是四分位数范围，它们分别作为位置和离散度的稳健估计量。 <span class="math notranslate nohighlight">\(sg\)</span> 和 <span class="math notranslate nohighlight">\(sk\)</span> 看起来有点模糊，但它们分别是偏度 <span id="id31">[<a class="reference internal" href="references.html#id43">104</a>]</span> 和峰度 <span id="id32">[<a class="reference internal" href="references.html#id44">105</a>]</span> 的稳健估计量。</p>
<p>对于对称分布，<span class="math notranslate nohighlight">\(e6-e4\)</span> 和 <span class="math notranslate nohighlight">\(e2-e4\)</span> 将具有相同的幅度但符号相反，此时 <span class="math notranslate nohighlight">\(sg\)</span> 将为零，而对于偏斜分布，<span class="math notranslate nohighlight">\(e6-e4\)</span> 将大于 <span class="math notranslate nohighlight">\( e2-e4\)</span> 或相反。</p>
<p>当 <span class="math notranslate nohighlight">\(e6\)</span> 和 <span class="math notranslate nohighlight">\(e2\)</span> 附近的概率质量减少时（ 即当质量从分布的中心部分移动到尾部时 ），<span class="math notranslate nohighlight">\(sk\)</span> 的分子项在增加。而 <span class="math notranslate nohighlight">\(sg\)</span> 和 <span class="math notranslate nohighlight">\(sk\)</span> 中的分母都充当了归一化因子。</p>
<p>综合分析后，可以使用 Python 为问题创建新的统计量，如以下代码所示。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">octo_summary</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">e1</span><span class="p">,</span> <span class="n">e2</span><span class="p">,</span> <span class="n">e3</span><span class="p">,</span> <span class="n">e4</span><span class="p">,</span> <span class="n">e5</span><span class="p">,</span> <span class="n">e6</span><span class="p">,</span> <span class="n">e7</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.quantile.html#numpy.quantile" title="numpy.quantile"><span class="n">np</span><span class="o">.</span><span class="n">quantile</span></a><span class="p">(</span>
        <span class="n">x</span><span class="p">,</span> <span class="p">[</span><span class="mf">.125</span><span class="p">,</span> <span class="mf">.25</span><span class="p">,</span> <span class="mf">.375</span><span class="p">,</span> <span class="mf">.5</span><span class="p">,</span> <span class="mf">.625</span><span class="p">,</span> <span class="mf">.75</span><span class="p">,</span> <span class="mf">.875</span><span class="p">])</span>
    <span class="n">sa</span> <span class="o">=</span> <span class="n">e4</span>
    <span class="n">sb</span> <span class="o">=</span> <span class="n">e6</span> <span class="o">-</span> <span class="n">e2</span>
    <span class="n">sg</span> <span class="o">=</span> <span class="p">(</span><span class="n">e6</span> <span class="o">+</span> <span class="n">e2</span> <span class="o">-</span> <span class="mi">2</span><span class="o">*</span><span class="n">e4</span><span class="p">)</span><span class="o">/</span><span class="n">sb</span>
    <span class="n">sk</span> <span class="o">=</span> <span class="p">(</span><span class="n">e7</span> <span class="o">-</span> <span class="n">e5</span> <span class="o">+</span> <span class="n">e3</span> <span class="o">-</span> <span class="n">e1</span><span class="p">)</span><span class="o">/</span><span class="n">sb</span>
    <span class="k">return</span> <a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="n">sa</span><span class="p">,</span> <span class="n">sb</span><span class="p">,</span> <span class="n">sg</span><span class="p">,</span> <span class="n">sk</span><span class="p">])</span>
</pre></div>
</div>
<p>现在我们需要定义一个模拟器，只需将之前在代码 <a class="reference internal" href="#gk-quantile"><span class="std std-ref">gk_quantile</span></a> 中定义的 <code class="docutils literal notranslate"><span class="pre">g_and_k_quantile()</span></code> 函数的 <code class="docutils literal notranslate"><span class="pre">rvs</span></code> 方法封装起来即可。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">gk</span> <span class="o">=</span> <span class="n">g_and_k_quantile</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">gk_simulator</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">gk</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">bsas_co</span><span class="p">),</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
</pre></div>
</div>
<p>在定义了统计量和模拟器并导入数据之后，就可以定义模型了。</p>
<p>对于这个例子，基于所有参数都限制为正的事实，可以使用弱信息先验。 <span class="math notranslate nohighlight">\(CO\)</span> 水平不能取负值，因此 <span class="math notranslate nohighlight">\(a\)</span> 为正值； <span class="math notranslate nohighlight">\(g\)</span> 也预计为 <span class="math notranslate nohighlight">\(0\)</span> 或正值，因为大部分测量值预计为“low”，只有某些测量值值较大。我们也有理由假设参数很有可能低于 <span class="math notranslate nohighlight">\(1\)</span>。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">gkm</span><span class="p">:</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s2">"a"</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s2">"b"</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">g</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s2">"g"</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">k</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s2">"k"</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="n">s</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Simulator</span><span class="p">(</span><span class="s2">"s"</span><span class="p">,</span> <span class="n">gk_simulator</span><span class="p">,</span>
    <span class="n">params</span><span class="o">=</span><span class="p">[</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">k</span><span class="p">],</span>        
                     <span class="n">sum_stat</span><span class="o">=</span><span class="n">octo_summary</span><span class="p">,</span>
                     <span class="n">epsilon</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                     <span class="n">observed</span><span class="o">=</span><span class="n">bsas_co</span><span class="p">)</span>
    
    <span class="n">trace_gk</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample_smc</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s2">"ABC"</span><span class="p">,</span> <span class="n">parallel</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p><a class="reference internal" href="#fig-plot-pair"><span class="std std-numref">Fig. 144</span></a> 显示了拟合后 <code class="docutils literal notranslate"><span class="pre">gkm</span> <span class="pre">模型</span></code> 的配对图。</p>
<div class="figure align-default" id="fig-plot-pair">
<a class="reference internal image-reference" href="../_images/pair_gk.png"><img alt="../_images/pair_gk.png" src="../_images/pair_gk.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 144 </span><span class="caption-text">分布略微偏斜，并且具有一定程度的峰度，正如所预计的那样，少量的 <span class="math notranslate nohighlight">\(CO\)</span> 水平比其他大部分情况要高出一到两个数量级。可以看到 <span class="math notranslate nohighlight">\(b\)</span> 和 <span class="math notranslate nohighlight">\(k\)</span> （略微）相关。这也是可预期的，因为随着尾部密度（峰度）的增加，离散度会同时增加，但如果 <span class="math notranslate nohighlight">\(k\)</span> 增加，<code class="docutils literal notranslate"><span class="pre">g-and-k</span> <span class="pre">分布</span></code>可以保持 <span class="math notranslate nohighlight">\(b\)</span> 较小。这就像 <span class="math notranslate nohighlight">\(k\)</span> 在吸收离散度一样，有点类似于在学生 <span class="math notranslate nohighlight">\(t\)</span> 分布中使用的尺度和 <span class="math notranslate nohighlight">\(\nu\)</span> 参数的情况。</span><a class="headerlink" href="#fig-plot-pair" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="section" id="abc-ma">
<span id="id33"></span><h2>8.6 移动平均模型的近似<a class="headerlink" href="#abc-ma" title="Permalink to this headline">¶</a></h2>
<p>移动平均 (MA) 模型是建模单变量时间序列的常用方法（参见 <a class="reference internal" href="chp_06.html#chap4"><span class="std std-ref"> 第 6 章 </span></a> ）。 <span class="math notranslate nohighlight">\(MA(q)\)</span> 模型指定输出变量线性依赖于随机项 <span class="math notranslate nohighlight">\(\lambda\)</span> 的当前值和 <span class="math notranslate nohighlight">\(q\)</span> 个历史值， <span class="math notranslate nohighlight">\(q\)</span> 被称为 <code class="docutils literal notranslate"><span class="pre">MA</span> <span class="pre">模型</span></code> 的阶数。</p>
<div class="math notranslate nohighlight">
\[y_t = \mu + \lambda_t + \theta_1 \lambda_{t-1} + \cdots + \theta_q \lambda_{t-q}\]</div>
<p>其中 <span class="math notranslate nohighlight">\(\lambda\)</span> 是高斯白噪声误差项 <a class="footnote-reference brackets" href="#id63" id="id34">9</a>。</p>
<p>这里将使用 <span id="id35">Marin <em>et al.</em> [<a class="reference internal" href="references.html#id39">106</a>]</span> 中的玩具模型。在该例中，使用均值为 <span class="math notranslate nohighlight">\(0\)</span> 的 <span class="math notranslate nohighlight">\(MA(2)\)</span> 模型（ 即 <span class="math notranslate nohighlight">\(\mu =0\)</span> )，模型如下所示：</p>
<div class="math notranslate nohighlight">
\[y_t = \lambda_t + \theta_1 \lambda_{t-1} +  \theta_2 \lambda_{t-2}\]</div>
<p>代码 <a class="reference internal" href="#ma2-simulator-abc"><span class="std std-ref">ma2_simulator_abc</span></a> 显示了此模型的 Python 模拟器，在 <a class="reference internal" href="#fig-ma2-simulator-abc"><span class="std std-numref">Fig. 145</span></a> 中，可以看到 <span class="math notranslate nohighlight">\(\theta1 = 0.6\)</span> 、 <span class="math notranslate nohighlight">\(\theta2=0.2\)</span> 时该模拟器的两个实现。</p>
<div class="literal-block-wrapper docutils container" id="ma2-simulator-abc">
<div class="code-block-caption"><span class="caption-number">Listing 108 </span><span class="caption-text">ma2_simulator_abc</span><a class="headerlink" href="#ma2-simulator-abc" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">moving_average_2</span><span class="p">(</span><span class="n">θ1</span><span class="p">,</span> <span class="n">θ2</span><span class="p">,</span> <span class="n">n_obs</span><span class="o">=</span><span class="mi">200</span><span class="p">):</span>
    <span class="n">λ</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/random/generated/numpy.random.normal.html#numpy.random.normal" title="numpy.random.normal"><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span></a><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_obs</span><span class="o">+</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">λ</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span> <span class="o">+</span> <span class="n">θ1</span><span class="o">*</span><span class="n">λ</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">θ2</span><span class="o">*</span><span class="n">λ</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">y</span>
</pre></div>
</div>
</div>
<div class="figure align-default" id="fig-ma2-simulator-abc">
<a class="reference internal image-reference" href="../_images/ma2_simulator_abc.png"><img alt="../_images/ma2_simulator_abc.png" src="../_images/ma2_simulator_abc.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 145 </span><span class="caption-text"><span class="math notranslate nohighlight">\(MA(2)\)</span> 模型的两种实现， <span class="math notranslate nohighlight">\(\theta1=0.6\)</span> ， <span class="math notranslate nohighlight">\(\theta2 =0.2\)</span>。左列为核密度估计，右列为时间序列。</span><a class="headerlink" href="#fig-ma2-simulator-abc" title="Permalink to this image">¶</a></p>
</div>
<p>理论上，我们可以尝试想要的任何距离函数和/或统计量来拟合 <span class="math notranslate nohighlight">\(MA(q)\)</span> 模型，但此处我们不会这样做，而是使用 <span class="math notranslate nohighlight">\(MA(q)\)</span> 模型的一些属性作为牵引。时间序列的自相关性是 <span class="math notranslate nohighlight">\(MA(q)\)</span> 模型的一个重要属性。理论表明，对于 <span class="math notranslate nohighlight">\(MA(q)\)</span> 模型，大于 <span class="math notranslate nohighlight">\(q\)</span> 的滞后效应为零，因此对于 <span class="math notranslate nohighlight">\(MA(2)\)</span> ，使用滞后 <span class="math notranslate nohighlight">\(1\)</span> 和滞后 <span class="math notranslate nohighlight">\(2\)</span> 的自相关函数作为统计量似乎也是合理的。此外，为了避免计算数据的方差，我们将使用自协方差函数而不是自相关函数。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">autocov</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
    <span class="k">return</span> <a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.mean.html#numpy.mean" title="numpy.mean"><span class="n">np</span><span class="o">.</span><span class="n">mean</span></a><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">:]</span> <span class="o">*</span> <span class="n">x</span><span class="p">[:</span><span class="o">-</span><span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">)])</span>
</pre></div>
</div>
<p>此外，除非引入一些约束，否则 <span class="math notranslate nohighlight">\(MA(q)\)</span> 模型是不可识别的。对于 $<span class="math notranslate nohighlight">\(MA(1)\)</span><span class="math notranslate nohighlight">\( 模型，约束为 \)</span>-1&lt;\theta_1&lt;1<span class="math notranslate nohighlight">\(。 对于 \)</span>MA(2)<span class="math notranslate nohighlight">\(， 约束为 \)</span>-2&lt;\theta_1&lt;2<span class="math notranslate nohighlight">\( 、 \)</span>\theta_1 + \theta_2 &gt; -1<span class="math notranslate nohighlight">\( 和 \)</span>\theta_1 - \theta_2 &lt; 1$，这意味着需要从一个三角形中采样，如<a class="reference internal" href="#fig-ma2-triangle"><span class="std std-numref">Fig. 147</span></a>。</p>
<p>结合自定义的统计量和可识别约束的近似贝叶斯计算模型见代码 <a class="reference internal" href="#ma2-abc"><span class="std std-ref">MA2_abc</span></a> 。</p>
<div class="literal-block-wrapper docutils container" id="ma2-abc">
<div class="code-block-caption"><span class="caption-number">Listing 109 </span><span class="caption-text">MA2_abc</span><a class="headerlink" href="#ma2-abc" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">m_ma2</span><span class="p">:</span>
    <span class="n">θ1</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="s2">"θ1"</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">θ2</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="s2">"θ2"</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">p1</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Potential</span><span class="p">(</span><span class="s2">"p1"</span><span class="p">,</span> <span class="n">pm</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">switch</span><span class="p">(</span><span class="n">θ1</span><span class="o">+</span><span class="n">θ2</span> <span class="o">&gt;</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/constants.html#numpy.inf" title="numpy.inf"><span class="n">np</span><span class="o">.</span><span class="n">inf</span></a><span class="p">))</span>
    <span class="n">p2</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Potential</span><span class="p">(</span><span class="s2">"p2"</span><span class="p">,</span> <span class="n">pm</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">switch</span><span class="p">(</span><span class="n">θ1</span><span class="o">-</span><span class="n">θ2</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/constants.html#numpy.inf" title="numpy.inf"><span class="n">np</span><span class="o">.</span><span class="n">inf</span></a><span class="p">))</span>

    <span class="n">y</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Simulator</span><span class="p">(</span><span class="s2">"y"</span><span class="p">,</span> <span class="n">moving_average_2</span><span class="p">,</span> 
                     <span class="n">params</span><span class="o">=</span><span class="p">[</span><span class="n">θ1</span><span class="p">,</span> <span class="n">θ2</span><span class="p">],</span>
                     <span class="n">sum_stat</span><span class="o">=</span><span class="n">autocov</span><span class="p">,</span>
                     <span class="n">epsilon</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                     <span class="n">observed</span><span class="o">=</span><span class="n">y_obs</span><span class="p">)</span>

    <span class="n">trace_ma2</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample_smc</span><span class="p">(</span><span class="mi">3000</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="s2">"ABC"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">pm.Potential</span></code> 是一种无需向模型添加新变量，即可将任意项合并到（伪）似然的方法。引入约束特别有用。在代码 <a class="reference internal" href="#ma2-abc"><span class="std std-ref">MA2_abc</span></a> 中，如果 <code class="docutils literal notranslate"><span class="pre">pm.math.switch</span></code> 中的第一个参数为真，则我们将 <span class="math notranslate nohighlight">\(0\)</span> 与似然相加，否则为 <span class="math notranslate nohighlight">\(-\infty\)</span>。</p>
<div class="figure align-default" id="fig-ma2-trace">
<a class="reference internal image-reference" href="../_images/ma2_trace.png"><img alt="../_images/ma2_trace.png" src="../_images/ma2_trace.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 146 </span><span class="caption-text"><span class="math notranslate nohighlight">\(MA(2)\)</span> 模型的近似贝叶斯计算轨迹图。正如预计的那样，真实参数被恢复，秩图看起来非常平坦。</span><a class="headerlink" href="#fig-ma2-trace" title="Permalink to this image">¶</a></p>
</div>
<div class="figure align-default" id="fig-ma2-triangle">
<a class="reference internal image-reference" href="../_images/ma2_triangle.png"><img alt="../_images/ma2_triangle.png" src="../_images/ma2_triangle.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 147 </span><span class="caption-text">代码 <a class="reference internal" href="#ma2-abc"><span class="std std-ref">MA2_abc</span></a> 中定义的 <span class="math notranslate nohighlight">\(MA(2)\)</span> 模型的近似贝叶斯计算后验。中间的子图为 <span class="math notranslate nohighlight">\(\theta1\)</span> 和 <span class="math notranslate nohighlight">\(\theta2\)</span> 的联合后验分布，两侧为其边缘分布；灰色的三角形代表先验分布；均值用黑色的点表示。</span><a class="headerlink" href="#fig-ma2-triangle" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="section" id="model-comparison-in-the-abc-context">
<span id="id36"></span><h2>8.7 在近似贝叶斯计算的场景中做模型比较<a class="headerlink" href="#model-comparison-in-the-abc-context" title="Permalink to this headline">¶</a></h2>
<p>近似贝叶斯计算方法经常用于模型选择。虽然已经提出了许多模型比较方法 <span id="id37">[<a class="reference internal" href="references.html#id50">96</a>, <a class="reference internal" href="references.html#id52">107</a>]</span>，但此处将重点讨论两种方法：<strong>贝叶斯因子法</strong>（包括与 <code class="docutils literal notranslate"><span class="pre">LOO</span></code> 的比较）和<strong>随机森林法</strong> <span id="id38">[<a class="reference internal" href="references.html#id51">99</a>]</span>。</p>
<p>与参数推断一样，在模型比较中统计量的选择至关重要。当使用模型的预测结果来评估多个模型时，如果它们都做出了大致相同的预测，则我们无法偏爱其中任何一个模型。相同的思想可以应用于（含统计量的）近似贝叶斯计算场景下的模型比较和选择。如果使用均值作为统计量，而模型预测的均值相同，那么此统计量将不足以区分模型的优劣。</p>
<p>我们应该花更多时间来思考是什么让模型与众不同。</p>
<div class="section" id="marginal-likelihood-and-loo">
<span id="id39"></span><h3>8.7.1 贝叶斯因子法<a class="headerlink" href="#marginal-likelihood-and-loo" title="Permalink to this headline">¶</a></h3>
<p>用于做模型比较的一个常见量是边缘似然。通常这种比较采用边缘似然比的形式，即<strong>贝叶斯因子</strong>。如果贝叶斯因子的值大于 <span class="math notranslate nohighlight">\(1\)</span> ，则分子中的模型优于分母中的模型，反之亦然。在 <a class="reference internal" href="chp_11.html#bayes-factors"><span class="std std-ref">边缘似然与模型比较</span></a> 中，我们讨论了有关贝叶斯因子的更多细节，包括其注意事项。其中一个警示是边缘似然通常难以计算。幸运的是，<code class="docutils literal notranslate"><span class="pre">SMC</span> <span class="pre">方法</span></code>和扩展的 <code class="docutils literal notranslate"><span class="pre">SMC-ABC</span> <span class="pre">方法</span></code>能够将边缘似然的计算转变成采样的副产品。 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 中的 <code class="docutils literal notranslate"><span class="pre">SMC</span></code> 计算并保存轨迹中的对数边缘似然，因此可以通过执行 <code class="docutils literal notranslate"><span class="pre">trace.report.log_marginal_likelihood</span></code> 来访问对数边缘似然的值。考虑到该值采用对数刻度，因此在计算贝叶斯因子时可以这样做：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ml1</span> <span class="o">=</span> <span class="n">trace_1</span><span class="o">.</span><span class="n">report</span><span class="o">.</span><span class="n">log_marginal_likelihood</span>
<span class="n">ml2</span> <span class="o">=</span> <span class="n">trace_2</span><span class="o">.</span><span class="n">report</span><span class="o">.</span><span class="n">log_marginal_likelihood</span>
<a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.exp.html#numpy.exp" title="numpy.exp"><span class="n">np</span><span class="o">.</span><span class="n">exp</span></a><span class="p">(</span><span class="n">ml1</span> <span class="o">-</span> <span class="n">ml2</span><span class="p">)</span>
</pre></div>
</div>
<p>当使用统计量时，通常不能用近似贝叶斯计算方法得出的边缘似然来比较竞争中的模型 <span id="id40">[<a class="reference internal" href="references.html#id61">108</a>]</span>，除非统计量对于模型比较来说是充分的。这一点非常令人沮丧，因为除了一些形式化示例或特定模型之外，没有通用的指南来确保模型的充分性 <span id="id41">[<a class="reference internal" href="references.html#id61">108</a>]</span> 。如果使用所有数据（ 即不依赖统计量 ）则不存在问题 <a class="footnote-reference brackets" href="#id64" id="id42">10</a>。这类似于 <a class="reference internal" href="chp_11.html#bayes-factors"><span class="std std-ref">边缘似然与模型比较</span></a> 中的讨论，即计算边缘似然通常是比计算后验困难得多的问题。即便我们设法找到了足以计算后验的统计量，也不能保证它对模型比较也有效。</p>
<p>为了更好地理解边缘似然在近似贝叶斯计算中的表现，现在将分析一个简短的实验。该实验中还包含 <code class="docutils literal notranslate"><span class="pre">LOO</span></code>，因为我们认为 <code class="docutils literal notranslate"><span class="pre">LOO</span></code> 是比<code class="docutils literal notranslate"><span class="pre">边缘似然</span></code>和<code class="docutils literal notranslate"><span class="pre">贝叶斯因子</span></code>更好的整体指标。</p>
<p>实验的基本方法是将具有显式似然的模型的对数边缘似然值、使用 <code class="docutils literal notranslate"><span class="pre">LOO</span></code> 计算的值、近似贝叶斯计算模型（采用含统计量和不含统计量的模拟器）的值进行比较。结果显示在图 <a class="reference internal" href="#fig-model-comp-normal-0"><span class="std std-numref">Fig. 148</span></a> 中，和代码 <a class="reference internal" href="#gauss-nuts"><span class="std std-ref">gauss_nuts</span></a> 以及代码 <a class="reference internal" href="#gauss-abc"><span class="std std-ref">gauss_abc</span></a> 中的。边缘（伪）似然值由 <code class="docutils literal notranslate"><span class="pre">SMC</span></code> 和 <code class="docutils literal notranslate"><span class="pre">LOO</span> <span class="pre">值</span></code>（ 调用 <code class="docutils literal notranslate"><span class="pre">az.loo()</span></code> 函数 ）的乘积计算得出。请注意，<code class="docutils literal notranslate"><span class="pre">LOO</span></code> 是在逐点的对数似然值上定义的，而在近似贝叶斯计算中，我们只能访问逐点的对数伪似然值。</p>
<p>从 <a class="reference internal" href="#fig-model-comp-normal-0"><span class="std std-numref">Fig. 148</span></a> 中可以看到，通常 <code class="docutils literal notranslate"><span class="pre">LOO</span></code> 和对数边缘似然的表现相似。从第一列中可以看到，<code class="docutils literal notranslate"><span class="pre">model_1</span></code> 始终被选为比 <code class="docutils literal notranslate"><span class="pre">model_0</span></code> 更好（这里越高越好）。模型之间的对数边缘似然的差（斜率）较 <code class="docutils literal notranslate"><span class="pre">LOO</span></code> 更大，这可以解释为 “边缘似然的计算明确考虑了先验，而 <code class="docutils literal notranslate"><span class="pre">LOO</span></code> 仅通过后验间接进行”，参见 <a class="reference internal" href="chp_11.html#bayes-factors"><span class="std std-ref">边缘似然与模型比较</span></a>  以了解详情。即使 <code class="docutils literal notranslate"><span class="pre">LOO</span></code> 值和边缘似然值因样本而异，它们也会存在比较一致的表现。我们可以从 <code class="docutils literal notranslate"><span class="pre">model_0</span></code> 和 <code class="docutils literal notranslate"><span class="pre">model_1</span></code> 之间线的斜率看到这一点。虽然线的斜率并不完全相同，但非常相似。这是模型选择方法的理想表现。如果我们比较<code class="docutils literal notranslate"><span class="pre">model_1</span></code>和<code class="docutils literal notranslate"><span class="pre">model_2</span></code>，可以得出类似结论。另外，注意两种模型对于 <code class="docutils literal notranslate"><span class="pre">LOO</span></code> 基本上无法区分，而边缘似然反映了更大的差异。再一次，原因是 <code class="docutils literal notranslate"><span class="pre">LOO</span></code> 仅从后验计算，而边缘似然直接考虑了先验。</p>
<div class="figure align-default" id="fig-model-comp-normal-0">
<a class="reference internal image-reference" href="../_images/model_comp_normal_00.png"><img alt="../_images/model_comp_normal_00.png" src="../_images/model_comp_normal_00.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 148 </span><span class="caption-text">模型 <code class="docutils literal notranslate"><span class="pre">m_0</span></code> 与公式 <a class="reference internal" href="#equation-eq-gauss-model">(73)</a> 中描述的模型相似，但具有 <span class="math notranslate nohighlight">\(\sigma \sim \mathcal{HN}(0.1)\)</span>。 <code class="docutils literal notranslate"><span class="pre">model_1</span></code> 与公式 <a class="reference internal" href="#equation-eq-gauss-model">(73)</a> 相同。 <code class="docutils literal notranslate"><span class="pre">model_2</span></code> 与公式 <a class="reference internal" href="#equation-eq-gauss-model">(73)</a> 相同，但使用 <span class="math notranslate nohighlight">\(\sigma \sim \mathcal{HN}(10)\)</span>。</span><a class="headerlink" href="#fig-model-comp-normal-0" title="Permalink to this image">¶</a></p>
<div class="legend">
<p>第一行对应于对数边缘似然值，第二行对应于 <code class="docutils literal notranslate"><span class="pre">LOO</span></code> 计算的值。</p>
<p>各列分别对应于序贯蒙特卡洛方法（<code class="docutils literal notranslate"><span class="pre">SMC</span></code>）、完整数据集的近似贝叶斯计算方法（ <code class="docutils literal notranslate"><span class="pre">SMC-ABC</span></code> ）、 使用均值统计量的近似贝叶斯计算方法（ <code class="docutils literal notranslate"><span class="pre">SMC-ABC_sm</span></code> ）、使用均值和标准差统计量的近似贝叶斯计算方法（ <code class="docutils literal notranslate"><span class="pre">SMC-ABC_sq</span></code> ）。我们共进行了 <span class="math notranslate nohighlight">\(50\)</span> 次实验，每次实验的样本量为 <span class="math notranslate nohighlight">\(50\)</span>。</p>
</div>
</div>
<p>图中第二列显示了近似贝叶斯计算方法的效果。我们仍然选择了 <code class="docutils literal notranslate"><span class="pre">model_1</span></code> 作为更好的模型，但现在 <code class="docutils literal notranslate"><span class="pre">model_0</span></code> 的离散度比 <code class="docutils literal notranslate"><span class="pre">model_1</span></code> 或 <code class="docutils literal notranslate"><span class="pre">model_2</span></code> 的离散度要大得多。此外，现在得到了相互交叉的线。综合起来，这两个观测似乎表明我们仍然可以使用 <code class="docutils literal notranslate"><span class="pre">LOO</span></code> 或对数边缘似然来选择最佳模型，但是相对值（ 例如由 <code class="docutils literal notranslate"><span class="pre">az.compare()</span></code> 计算的值或贝叶斯因子），则具有较大的变化性。</p>
<p>第三列显示了使用均值作为统计量时的情况。现在模型 <code class="docutils literal notranslate"><span class="pre">model_0</span></code> 和 <code class="docutils literal notranslate"><span class="pre">model_1</span></code> 看起来差不多，但 <code class="docutils literal notranslate"><span class="pre">model_2</span></code> 看起来比较糟糕。它几乎就像前一列的镜面图。这表明当使用含统计量的近似贝叶斯计算方法时，对数边缘似然和 <code class="docutils literal notranslate"><span class="pre">LOO</span></code> 可能无法提供合理答案。</p>
<p>第四列显示了使均值和标准差作为统计量时的情况。我们看到，可以定性地恢复第二列时观测到的表现。</p>
<div class="admonition- admonition">
<p class="admonition-title">关于伪似然的尺度</p>
<p>请注意 <span class="math notranslate nohighlight">\(y\)</span> 轴上的比例是不同的，尤其是跨列时。原因有两个：</p>
<p>（1）当使用近似贝叶斯计算时，我们使用按 <span class="math notranslate nohighlight">\(\epsilon\)</span> 缩放的核函数来逼近似然；</p>
<p>（2）当使用统计量时，我们正在减小数据的大小。另请注意，如果增加均值或分位数等统计量的样本量，则该大小将保持不变，即无论从 <span class="math notranslate nohighlight">\(10\)</span> 次还是 <span class="math notranslate nohighlight">\(1000\)</span> 次观测中计算均值，结果都是相同的数字。</p>
</div>
<p><a class="reference internal" href="#fig-model-comp-normal-forest"><span class="std std-numref">Fig. 149</span></a> 可以帮助我们理解 <a class="reference internal" href="#fig-model-comp-normal-0"><span class="std std-numref">Fig. 148</span></a> 中讨论的内容，建议你自己分析这两个图。</p>
<p>当前我们将重点关注两个结果：</p>
<p>首先，在执行 <code class="docutils literal notranslate"><span class="pre">SMC-ABC_sm</span></code> 时，我们有充分的均值统计量，但没有数据离散度的信息，因此参数 <code class="docutils literal notranslate"><span class="pre">a</span></code> 和 <code class="docutils literal notranslate"><span class="pre">σ</span></code> 的后验不确定性基本上由先验控制。注意 <code class="docutils literal notranslate"><span class="pre">model_0</span></code> 和 <code class="docutils literal notranslate"><span class="pre">model_1</span></code> 对于 <code class="docutils literal notranslate"><span class="pre">μ</span></code> 的估计值非常相似，而 <code class="docutils literal notranslate"><span class="pre">model_2</span></code> 的不确定性非常大。</p>
<p>其次，关于参数 <code class="docutils literal notranslate"><span class="pre">σ</span></code> ，<code class="docutils literal notranslate"><span class="pre">model_0</span></code> 的不确定性非常小，<code class="docutils literal notranslate"><span class="pre">model_1</span></code> 的不确定性应该更大，<code class="docutils literal notranslate"><span class="pre">model_2</span></code> 的不确定性大得离谱。</p>
<p>综上所述，我们可以看到为什么对数边缘似然和 <code class="docutils literal notranslate"><span class="pre">LOO</span></code> 表明 <code class="docutils literal notranslate"><span class="pre">model_0</span></code> 和 <code class="docutils literal notranslate"><span class="pre">model_1</span></code> 差不多，但 <code class="docutils literal notranslate"><span class="pre">model_2</span></code> 却非常不同。而基本上，<code class="docutils literal notranslate"><span class="pre">SMC-ABC_sm</span></code> 无法很好地拟合！因此使用 <code class="docutils literal notranslate"><span class="pre">SMC-ABC_sm</span></code> 计算的对数边缘似然和 <code class="docutils literal notranslate"><span class="pre">LOO</span></code> 与使用 <code class="docutils literal notranslate"><span class="pre">SMC</span></code> 或  <code class="docutils literal notranslate"><span class="pre">SMC-ABC</span></code> 计算的结果相矛盾。如果使用均值和标准差作为统计量（ <code class="docutils literal notranslate"><span class="pre">SMC-ABC_sq</span></code> ），我们可以部分恢复使用完整数据集的 <code class="docutils literal notranslate"><span class="pre">SMC-ABC</span></code> 时的表现。</p>
<div class="figure align-default" id="fig-model-comp-normal-forest">
<a class="reference internal image-reference" href="../_images/model_comp_normal_forest.png"><img alt="../_images/model_comp_normal_forest.png" src="../_images/model_comp_normal_forest.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 149 </span><span class="caption-text">模型 <code class="docutils literal notranslate"><span class="pre">m_0</span></code> 与公式 <a class="reference internal" href="#equation-eq-gauss-model">(73)</a> 中描述的模型相似，但具有 <span class="math notranslate nohighlight">\(\sigma \sim \mathcal{HN}(0.1)\)</span>。 <code class="docutils literal notranslate"><span class="pre">model_1</span></code> 与公式 <a class="reference internal" href="#equation-eq-gauss-model">(73)</a> 相同。 <code class="docutils literal notranslate"><span class="pre">model_2</span></code> 与公式 <a class="reference internal" href="#equation-eq-gauss-model">(73)</a> 相同，但使用 <span class="math notranslate nohighlight">\(\sigma \sim \mathcal{HN}(10)\)</span>。</span><a class="headerlink" href="#fig-model-comp-normal-forest" title="Permalink to this image">¶</a></p>
<div class="legend">
<p>第一行包含边缘似然值，第二行包含 <code class="docutils literal notranslate"><span class="pre">LOO</span> <span class="pre">值</span></code>。图中的列表示计算这些值的不同方法，分别是：序贯蒙特卡洛（<code class="docutils literal notranslate"><span class="pre">SMC</span></code>）、使用整个数据集的近似贝叶斯计算（<code class="docutils literal notranslate"><span class="pre">SMC-ABC</span></code>）、 使用均值作为统计量的近似贝叶斯计算（<code class="docutils literal notranslate"><span class="pre">SMC-ABC_sm</span></code>）、使用均值和标准差统计量的近似贝叶斯计算（<code class="docutils literal notranslate"><span class="pre">SMC-ABC_sq</span></code> ）。我们进行了 <span class="math notranslate nohighlight">\(50\)</span> 次实验，每次实验的样本量为 <span class="math notranslate nohighlight">\(50\)</span>。</p>
</div>
</div>
<p>图 <a class="reference internal" href="#fig-model-comp-pois-geom-0"><span class="std std-numref">Fig. 150</span></a> 和 <a class="reference internal" href="#fig-model-comp-pois-geom-forest"><span class="std std-numref">Fig. 151</span></a> 显示了类似的分析，但 <code class="docutils literal notranslate"><span class="pre">model_0</span></code> 是几何模型，而 <code class="docutils literal notranslate"><span class="pre">model_1</span></code> 是泊松模型。数据服从移位的泊松分布 <span class="math notranslate nohighlight">\(\mu \sim 1 + \text{Pois}(2.5)\)</span> 。我们将这些图的分析留给读者作为练习。</p>
<div class="figure align-default" id="fig-model-comp-pois-geom-0">
<a class="reference internal image-reference" href="../_images/model_comp_pois_geom_00.png"><img alt="../_images/model_comp_pois_geom_00.png" src="../_images/model_comp_pois_geom_00.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 150 </span><span class="caption-text">模型 <code class="docutils literal notranslate"><span class="pre">m_0</span></code> 是先验为 <span class="math notranslate nohighlight">\(p \sim \mathcal{U}(0, 1)\)</span> 的几何分布，而 <code class="docutils literal notranslate"><span class="pre">model_1</span></code> 是先验为 <span class="math notranslate nohighlight">\(\mu \sim \mathcal{E}(1)\)</span> 的泊松分布。数据服从移位的泊松分布 <span class="math notranslate nohighlight">\(\mu \sim 1 + \text{Pois}(2.5)\)</span>。序贯蒙特卡洛（ <code class="docutils literal notranslate"><span class="pre">SMC</span></code> ）、完整数据集的近似贝叶斯计算（ <code class="docutils literal notranslate"><span class="pre">SMC-ABC</span></code> ）、 使用均值作为统计量的近似贝叶斯计算（<code class="docutils literal notranslate"><span class="pre">SMC-ABC_sm</span></code>）、使用均值和标准差统计量的近似贝叶斯计算（<code class="docutils literal notranslate"><span class="pre">SMC-ABC_sq</span></code> ）。 我们进行了 <span class="math notranslate nohighlight">\(50\)</span> 次实验，每次实验的样本量为 <span class="math notranslate nohighlight">\(50\)</span>。</span><a class="headerlink" href="#fig-model-comp-pois-geom-0" title="Permalink to this image">¶</a></p>
</div>
<div class="figure align-default" id="fig-model-comp-pois-geom-forest">
<a class="reference internal image-reference" href="../_images/model_comp_pois_geom_forest.png"><img alt="../_images/model_comp_pois_geom_forest.png" src="../_images/model_comp_pois_geom_forest.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 151 </span><span class="caption-text"><code class="docutils literal notranslate"><span class="pre">model_0</span></code> 是先验为 <span class="math notranslate nohighlight">\(p \sim \mathcal{U}(0, 1)\)</span> 的几何模型/模拟器 <code class="docutils literal notranslate"><span class="pre">model_1</span></code> 是先验为 <span class="math notranslate nohighlight">\(p \sim \text{Expo}(1)\)</span> 的泊松模型/模拟器。第一行包含边缘似然值，第二行包含 <code class="docutils literal notranslate"><span class="pre">LOO</span></code> 值。各列表示计算这些值的不同方法：序贯蒙特卡洛（ <code class="docutils literal notranslate"><span class="pre">SMC</span></code> ）、完整数据集的近似贝叶斯计算（ <code class="docutils literal notranslate"><span class="pre">SMC-ABC</span></code> ）、 使用均值作为统计量的近似贝叶斯计算（<code class="docutils literal notranslate"><span class="pre">SMC-ABC_sm</span></code>）、使用均值和标准差统计量的近似贝叶斯计算（<code class="docutils literal notranslate"><span class="pre">SMC-ABC_sq</span></code> ）。 我们进行了 <span class="math notranslate nohighlight">\(50\)</span> 次实验，每次实验的样本量为 <span class="math notranslate nohighlight">\(50\)</span>。</span><a class="headerlink" href="#fig-model-comp-pois-geom-forest" title="Permalink to this image">¶</a></p>
</div>
<p>在近似贝叶斯计算的文献中，常使用贝叶斯因子来尝试将相对概率分配给模型，而这在某些领域是有价值的。所以我们想提醒那些从业者，在近似贝叶斯计算框架下这种做法存在一些潜在问题，特别是在实际应用中使用统计量比不使用统计量的情况要普遍得多。</p>
<p>模型比较仍然有用，主要是如果采用更具探索性的方法以及在模型比较之前执行模型批判以改进或丢弃明显错误指定的模型。这是在本书中为非近似贝叶斯计算方法采用的一般方法，因此我们认为将其扩展到近似贝叶斯计算框架也很自然。本书中也偏爱 <code class="docutils literal notranslate"><span class="pre">LOO</span></code> 而不是边缘似然，尽管目前尚缺少有关近似贝叶斯计算方法中 <code class="docutils literal notranslate"><span class="pre">LOO</span></code> 优缺点的研究，但我们认为 <code class="docutils literal notranslate"><span class="pre">LOO</span></code> 也可能对近似贝叶斯计算方法有用。请大家继续关注未来的消息！</p>
<div class="admonition- admonition">
<p class="admonition-title">模型批判和模型比较</p>
<p>虽然总是会出现一些错误指定，但模型比较可以帮助我们更好地理解模型及其错误指定。只有在我们证明模型对数据提供了合理的拟合之后，才应该进行模型比较。比较明显未拟合的模型没有太大意义。</p>
</div>
</div>
<div class="section" id="model-choice-via-random-forest">
<span id="id43"></span><h3>8.7.2 随机森林法<a class="headerlink" href="#model-choice-via-random-forest" title="Permalink to this headline">¶</a></h3>
<p>我们在上一节中讨论的一些注意事项促进了近似贝叶斯计算框架下模型选择新方法的研究。其中一种替代方法是<strong>将模型选择问题定义为随机森林分类问题</strong> <span id="id44">[<a class="reference internal" href="references.html#id51">99</a>]</span> <a class="footnote-reference brackets" href="#id65" id="id45">11</a>。随机森林是一种基于许多决策树的组合分类和回归方法，它与 <a class="reference internal" href="chp_07.html#chap6"><span class="std std-ref"> 第 7 章 </span></a> 中的 BART 密切相关。</p>
<p>该方法的主要思想是：最可能的模型可以从先验或后验预测分布的模拟样本中通过构建随机森林分类器获得。在原始论文中，作者使用了先验预测分布，但也提到对于更高级的近似贝叶斯计算方法，可以使用其他分布。在这里，我们将使用后验预测分布。对于 <span class="math notranslate nohighlight">\(m\)</span> 个模型，模拟数据在参考表中进行了排序，参见 <a class="reference internal" href="#table-abc-random-forest-ref-table"><span class="std std-numref">Table 15</span></a> 。</p>
<p>其中每一行是来自后验预测分布的一个样本，每一列是 <span class="math notranslate nohighlight">\(n\)</span> 个统计量之一。我们使用这个参考表来训练分类器，其任务是在给定统计量值的情况下，正确分类模型。重要的是要注意，用于模型选择的统计量和用于计算后验的统计量不一定相同。事实上，建议包括更多的统计量信息。一旦分类器训练完成，我们就使用和参考表中相同的 <span class="math notranslate nohighlight">\(n\)</span> 个统计量作为其输入，不过这次统计量的值来自于观测数据。分类器预测的模型将是最佳模型。</p>
<table class="table" id="table-abc-random-forest-ref-table">
<caption><span class="caption-number">Table 15 </span><span class="caption-text">Reference table</span><a class="headerlink" href="#table-abc-random-forest-ref-table" title="Permalink to this table">¶</a></caption>
<colgroup>
<col style="width: 20%"/>
<col style="width: 20%"/>
<col style="width: 20%"/>
<col style="width: 20%"/>
<col style="width: 20%"/>
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>Model</strong></p></td>
<td><p><span class="math notranslate nohighlight">\(\mathbf{S^{0}}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\mathbf{S^{1}}\)</span></p></td>
<td><p>…</p></td>
<td><p><span class="math notranslate nohighlight">\(\mathbf{S^{n}}\)</span></p></td>
</tr>
<tr class="row-even"><td><p>0</p></td>
<td></td>
<td></td>
<td><p>…</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>0</p></td>
<td></td>
<td></td>
<td><p>…</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>…</p></td>
<td><p>…</p></td>
<td><p>…</p></td>
<td><p>…</p></td>
<td><p>…</p></td>
</tr>
<tr class="row-odd"><td><p>1</p></td>
<td></td>
<td></td>
<td><p>…</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>1</p></td>
<td></td>
<td></td>
<td><p>…</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>m</p></td>
<td></td>
<td></td>
<td><p>…</p></td>
<td></td>
</tr>
</tbody>
</table>
<p>此外，还可以计算最佳模型相对于其他模型的近似后验概率。再一次，可以使用随机森林来实现，但这次使用回归，将错误分类的错误率作为结果变量，将参考表中的统计量作为自变量 <span id="id46">[<a class="reference internal" href="references.html#id51">99</a>]</span>。</p>
</div>
<div class="section" id="model-choice-for-ma-model">
<span id="id47"></span><h3>8.7.3 移动平均模型的模型选择<a class="headerlink" href="#model-choice-for-ma-model" title="Permalink to this headline">¶</a></h3>
<p>让我们回到移动平均的例子，这次将重点关注以下问题。 <span class="math notranslate nohighlight">\(MA(1)\)</span> 或 <span class="math notranslate nohighlight">\(MA(2)\)</span> 是更好的选择吗？为了回答这个问题，我们将使用 <code class="docutils literal notranslate"><span class="pre">LOO</span></code>（基于逐点伪似然值）和<code class="docutils literal notranslate"><span class="pre">随机森林法</span></code>。 <span class="math notranslate nohighlight">\(MA(1)\)</span> 模型看起来像这样：</p>
<div class="literal-block-wrapper docutils container" id="ma1-abc">
<div class="code-block-caption"><span class="caption-number">Listing 110 </span><span class="caption-text">MA1_abc</span><a class="headerlink" href="#ma1-abc" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">m_ma1</span><span class="p">:</span>
    <span class="n">θ1</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="s2">"θ1"</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Simulator</span><span class="p">(</span><span class="s2">"y"</span><span class="p">,</span> <span class="n">moving_average_1</span><span class="p">,</span>
                     <span class="n">params</span><span class="o">=</span><span class="p">[</span><span class="n">θ1</span><span class="p">],</span> <span class="n">sum_stat</span><span class="o">=</span><span class="n">autocov</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">y_obs</span><span class="p">)</span>
    <span class="n">trace_ma1</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample_smc</span><span class="p">(</span><span class="mi">2000</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="s2">"ABC"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>为了比较使用 <code class="docutils literal notranslate"><span class="pre">LOO</span></code> 的近似贝叶斯计算模型，不能直接使用 <code class="docutils literal notranslate"><span class="pre">az.compare</span></code> 函数。我们需要首先创建一个带有 <code class="docutils literal notranslate"><span class="pre">log_likelihood</span></code> 组的 <code class="docutils literal notranslate"><span class="pre">InferenceData</span></code> 对象，详见代码 <a class="reference internal" href="#idata-pseudo"><span class="std std-ref">idata_pseudo</span></a> <a class="footnote-reference brackets" href="#id66" id="id48">12</a>。此比较的结果汇总在 <a class="reference internal" href="#table-abc-loo"><span class="std std-numref">Table 16</span></a> 中，可以看到 <span class="math notranslate nohighlight">\(MA(2)\)</span> 模型是首选。</p>
<div class="literal-block-wrapper docutils container" id="idata-pseudo">
<div class="code-block-caption"><span class="caption-number">Listing 111 </span><span class="caption-text">idata_pseudo</span><a class="headerlink" href="#idata-pseudo" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">idata_ma1</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="https://arviz-devs.github.io/arviz/api/generated/arviz.from_pymc3.html#arviz.from_pymc3" title="arviz.from_pymc3"><span class="n">az</span><span class="o">.</span><span class="n">from_pymc3</span></a><span class="p">(</span><span class="n">trace_ma1</span><span class="p">)</span>
<span class="n">lpll</span> <span class="o">=</span> <span class="p">{</span><span class="s2">"s"</span><span class="p">:</span> <span class="n">trace_ma2</span><span class="o">.</span><span class="n">report</span><span class="o">.</span><span class="n">log_pseudolikelihood</span><span class="p">}</span>
<span class="n">idata_ma1</span><span class="o">.</span><span class="n">log_likelihood</span> <span class="o">=</span> <span class="n">az</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">base</span><span class="o">.</span><span class="n">dict_to_dataset</span><span class="p">(</span><span class="n">lpll</span><span class="p">)</span>

<span class="n">idata_ma2</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="https://arviz-devs.github.io/arviz/api/generated/arviz.from_pymc3.html#arviz.from_pymc3" title="arviz.from_pymc3"><span class="n">az</span><span class="o">.</span><span class="n">from_pymc3</span></a><span class="p">(</span><span class="n">trace_ma2</span><span class="p">)</span>
<span class="n">lpll</span> <span class="o">=</span> <span class="p">{</span><span class="s2">"s"</span><span class="p">:</span> <span class="n">trace_ma2</span><span class="o">.</span><span class="n">report</span><span class="o">.</span><span class="n">log_pseudolikelihood</span><span class="p">}</span>
<span class="n">idata_ma2</span><span class="o">.</span><span class="n">log_likelihood</span> <span class="o">=</span> <span class="n">az</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">base</span><span class="o">.</span><span class="n">dict_to_dataset</span><span class="p">(</span><span class="n">lpll</span><span class="p">)</span>

<a class="sphinx-codeautolink-a" href="https://arviz-devs.github.io/arviz/api/generated/arviz.compare.html#arviz.compare" title="arviz.compare"><span class="n">az</span><span class="o">.</span><span class="n">compare</span></a><span class="p">({</span><span class="s2">"m_ma1"</span><span class="p">:</span><span class="n">idata_ma1</span><span class="p">,</span> <span class="s2">"m_ma2"</span><span class="p">:</span><span class="n">idata_ma2</span><span class="p">})</span>
</pre></div>
</div>
</div>
<table class="table" id="table-abc-loo">
<caption><span class="caption-number">Table 16 </span><span class="caption-text">Summary ABC-model comparison using LOO</span><a class="headerlink" href="#table-abc-loo" title="Permalink to this table">¶</a></caption>
<colgroup>
<col style="width: 10%"/>
<col style="width: 10%"/>
<col style="width: 10%"/>
<col style="width: 10%"/>
<col style="width: 10%"/>
<col style="width: 10%"/>
<col style="width: 10%"/>
<col style="width: 10%"/>
<col style="width: 10%"/>
<col style="width: 10%"/>
</colgroup>
<tbody>
<tr class="row-odd"><td></td>
<td><p><strong>rank</strong></p></td>
<td><p><strong>loo</strong></p></td>
<td><p><strong>p_loo</strong></p></td>
<td><p><strong>d_loo</strong></p></td>
<td><p><strong>weight</strong></p></td>
<td><p><strong>se</strong></p></td>
<td><p><strong>dse</strong></p></td>
<td><p><strong>warning</strong></p></td>
<td><p><strong>loo_scale</strong></p></td>
</tr>
<tr class="row-even"><td><p>model_ma2</p></td>
<td><p>0</p></td>
<td><p>-2.22</p></td>
<td><p>1.52</p></td>
<td><p>0.00</p></td>
<td><p>1.0</p></td>
<td><p>0.08</p></td>
<td><p>0.00</p></td>
<td><p>False</p></td>
<td><p>log</p></td>
</tr>
<tr class="row-odd"><td><p>model_ma1</p></td>
<td><p>1</p></td>
<td><p>-3.53</p></td>
<td><p>2.04</p></td>
<td><p>1.31</p></td>
<td><p>0.0</p></td>
<td><p>1.50</p></td>
<td><p>1.43</p></td>
<td><p>False</p></td>
<td><p>log</p></td>
</tr>
</tbody>
</table>
<p>要使用随机森林法，可以使用本书随附代码中包含的 <code class="docutils literal notranslate"><span class="pre">select_model</span></code> 函数。为了使该函数工作，我们需要传递一个包含模型名称和轨迹的元组列表、一个统计量列表和观测数据。作为统计量，我们将使用前六个自相关。选择这些统计量有两个原因：第一个表明我们可以使用一组不同于拟合数据的统计量；第二个表明我们可以混合有用的统计量（前两个自相关）和不是非常有用的统计量（其余的）。请记住，理论说，对于一个 <span class="math notranslate nohighlight">\(MA(q)\)</span> 过程，最多有 <span class="math notranslate nohighlight">\(q\)</span> 个自相关。对于复杂问题，例如群体遗传学问题，使用数百甚至数万个统计量数据的情况并不少见 <span id="id49">[<a class="reference internal" href="references.html#id64">109</a>]</span>。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="n">select_model</span><span class="p">([(</span><span class="n">m_ma1</span><span class="p">,</span> <span class="n">trace_ma1</span><span class="p">),</span> <span class="p">(</span><span class="n">m_ma2</span><span class="p">,</span> <span class="n">trace_ma2</span><span class="p">)],</span>
             <span class="n">statistics</span><span class="o">=</span><span class="p">[</span><span class="n">partial</span><span class="p">(</span><span class="n">autocov</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">6</span><span class="p">)],</span>
             <span class="n">n_samples</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span>
             <span class="n">observations</span><span class="o">=</span><span class="n">y_obs</span><span class="p">)</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">select_model</span></code> 返回最佳模型的索引值（从 <span class="math notranslate nohighlight">\(0\)</span> 开始）和估计得出的模型后验概率。对于示例，我们得到模型 <span class="math notranslate nohighlight">\(0\)</span> 的概率为 <span class="math notranslate nohighlight">\(0.68\)</span> 。在这个例子中，<code class="docutils literal notranslate"><span class="pre">LOO</span></code> 和<code class="docutils literal notranslate"><span class="pre">随机森林法</span></code>都同意模型选择结论，甚至模型间的相对权重，这让人比较放心。</p>
</div>
</div>
<div class="section" id="choosing-priors-for-abc">
<span id="id50"></span><h2>8.8 为近似贝叶斯计算选择先验<a class="headerlink" href="#choosing-priors-for-abc" title="Permalink to this headline">¶</a></h2>
<p>没有封闭形式的似然使得好模型更加难以得到，因此近似贝叶斯计算方法通常比其他近似解更脆弱。因此，我们应格外小心一些建模的选择，包括先验的选择和比有明确似然时更严谨的模型评估。这些都是为获得近似似然而必须付出的成本。</p>
<p>与其他方法相比，在近似贝叶斯计算方法中更仔细的选择先验，可能比在其他方法中更有价值。如果在近似似然时会丢失信息，那我们希望通过包含更多信息的先验来进行部分补偿。此外，更好的先验通常会使我们免于浪费计算资源和时间。对于近似贝叶斯计算拒绝方法，我们使用先验作为采样分布，这是显而易见的。但 <code class="docutils literal notranslate"><span class="pre">SMC</span></code> 方法也是如此，特别是模拟器对输入参数比较敏感时。例如，当使用近似贝叶斯计算推断常微分方程时，某些参数组合可能难以进行数值模拟，从而导致模拟速度极慢。在 <code class="docutils literal notranslate"><span class="pre">SMC</span></code> 和  <code class="docutils literal notranslate"><span class="pre">SMC-ABC</span></code> 的加权采样过程中出现了使用模糊先验的另一个问题，因为在对退火后验进行评估时，除了少数先验样本外，几乎所有样本的权重都非常小。这导致 <code class="docutils literal notranslate"><span class="pre">SMC</span></code> 粒子在几个步骤后变得奇异（ 因为只选择了少数重量较大的样本 ）。这种现象称为权重崩塌，这也是粒子方法的一个众所周知的问题 <span id="id51">[<a class="reference internal" href="references.html#id143">110</a>]</span> 。</p>
<p>良好的先验可以降低计算成本，从而在一定程度上允许我们使用 <code class="docutils literal notranslate"><span class="pre">SMC</span></code> 和  <code class="docutils literal notranslate"><span class="pre">SMC-ABC</span></code> 拟合更复杂的模型。除了提供信息性更强的先验和在本书中讨论过的有关先验选择/评估的内容之外，我们暂时没有针对近似贝叶斯计算方法的进一步推荐。</p>
</div>
<div class="section" id="exercises8">
<span id="id52"></span><h2>8.9 练习<a class="headerlink" href="#exercises8" title="Permalink to this headline">¶</a></h2>
<p><strong>8E1.</strong> In your words explain how 近似贝叶斯计算 is approximate? What object or quantity is approximated and how.</p>
<p><strong>8E2.</strong> In the context of 近似贝叶斯计算，what is the problem that SMC is trying to solve compared to rejection sampling?</p>
<p><strong>8E3.</strong> Write a Python function to compute the Gaussian kernel as in Equation <a class="reference internal" href="#equation-eq-euclidean-abc">(74)</a>, but without the summation.</p>
<p>Generate two random samples of size 100 from the same distribution. Use the implemented function to compute the distances between those two random samples. You will get two distributions each of size 100. Show the differences using a KDE plot, the mean and the standard deviation.</p>
<p><strong>8E4.</strong> What do you expect to the results to be in terms of accuracy and convergence of the sampler if in model <code class="docutils literal notranslate"><span class="pre">gauss</span></code> model from Code Block <a class="reference internal" href="#gauss-abc"><span class="std std-ref">gauss_abc</span></a> we would have used <code class="docutils literal notranslate"><span class="pre">sum_stat="identity"</span></code>. Justify.</p>
<p><strong>8E5.</strong> Refit the <code class="docutils literal notranslate"><span class="pre">gauss</span></code> model from Code Block <a class="reference internal" href="#gauss-abc"><span class="std std-ref">gauss_abc</span></a> using <code class="docutils literal notranslate"><span class="pre">sum_stat="identity"</span></code>.</p>
<p>Evaluate the results using:</p>
<ol class="simple">
<li><p>Trace Plot</p></li>
<li><p>Rank Plot</p></li>
<li><p><span class="math notranslate nohighlight">\(\hat R\)</span></p></li>
<li><p>The mean and HDI for the parameters <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span>.</p></li>
</ol>
<p>Compare the results with those from the example in the book (i.e. using <code class="docutils literal notranslate"><span class="pre">sum_stat="sort"</span></code>).</p>
<p><strong>8E6.</strong> Refit the <code class="docutils literal notranslate"><span class="pre">gauss</span></code> model from Code Block <a class="reference internal" href="#gauss-abc"><span class="std std-ref">gauss_abc</span></a> using quintiles as summary statistics.</p>
<ol class="simple">
<li><p>How the results compare with the example in the book?</p></li>
<li><p>Try other values for <code class="docutils literal notranslate"><span class="pre">epsilon</span></code>. Is 1 a good choice?</p></li>
</ol>
<p><strong>8E7.</strong> Use the <code class="docutils literal notranslate"><span class="pre">g_and_k_quantile</span></code> class to generate a sample (n=500) from a g-and-k distribution with parameters a=0,b=1,g=0.4,k=0. Then use the <code class="docutils literal notranslate"><span class="pre">gkm</span></code> model to fit it using 3 different values of <span class="math notranslate nohighlight">\(\epsilon\)</span> (0.05, 0.1, 0.5). Which value of <span class="math notranslate nohighlight">\(\epsilon\)</span> do you think is the best for this problem? Use diagnostics tools to help you answer this question.</p>
<p><strong>8E8.</strong> Use the sample from the previous exercise and the <code class="docutils literal notranslate"><span class="pre">gkm</span></code> model. Fit the using the summary statistics <code class="docutils literal notranslate"><span class="pre">octo_summary</span></code>, the <code class="docutils literal notranslate"><span class="pre">octile-vector</span></code> (i.e. the quantiles 0.125, 0.25, 0.375, 0.5, 0.625, 0.75, 0.875) and <code class="docutils literal notranslate"><span class="pre">sum_stat="sorted"</span></code>. Compare the results with the known parameter values, which option provides higher accuracy and lower uncertainty?</p>
<p><strong>8M9.</strong> In the GitHub repository you will find a dataset of the distribution of citations of scientific papers. Use  SMC-ABC to fit a g-and-k distribution to this dataset. Perform all the necessary steps to find a suitable value for <code class="docutils literal notranslate"><span class="pre">"epsilon"</span></code> and ensuring the model converge and results provides a suitable fit.</p>
<p><strong>8M10.</strong> The Lotka-Volterra is well-know biological model describing how the number of individuals of two species change when there is a predator-prey interaction <span id="id53">[<a class="reference internal" href="references.html#id174">111</a>]</span>. Basically, as the population of prey increase there is more food for the predator which leads to an increase in the predator population. But a large number of predators produce a decline in the number of pray which in turn produce a decline in the predator as food becomes scarce. Under certain conditions this leads to an stable cyclic pattern for both populations.</p>
<p>In the GitHub repository you will find a Lotka-Volterra simulator with unknown parameters and the data set <code class="docutils literal notranslate"><span class="pre">Lotka-Volterra_00</span></code>. Assume the unknown parameters are positive. Use a  SMC-ABC model to find the posterior distribution of the parameters.</p>
<p><strong>8H11.</strong> Following with the Lotka-Volterra example. The dataset <code class="docutils literal notranslate"><span class="pre">Lotka-Volterra_01</span></code> includes data for a predator prey with the twist that at some point a disease suddenly decimate the prey population. Expand the model to allow for a “switchpoint”, i.e. a point that marks two different predator-prey dynamics (and hence two different set of parameters).</p>
<p><strong>8H12.</strong> This exercise is based in the sock problem formulated by Rasmus Bååth. The problem goes like this. We get 11 socks out of the laundry and to our surprise we find that they are all unique, that is we can not pair them. What is the total number of socks that we laundry? Let assume that the laundry contains both paired and unpaired socks, we do not have more than two socks of the same kind. That is we either have 1 or 2 socks of each kind.</p>
<p>Assume the number of socks follows a <span class="math notranslate nohighlight">\(\text{NB}(30, 4.5)\)</span>. And that the proportion of unpaired socks follows a <span class="math notranslate nohighlight">\(\text{Beta}(15, 2)\)</span></p>
<p>Generate a simulator suitable for this problem and create a  SMC-ABC model to compute the posterior distribution of the number of socks, the proportion of unpaired socks, and the number of pairs.</p>
<hr class="docutils"/>
<hr class="footnotes docutils"/>
<dl class="footnote brackets">
<dt class="label" id="id54"><span class="brackets"><a class="fn-backref" href="#id5">1</a></span></dt>
<dd><p>It can work for discrete variables, especially if they take only a   few possible values.</p>
</dd>
<dt class="label" id="id55"><span class="brackets"><a class="fn-backref" href="#id6">2</a></span></dt>
<dd><p>This is another manifestation of the curse of dimensionality. See   Section <a class="reference internal" href="chp_11.html#high-dimensions"><span class="std std-ref">11.8 走出平地</span></a> for a full explanation.</p>
</dd>
<dt class="label" id="id56"><span class="brackets"><a class="fn-backref" href="#id9">3</a></span></dt>
<dd><p>The default SMC <code class="docutils literal notranslate"><span class="pre">kernel</span></code> is <code class="docutils literal notranslate"><span class="pre">"metropolis"</span></code>. See <a class="reference internal" href="chp_11.html#inference-methods"><span class="std std-ref">11.9 推断方法</span></a> for details.</p>
</dd>
<dt class="label" id="id57"><span class="brackets"><a class="fn-backref" href="#id11">4</a></span></dt>
<dd><p>Is similar to the Gaussian distribution but without the   normalization term <span class="math notranslate nohighlight">\(\frac{1}{\sigma\sqrt{2\pi}}\)</span>.</p>
</dd>
<dt class="label" id="id58"><span class="brackets"><a class="fn-backref" href="#id12">5</a></span></dt>
<dd><p>This is something PyMC3 does, other packages could be different</p>
</dd>
<dt class="label" id="id59"><span class="brackets"><a class="fn-backref" href="#id14">6</a></span></dt>
<dd><p>Even when PyMC3 uses <code class="docutils literal notranslate"><span class="pre">sum_stat="sort"</span></code> as summary statistic,   sorting is not a true summary as we are still using the whole data</p>
</dd>
<dt class="label" id="id60"><span class="brackets"><a class="fn-backref" href="#id19">7</a></span></dt>
<dd><p>In a similar fashion as the <span class="math notranslate nohighlight">\(\beta\)</span> parameters in the description   of the SMC/ SMC-ABC algorithm explained before</p>
</dd>
<dt class="label" id="id61"><span class="brackets"><a class="fn-backref" href="#id27">8</a></span></dt>
<dd><p>In Prangle <span id="id62">[<a class="reference internal" href="references.html#id45">102</a>]</span> you will find a description of an R   package with a lot of functions to work with g-and-k distributions.</p>
</dd>
<dt class="label" id="id63"><span class="brackets"><a class="fn-backref" href="#id34">9</a></span></dt>
<dd><p>In the literature is common to use <span class="math notranslate nohighlight">\(\varepsilon\)</span> to denote these   terms, but we want to avoid confusion with the <span class="math notranslate nohighlight">\(\epsilon\)</span> parameter   in the  SMC-ABC sampler</p>
</dd>
<dt class="label" id="id64"><span class="brackets"><a class="fn-backref" href="#id42">10</a></span></dt>
<dd><p>Good moment to remember that <code class="docutils literal notranslate"><span class="pre">sum_stat="sort"</span></code> is not actually a   summary statistic as we are using the entire dataset</p>
</dd>
<dt class="label" id="id65"><span class="brackets"><a class="fn-backref" href="#id45">11</a></span></dt>
<dd><p>Other classifiers could have been chosen, but the authors decided   to use a random forest.</p>
</dd>
<dt class="label" id="id66"><span class="brackets"><a class="fn-backref" href="#id48">12</a></span></dt>
<dd><p>In future versions of PyMC <code class="docutils literal notranslate"><span class="pre">pm.sample_smc</span></code> will return and   InferenceData object with the proper groups.</p>
</dd>
</dl>
</div>
</div>
<script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./zh_CN"
        },
        predefinedOutput: true
    }
    </script>
<script>kernelName = 'python3'</script>
</div>
<!-- Previous / next buttons -->
<div class="prev-next-area">
<a class="left-prev" href="chp_07.html" id="prev-link" title="previous page">
<i class="fas fa-angle-left"></i>
<div class="prev-next-info">
<p class="prev-next-subtitle">previous</p>
<p class="prev-next-title">第七章：贝叶斯加性回归树</p>
</div>
</a>
<a class="right-next" href="chp_09.html" id="next-link" title="next page">
<div class="prev-next-info">
<p class="prev-next-subtitle">next</p>
<p class="prev-next-title">第九章: 端到端的贝叶斯工作流</p>
</div>
<i class="fas fa-angle-right"></i>
</a>
</div>
</div>
</div>
<footer class="footer">
<p>
    
      By Martin, Kumar, Lao<br/>
    
        © Copyright 2021.<br/>
</p>
</footer>
</main>
</div>
</div>
<script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>
</body>
</html>