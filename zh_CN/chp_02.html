
<!DOCTYPE html>

<html>
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>第二章: 贝叶斯模型的探索性分析 — Bayesian Modeling and Computation in Python</title>
<link href="../_static/css/theme.css" rel="stylesheet"/>
<link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet"/>
<link href="../_static/vendor/fontawesome/5.13.0/css/all.min.css" rel="stylesheet"/>
<link as="font" crossorigin="" href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2" rel="preload" type="font/woff2"/>
<link href="../_static/pygments.css" rel="stylesheet" type="text/css">
<link href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" rel="stylesheet" type="text/css">
<link href="../_static/togglebutton.css" rel="stylesheet" type="text/css">
<link href="../_static/copybutton.css" rel="stylesheet" type="text/css">
<link href="../_static/mystnb.css" rel="stylesheet" type="text/css">
<link href="../_static/sphinx-thebe.css" rel="stylesheet" type="text/css"/>
<link href="../_static/sphinx-codeautolink.css" rel="stylesheet" type="text/css"/>
<link href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" rel="stylesheet" type="text/css"/>
<link href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" rel="stylesheet" type="text/css"/>
<link as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js" rel="preload"/>
<script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
<script src="../_static/jquery.js"></script>
<script src="../_static/underscore.js"></script>
<script src="../_static/doctools.js"></script>
<script src="../_static/togglebutton.js"></script>
<script src="../_static/clipboard.min.js"></script>
<script src="../_static/copybutton.js"></script>
<script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
<script src="../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
<script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
<script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
<script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
<script async="async" src="../_static/sphinx-thebe.js"></script>
<link href="../_static/favicon.ico" rel="shortcut icon">
<link href="../genindex.html" rel="index" title="Index"/>
<link href="../search.html" rel="search" title="Search"/>
<link href="chp_03.html" rel="next" title="第三章：线性模型与概率编程语言"/>
<link href="chp_01.html" rel="prev" title="第一章: 贝叶斯推断"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="None" name="docsearch:language"/>
<!-- Google Analytics -->
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-702QMHG8ST"></script>
<script>
                    window.dataLayer = window.dataLayer || [];
                    function gtag(){ dataLayer.push(arguments); }
                    gtag('js', new Date());
                    gtag('config', 'G-702QMHG8ST');
                </script>
</link></link></link></link></link></link></head>
<body data-offset="80" data-spy="scroll" data-target="#bd-toc-nav">
<div class="container-fluid" id="banner"></div>
<div class="container-xl">
<div class="row">
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
<div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
<h1 class="site-logo" id="site-title">Bayesian Modeling and Computation in Python</h1>
</a>
</div><form action="../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="icon fas fa-search"></i>
<input aria-label="Search this book..." autocomplete="off" class="form-control" id="search-input" name="q" placeholder="Search this book..." type="search"/>
</form><nav aria-label="Main" class="bd-links" id="bd-docs-nav">
<div class="bd-toc-item active">
<ul class="current nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="dedication.html">
   贡献
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="foreword.html">
   序言
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="preface.html">
   前言
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="symbollist.html">
   符号表
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chp_01.html">
   第一章: 贝叶斯推断
  </a>
</li>
<li class="toctree-l1 current active">
<a class="current reference internal" href="#">
   第二章: 贝叶斯模型的探索性分析
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chp_03.html">
   第三章：线性模型与概率编程语言
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chp_04.html">
   第四章：扩展线性模型
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chp_05.html">
   第五章: 样条
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chp_06.html">
   第六章: 时间序列
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chp_07.html">
   第七章：贝叶斯加性回归树
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chp_08.html">
   第八章：近似贝叶斯计算
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chp_09.html">
   第九章: 端到端的贝叶斯工作流
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chp_10.html">
   第十章: 概率编程语言
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chp_11.html">
   第十一章: 附加主题
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="glossary.html">
   词汇表
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="references.html">
   References
  </a>
</li>
</ul>
</div>
</nav> <!-- To handle the deprecated key -->
<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>
</div>
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
<div class="topbar container-xl fixed-top">
<div class="topbar-contents row">
<div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
<div class="col pl-md-4 topbar-main">
<button aria-controls="site-navigation" aria-expanded="true" aria-label="Toggle navigation" class="navbar-toggler ml-0" data-placement="left" data-target=".site-navigation" data-toggle="tooltip" id="navbar-toggler" title="Toggle navigation" type="button">
<i class="fas fa-bars"></i>
<i class="fas fa-arrow-left"></i>
<i class="fas fa-arrow-up"></i>
</button>
<!-- Source interaction buttons -->
<div class="dropdown-buttons-trigger">
<button aria-label="Connect with source repository" class="btn btn-secondary topbarbtn" id="dropdown-buttons-trigger"><i class="fab fa-github"></i></button>
<div class="dropdown-buttons sourcebuttons">
<a class="repository-button" href="https://github.com/BayesianModelingandComputationInPython/BookCode_Edition1"><button class="btn btn-secondary topbarbtn" data-placement="left" data-toggle="tooltip" title="Source repository" type="button"><i class="fab fa-github"></i>repository</button></a>
<a class="issues-button" href="https://github.com/BayesianModelingandComputationInPython/BookCode_Edition1/issues/new?title=Issue%20on%20page%20%2Fzh_CN/chp_02.html&amp;body=Your%20issue%20content%20here."><button class="btn btn-secondary topbarbtn" data-placement="left" data-toggle="tooltip" title="Open an issue" type="button"><i class="fas fa-lightbulb"></i>open issue</button></a>
</div>
</div>
<!-- Full screen (wrap in <a> to have style consistency -->
<a class="full-screen-button"><button aria-label="Fullscreen mode" class="btn btn-secondary topbarbtn" data-placement="bottom" data-toggle="tooltip" onclick="toggleFullScreen()" title="Fullscreen mode" type="button"><i class="fas fa-expand"></i></button></a>
<!-- Launch buttons -->
</div>
<!-- Table of contents -->
<div class="d-none d-md-block col-md-2 bd-toc show noprint">
<div class="tocsection onthispage pt-5 pb-3">
<i class="fas fa-list"></i> Contents
            </div>
<nav aria-label="Page" id="bd-toc-nav">
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#there-is-life-after-inference-and-before-too">
   2.1 “贝叶斯建模”大于“贝叶斯推断”
  </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#prior-predictive-checks">
   2.2 先验预测检查
  </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#posterior-pd">
   2.3 后验预测检查
  </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id15">
     2.3.3 图表的分析与理解
    </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#diagnosing-inference">
   2.4 常用的数值化诊断方法
  </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#ess">
     2.4.1 有效样本数量
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#hat-r">
     2.4.2 潜在的尺度缩减因子
     <span class="math notranslate nohighlight">
      \(\hat R\)
     </span>
</a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#monte-carlo-standard-error">
     2.4.3 蒙特卡洛标准误差
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#trace-plots">
     2.4.4 轨迹图
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#autocorr-plot">
     2.4.5 自相关图
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#rank-plots">
     2.4.6 秩图
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#divergences">
     2.4.7 发散性
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#sampler-parameters-and-other-diagnostics">
     2.4.8 采样器的参数和其他诊断方法
    </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#model-cmp">
   2.5 模型比较
  </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#elpd">
     2.5.1 评分法与对数评分规则（ ELPD ）
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#cv-and-loo">
     2.5.2 交叉验证和留一法
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#elpd-plots">
     2.5.3 对数预测密度的期望
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#hat-kappa">
     2.5.4 帕累托形状参数
     <span class="math notranslate nohighlight">
      \(\hat \kappa\)
     </span>
</a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#hat-kappa-p-loo">
     2.5.5 当帕累托参数
     <span class="math notranslate nohighlight">
      \(\hat \kappa\)
     </span>
     较大时解读
     <code class="docutils literal notranslate">
<span class="pre">
       p_loo
      </span>
</code>
</a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#loo-loo-pit">
     2.5.6 LOO – 概率积分变换（ LOO-PIT ）
    </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#model-averaging">
   2.6 模型平均
  </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#exercises2">
   2.7 练习
  </a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="row" id="main-content">
<div class="col-12 col-md-9 pl-md-3 pr-md-0">
<!-- Table of contents that is only displayed when printing the page -->
<div class="onlyprint" id="jb-print-docs-body">
<h1>第二章: 贝叶斯模型的探索性分析</h1>
<!-- Table of contents -->
<div id="print-main-content">
<div id="jb-print-toc">
<div>
<h2> Contents </h2>
</div>
<nav aria-label="Page">
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#there-is-life-after-inference-and-before-too">
   2.1 “贝叶斯建模”大于“贝叶斯推断”
  </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#prior-predictive-checks">
   2.2 先验预测检查
  </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#posterior-pd">
   2.3 后验预测检查
  </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id15">
     2.3.3 图表的分析与理解
    </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#diagnosing-inference">
   2.4 常用的数值化诊断方法
  </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#ess">
     2.4.1 有效样本数量
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#hat-r">
     2.4.2 潜在的尺度缩减因子
     <span class="math notranslate nohighlight">
      \(\hat R\)
     </span>
</a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#monte-carlo-standard-error">
     2.4.3 蒙特卡洛标准误差
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#trace-plots">
     2.4.4 轨迹图
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#autocorr-plot">
     2.4.5 自相关图
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#rank-plots">
     2.4.6 秩图
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#divergences">
     2.4.7 发散性
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#sampler-parameters-and-other-diagnostics">
     2.4.8 采样器的参数和其他诊断方法
    </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#model-cmp">
   2.5 模型比较
  </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#elpd">
     2.5.1 评分法与对数评分规则（ ELPD ）
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#cv-and-loo">
     2.5.2 交叉验证和留一法
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#elpd-plots">
     2.5.3 对数预测密度的期望
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#hat-kappa">
     2.5.4 帕累托形状参数
     <span class="math notranslate nohighlight">
      \(\hat \kappa\)
     </span>
</a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#hat-kappa-p-loo">
     2.5.5 当帕累托参数
     <span class="math notranslate nohighlight">
      \(\hat \kappa\)
     </span>
     较大时解读
     <code class="docutils literal notranslate">
<span class="pre">
       p_loo
      </span>
</code>
</a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#loo-loo-pit">
     2.5.6 LOO – 概率积分变换（ LOO-PIT ）
    </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#model-averaging">
   2.6 模型平均
  </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#exercises2">
   2.7 练习
  </a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div>
<div class="tex2jax_ignore mathjax_ignore section" id="chap1bis">
<span id="id1"></span><h1>第二章: 贝叶斯模型的探索性分析<a class="headerlink" href="#chap1bis" title="Permalink to this headline">¶</a></h1>
<style>p{text-indent:2em;2}</style>
<p>正如我们在 <a class="reference internal" href="chp_01.html#chap1"><span class="std std-ref">第 1 章</span></a> 中所见，<strong>贝叶斯推断</strong>使用可用数据对模型进行条件化并获得后验分布。我们可以使用笔和纸、计算机或其他设备 <a class="footnote-reference brackets" href="#id57" id="id2">1</a> 来实现推断；此外，推断过程通常还包括一些其他量的计算，例如先验预测分布和后验预测分布。但是，<strong>贝叶斯建模</strong>相对于贝叶斯推断而言更为广泛。我们通常希望贝叶斯建模能够仅仅靠指定模型和计算后验就能实现，但通常情况下并非如此。现实情况是，成功的贝叶斯数据分析需要完成许多其他同等重要的任务。</p>
<p>在本章中，我们将讨论其中一些任务，包括：<strong>模型假设的检查</strong>、<strong>模型推断结果的诊断</strong> 和 <strong>模型的比较</strong>。</p>
<div class="section" id="there-is-life-after-inference-and-before-too">
<span id="id3"></span><h2>2.1 “贝叶斯建模”大于“贝叶斯推断”<a class="headerlink" href="#there-is-life-after-inference-and-before-too" title="Permalink to this headline">¶</a></h2>
<p>成功的贝叶斯建模方法除了贝叶斯推断之外，还需要执行其他额外的任务 <a class="footnote-reference brackets" href="#id58" id="id4">2</a>。</p>
<p>典型如：</p>
<ul class="simple">
<li><p>模型诊断，对使用数值方法获得的推断结果进行诊断，评估其质量。</p></li>
<li><p>模型评判，包括对模型假设和模型预测的评估。</p></li>
<li><p>模型比较，包括模型选择或模型平均。</p></li>
<li><p>模型沟通，为特定受众准备结果。</p></li>
</ul>
<p>实现上述任务需要一些数字汇总和可视化手段来帮助从业者对模型进行分析，我们称此类方法为<strong>贝叶斯模型的探索性分析（ Exploratory Analysis of Bayesian Models ）</strong>。此名称源于统计方法中的探索性数据分析 ( Exploratory Data Analysis, EDA ) <span id="id5">[<a class="reference internal" href="references.html#id34">14</a>]</span> 。该分析方法旨在汇总数据集的主要特征，并且通常使用可视化方法。用 <code class="docutils literal notranslate"><span class="pre">Persi</span> <span class="pre">Diaconis</span></code> 的话来说 <span id="id6">[<a class="reference internal" href="references.html#id27">15</a>]</span> ：</p>
<blockquote>
<div><p>探索性数据分析 (探索性数据分析) 旨在揭示数据中的结构或简单描述。人们查看数字或图表并尝试找到其中蕴含的模式（ Patterns ），寻求由背景信息、想象力、感知到的模式和其他数据分析经验提供的前瞻性线索。</p>
</div></blockquote>
<p>探索性数据分析 通常在推断之前执行，有时甚至可以代替推断。我们以及之前许多研究者 <span id="id7">[<a class="reference internal" href="references.html#id20">16</a>, <a class="reference internal" href="references.html#id78">17</a>]</span> 认为，探索性数据分析 中的许多想法都可以被使用、重新解释，并扩展为强大的贝叶斯建模方法。</p>
<p>在本书中将主要使用 <code class="docutils literal notranslate"><span class="pre">Python</span></code> 的 <code class="docutils literal notranslate"><span class="pre">ArviZ</span></code> 库 <a class="footnote-reference brackets" href="#id59" id="id8">3</a> 来对贝叶斯模型进行探索性分析。</p>
<p>在现实生活中，贝叶斯推断步骤和模型的探索性分析步骤经常交织在一个迭代的工作流中，其中可能还包括编码错误、计算问题、对模型充分性的怀疑、对我们当前对数据的理解的怀疑、非线性模型构建、模型检查等很多方面。试图在一本书中描述这种复杂的工作流非常具有挑战性，而且也不是本书的重点。因此，我们可能会省略部分甚至全部探索性分析步骤，或者将其留作练习。这并非因为探索性分析没有必要或不重要；相反，它非常地重要，在编写本书过程中，我们实际上在 “幕后” 进行了大量地迭代工作。但也确实在某些地方省略了它们，以便将重点放在其他注意力方面，例如模型细节、计算特征或基础数学。</p>
</div>
<div class="section" id="prior-predictive-checks">
<span id="id9"></span><h2>2.2 先验预测检查<a class="headerlink" href="#prior-predictive-checks" title="Permalink to this headline">¶</a></h2>
<p>正如在 <a class="reference internal" href="chp_01.html#make-prior-count"><span class="std std-ref">1.4 量化先验信息的几种选择</span></a> 节中讨论的，“什么是最好的先验？” 是一个很吸引人的话题。但除了 “这取决于 ？” 之外，很难给出一个令人满意的答案。我们可以尝试寻找给定模型或模型族的默认先验，将其推广到更广泛的数据集，并产生良好结果。但如果能够为特定问题生成具有更多信息的先验，那么一定也能够找到在特定问题上优于它们的方法。事实上，好的缺省先验不仅可以作为快速分析的基础，当我们深入迭代式探索的贝叶斯建模工作流时，它还可以作为更优先验的一个占位符。</p>
<p>选择先验时的一个问题在于：当先验按照模型传导到数据中时，有时候很难直观理解其产生的结果。我们在参数空间中做出的选择，在观测数据空间中可能会引发一些意想不到的结果。因此，为了更好地理解假设，我们需要一种能够查看其效果的工具，这就是 <strong>先验预测检查（ Prior Predictive Checks ）</strong>，我们曾经在 <a class="reference internal" href="chp_01.html#bayesian-inference"><span class="std std-ref">1.1.2 贝叶斯推断</span></a> 和公式 <a class="reference internal" href="chp_01.html#equation-eq-prior-pred-dist">(5)</a> 中提到过它。</p>
<p>在实际工作中，当做出先验假设（可能是不合适的）后，无需以观测数据为条件，就可以通过从模型中采样来获得<strong>先验预测分布（ Prior Predictive Distribution ）</strong>。 这些先验预测分布的样本，将我们在参数空间中所做的选择，转换成了观测数据空间中的预测结果，从而让我们有机会更直接得理解假设。这种利用先验和模型生成样本，并用样本来评估先验的过程，被称为先验预测检查。</p>
<p><strong>（ 1 ） 罚球命中率的例子</strong></p>
<p>假设我们希望建立一个足球模型。具体来说，我们对踢点球的进球概率感兴趣。经过思考，我们决定使用几何模型来建模 <a class="footnote-reference brackets" href="#id60" id="id10">4</a>。根据 <a class="reference internal" href="#fig-football-sketch"><span class="std std-numref">Fig. 12</span></a> 中的草图和三角函数知识，可以得出以下计算进球概率的公式：</p>
<div class="math notranslate nohighlight" id="equation-eq-geometric-football">
<span class="eqno">(16)<a class="headerlink" href="#equation-eq-geometric-football" title="Permalink to this equation">¶</a></span>\[p\left(|\alpha| &lt; \tan^{-1}\left(\frac{L}{x}\right)\right) = 2\Phi\left(\frac{\tan^{-1}\left(\frac{L}{x}\right)}{\sigma}\right) - 1\]</div>
<p>公式 <a class="reference internal" href="#equation-eq-geometric-football">(16)</a> 的直觉印象是：（1）我们假设进球结果由 <span class="math notranslate nohighlight">\(|\alpha|\)</span> 是否小于某个角度阈值 <span class="math notranslate nohighlight">\(\tan^{-1}\left(\frac{L}{x}\right)\)</span> 决定；(2) 虽然我们假设球员努力将球踢直，但存在某些因素导致足球的轨迹出现偏差（ 其值为 <span class="math notranslate nohighlight">\(\sigma\)</span> ，单位为角度），从而导致进球结果出现了不确定性。</p>
<div class="figure align-default" id="fig-football-sketch">
<a class="reference internal image-reference" href="../_images/football_sketch.png"><img alt="../_images/football_sketch.png" src="../_images/football_sketch.png" style="width: 4in;"/></a>
<p class="caption"><span class="caption-number">Fig. 12 </span><span class="caption-text">罚球示意草图。虚线表示进球得分所必须的角度 <span class="math notranslate nohighlight">\(\alpha\)</span> 。 <span class="math notranslate nohighlight">\(x\)</span> 代表罚球距离（ 11 米），<span class="math notranslate nohighlight">\(L\)</span> 代表球门长度的一半（ 3.66 米）。</span><a class="headerlink" href="#fig-football-sketch" title="Permalink to this image">¶</a></p>
</div>
<p>公式 <a class="reference internal" href="#equation-eq-geometric-football">(16)</a> 中唯一的未知量是 <span class="math notranslate nohighlight">\(\sigma\)</span> ，而 <span class="math notranslate nohighlight">\(L\)</span> 和 <span class="math notranslate nohighlight">\(x\)</span> 的值都可以从足球规则中得到。作为贝叶斯工作者，当我们不知道一个量时，通常会为其分配先验，然后尝试建立贝叶斯模型去估计它。例如，我们可以这样写：</p>
<div class="math notranslate nohighlight" id="equation-eq-geometric-model">
<span class="eqno">(17)<a class="headerlink" href="#equation-eq-geometric-model" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{split}
\sigma &amp;= \mathcal{HN}(\sigma_{\sigma}) \\
\text{p_goal} &amp;= 2\Phi\left(\frac{\tan^{-1}\left(\frac{L}{x}\right)}{\sigma}\right) - 1 \\
Y &amp;= \text{Bin}(n=1, p=\text{p_goal})
\end{split}\end{split}\]</div>
<p>现在我们尚不完全确定模型对足球领域知识的表达程度如何，因此可以尝试从先验预测中采样以获得一些直观的感觉。</p>
<p><a class="reference internal" href="#fig-prior-predictive-check-00"><span class="std std-numref">Fig. 13</span></a> 显示了三个先验样本（分别用 <span class="math notranslate nohighlight">\(\sigma_{\sigma}\)</span> 的三个值来表示：<span class="math notranslate nohighlight">\(5\)</span>、<span class="math notranslate nohighlight">\(20\)</span> 和 <span class="math notranslate nohighlight">\(60\)</span> ）对应的预测结果。灰色的扇形区域代表罚球未受其他因素（如：风、摩擦等）影响时，应该进球的一组角度。可以看到，当前的模型假设在射门角度比灰色区域更大时，也是有可能进球的。更为有趣的是，如果存在较大的 <span class="math notranslate nohighlight">\(\sigma_{\sigma}\)</span> 值，当前模型会认为朝球门相反的方向射门也是有可能进球的（ 虽然可能性很小 ），这样的假设显然存在一些缺陷。</p>
<div class="figure align-default" id="fig-prior-predictive-check-00">
<a class="reference internal image-reference" href="../_images/prior_predictive_distributions_00.png"><img alt="../_images/prior_predictive_distributions_00.png" src="../_images/prior_predictive_distributions_00.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 13 </span><span class="caption-text">公式 <a class="reference internal" href="#equation-eq-geometric-model">(17)</a> 对应模型的先验预测检查。每个子图对应于 <span class="math notranslate nohighlight">\(\sigma\)</span> 参数的不同先验样本。每个圆形图中心的黑点代表罚球点，边缘处的点代表射门位置，由角度 <span class="math notranslate nohighlight">\(\alpha\)</span> 的值刻画（ 参见 <a class="reference internal" href="#fig-football-sketch"><span class="std std-numref">Fig. 12</span></a> ），不同颜色代表了有区别的进球概率。</span><a class="headerlink" href="#fig-prior-predictive-check-00" title="Permalink to this image">¶</a></p>
</div>
<p>针对上述问题，我们现在有几个选择：一是重新设计模型以结合更多的几何性质；二是调整先验以减少无意义结果发生的机会（即便我们并没有完全排除它们）；三是将错就错，直接用当前先验拟合数据，然后查看数据是否具备足够信息（充分到能够排除无意义的参数值）来得出后验。</p>
<p><strong>（2）多个预测变量的逻辑斯蒂回归示例</strong></p>
<p><a class="reference internal" href="#fig-prior-predictive-check-01"><span class="std std-numref">Fig. 14</span></a> 显示了另一个我们可能觉得意外的例子 <a class="footnote-reference brackets" href="#id61" id="id11">5</a> 。该示例显示了一个具有两个预测变量的逻辑斯蒂回归 <a class="footnote-reference brackets" href="#id63" id="id12">6</a> ，其回归系数上的先验为 <span class="math notranslate nohighlight">\(\mathcal{N}(0, 1)\)</span> 。</p>
<p>当我们增加预测变量的数量时，先验预测分布的均值参数从聚集在 <span class="math notranslate nohighlight">\(0.5\)</span> 左右（左侧子图）变为均匀分布（中间子图），更进一步变得支持极值 <span class="math notranslate nohighlight">\(0\)</span> 或 <span class="math notranslate nohighlight">\(1\)</span>（右侧子图）。</p>
<p>这个例子提示我们：随着预测变量数量的增加，先验预测分布会将更多质量放在极值上。因此，我们可能需要一个更强的正则化先验，以使模型远离那些不太可能发生的极值。</p>
<div class="figure align-default" id="fig-prior-predictive-check-01">
<a class="reference internal image-reference" href="../_images/prior_predictive_distributions_01.png"><img alt="../_images/prior_predictive_distributions_01.png" src="../_images/prior_predictive_distributions_01.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 14 </span><span class="caption-text">对具有 <span class="math notranslate nohighlight">\(2\)</span> 个、<span class="math notranslate nohighlight">\(5\)</span> 个、 <span class="math notranslate nohighlight">\(15\)</span> 个预测变量和 <span class="math notranslate nohighlight">\(100\)</span> 个数据点的逻辑斯蒂回归模型做出的先验预测分布。 <code class="docutils literal notranslate"><span class="pre">KDE</span></code> 曲线表示了 <span class="math notranslate nohighlight">\(10000\)</span> 条模拟数据的均值呈现出的分布特点。三个图中的系数均采用了 <span class="math notranslate nohighlight">\(\mathcal{N}(0, 1)\)</span> 先验，但预测变量数量的增加在实际上等价于使用了一个偏爱极值的先验。</span><a class="headerlink" href="#fig-prior-predictive-check-01" title="Permalink to this image">¶</a></p>
</div>
<p><strong>（3）小结</strong></p>
<p>上述两个例子都表明，不能孤立地理解先验，我们必须将其放在特定模型的语境中。通常直接根据观测值进行思考，会比简接根据模型参数进行思考更容易，因此先验预测分布有助于降低模型评估的难度。在参数经过多次转换或多个先验存在交互的复杂模型场景中，先验预测分布的这种作用更为明显。</p>
<p>此外，先验预测分布也可用于直观地向广大涉众展示结果或讨论模型。当领域专家不熟悉统计符号或代码时，沟通很难富有成效，但如果你展示的是一个或多个模型的直观涵义，那就可以为他们提供更多讨论材料，进而为你和合作伙伴提供有价值的见解。</p>
<p>计算先验预测还具有其他优势，例如辅助调试模型、确保模型编写正确、保证模型能够在计算环境中正确运行等。</p>
</div>
<div class="section" id="posterior-pd">
<span id="id13"></span><h2>2.3 后验预测检查<a class="headerlink" href="#posterior-pd" title="Permalink to this headline">¶</a></h2>
<p>既然可以使用来自先验预测分布的合成数据来帮助我们检查模型，那么也可以使用<strong>后验预测分布</strong>进行类似的分析，这个概念在 <a class="reference internal" href="chp_01.html#bayesian-inference"><span class="std std-ref">1.1.2 贝叶斯推断</span></a> 和公式 <a class="reference internal" href="chp_01.html#equation-eq-post-pred-dist">(6)</a> 中曾经提到过。</p>
<p>生成后验预测样本并基于样本做模型评估的过程，通常被称为<strong>后验预测检查（ Posterior Predictive Checks ）</strong>。其基本思想是评估生成数据与实际观测数据的接近程度。</p>
<p>理论上，评估接近程度的方法取决于研究问题本身，但也存在一些通用规则。我们甚至可能想要使用多个测度来评估模型匹配数据（或错配数据）的多种方式。</p>
<p><a class="reference internal" href="#fig-posterior-predictive-check"><span class="std std-numref">Fig. 15</span></a> 显示了一个非常简单的二项模型和数据示例。在左侧子图中，我们将数据中观测到的成功次数（蓝线）与后验预测分布中超过 <span class="math notranslate nohighlight">\(1000\)</span> 个样本的预测成功次数进行比较。右侧子图是另一种表示结果的方式，显示了观测数据（蓝线）与来自后验分布的 <span class="math notranslate nohighlight">\(1000\)</span> 个样本的成功和失败比率。正如我们所见，在当前设置下，模型在捕获均值方面做得非常好，即使模型认识到存在很多不确定性。我们不应该对模型在捕获均值方面做得好而感到惊讶，因为我们直接对二项分布的均值进行了建模。在后续章节中，我们将看到一些后验预测检查为模型拟合数据提供了有价值信息的示例。</p>
<div class="figure align-default" id="fig-posterior-predictive-check">
<a class="reference internal image-reference" href="../_images/posterior_predictive_check.png"><img alt="../_images/posterior_predictive_check.png" src="../_images/posterior_predictive_check.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 15 </span><span class="caption-text"><code class="docutils literal notranslate"><span class="pre">Beta-Binomial</span> <span class="pre">模型</span></code>的后验预测检查。在左侧子图中，有预测成功的数量（灰色直方图），黑色虚线表示预测成功的均值。蓝线是根据数据计算的均值。在右侧子图中，有相同的信息，但以另一种方式表示。我们绘制的是获得 <span class="math notranslate nohighlight">\(0\)</span> 或 <span class="math notranslate nohighlight">\(1\)</span> 的概率，而不是成功的数量。我们用一条线来表示 <span class="math notranslate nohighlight">\(p(y=0) = 1-p(y=1)\)</span> 的概率。黑虚线是平均预测概率，蓝线是从数据计算的平均值。</span><a class="headerlink" href="#fig-posterior-predictive-check" title="Permalink to this image">¶</a></p>
</div>
<p>后验预测检查不仅限于绘图，我们还可以执行数值检验 <span id="id14">[<a class="reference internal" href="references.html#id3">18</a>]</span>。其中一种方法是计算贝叶斯 <span class="math notranslate nohighlight">\(p\)</span> 值：</p>
<div class="math notranslate nohighlight" id="equation-eq-post-pred-test-quantity">
<span class="eqno">(18)<a class="headerlink" href="#equation-eq-post-pred-test-quantity" title="Permalink to this equation">¶</a></span>\[p_{B} = p(T_{sim} \leq T_{obs} \mid \tilde Y)\]</div>
<p>其中 <span class="math notranslate nohighlight">\(p_{B}\)</span> 是贝叶斯 <span class="math notranslate nohighlight">\(p\)</span> 值，定义为模拟统计量 <span class="math notranslate nohighlight">\(T_{sim}\)</span> 小于或等于观测统计量 <span class="math notranslate nohighlight">\(T_{obs}\)</span> 的概率。统计量 <span class="math notranslate nohighlight">\(T\)</span> 可以是任何用来评估模型是否适合数据的指标。</p>
<p>对于上述二项模型的示例，我们可以选择观测到的成功率作为 <span class="math notranslate nohighlight">\(T_{obs}\)</span> ，然后将其与后验预测分布 <span class="math notranslate nohighlight">\(T_{sim}\)</span> 进行比较。 <span class="math notranslate nohighlight">\(p_{B}=0.5\)</span> 的理想值意味着，我们模拟生成的统计量 <span class="math notranslate nohighlight">\(T_{sim}\)</span> 有一半时间低于观测统计量 <span class="math notranslate nohighlight">\(T_{obs}\)</span>，另外一半时间高于观测统计量 <span class="math notranslate nohighlight">\(T_{obs}\)</span>，这是一个正确拟合的预期结果。</p>
<p>因为绘图更加直观一些，所以也可以使用贝叶斯 <span class="math notranslate nohighlight">\(p\)</span> 值来制图。</p>
<p><a class="reference internal" href="#fig-posterior-predictive-check-pu-values"><span class="std std-numref">Fig. 16</span></a> 的第一个子图以黑色实线显示贝叶斯 <span class="math notranslate nohighlight">\(p\)</span> 值的分布，虚线表示相同大小数据集的预期分布。 我们使用 ArviZ 的 <code class="docutils literal notranslate"><span class="pre">az.plot_bpv(.,</span> <span class="pre">kind="p_value")</span></code> 函数获得此图。</p>
<p>第二个子图在概念上相似，不同之处在于评估了有多少模拟低于（或高于）观测数据。对于一个校准良好的模型，所有观测值都应该得到同样好的预测，即高于或低于预期的数量应该相同。因此应该得到一个均匀分布。对于任何有限数据集，即使完美校准的模型也会显示出与均匀分布的偏差，我们绘制了一个条带，预计会看到 <span class="math notranslate nohighlight">\(94\%\)</span> 的均匀曲线。</p>
<div class="admonition-p admonition">
<p class="admonition-title">贝叶斯 <span class="math notranslate nohighlight">\(p\)</span> 值 </p>
<p>我们将 <span class="math notranslate nohighlight">\(p_{B}\)</span> 称为贝叶斯 <span class="math notranslate nohighlight">\(p\)</span> 值，因为公式 <a class="reference internal" href="#equation-eq-post-pred-test-quantity">(18)</a> 中的量，实质上是 <span class="math notranslate nohighlight">\(p\)</span> 值的定义，之所以称其为贝叶斯的，是因为我们并没有使用零假设的统计量 <span class="math notranslate nohighlight">\(T\)</span> 作为后验预测分布的采样分布。请注意，我们没有以任何零假设为条件；也没有使用任何预定义的阈值来声明统计显著性或执行假设检验。</p>
</div>
<div class="figure align-default" id="fig-posterior-predictive-check-pu-values">
<a class="reference internal image-reference" href="../_images/posterior_predictive_check_pu_values.png"><img alt="../_images/posterior_predictive_check_pu_values.png" src="../_images/posterior_predictive_check_pu_values.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 16 </span><span class="caption-text"><code class="docutils literal notranslate"><span class="pre">Beta-Binomial</span> <span class="pre">模型</span></code>的后验预测分布。在左图中，实曲线是小于等于观测数据的预测值比例（采用了核密度估计）。虚线表示对于一个与观测数据大小相同的数据集，其预期的分布。在右图中，黑线同样表示了小于等于观测数据的预测值比例 （采用了核密度估计），但与左图中在每个模拟上做计算不同，右图是在每个观测上做计算。白线代表了一个标准均匀分布的理想情况，灰色区域表示在相同大小数据集上，我们期望看到的该均匀分布的偏差（<span class="math notranslate nohighlight">\(94\%\)</span> 区间）。</span><a class="headerlink" href="#fig-posterior-predictive-check-pu-values" title="Permalink to this image">¶</a></p>
</div>
<p>正如之前所说，我们可以在许多 <span class="math notranslate nohighlight">\(T\)</span> 统计量中做出选择，来汇总观测数据和预测结果。</p>
<p><a class="reference internal" href="#fig-posterior-predictive-check-tstat"><span class="std std-numref">Fig. 17</span></a> 显示了其中两个示例，左图中的 <span class="math notranslate nohighlight">\(T\)</span> 为均值，右图中的 <span class="math notranslate nohighlight">\(T\)</span> 为标准差。曲线表示基于后验预测分布的 <span class="math notranslate nohighlight">\(T\)</span> 统计量的分布（采用了核密度估计），点是实际观测数据的值。</p>
<div class="figure align-default" id="fig-posterior-predictive-check-tstat">
<a class="reference internal image-reference" href="../_images/posterior_predictive_check_tstat.png"><img alt="../_images/posterior_predictive_check_tstat.png" src="../_images/posterior_predictive_check_tstat.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 17 </span><span class="caption-text"><code class="docutils literal notranslate"><span class="pre">Beta-Binomial</span> <span class="pre">模型</span></code>的后验预测分布。在左图中，实曲线表示均值小于等于实际观测数据的模拟预测结果的比例（采用了核密度估计）。在右图中，形式相同，只是统计量变成了标准差。黑点代表从观测数据计算的均值（左图）或标准差（右图）。</span><a class="headerlink" href="#fig-posterior-predictive-check-tstat" title="Permalink to this image">¶</a></p>
</div>
<div class="section" id="id15">
<h3>2.3.3 图表的分析与理解<a class="headerlink" href="#id15" title="Permalink to this headline">¶</a></h3>
<p>在继续阅读之前，你应该花点时间仔细检查 <a class="reference internal" href="#fig-posterior-predictive-many-examples"><span class="std std-numref">Fig. 18</span></a> ，并自己尝试着理解这些图为什么会有如此表现。在此图中，有一系列简单例子来帮助我们获得用于解释后验预测检查图的直观感觉<a class="footnote-reference brackets" href="#id64" id="id16">7</a>。在所有这些示例中，观测数据（蓝色）都遵循高斯分布。</p>
<ol class="simple">
<li><p>在第一行，模型预测相对于观测数据系统地转移到更高值的观测值。</p></li>
<li><p>在第二行，模型做出的预测比观测数据更广泛。</p></li>
<li><p>在第三行，我们有相反的情况，模型没有在尾部生成足够的预测。</p></li>
<li><p>最后一行显示了一个模型在混合高斯后进行预测。</p></li>
</ol>
<p>现在注意 <a class="reference internal" href="#fig-posterior-predictive-many-examples"><span class="std std-numref">Fig. 18</span></a> 的第三列。此列中的图表非常有用，但同时可能会令人困惑。</p>
<p>从上到下，你可以将它们阅读为：</p>
<ol class="simple">
<li><p>模型左尾缺少观测值（而右尾观测值更多）。</p></li>
<li><p>模型在中间做出更少的预测（而在尾部做出更多的预测）。</p></li>
<li><p>模型在尾部的预测较少。</p></li>
<li><p>该模型正在或多或少地做出经过良好校准的预测，但我是一个持怀疑态度的人，所以我应该运行另一个后验预测检查来确认。</p></li>
</ol>
<p>如果这种阅读图表的方式仍然让你感到困惑，可以从完全等效的不同角度尝试，但它可能更直观，只要你记住你可以更改模型，而不是观测结果 <a class="footnote-reference brackets" href="#id65" id="id17">8</a>。从上到下，你可以将它们阅读为：</p>
<ol class="simple">
<li><p>左侧观测较多</p></li>
<li><p>中间观测较多</p></li>
<li><p>尾部观测较多。</p></li>
<li><p>观测结果似乎分布良好（至少在预期范围内），但你不应该相信我。我只是柏拉图世界中的柏拉图模型。</p></li>
</ol>
<p>我们希望 <a class="reference internal" href="#fig-posterior-predictive-many-examples"><span class="std std-numref">Fig. 18</span></a> 和随附的讨论为你提供了足够的直觉，以便更好地在实际场景中执行模型检查。</p>
<div class="figure align-default" id="fig-posterior-predictive-many-examples">
<a class="reference internal image-reference" href="../_images/posterior_predictive_many_examples.png"><img alt="../_images/posterior_predictive_many_examples.png" src="../_images/posterior_predictive_many_examples.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 18 </span><span class="caption-text">一组简单模型的后验预测检查。在第一列中，蓝色实线代表观测数据和来自模型的浅灰色预测结果。在第二列中，实线是小于等于观测数据的预测结果比例（采用了核密度估计），而虚线表示采用与观测数据集大小相同的数据集时预期的分布。在第三列中，黑色曲线指在每个观测处，小于等于观测数据的预测结果比例。白线代表预期的均匀分布，灰色区域表示采用与观测数据集大小相同的数据集时预期的偏差。该图使用 ArviZ 的函数 <code class="docutils literal notranslate"><span class="pre">az.plot_ppc(.)</span></code>、<code class="docutils literal notranslate"><span class="pre">az.plot_bpv(.,</span> <span class="pre">kind="p_values")</span></code> 和 <code class="docutils literal notranslate"><span class="pre">az.plot_bpv(.,</span> <span class="pre">kind="u_values")</span></code> 绘制。</span><a class="headerlink" href="#fig-posterior-predictive-many-examples" title="Permalink to this image">¶</a></p>
</div>
<p>无论是采用绘图、数字汇总信息还是两者结合的方式，后验预测检查都是一个足够灵活的思想。这个概念足以让从业者发挥他们的想象力，通过自己的后验预测来探索、评估和理解不同的途径和模型，进一步在面向特定问题时，掌握这些模型工作的优劣程度。</p>
</div>
</div>
<div class="section" id="diagnosing-inference">
<span id="id18"></span><h2>2.4 常用的数值化诊断方法<a class="headerlink" href="#diagnosing-inference" title="Permalink to this headline">¶</a></h2>
<p>对于某些模型，用笔和纸求解后验可能很乏味，有些甚至在数学上可能是无解的，此时采用数值方法来近似计算后验分布，能够让我们求解贝叶斯模型。不幸的是，这些数值方法并不总是按照预期工作。出于此原因，必须人工参与评估其结果的可用性。目前，有一系列数值和可视化诊断工具用于辅助诊断。在本节中，我们将面向 MCMC 方法，讨论其最常见和最有用的诊断工具。</p>
<p>为了理解这些诊断工具，我们先创建三个 <em>合成后验</em> ：</p>
<p>第一个为来自 <span class="math notranslate nohighlight">\(\text{Beta}(2, 5)\)</span> 的样本。我们使用 <code class="docutils literal notranslate"><span class="pre">SciPy</span></code> 生成它，并称之为 <code class="docutils literal notranslate"><span class="pre">good_chains</span></code>，表示这是一个好样本，因为这是在理想情况下，我们想要的独立同分布样本。</p>
<p>第二个合成后验被称为 <code class="docutils literal notranslate"><span class="pre">bad_chains0</span></code>，表示来自后验的不良样本。它是在对 <code class="docutils literal notranslate"><span class="pre">good_chains</span></code> 排序后，通过添加一个小的高斯误差生成的。 <code class="docutils literal notranslate"><span class="pre">bad_chains0</span></code> 是一个糟糕的样本，原因有两个：一是这些值不独立。相反，它们是高度自相关的，这意味着如果给定序列中任何位置的任何数字，都可以高精度地计算出其前后的值。二是这些值并非同分布的，因为我们正在将之前展平并排序的数组整形为二维数组，代表了两条链。</p>
<p>第三个合成后验被称为 <code class="docutils literal notranslate"><span class="pre">bad_chains1</span></code>，它也是从 <code class="docutils literal notranslate"><span class="pre">good_chains</span></code> 生成的，我们随机地引入彼此高度相关的连续样本片段，来生成后验的不良样本表示。 <code class="docutils literal notranslate"><span class="pre">bad_chains1</span></code> 代表了一种很常见的场景，即采样器可以很好处理参数空间的大部分区域，但同时存在一个或多个很难采样的区域。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">good_chains</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2000</span><span class="p">))</span>
<span class="n">bad_chains0</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/random/generated/numpy.random.normal.html#numpy.random.normal" title="numpy.random.normal"><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span></a><span class="p">(</span><a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.sort.html#numpy.sort" title="numpy.sort"><span class="n">np</span><span class="o">.</span><span class="n">sort</span></a><span class="p">(</span><span class="n">good_chains</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">),</span> <span class="mf">0.05</span><span class="p">,</span>
                               <span class="n">size</span><span class="o">=</span><span class="mi">4000</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="n">bad_chains1</span> <span class="o">=</span> <span class="n">good_chains</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/random/generated/numpy.random.randint.html#numpy.random.randint" title="numpy.random.randint"><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span></a><span class="p">(</span><span class="mi">1900</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">4</span><span class="p">):</span>
    <span class="n">bad_chains1</span><span class="p">[</span><span class="n">i</span><span class="o">%</span><span class="mi">2</span><span class="p">:,</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="mi">100</span><span class="p">]</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/random/generated/numpy.random.beta.html#numpy.random.beta" title="numpy.random.beta"><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">beta</span></a><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="mi">950</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

<span class="n">chains</span> <span class="o">=</span> <span class="p">{</span><span class="s2">"good_chains"</span><span class="p">:</span><span class="n">good_chains</span><span class="p">,</span>
          <span class="s2">"bad_chains0"</span><span class="p">:</span><span class="n">bad_chains0</span><span class="p">,</span>
          <span class="s2">"bad_chains1"</span><span class="p">:</span><span class="n">bad_chains1</span><span class="p">}</span>
</pre></div>
</div>
<p>请注意，<span class="math notranslate nohighlight">\(3\)</span> 个合成后验都是标量（单参数或一元随机变量）的后验分布样本，不过这对于当前讨论来说已经足够了，因为后面的诊断都是逐模型参数计算的。</p>
<div class="section" id="ess">
<span id="id19"></span><h3>2.4.1 有效样本数量<a class="headerlink" href="#ess" title="Permalink to this headline">¶</a></h3>
<p>使用 MCMC 采样方法时，有理由怀疑样本是否足够大，是否能够可靠地支撑计算感兴趣的量，如均值或 HDI。这个问题无法仅通过查看样本数量直接回答，因为来自 MCMC 方法的样本具有一定程度的<strong>自相关</strong>，因此其中包含的实际 <em>信息量</em> 会比从相同大小的独立同分布样本要少。一系列数值的自相关是指，我们可以观测到这些值之间的相似性是其时间滞后的函数。例如，如果今天的日出时间是早上 6:03，那么你知道明天的日出时间大约是同一时间。事实上，在知道今天的值后，你离赤道越近预测未来日落时间的时间滞后就越长。也就是说，赤道处的自相关比靠近两极的地方大 <a class="footnote-reference brackets" href="#id66" id="id20">9</a>。</p>
<p>从上述分析出发，我们可以将有效样本数 (Effective Sample Size, ESS) 视为一个考虑了自相关的估计量，能够提供当样本为独立同分布时应该具备的抽样次数。此解释很吸引人，但小心不要过度解读，我们将在后面看到这一点。</p>
<p>我们可以使用 ArviZ 的 <code class="docutils literal notranslate"><span class="pre">az.ess()</span></code> 函数计算均值参数的有效样本大小：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><a class="sphinx-codeautolink-a" href="https://arviz-devs.github.io/arviz/api/generated/arviz.ess.html#arviz.ess" title="arviz.ess"><span class="n">az</span><span class="o">.</span><span class="n">ess</span></a><span class="p">(</span><span class="n">chains</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;xarray.Dataset&gt;
Dimensions:      ()
Data variables:
    good_chains  float64 4.389e+03
    bad_chains0  float64 2.436
    bad_chains1  float64 111.1
</pre></div>
</div>
<p>可以看到，当合成后验中的真实样本数为 <span class="math notranslate nohighlight">\(4000\)</span> 时，<code class="docutils literal notranslate"><span class="pre">bad_chains0</span></code> 的有效样本数量仅相当于 <span class="math notranslate nohighlight">\(\approx 2\)</span> 个独立同分布样本。这个数字过低，表明采样器存在问题。不过考虑到我们创建 <code class="docutils literal notranslate"><span class="pre">bad_chains0</span></code> 的方法，此结果完全可以预期。<code class="docutils literal notranslate"><span class="pre">bad_chains0</span></code> 为双峰分布，每条链都被卡在了两个峰值之间。此时，有效样本数将大约等于 MCMC 链所探索的峰值数量。 <code class="docutils literal notranslate"><span class="pre">bad_chains1</span></code> 也得到了一个较低的数字 <span class="math notranslate nohighlight">\(\approx 111\)</span>，只有 <code class="docutils literal notranslate"><span class="pre">good_chains</span></code> 的有效样本数接近实际样本数。</p>
<div class="admonition- admonition">
<p class="admonition-title">关于有效样本的有效性</p>
<p>如果使用不同的随机种子重新生成合成后验的样本，你会看到每次的有效样本数都不同，这是由于每次的样本不会完全相同。对于 <code class="docutils literal notranslate"><span class="pre">good_chains</span></code> ，平均而言有效样本数的值将低于样本数。但请注意，有效样本数实际上可能更大！当使用 NUTS 采样器（ 参见 <a class="reference internal" href="chp_11.html#inference-methods"><span class="std std-ref">11.9 推断方法</span></a> ）时，如果存在某些参数的后验分布接近高斯分布但几乎独立于模型中其他参数，则可能会出现大于样本实际数的有效样本数。</p>
</div>
<p>马尔可夫链的收敛性在参数空间上并不均匀 <span id="id21">[<a class="reference internal" href="references.html#id13">19</a>]</span> ，直观地说，从分布主体中获得良好近似值比从尾部更容易，因为尾部由罕见的事件主导。 <code class="docutils literal notranslate"><span class="pre">az.ess()</span></code> 返回的默认值为 <code class="docutils literal notranslate"><span class="pre">bulk-ESS</span></code>，它主要评估分布中心的情况。如果你对后验区间或者罕见事件感兴趣，可以检查 <code class="docutils literal notranslate"><span class="pre">tail-ESS</span></code> 的值，它对应于百分位数 <span class="math notranslate nohighlight">\(5\)</span> 和 <span class="math notranslate nohighlight">\(95\)</span> 处的最小有效样本数。如果你对特定分位数感兴趣，可以使用 <code class="docutils literal notranslate"><span class="pre">az.ess(.,</span> <span class="pre">method='quantile')</span></code> 函数对特定值进行查询。</p>
<p>由于有效样本数在参数空间中存在变化，因此在一个图中可视化这种变化会很有用。目前至少有两种方法可以做到这一点：一是用 <code class="docutils literal notranslate"><span class="pre">az.plot_ess(.,</span> <span class="pre">kind="quantiles")</span></code> 函数绘制有效样本数的具体分位数，二是用 <code class="docutils literal notranslate"><span class="pre">az.plot_ess(.,</span> <span class="pre">kind="local")</span></code> 函数绘制两个分位数之间定义的区间，如 <a class="reference internal" href="#fig-plot-ess"><span class="std std-numref">Fig. 19</span></a>。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">_</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.subplots.html#matplotlib.pyplot.subplots" title="matplotlib.pyplot.subplots"><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span></a><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a class="sphinx-codeautolink-a" href="https://arviz-devs.github.io/arviz/api/generated/arviz.plot_ess.html#arviz.plot_ess" title="arviz.plot_ess"><span class="n">az</span><span class="o">.</span><span class="n">plot_ess</span></a><span class="p">(</span><span class="n">chains</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s2">"local"</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span>
<a class="sphinx-codeautolink-a" href="https://arviz-devs.github.io/arviz/api/generated/arviz.plot_ess.html#arviz.plot_ess" title="arviz.plot_ess"><span class="n">az</span><span class="o">.</span><span class="n">plot_ess</span></a><span class="p">(</span><span class="n">chains</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s2">"quantile"</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span>
</pre></div>
</div>
<div class="figure align-default" id="fig-plot-ess">
<a class="reference internal image-reference" href="../_images/plot_ess.png"><img alt="../_images/plot_ess.png" src="../_images/plot_ess.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 19 </span><span class="caption-text">上图：小区间概率估计的局部有效样本数。底部：分位数有效样本数估计。虚线为人为设定的有效样本数最小建议值 <span class="math notranslate nohighlight">\(400\)</span>。理想情况下，我们希望局部和分位数有效样本数在参数空间的所有区域都很高。</span><a class="headerlink" href="#fig-plot-ess" title="Permalink to this image">¶</a></p>
</div>
<p>作为一般经验，我们建议有效样本数大于 <span class="math notranslate nohighlight">\(400\)</span>，否则，对有效样本数自身的估计和对其他量（ 如下面将看到的 <span class="math notranslate nohighlight">\(\hat R\)</span> ）的估计，基本上不可靠 {cite: p}<code class="docutils literal notranslate"><span class="pre">vehtari_rank_2019</span></code>。最后再次强调，我们讨论的有效样本数是指当样本为独立同分布采样时的样本数量，但我们必须非常小心地做出这种解释，因为参数空间不同区域的实际有效样本数不会相同。</p>
</div>
<div class="section" id="hat-r">
<span id="potential-scale-reduction-factor-hat-r"></span><h3>2.4.2 潜在的尺度缩减因子 <span class="math notranslate nohighlight">\(\hat R\)</span><a class="headerlink" href="#hat-r" title="Permalink to this headline">¶</a></h3>
<p>在一般条件下，MCMC 方法有理论上的保证，无论该链的起点在哪儿，最终都会得到正确答案，但这仅对无限样本有效。在实践中，需要一些估计有限样本收敛性的方法。其中一个普遍做法是运行多个链，各自从不同的点开始，然后检查这些生成的链是否<em>彼此看起来足够相似</em>。</p>
<p>这个直观的概念可以被形式化为数字诊断指标 <span class="math notranslate nohighlight">\(\hat R\)</span> 。这个指标的计算有很多版本，因为多年来它一直在改进 <span id="id22">[<a class="reference internal" href="references.html#id13">19</a>]</span>。最初，<span class="math notranslate nohighlight">\(\hat R\)</span> 被解释为由于 MCMC 的有限样本而被高估了的方差，这意味着如果继续进行无限地采样，你应该得到一个根据因子 <span class="math notranslate nohighlight">\(\hat R\)</span> 逐步缩减的估计方差。也就是说，当<code class="docutils literal notranslate"><span class="pre">潜在尺度缩减因子</span></code>达到的目标值 <span class="math notranslate nohighlight">\(1\)</span> 时，继续增加样本将无法进一步减少估计方差。</p>
<p>在实践中，最好将 <span class="math notranslate nohighlight">\(\hat R\)</span> 视为一种诊断工具，而不是过度解读它。</p>
<p><span class="math notranslate nohighlight">\(\theta\)</span> 参数的 <span class="math notranslate nohighlight">\(\hat R\)</span> 计算为其所有样本（含所有链）的标准差除以各独立链内标准差的均方根。</p>
<div class="math notranslate nohighlight">
\[\hat R = \frac{\text{sd}_{All-Samples}}{\sqrt{\sum_{i=1}^N \text{sd}_{samples-of-Chain_i}}}\]</div>
<p>实际计算时涉及的内容会更多一点，但总体思路仍然不变 <span id="id23">[<a class="reference internal" href="references.html#id13">19</a>]</span>。理想情况下，我们应该得到值 <span class="math notranslate nohighlight">\(1\)</span>，因为链间方差应该与链内方差一致。但从实用角度来看，<span class="math notranslate nohighlight">\(\hat R \lessapprox 1.01\)</span> 被认为是安全的。</p>
<p>使用 ArviZ，我们可以使用 <code class="docutils literal notranslate"><span class="pre">az.rhat()</span></code> 函数计算 <span class="math notranslate nohighlight">\(\hat R\)</span> ：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><a class="sphinx-codeautolink-a" href="https://arviz-devs.github.io/arviz/api/generated/arviz.rhat.html#arviz.rhat" title="arviz.rhat"><span class="n">az</span><span class="o">.</span><span class="n">rhat</span></a><span class="p">(</span><span class="n">chains</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;xarray.Dataset&gt;
Dimensions:      ()
Data variables:
    good_chains  float64 1.000
    bad_chains0  float64 2.408
    bad_chains1  float64 1.033
</pre></div>
</div>
<p>从此结果可以看出 <span class="math notranslate nohighlight">\(\hat R\)</span> 准确地将 <code class="docutils literal notranslate"><span class="pre">good_chains</span></code> 识别为好样本，将 <code class="docutils literal notranslate"><span class="pre">bad_chains0</span></code> 和 <code class="docutils literal notranslate"><span class="pre">bad_chains1</span></code> 正确识别为具有不同程度问题的样本。虽然 <code class="docutils literal notranslate"><span class="pre">bad_chains0</span></code> 完全是一场灾难，但 <code class="docutils literal notranslate"><span class="pre">bad_chains1</span></code> 似乎更接近于达到良好链的状态，但其值 <span class="math notranslate nohighlight">\(\hat R = 1.033 &gt; 1.01\)</span> 依然有点大。</p>
</div>
<div class="section" id="monte-carlo-standard-error">
<span id="id24"></span><h3>2.4.3 蒙特卡洛标准误差<a class="headerlink" href="#monte-carlo-standard-error" title="Permalink to this headline">¶</a></h3>
<p>当使用 MCMC 方法时，我们用有限数量的样本来近似后验分布，从而引入了额外的不确定性。这种不确定性可以使用基于 <em>马尔可夫链中心极限定理</em> 的<strong>蒙特卡洛标准误差 (MCSE)</strong> 来量化估计（参见 <a class="reference internal" href="chp_11.html#markov-chains"><span class="std std-ref">马尔可夫链</span></a> ）。 考虑到样本并非真正相互独立，蒙特卡洛标准误差实际上是从有效样本数（ ESS ） 计算得出的 <span id="id25">[<a class="reference internal" href="references.html#id13">19</a>]</span> 。有效样本数和 <span class="math notranslate nohighlight">\(\hat R\)</span> 的取值独立于参数的规模，因此解释 MCSE 是否足够小，需要领域专业知识。如果想要将估计的参数值取到小数点后两位，我们就需要确保 MCSE 低于小数点后两位，否则将错误地取得比实际精度更高的精度。只有当我们确定 ESS 足够大并且 <span class="math notranslate nohighlight">\(\hat R\)</span> 足够小时，才应该检查 MCSE；否则，MCSE 是无效的。</p>
<p>使用 ArviZ，我们可以使用函数 <code class="docutils literal notranslate"><span class="pre">az.mcse()</span></code> 计算 MCSE</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><a class="sphinx-codeautolink-a" href="https://arviz-devs.github.io/arviz/api/generated/arviz.mcse.html#arviz.mcse" title="arviz.mcse"><span class="n">az</span><span class="o">.</span><span class="n">mcse</span></a><span class="p">(</span><span class="n">chains</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;xarray.Dataset&gt;
Dimensions:      ()
Data variables:
    good_chains  float64 0.002381
    bad_chains0  float64 0.1077
    bad_chains1  float64 0.01781
</pre></div>
</div>
<p>与有效样本数一样，MCSE 在参数空间中也是存在变化的，因此我们可能还想进一步评估不同区域的 MCSE，例如特定分位数。此外，我们可能还希望像 <a class="reference internal" href="#fig-plot-mcse"><span class="std std-numref">Fig. 20</span></a> 一样，一次可视化多个值。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><a class="sphinx-codeautolink-a" href="https://arviz-devs.github.io/arviz/api/generated/arviz.plot_mcse.html#arviz.plot_mcse" title="arviz.plot_mcse"><span class="n">az</span><span class="o">.</span><span class="n">plot_mcse</span></a><span class="p">(</span><span class="n">chains</span><span class="p">)</span>
</pre></div>
</div>
<div class="figure align-default" id="fig-plot-mcse">
<a class="reference internal image-reference" href="../_images/plot_mcse.png"><img alt="../_images/plot_mcse.png" src="../_images/plot_mcse.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 20 </span><span class="caption-text">分位数的局部 MCSE。子图的 <span class="math notranslate nohighlight">\(y\)</span> 轴共享相同的刻度以方便对比。理想情况下，我们希望 MCSE 在参数空间的所有区域中都很小。请注意，与两条不良链的 MCSE 相比，<code class="docutils literal notranslate"><span class="pre">good_chains</span></code> 的 MCSE 值在所有值处都相对较低。</span><a class="headerlink" href="#fig-plot-mcse" title="Permalink to this image">¶</a></p>
</div>
<p>最后，ESS、<span class="math notranslate nohighlight">\(\hat R\)</span> 和 MCSE 可以通过一次调用 <code class="docutils literal notranslate"><span class="pre">az.summary(.)</span></code> 函数来计算。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><a class="sphinx-codeautolink-a" href="https://arviz-devs.github.io/arviz/api/generated/arviz.summary.html#arviz.summary" title="arviz.summary"><span class="n">az</span><span class="o">.</span><span class="n">summary</span></a><span class="p">(</span><span class="n">chains</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s2">"diagnostics"</span><span class="p">)</span>
</pre></div>
</div>
<table class="table">
<colgroup>
<col style="width: 17%"/>
<col style="width: 17%"/>
<col style="width: 17%"/>
<col style="width: 17%"/>
<col style="width: 17%"/>
<col style="width: 17%"/>
</colgroup>
<tbody>
<tr class="row-odd"><td></td>
<td><p><strong>mcse_mean</strong>*</p></td>
<td><p><strong>mcse_sd</strong></p></td>
<td><p><strong>ess_bulk</strong></p></td>
<td><p><strong>ess_tail</strong></p></td>
<td><p><strong>r_hat</strong></p></td>
</tr>
<tr class="row-even"><td><p>good_chains</p></td>
<td><p>0.002</p></td>
<td><p>0.002</p></td>
<td><p>4389.0</p></td>
<td><p>3966.0</p></td>
<td><p>1.00</p></td>
</tr>
<tr class="row-odd"><td><p>bad_chains0</p></td>
<td><p>0.108</p></td>
<td><p>0.088</p></td>
<td><p>2.0</p></td>
<td><p>11.0</p></td>
<td><p>2.41</p></td>
</tr>
<tr class="row-even"><td><p>bad_chains1</p></td>
<td><p>0.018</p></td>
<td><p>0.013</p></td>
<td><p>111.0</p></td>
<td><p>105.0</p></td>
<td><p>1.03</p></td>
</tr>
</tbody>
</table>
<p>第一列是均值参数的蒙特卡洛标准误差，第二列是标准差参数的蒙特卡洛标准误差 <a class="footnote-reference brackets" href="#id67" id="id26">10</a> 。然后依次是主体和尾部的有效样本数，最后是 <span class="math notranslate nohighlight">\(\hat R\)</span> 收敛性诊断。</p>
</div>
<div class="section" id="trace-plots">
<span id="id27"></span><h3>2.4.4 轨迹图<a class="headerlink" href="#trace-plots" title="Permalink to this headline">¶</a></h3>
<p>轨迹图可能是贝叶斯领域中最流行的图。</p>
<p>它们通常是我们在推断完成后制作的第一张图，以直观地检查<em>我们得到了什么</em>。轨迹图利用在每个迭代步骤中抽取得到的采样值来绘制。在轨迹图中，我们能够看到不同的链是否收敛到了同一分布、可以得到自相关程度的<em>直观感觉</em>、… 。在 ArviZ 中，只需调用函数 <code class="docutils literal notranslate"><span class="pre">az.plot_trace(.)</span></code> 即可得到右侧的轨迹图，以及左侧的样本值概率分布图，其中连续型变量采用核密度估计曲线表示，离散变量采用直方图表示。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><a class="sphinx-codeautolink-a" href="https://arviz-devs.github.io/arviz/api/generated/arviz.plot_trace.html#arviz.plot_trace" title="arviz.plot_trace"><span class="n">az</span><span class="o">.</span><span class="n">plot_trace</span></a><span class="p">(</span><span class="n">chains</span><span class="p">)</span>
</pre></div>
</div>
<div class="figure align-default" id="fig-trace-plots">
<a class="reference internal image-reference" href="../_images/trace_plots.png"><img alt="../_images/trace_plots.png" src="../_images/trace_plots.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 21 </span><span class="caption-text">在左侧图中，可以看到每条链的一个核密度估计的分布图。在右侧图中，可以看到每条链每一步的采样值情况。请注意各示例链之间分布图和轨迹图的差异，特别是 <code class="docutils literal notranslate"><span class="pre">good_chains</span></code> 中毛毛虫似的外观，以及其他两条链中的不规整性。</span><a class="headerlink" href="#fig-trace-plots" title="Permalink to this image">¶</a></p>
</div>
<p><a class="reference internal" href="#fig-trace-plots"><span class="std std-numref">Fig. 21</span></a> 显示了三种情况下的双链轨迹图（即将两条独立链的轨迹绘制在一张图上）。从中可以看到：</p>
<p>在 <code class="docutils literal notranslate"><span class="pre">good_chains</span></code> 中，两条独立链的抽取几乎来自于同一分布，因为它们的分布图之间（随机）差异很小。当我们按照迭代顺序查看抽取的样本时，可以发现两条链都相当<em>杂乱</em> 且不存在明显趋势或模式，而且将两条链区分开来。</p>
<p><code class="docutils literal notranslate"><span class="pre">bad_chains0</span></code> 的情况与之形成了鲜明对比，可以通过分布图和轨迹图清楚地看到两个不同的分布，其间只有少量重叠区，表明这些链正在探索参数空间的两个不同区域且无法收敛。</p>
<p><code class="docutils literal notranslate"><span class="pre">bad_chains1</span></code> 的情况有点微妙。其分布图似乎与 <code class="docutils literal notranslate"><span class="pre">good_chains</span></code> 中的分布相似，但两条独立链之间的差异更加明显。另外，我们真的有 <span class="math notranslate nohighlight">\(2\)</span> 个或 <span class="math notranslate nohighlight">\(3\)</span> 个峰吗？分布似乎也不一致，也许我们的真实分布只有一个峰，而另外一个是伪影！多峰通常看起来比较可疑，除非有确切理由让我们相信确实存在多峰分布，例如，数据来自多个群组。其轨迹图似乎也与 <code class="docutils literal notranslate"><span class="pre">good_chains</span></code> 中的轨迹有些相似，但仔细检查会发现其中存在部分长单调性区域（图中平行于 <span class="math notranslate nohighlight">\(x\)</span> 轴的线）。这清楚地表明采样器卡在了参数空间的某些区域中，这或许因为后验存在多峰，且在峰之间存在低概率障碍区，也或许是因为参数空间中存在一些区域的曲率与其他区域明显不同。</p>
</div>
<div class="section" id="autocorr-plot">
<span id="id28"></span><h3>2.4.5 自相关图<a class="headerlink" href="#autocorr-plot" title="Permalink to this headline">¶</a></h3>
<p>正如在讨论有效样本数时所述，自相关减少了样本中包含的实际信息量，因此希望尽量将其控制在最低限度，此时我们可以使用 <code class="docutils literal notranslate"><span class="pre">az.plot_autocorr</span></code> 函数直接可视化地检查自相关性。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><a class="sphinx-codeautolink-a" href="https://arviz-devs.github.io/arviz/api/generated/arviz.plot_autocorr.html#arviz.plot_autocorr" title="arviz.plot_autocorr"><span class="n">az</span><span class="o">.</span><span class="n">plot_autocorr</span></a><span class="p">(</span><span class="n">chains</span><span class="p">,</span> <span class="n">combined</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<div class="figure align-default" id="fig-autocorrelation-plot">
<a class="reference internal image-reference" href="../_images/autocorrelation_plot.png"><img alt="../_images/autocorrelation_plot.png" src="../_images/autocorrelation_plot.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 22 </span><span class="caption-text">在 <span class="math notranslate nohighlight">\(100\)</span> 步窗口上的自相关函数柱状图。对于整个图，<code class="docutils literal notranslate"><span class="pre">good_chains</span></code> 的柱高度接近于零（并且大部分在灰色带内），这表明自相关非常低。 <code class="docutils literal notranslate"><span class="pre">bad_chains0</span></code> 和 <code class="docutils literal notranslate"><span class="pre">bad_chains1</span></code> 中较高的柱状图表明自相关值较大，这是不可取的。灰色区域代表 <span class="math notranslate nohighlight">\(95\%\)</span> 信念区间。</span><a class="headerlink" href="#fig-autocorrelation-plot" title="Permalink to this image">¶</a></p>
</div>
<p><code class="xref std std-numref docutils literal notranslate"><span class="pre">fig:autocorrelation_plot</span></code> 中的内容在看到的 <code class="docutils literal notranslate"><span class="pre">az.ess</span></code> 结果后，至少是可定性预见的。<code class="docutils literal notranslate"><span class="pre">good_chains</span></code> 显示出基本上为零的自相关；<code class="docutils literal notranslate"><span class="pre">bad_chains0</span></code> 高度相关；而 <code class="docutils literal notranslate"><span class="pre">bad_chains1</span></code> 并没有那么糟糕，但自相关仍然很明显并且不会迅速下降。</p>
</div>
<div class="section" id="rank-plots">
<span id="id29"></span><h3>2.4.6 秩图<a class="headerlink" href="#rank-plots" title="Permalink to this headline">¶</a></h3>
<p>秩图是另一种可视化诊断工具，我们可以用它来比较链内和链间的采样行为。秩图是秩后的样本的直方图，它先组合所有链后统一计算秩，然后分别为每条链绘制结果。如果所有链都针对同一分布，则我们希望秩服从均匀分布。此外，如果所有链的秩图看起来相似，表明链的混合良好 <span id="id30">[<a class="reference internal" href="references.html#id13">19</a>]</span>。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><a class="sphinx-codeautolink-a" href="https://arviz-devs.github.io/arviz/api/generated/arviz.plot_rank.html#arviz.plot_rank" title="arviz.plot_rank"><span class="n">az</span><span class="o">.</span><span class="n">plot_rank</span></a><span class="p">(</span><span class="n">chains</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">kind</span><span class="o">=</span><span class="s2">"bars"</span><span class="p">)</span>
</pre></div>
</div>
<div class="figure align-default" id="fig-rank-plot-bars">
<img alt="../_images/rank_plot_bars.png" src="../_images/rank_plot_bars.png"/>
<p class="caption"><span class="caption-number">Fig. 23 </span><span class="caption-text">使用柱状图表示的秩图。特别将柱高度与表示均匀分布的虚线进行比较。理想情况下，柱图应遵循均匀分布。</span><a class="headerlink" href="#fig-rank-plot-bars" title="Permalink to this image">¶</a></p>
</div>
<p>柱图表示法的一种替代方法是垂线，缩写为“vlines”。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><a class="sphinx-codeautolink-a" href="https://arviz-devs.github.io/arviz/api/generated/arviz.plot_rank.html#arviz.plot_rank" title="arviz.plot_rank"><span class="n">az</span><span class="o">.</span><span class="n">plot_rank</span></a><span class="p">(</span><span class="n">chains</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s2">"vlines"</span><span class="p">)</span>
</pre></div>
</div>
<div class="figure align-default" id="fig-rank-plot-vlines">
<a class="reference internal image-reference" href="../_images/rank_plot_vlines.png"><img alt="../_images/rank_plot_vlines.png" src="../_images/rank_plot_vlines.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 24 </span><span class="caption-text">使用垂线表示的秩图。垂线越短越好，虚线上方的垂线表示特定秩的采样量过多，而下方的垂线表示缺少采样。</span><a class="headerlink" href="#fig-rank-plot-vlines" title="Permalink to this image">¶</a></p>
</div>
<p>我们可以在 <a class="reference internal" href="#fig-rank-plot-bars"><span class="std std-numref">Fig. 23</span></a> 和 <a class="reference internal" href="#fig-rank-plot-vlines"><span class="std std-numref">Fig. 24</span></a> 中看到，<code class="docutils literal notranslate"><span class="pre">good_chains</span></code> 的秩非常接近均匀分布，并且两条链看起来彼此相似，没有明显的模式。这与 <code class="docutils literal notranslate"><span class="pre">bad_chains0</span></code> 的结果形成鲜明对比，后者偏离了均匀分布，并且正在分别探索两组不同的值，只是在中等秩上有一些重叠。请注意，这与创建 <code class="docutils literal notranslate"><span class="pre">bad_chains0</span></code> 的方式以及轨迹图的显示一致。 <code class="docutils literal notranslate"><span class="pre">bad_chains1</span></code> 在某种程度上是均匀的，但随处都存在较大的偏离，反映出问题比 <code class="docutils literal notranslate"><span class="pre">bad_chains0</span></code> 更局部。</p>
<p>秩图可能比轨迹图更敏感，因此我们推荐使用秩图。你可以使用 <code class="docutils literal notranslate"><span class="pre">az.plot_trace(.,</span> <span class="pre">kind="rank_bars")</span></code> 或 <code class="docutils literal notranslate"><span class="pre">az.plot_trace(.,</span> <span class="pre">kind="rank_vlines")</span></code> 绘制上面的两种秩图。这些函数不仅绘制秩，还绘制后验的边缘分布。这有助于快速了解后验<em>看起来像什么</em>，这可以帮助我们发现采样或模型定义中存在的问题。尤其是在建模早期阶段时，我们很可能不太确定真正想做的事情，因此需要探索许多不同的选择。随着进展，模型开始变得更有意义，然后我们再检查 ESS 、<span class="math notranslate nohighlight">\(\hat R\)</span> 和 MCSE 是否正常，如果不正常我们也可以知道模型下一步需要改进的方向。</p>
</div>
<div class="section" id="divergences">
<span id="id31"></span><h3>2.4.7 发散性<a class="headerlink" href="#divergences" title="Permalink to this headline">¶</a></h3>
<p>到目前为止，我们一直在研究 MCMC 方法生成的样本，以诊断采样器的工作状况。本节将介绍另外一种通过监视采样器内部工作行为做诊断的方法。此类诊断方法的一个突出例子是 <strong>Hamiltonian Monte Carlo ( HMC )</strong> 采样器中涉及的**散度（ Divergences ）**概念 <a class="footnote-reference brackets" href="#id68" id="id32">11</a>。散度（源于物理统计学中的概念）是一种强大而灵敏的样本诊断方法，可作为前几节中诊断方法的补充。</p>
<p>让我们在一个简单模型背景下讨论散度，本书后面还能找到更现实的例子。模型由一个参数 <span class="math notranslate nohighlight">\(\theta2\)</span> 组成，该参数服从区间 <span class="math notranslate nohighlight">\([-\theta1, \theta1]\)</span> 内的均匀分布，并且 <span class="math notranslate nohighlight">\(\theta1\)</span> 采样自正态分布。当<span class="math notranslate nohighlight">\(\theta1\)</span> 很大时，<span class="math notranslate nohighlight">\(\theta2\)</span> 将服从一个跨越很大范围的均匀分布，当<span class="math notranslate nohighlight">\(\theta1\)</span> 接近于零时，<span class="math notranslate nohighlight">\(\theta2\)</span> 的分布宽度也将接近于零。使用 PyMC3，可以将此模型编写为：</p>
<div class="literal-block-wrapper docutils container" id="divm0">
<div class="code-block-caption"><span class="caption-number">Listing 9 </span><span class="caption-text">divm0</span><a class="headerlink" href="#divm0" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">model_0</span><span class="p">:</span>
    <span class="n">θ1</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s2">"θ1"</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">testval</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
    <span class="n">θ2</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="s2">"θ2"</span><span class="p">,</span> <span class="o">-</span><span class="n">θ1</span><span class="p">,</span> <span class="n">θ1</span><span class="p">)</span>
    <span class="n">idata_0</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">return_inferencedata</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="admonition-arviz-inferencedata-format admonition">
<p class="admonition-title">ArviZ 支持的推断数据格式 – InferenceData Format </p>
<p><code class="docutils literal notranslate"><span class="pre">az.InferenceData</span></code> 是一种专门为 MCMC 的贝叶斯用户设计的数据格式。</p>
<p>它以一个 <span class="math notranslate nohighlight">\(N\)</span> 维数组的软件包 <code class="docutils literal notranslate"><span class="pre">xarray</span></code> <span id="id33">[<a class="reference internal" href="references.html#id171">20</a>]</span> 为基础。 InferenceData 对象的主要目的是提供一种方便的方法来存储和操作贝叶斯工作流程中生成的信息，包括来自分布的样本，如后验、先验、后验预测、先验预测以及采样期间生成的其他信息和诊断数据。 InferenceData 对象使用组的概念来组织这些信息。</p>
<p>在本书中，我们会大量使用<code class="docutils literal notranslate"><span class="pre">az.InferenceData</span></code>。用它来存储贝叶斯推断结果、计算诊断、生成绘图以及从磁盘读取和写入。有关完整的技术说明和 API，请参阅 ArviZ 文档。</p>
</div>
<p>请注意代码 <a class="reference internal" href="#divm0"><span class="std std-ref">divm0</span></a> 中的模型不以任何观测为条件，这意味着 <code class="docutils literal notranslate"><span class="pre">model_0</span></code> 指定了由两个未知数（“θ1”和“θ2”）参数化的后验分布。</p>
<p>你可能注意到代码中包含了参数 <code class="docutils literal notranslate"><span class="pre">testval=0.1</span></code>。这样做是为了指示 PyMC3 从特定值（本例中为 <span class="math notranslate nohighlight">\(0.1\)</span>）开始采样，而不是从其默认值 <span class="math notranslate nohighlight">\(\theta1 = 0\)</span> 开始采样。因为对于  <span class="math notranslate nohighlight">\(\theta1 = 0\)</span> ，<span class="math notranslate nohighlight">\(\theta2\)</span> 的概率密度函数将对应狄拉克函数 <a class="footnote-reference brackets" href="#id69" id="id34">12</a>，这会产生错误。使用 <code class="docutils literal notranslate"><span class="pre">testval=0.1</span></code> 只会影响采样的初始化方式。</p>
<p>在 <a class="reference internal" href="#fig-divergences-trace"><span class="std std-numref">Fig. 25</span></a> 中，可以在 <code class="docutils literal notranslate"><span class="pre">model0</span></code> 的核密度估计曲线底部看到很多竖线。每条竖线都代表一个散度，表明在采样过程中出现了问题。我们可以其他图看到类似的东西，例如 {numref} <code class="docutils literal notranslate"><span class="pre">fig:divergences_pair</span></code> 中所示的 <code class="docutils literal notranslate"><span class="pre">az.plot_pair(.,divergences=True)</span></code>，这里的散度是无处不在的蓝点！</p>
<div class="figure align-default" id="fig-divergences-trace">
<a class="reference internal image-reference" href="../_images/divergences_trace.png"><img alt="../_images/divergences_trace.png" src="../_images/divergences_trace.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 25 </span><span class="caption-text">模型 <span class="math notranslate nohighlight">\(0\)</span> <a class="reference internal" href="#divm0"><span class="std std-ref">divm0</span></a>、模型 <span class="math notranslate nohighlight">\(1\)</span> <a class="reference internal" href="#divm1"><span class="std std-ref">divm1</span></a> 、模型 <span class="math notranslate nohighlight">\(1bis\)</span> （与模型 <span class="math notranslate nohighlight">\(1\)</span> 相同，但带有 <code class="docutils literal notranslate"><span class="pre">pm.sample(.,</span> <span class="pre">target_accept</span> <span class="pre">=0.95)</span></code> ）的核密度估计和秩图。黑色竖条代表散度。</span><a class="headerlink" href="#fig-divergences-trace" title="Permalink to this image">¶</a></p>
</div>
<div class="figure align-default" id="fig-divergences-pair">
<a class="reference internal image-reference" href="../_images/divergences_pair.png"><img alt="../_images/divergences_pair.png" src="../_images/divergences_pair.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 26 </span><span class="caption-text">模型 <span class="math notranslate nohighlight">\(0\)</span> <a class="reference internal" href="#divm0"><span class="std std-ref">divm0</span></a>、模型 <span class="math notranslate nohighlight">\(1\)</span> <a class="reference internal" href="#divm1"><span class="std std-ref">divm1</span></a> 、模型 <span class="math notranslate nohighlight">\(1bis\)</span> （与模型 <span class="math notranslate nohighlight">\(1\)</span> 相同但使用了 <code class="docutils literal notranslate"><span class="pre">pm.sample(.,</span> <span class="pre">target_accept=0.95)</span></code> ）的后验分布样本的散点图。蓝点代表散度。</span><a class="headerlink" href="#fig-divergences-pair" title="Permalink to this image">¶</a></p>
</div>
<p><code class="docutils literal notranslate"><span class="pre">model0</span></code> 肯定有问题。通过检查代码 <a class="reference internal" href="#divm0"><span class="std std-ref">divm0</span></a> 中的模型定义，可能会意识到我们以一种奇怪的方式定义了它。<span class="math notranslate nohighlight">\(\theta1\)</span> 是一个以 <span class="math notranslate nohighlight">\(0\)</span> 为中心的正态分布，因此我们应该期望一半的值是负数，但是对于负值 <span class="math notranslate nohighlight">\(\theta2\)</span> 将定义在区间 <span class="math notranslate nohighlight">\([\theta1, -\theta1]\)</span> 内，这多少有点奇怪。</p>
<p>因此，让我们尝试<strong>重参数化</strong>模型，即以不同但在数学上等效的方式表达模型。例如，我们可以这样做：</p>
<div class="literal-block-wrapper docutils container" id="divm1">
<div class="code-block-caption"><span class="caption-number">Listing 10 </span><span class="caption-text">divm1</span><a class="headerlink" href="#divm1" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">model_1</span><span class="p">:</span>
    <span class="n">θ1</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s2">"θ1"</span><span class="p">,</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="mi">2</span><span class="o">/</span><a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/constants.html#numpy.pi" title="numpy.pi"><span class="n">np</span><span class="o">.</span><span class="n">pi</span></a><span class="p">)</span><span class="o">**</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="n">θ2</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="s2">"θ2"</span><span class="p">,</span> <span class="o">-</span><span class="n">θ1</span><span class="p">,</span> <span class="n">θ1</span><span class="p">)</span>
    <span class="n">idata_1</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">return_inferencedata</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>现在 <span class="math notranslate nohighlight">\(\theta1\)</span> 将始终提供合理的值，可以将其输入到 <span class="math notranslate nohighlight">\(\theta2\)</span> 的定义中。请注意，我们将 <span class="math notranslate nohighlight">\(\theta1\)</span> 的标准差定义为 <span class="math notranslate nohighlight">\(\frac{1}{\sqrt{(1-\frac{2}{\pi})}}\)</span> 而不是 1。这是因为半正态分布的标准差是 <span class="math notranslate nohighlight">\(\sigma \sqrt{(1-\frac{2}{\pi})}\)</span> 其中 <span class="math notranslate nohighlight">\(\sigma\)</span> 是半正态分布的尺度参数。换句话说，<span class="math notranslate nohighlight">\(\sigma\)</span> 是 <em>展开了的</em> 正态分布的标准差，而不是半正态分布的标准差。</p>
<p>无论如何，让我们看看重参数化的模型如何处理散度。 <a class="reference internal" href="#fig-divergences-trace"><span class="std std-numref">Fig. 25</span></a> 和 <a class="reference internal" href="#fig-divergences-pair"><span class="std std-numref">Fig. 26</span></a> 表明，<code class="docutils literal notranslate"><span class="pre">model1</span></code> 的散度数量已大大减少，但仍然可以看到一部分。尝试减少散度的一个简单选择是增加 <code class="docutils literal notranslate"><span class="pre">target_accept</span></code> 的值，如代码 <a class="reference internal" href="#divm2"><span class="std std-ref">divm2</span></a> 所示，默认情况下此值为 <span class="math notranslate nohighlight">\(0.8\)</span>，最大有效值为 <span class="math notranslate nohighlight">\(1\)</span>（请参阅 <a class="reference internal" href="chp_11.html#hmc"><span class="std std-ref">汉密尔顿蒙特卡洛采样器（ HMC ）</span></a> 了解详情）。</p>
<div class="literal-block-wrapper docutils container" id="divm2">
<div class="code-block-caption"><span class="caption-number">Listing 11 </span><span class="caption-text">divm2</span><a class="headerlink" href="#divm2" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">model_1bis</span><span class="p">:</span>
    <span class="n">θ1</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s2">"θ1"</span><span class="p">,</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="mi">2</span><span class="o">/</span><a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/constants.html#numpy.pi" title="numpy.pi"><span class="n">np</span><span class="o">.</span><span class="n">pi</span></a><span class="p">)</span><span class="o">**</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="n">θ2</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="s2">"θ2"</span><span class="p">,</span> <span class="o">-</span><span class="n">θ1</span><span class="p">,</span> <span class="n">θ1</span><span class="p">)</span>
    <span class="n">idata_1bis</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">target_accept</span><span class="o">=</span><span class="mf">.95</span><span class="p">,</span> <span class="n">return_inferencedata</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p><a class="reference internal" href="#fig-divergences-trace"><span class="std std-numref">Fig. 25</span></a> 和 <a class="reference internal" href="#fig-divergences-pair"><span class="std std-numref">Fig. 26</span></a> 中的<code class="docutils literal notranslate"><span class="pre">model1bis</span></code> 与 <code class="docutils literal notranslate"><span class="pre">model1</span></code> 相同，但更改了一个采样参数的默认值 <code class="docutils literal notranslate"><span class="pre">pm.sample(.,</span> <span class="pre">target_accept</span> <span class="pre">=0.95)</span></code> 。可以看到最终消除了所有散度。这是个好消息，但为了信任这些样本，仍然需要像前几节一样，检查 <span class="math notranslate nohighlight">\(\hat R\)</span> 和 ESS 的值，。</p>
<div class="admonition- admonition">
<p class="admonition-title">重参数化</p>
<p>重参数化有助于将难以采样的后验几何形态转换为更容易采样的几何形态。这有助于消除散度，但即使不存在散度时，重参数化也会有所帮助。例如，可以在无需增加计算成本的条件下，使用它加快采样速度或增加有效样本数。此外，重参数化还有助于更好地解释或沟通模型及其结果（参见第 <a class="reference internal" href="chp_01.html#conjugate-priors"><span class="std std-ref">1.4.1 共轭先验</span></a> 节中的 Alice 和 Bob 示例）。</p>
</div>
</div>
<div class="section" id="sampler-parameters-and-other-diagnostics">
<span id="id35"></span><h3>2.4.8 采样器的参数和其他诊断方法<a class="headerlink" href="#sampler-parameters-and-other-diagnostics" title="Permalink to this headline">¶</a></h3>
<p>大多数采样器方法都有影响自身性能的超参数。虽然大多数概率编程语言尝试使用合理的默认值，但实践中并不适用于所有的数据和模型。</p>
<p>有时可以通过增加参数<code class="docutils literal notranslate"><span class="pre">target_accept</span></code> 来消除部分散度，例如，当散度源于数值不精确的时候。</p>
<p>另外还有其他参数能够帮助解决采样问题，例如，我们可能希望增加 MCMC 采样器的迭代次数。在 PyMC3 中，有默认的采样参数 <code class="docutils literal notranslate"><span class="pre">pm.sample(.,tune=1000)</span></code>。在调整阶段，采样器参数会自动调整。而有些模型更复杂，需要更多交互才能让采样器学习到更好的参数。因此增加调整步数有助于增加 ESS 或降低 <span class="math notranslate nohighlight">\(\hat R\)</span>。增加抽样次数也有助于收敛，但总的来说其他途径更有效。如果一个模型在数千次抽取后都未能收敛，那么通常它在 <span class="math notranslate nohighlight">\(10\)</span> 倍以上的抽取中仍然会失败，或者稍有改进但其额外计算成本并不合理。此时，重参数化、改进模型结构、提供信息更多的先验，甚至更改模型通常会更有效 <a class="footnote-reference brackets" href="#id70" id="id36">13</a>。</p>
<p>需要注意的是，在建模早期，我们可以使用较少的抽取次数来测试模型是否能够运行、是否已经编写了期望的模型、是否大致得到了合理结果等。这种初始检查大约只需要 <span class="math notranslate nohighlight">\(200\)</span> 或 <span class="math notranslate nohighlight">\(300\)</span> 次抽样就足够达到目的了。然后，当我们对模型更有信心时，可以将抽取次数增加到几千次，大约可以设置为 <span class="math notranslate nohighlight">\(2000\)</span> 或 <span class="math notranslate nohighlight">\(4000\)</span> 次。</p>
<p>除了本章中介绍的诊断之外，还存在其他诊断方法，例如平行图和分离图。所有这些诊断方法都是有自己的用途。但是为了简洁性，本节中没有介绍它们。建议你访问包含更多示例的 ArviZ 文档和绘图库。</p>
</div>
</div>
<div class="section" id="model-cmp">
<span id="id37"></span><h2>2.5 模型比较<a class="headerlink" href="#model-cmp" title="Permalink to this headline">¶</a></h2>
<p>通常，我们希望模型既不太简单以至于错过了数据中有价值的信息，也不会太复杂从而过拟合了数据中的噪声。找到这个 <em>甜蜜点</em> 是一项复杂的任务，一方面没有单一的标准来定义最佳解决方案，二是可能压根儿不存在最佳解决方案，三是在实践中需要对同一数据集支撑下的有限个模型进行选择。</p>
<div class="section" id="elpd">
<h3>2.5.1 评分法与对数评分规则（ ELPD ）<a class="headerlink" href="#elpd" title="Permalink to this headline">¶</a></h3>
<p>尽管没有最佳解决方案，我们仍然可以尝试寻找一些好的通用策略。一种解决方案是计算模型的泛化误差，也被称为样本外预测精度，这是对新数据进行预测时，模型表现情况的一种估计。理想情况下，任何预测准确性的度量都应该考虑到问题本身，包括与模型预测有关的收益和成本。也就是说，应该应用一些决策论方法。不过我们也可以依赖一些适用于广泛模型和问题的通用手段，这种手段有时被称为评分规则，因为它们有助于对模型进行评分和排序。</p>
<p>在众多评分规则中，对数评分规则具有非常好的理论性质 <span id="id38">[<a class="reference internal" href="references.html#id18">21</a>]</span>，因此被广泛使用。对数评分规则的计算公式为：</p>
<div class="math notranslate nohighlight" id="equation-eq-elpd">
<span class="eqno">(19)<a class="headerlink" href="#equation-eq-elpd" title="Permalink to this equation">¶</a></span>\[\text{ELPD} = \sum_{i=1}^离差{n} \int p_t(\tilde y_i) \; \log p(\tilde y_i \mid y_i) \; d\tilde y_i \]</div>
<p>其中 <span class="math notranslate nohighlight">\(p_t(\tilde y_i)\)</span> 为生成数据 <span class="math notranslate nohighlight">\(\tilde y_i\)</span> 的真实分布（即理想中的数据生成分布），而 <span class="math notranslate nohighlight">\(p(\tilde y_i \mid y_i)\)</span> 为模型对应的后验预测分布。</p>
<p>公式 <a class="reference internal" href="#equation-eq-elpd">(19)</a> 中定义的量被称为 <strong>逐点对数预测密度的期望（Expected Log Pointwise Predict Density, ELPD）</strong>。之所以称为”期望“，是因为我们是在真实数据生成过程上做<strong>积分运算</strong>，即在可能由该过程生成的所有数据上做积分；之所以称为“逐点”，是因为我们是在 <span class="math notranslate nohighlight">\(n\)</span> 个观测点上执行<strong>逐点计算</strong>；术语“密度”，则是为了简化表述而同时被用于表示连续和离散模型 <a class="footnote-reference brackets" href="#id71" id="id39">14</a>。</p>
<p>在实践中，我们并不知道真实的数据分布 <span class="math notranslate nohighlight">\(p_t(\tilde y_i)\)</span> ，因此公式 <a class="reference internal" href="#equation-eq-elpd">(19)</a> 中定义的 ELPD 没法直接计算，实践中只能用观测数据集做经验主义的近似，即用下式计算：</p>
<div class="math notranslate nohighlight" id="equation-eq-elpd-practice">
<span class="eqno">(20)<a class="headerlink" href="#equation-eq-elpd-practice" title="Permalink to this equation">¶</a></span>\[\sum_{i=1}^{n} \log \int \ p(y_i \mid \boldsymbol{\theta}) \; p(\boldsymbol{\theta} \mid y) d\boldsymbol{\theta} \]</div>
<p>公式 <a class="reference internal" href="#equation-eq-elpd-practice">(20)</a> 定义的量（或乘以某个常数的量）通常称为离差，它在贝叶斯和非贝叶斯场景中都有使用 <a class="footnote-reference brackets" href="#id72" id="id40">15</a>。当似然为高斯时，公式 <a class="reference internal" href="#equation-eq-elpd-practice">(20)</a> 与均方误差成正比。</p>
<div class="admonition-deviance admonition">
<p class="admonition-title">离差（ Deviance ）及相关容易混淆的概念 </p>
<p>离差（又称“偏差”）是关于某个统计模型拟合优劣的统计量。</p>
<p>离差在英文中与偏差（ Deviate ）、偏差值（ Deviation ）、离散度（ Discrepancy ）、散度（ Divergence ）等术语近似，所以比较容易产生混淆。</p>
<ul class="simple">
<li><p>偏差（ Deviate ）：是一个形式化的概念，用于泛指随机变量的输出值与该随机变量的中心（如均值）之间差。</p></li>
<li><p>偏差值（ Deviation ）：是随机变量的输出值与某个参考值（常见如均值） 之间差异的具体度量，是偏离概念的一次具体实现。偏离值的符号代表了差异的方向，偏离值的大小代表了偏离的程度。常见的偏差术语有：</p>
<ul>
<li><p>误差（ Error ）：某个感兴趣量的观测值与真实值（期望值）之间的偏差值。例如，如果 <span class="math notranslate nohighlight">\(21\)</span> 岁男性人口的平均高度为<span class="math notranslate nohighlight">\(1.75\)</span> 米，某个随机选择的人身高为 <span class="math notranslate nohighlight">\(1.80\)</span> 米，那么误差为 <span class="math notranslate nohighlight">\(0.05\)</span> 米;如果随机选择的人高 <span class="math notranslate nohighlight">\(1.70\)</span> 米，那么误差为 <span class="math notranslate nohighlight">\(-0.05\)</span> 米。期望值是整体的均值，通常不可观测，因此误差也无法观测。</p></li>
<li><p>残差（ Residual ）：某个感兴趣量的观测值与真实值的估计值之间的偏差值。针对身高的例子，假设我们有 <span class="math notranslate nohighlight">\(n\)</span> 个人的随机样本，则可以用样本作为总体的近似估计，例如用样本的均值作为总体均值的估计。进而样本中每个人每个人的身高与不可观测的期望值之差是误差，而样本中每个人的身高与可观测样本的均值之间的差是残差。这些偏差值的概念适用于测量间隔和比率水平的数据。通常会用一组偏离值的统计量来定量地刻画总体的偏离情况，其中常见的有标准差。</p></li>
</ul>
</li>
<li><p>散度（ Divergence ）：在统计和信息几何中，泛指一个概率分布到另一个概率分布的统计距离，参见 <a class="reference internal" href="chp_11.html#dkl"><span class="std std-ref">11.3 KL 散度</span></a> 中关于 <span class="math notranslate nohighlight">\(KL\)</span> 散度的定义。</p></li>
</ul>
</div>
<p>为了计算公式 <a class="reference internal" href="#equation-eq-elpd-practice">(20)</a>，我们使用了用于拟合模型的相同数据，因此平均而言，会高估 ELPD（ 公式 <a class="reference internal" href="#equation-eq-elpd">(19)</a> ），并导致最终选择的模型容易过拟合。幸运的是，还有几种方法可以更好地估计 ELPD 。其中之一是下面将看到的交叉验证法（ Cross Validation, CV ）。</p>
</div>
<div class="section" id="cv-and-loo">
<span id="id41"></span><h3>2.5.2 交叉验证和留一法<a class="headerlink" href="#cv-and-loo" title="Permalink to this headline">¶</a></h3>
<p><strong>（1）交叉验证的原理</strong></p>
<p>交叉验证 (CV) 是一种估计样本外预测准确性的方法。该方法需要在留出部分数据的情况下重复多次拟合模型（每次留出不同的数据），每次拟合后都使用被留出的数据来测量一次模型的准确性。此过程重复多次后，将所有精度测量结果的均值视为模型的预测精度。此后用完整数据集再拟合一次模型，此模型才是用于进一步分析和/或预测的最终模型。我们可以将 CV 视为一种在使用所有样本点的情况下（或者说无需投入新观测点的情况下），仍然能够模拟（或近似）样本外统计量的方法。</p>
<p><strong>（2）留一法交叉验证</strong></p>
<p>当被留出的数据仅包含一个数据点时，就是非常著名的留一法交叉验证 (LOO-CV) 。使用 LOO-CV 计算的 ELPD 为 <span class="math notranslate nohighlight">\(\text{ELPD}_\text{LOO-CV}\)</span> ：</p>
<div class="math notranslate nohighlight" id="equation-eq-elpd-loo-cv">
<span class="eqno">(21)<a class="headerlink" href="#equation-eq-elpd-loo-cv" title="Permalink to this equation">¶</a></span>\[\text{ELPD}_\text{LOO-CV} = \sum_{i=1}^{n} \log   \int \ p(y_i \mid \boldsymbol{\theta}) \; p(\boldsymbol{\theta} \mid y_{-i}) d\boldsymbol{\theta} \]</div>
<p>计算公式 <a class="reference internal" href="#equation-eq-elpd-loo-cv">(21)</a> 成本很高，因为在实践中，<span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span> 并不确定，因此我们每次运行都需要计算一次后验，也就是说，需要计算 <span class="math notranslate nohighlight">\(n\)</span> 次后验zhi， <span class="math notranslate nohighlight">\(n\)</span> 为数据集中观测点数量。</p>
<p><strong>（3）帕雷托平滑重要性采样留一交叉验证</strong></p>
<p>幸运的是，可以使用一种被称为 <strong>帕雷托平滑重要性采样留一交叉验证（ Pareto Smoothed Importance Sampling Leave-One-Out Cross Validation, PSIS-LOO-CV ）</strong> 的方法，仅通过一次拟合就可以得到 <span class="math notranslate nohighlight">\(\text{ELPD}_\text{LOO-CV}\)</span> 的近似值，详情参阅 <a class="reference internal" href="chp_11.html#loo-depth"><span class="std std-ref">11.5 深入理解留一交叉验证法</span></a> 。</p>
<p>为了与 ArviZ 保持一致，本书后面章节中所指的留一交叉验证（ LOO ），均为 PSIS-LOO-CV 。而且除非另有说明，否则本书中提到 ELPD 时，也均指采用 PSIS-LOO-CV 方法估计的 ELPD 。</p>
<p>ArviZ 提供了许多与 LOO 相关的函数，使用起来也非常简单，但理解其结果时可能需要仔细一点。为了说明如何解释这些函数的输出，我们将使用代码 <a class="reference internal" href="#pymc3-models-for-loo"><span class="std std-ref">pymc3_models_for_loo</span></a> 中定义的 <span class="math notranslate nohighlight">\(3\)</span> 个模型。</p>
<div class="literal-block-wrapper docutils container" id="pymc3-models-for-loo">
<div class="code-block-caption"><span class="caption-number">Listing 12 </span><span class="caption-text">pymc3_models_for_loo</span><a class="headerlink" href="#pymc3-models-for-loo" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_obs</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/random/generated/numpy.random.normal.html#numpy.random.normal" title="numpy.random.normal"><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span></a><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">idatas_cmp</span> <span class="o">=</span> <span class="p">{}</span>

<span class="c1"># Generate data from Skewnormal likelihood model</span>
<span class="c1"># with fixed mean and skewness and random standard deviation</span>
<span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">mA</span><span class="p">:</span>
    <span class="n">σ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s2">"σ"</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">SkewNormal</span><span class="p">(</span><span class="s2">"y"</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">σ</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">y_obs</span><span class="p">)</span>
    <span class="n">idataA</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">return_inferencedata</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># add_groups modifies an existing az.InferenceData</span>
<span class="n">idataA</span><span class="o">.</span><span class="n">add_groups</span><span class="p">({</span><span class="s2">"posterior_predictive"</span><span class="p">:</span>
                  <span class="p">{</span><span class="s2">"y"</span><span class="p">:</span><span class="n">pm</span><span class="o">.</span><span class="n">sample_posterior_predictive</span><span class="p">(</span><span class="n">idataA</span><span class="p">)[</span><span class="s2">"y"</span><span class="p">][</span><span class="kc">None</span><span class="p">,:]}})</span>
<span class="n">idatas_cmp</span><span class="p">[</span><span class="s2">"mA"</span><span class="p">]</span> <span class="o">=</span> <span class="n">idataA</span>

<span class="c1"># Generate data from Normal likelihood model</span>
<span class="c1"># with fixed mean with random standard deviation</span>
<span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">mB</span><span class="p">:</span>
    <span class="n">σ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s2">"σ"</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s2">"y"</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">σ</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">y_obs</span><span class="p">)</span>
    <span class="n">idataB</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">return_inferencedata</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">idataB</span><span class="o">.</span><span class="n">add_groups</span><span class="p">({</span><span class="s2">"posterior_predictive"</span><span class="p">:</span>
                  <span class="p">{</span><span class="s2">"y"</span><span class="p">:</span><span class="n">pm</span><span class="o">.</span><span class="n">sample_posterior_predictive</span><span class="p">(</span><span class="n">idataB</span><span class="p">)[</span><span class="s2">"y"</span><span class="p">][</span><span class="kc">None</span><span class="p">,:]}})</span>
<span class="n">idatas_cmp</span><span class="p">[</span><span class="s2">"mB"</span><span class="p">]</span> <span class="o">=</span> <span class="n">idataB</span>

<span class="c1"># Generate data from Normal likelihood model</span>
<span class="c1"># with random mean and random standard deviation</span>
<span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">mC</span><span class="p">:</span>
    <span class="n">μ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s2">"μ"</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">σ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s2">"σ"</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s2">"y"</span><span class="p">,</span> <span class="n">μ</span><span class="p">,</span> <span class="n">σ</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">y_obs</span><span class="p">)</span>
    <span class="n">idataC</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">return_inferencedata</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">idataC</span><span class="o">.</span><span class="n">add_groups</span><span class="p">({</span><span class="s2">"posterior_predictive"</span><span class="p">:</span>
                  <span class="p">{</span><span class="s2">"y"</span><span class="p">:</span><span class="n">pm</span><span class="o">.</span><span class="n">sample_posterior_predictive</span><span class="p">(</span><span class="n">idataC</span><span class="p">)[</span><span class="s2">"y"</span><span class="p">][</span><span class="kc">None</span><span class="p">,:]}})</span>
<span class="n">idatas_cmp</span><span class="p">[</span><span class="s2">"mC"</span><span class="p">]</span> <span class="o">=</span> <span class="n">idataC</span>
</pre></div>
</div>
</div>
<p>计算 LOO 只需要抽自后验的样本 <a class="footnote-reference brackets" href="#id73" id="id42">16</a> ，然后调用 <code class="docutils literal notranslate"><span class="pre">az.loo(.)</span></code> 函数计算模型的 LOO 。</p>
<p>在实践中，常常需要为多个模型计算 LOO ，Arviz 提供了 <code class="docutils literal notranslate"><span class="pre">az.compare(.)</span></code> 函数来进行多个模型之间 LOO 的比较。 <a class="reference internal" href="#table-compare-00"><span class="std std-numref">Table 2</span></a> 就是通过 <code class="docutils literal notranslate"><span class="pre">az.compare(idatas_cmp)</span></code> 生成的。</p>
<table class="table" id="table-compare-00">
<caption><span class="caption-number">Table 2 </span><span class="caption-text">模型比较的汇总数据。模型按照 loo 列的 ELPD 值自低至高排序.</span><a class="headerlink" href="#table-compare-00" title="Permalink to this table">¶</a></caption>
<colgroup>
<col style="width: 10%"/>
<col style="width: 10%"/>
<col style="width: 10%"/>
<col style="width: 10%"/>
<col style="width: 10%"/>
<col style="width: 10%"/>
<col style="width: 10%"/>
<col style="width: 10%"/>
<col style="width: 10%"/>
<col style="width: 10%"/>
</colgroup>
<tbody>
<tr class="row-odd"><td></td>
<td><p><strong>rank</strong></p></td>
<td><p><strong>loo</strong></p></td>
<td><p><strong>p_loo</strong></p></td>
<td><p><strong>d_loo</strong></p></td>
<td><p><strong>weight</strong></p></td>
<td><p><strong>se</strong></p></td>
<td><p><strong>dse</strong></p></td>
<td><p><strong>warning</strong></p></td>
<td><p><strong>loo_scale</strong></p></td>
</tr>
<tr class="row-even"><td><p>mB</p></td>
<td><p>0</p></td>
<td><p>-137.87</p></td>
<td><p>0.96</p></td>
<td><p>0.00</p></td>
<td><p>1.0</p></td>
<td><p>7.06</p></td>
<td><p>0.00</p></td>
<td><p>False</p></td>
<td><p>log</p></td>
</tr>
<tr class="row-odd"><td><p>mC</p></td>
<td><p>1</p></td>
<td><p>-138.61</p></td>
<td><p>2.03</p></td>
<td><p>0.74</p></td>
<td><p>0.0</p></td>
<td><p>7.05</p></td>
<td><p>0.85</p></td>
<td><p>False</p></td>
<td><p>logde qi wang</p></td>
</tr>
<tr class="row-even"><td><p>mA</p></td>
<td><p>2</p></td>
<td><p>-168.06</p></td>
<td><p>1.35</p></td>
<td><p>30.19</p></td>
<td><p>0.0</p></td>
<td><p>10.32</p></td>
<td><p>6.54</p></td>
<td><p>False</p></td>
<td><p>log</p></td>
</tr>
</tbody>
</table>
<p><a class="reference internal" href="#table-compare-00"><span class="std std-numref">Table 2</span></a> 中有很多列，让我们一一说明其含义：</p>
<ol class="simple">
<li><p>第一列为索引，它列出了传递给 <code class="docutils literal notranslate"><span class="pre">az.compare(.)</span></code> 的模型名称。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">rank</span></code> 列：按照预测精度做的排名，值从 <span class="math notranslate nohighlight">\(0\)</span> 依次到模型总数，其中 <span class="math notranslate nohighlight">\(0\)</span> 代表最高精度。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">loo</span></code> 列：各模型 ELPD 值的列表，总是按照 ELPD 值从最好到最差排序。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">p_loo</span></code> 列：惩罚项的值列表，可以将其粗略地视为有效参数数量的估计值（但不要太认真）。此值可能低于 <em>具有更多结构的模型</em> （如分层模型）中的实际参数数量，或者高于那些预测能力非常弱或严重错误指定的模型的实际参数数量。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">d_loo</span></code> 列：每个模型与排名第一的模型之间的 LOO 相对差。因此第一个模型始终取值为 <span class="math notranslate nohighlight">\(0\)</span> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">weight</span></code> 列：分配给每个模型的权重。权重可以粗略地解释为在指定数据的条件下，是（参与比较的各模型中）该模型的概率。详细信息参阅 <a class="reference internal" href="#model-averaging"><span class="std std-ref">2.6 模型平均</span></a> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">se</span></code> 列：ELPD 的标准误差。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">dse</span></code> 列：ELPD 相对差的标准误差。 <code class="docutils literal notranslate"><span class="pre">dse</span></code> 与 <code class="docutils literal notranslate"><span class="pre">se</span></code> 不一定相同，因为 ELPD 的不确定性在模型之间可能存在相关性。排名第一的模型 <code class="docutils literal notranslate"><span class="pre">dse</span></code> 值始终为 <span class="math notranslate nohighlight">\(0\)</span> 。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">warning</span></code> 列：如果为<code class="docutils literal notranslate"><span class="pre">True</span></code>，表示这是一个警告，LOO 的近似估计不可靠，详见 <a class="reference internal" href="#k-paretto"><span class="std std-ref">2.5.4 帕累托形状参数 \hat \kappa</span></a>。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">loo_scale</span></code> 列：估计值所用的尺度（或量纲）。默认为对数尺度。其他选项还包括：离差值尺度，即对数分值乘以 <span class="math notranslate nohighlight">\(-2\)</span> ，这会颠倒排序，较低的 ELPD 会更好；负对数尺度，即对数分值乘以 <span class="math notranslate nohighlight">\(-1\)</span>，与离差值尺度一样，值越低越好。</p></li>
</ol>
<p>我们还可以在 <a class="reference internal" href="#fig-compare-dummy"><span class="std std-numref">Fig. 27</span></a> 中以图形方式表示 <a class="reference internal" href="#table-compare-00"><span class="std std-numref">Table 2</span></a> 中的部分信息。图中模型的预测精度也是从高到低排列。空心点代表 <code class="docutils literal notranslate"><span class="pre">loo</span></code> 值，黑点是没有 <code class="docutils literal notranslate"><span class="pre">p_loo</span></code> 惩罚项时的预测精度。黑色部分代表计算 LOO 的 <code class="docutils literal notranslate"><span class="pre">se</span></code> 标准误差 。以三角形为中心的灰色区域表示每个模型与最佳模型之间的 <code class="docutils literal notranslate"><span class="pre">dse</span></code> 标准误差。可以看到 <code class="docutils literal notranslate"><span class="pre">mB</span></code> <span class="math notranslate nohighlight">\(\approx\)</span> <code class="docutils literal notranslate"><span class="pre">mC</span></code> <span class="math notranslate nohighlight">\(&gt;\)</span> <code class="docutils literal notranslate"><span class="pre">mA</span></code>。</p>
<p>从 <a class="reference internal" href="#table-compare-00"><span class="std std-numref">Table 2</span></a> 和 <a class="reference internal" href="#fig-compare-dummy"><span class="std std-numref">Fig. 27</span></a> 可以看到模型 <code class="docutils literal notranslate"><span class="pre">mA</span></code> 的排名最低，并且与其他两个明显分开。我们现在讨论另外两个模型，因为其间的区别更加微妙。 <code class="docutils literal notranslate"><span class="pre">mB</span></code> 是预测精度最高的模型，但与 <code class="docutils literal notranslate"><span class="pre">mC</span></code> 相比差异几乎可以忽略不计。根据经验，低于 <span class="math notranslate nohighlight">\(4\)</span> 的 <code class="docutils literal notranslate"><span class="pre">d_loo</span></code> 被认为很小。这两个模型之间的主要区别在于：对于 <code class="docutils literal notranslate"><span class="pre">mB</span></code> ，均值固定为 <span class="math notranslate nohighlight">\(0\)</span> ，而对于 <code class="docutils literal notranslate"><span class="pre">mC</span></code> ，均值具有先验分布。 LOO 会对添加此先验做出惩罚，由 <code class="docutils literal notranslate"><span class="pre">p_loo</span></code> 的值表示，可以看出 <code class="docutils literal notranslate"><span class="pre">mC</span></code> 大于 <code class="docutils literal notranslate"><span class="pre">mB</span></code>；黑点（未惩罚的 ELPD）和开放点（ <span class="math notranslate nohighlight">\(\text{ELPD}_ \text{LOO-CV}\)</span> ）之间的距离表现出， <code class="docutils literal notranslate"><span class="pre">mC</span></code> 比 <code class="docutils literal notranslate"><span class="pre">mB</span></code> 大。我们还可以看到，两个模型之间的 <code class="docutils literal notranslate"><span class="pre">dse</span></code> 远低于各自的 <code class="docutils literal notranslate"><span class="pre">se</span></code>，表明两者的预测结果高度相关。</p>
<p>鉴于 <code class="docutils literal notranslate"><span class="pre">mB</span></code> 和 <code class="docutils literal notranslate"><span class="pre">mC</span></code> 之间的微小差异，在稍微不同的数据集下，这些模型的排名就可能会交替， <code class="docutils literal notranslate"><span class="pre">mC</span></code> 可能会成为最佳模型。此外，权重的值也会发生变化，参见 <a class="reference internal" href="#model-averaging"><span class="std std-ref">2.6 模型平均</span></a> 。我们可以更改随机种子并重新拟合模型几次来检查这种现象。</p>
<div class="figure align-default" id="fig-compare-dummy">
<a class="reference internal image-reference" href="../_images/compare_dummy.png"><img alt="../_images/compare_dummy.png" src="../_images/compare_dummy.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 27 </span><span class="caption-text">使用 LOO 进行模型比较。空心点代表 <code class="docutils literal notranslate"><span class="pre">loo</span></code> 的值，黑点是不含惩罚项 <code class="docutils literal notranslate"><span class="pre">p_loo</span></code> 的预测精度。黑色部分代表 LOO 计算 <code class="docutils literal notranslate"><span class="pre">se</span></code> 的标准误差。以三角形为中心的灰色部分表示每个模型的相对差 <code class="docutils literal notranslate"><span class="pre">dse</span></code> 的标准误差。</span><a class="headerlink" href="#fig-compare-dummy" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="section" id="elpd-plots">
<span id="id43"></span><h3>2.5.3 对数预测密度的期望<a class="headerlink" href="#elpd-plots" title="Permalink to this headline">¶</a></h3>
<p>在上一节中，我们计算了每个模型的 ELPD 值。这是一个有关模型 <em>全局</em> 的比较，它会将模型和数据简化为一个数字。但是从公式 <a class="reference internal" href="#equation-eq-elpd-practice">(20)</a> 和 <a class="reference internal" href="#equation-eq-elpd-loo-cv">(21)</a> 可以看到， LOO 是对逐点值求和得到的，每个观测值对应一个。因此，我们还可以执行 <em>局部的</em> 比较，可以将 ELPD 的每个值视为一个<em>模型在预测特定观测值时的</em> 难度指示器。</p>
<p>为了利用逐观测点的 ELPD 值来比较模型，ArviZ 提供了 <code class="docutils literal notranslate"><span class="pre">az.plot_elpd(.)</span></code> 函数。 <a class="reference internal" href="#fig-elpd-dummy"><span class="std std-numref">Fig. 28</span></a> 以成对方式显示了模型 <code class="docutils literal notranslate"><span class="pre">mA</span></code>、<code class="docutils literal notranslate"><span class="pre">mB</span></code> 和 <code class="docutils literal notranslate"><span class="pre">mC</span></code> 之间的比较情况。</p>
<p>正值表示第一个模型比第二个模型更好地解释了观测结果。例如，如果观察第一个图（<code class="docutils literal notranslate"><span class="pre">mA-mB</span></code>），模型 <code class="docutils literal notranslate"><span class="pre">mA</span></code> 比模型 <code class="docutils literal notranslate"><span class="pre">mB</span></code> 更好地解释了观测 <span class="math notranslate nohighlight">\(49\)</span> 和 <span class="math notranslate nohighlight">\(72\)</span>，而观测 <span class="math notranslate nohighlight">\(75\)</span> 和 <span class="math notranslate nohighlight">\(95\)</span> 则相反。可以看到 <code class="docutils literal notranslate"><span class="pre">mA-mB</span></code> 和 <code class="docutils literal notranslate"><span class="pre">mA-mC</span></code> 这两个图非常相似，原因是模型 <code class="docutils literal notranslate"><span class="pre">mB</span></code> 和模型 <code class="docutils literal notranslate"><span class="pre">mC</span></code> 实际上彼此非常相似。 <a class="reference internal" href="#fig-elpd-and-khat"><span class="std std-numref">Fig. 30</span></a> 表明观测 <span class="math notranslate nohighlight">\(34\)</span>、 <span class="math notranslate nohighlight">\(49\)</span>、 <span class="math notranslate nohighlight">\(72\)</span>、 <span class="math notranslate nohighlight">\(75\)</span> 和 <span class="math notranslate nohighlight">\(82\)</span> 实际上是五个最<em>极端</em>的观测。</p>
<div class="figure align-default" id="fig-elpd-dummy">
<a class="reference internal image-reference" href="../_images/elpd_dummy.png"><img alt="../_images/elpd_dummy.png" src="../_images/elpd_dummy.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 28 </span><span class="caption-text">逐观测点的 ELPD 差。被标记的点对应于 ELPD 差为两倍标准差的观测值。所有 <span class="math notranslate nohighlight">\(3\)</span> 个示例中的差都很小，尤其是在 <code class="docutils literal notranslate"><span class="pre">mB</span></code> 和 <code class="docutils literal notranslate"><span class="pre">mC</span></code> 之间。正值表示第一个模型比第二个模型更好地解释了观测结果。</span><a class="headerlink" href="#fig-elpd-dummy" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="section" id="hat-kappa">
<span id="k-paretto"></span><h3>2.5.4 帕累托形状参数 <span class="math notranslate nohighlight">\(\hat \kappa\)</span><a class="headerlink" href="#hat-kappa" title="Permalink to this headline">¶</a></h3>
<p>用 LOO 近似计算 <span class="math notranslate nohighlight">\(\text{ELPD}_\text{LOO-CV}\)</span> 涉及帕累托分布的计算（ 参见 <a class="reference internal" href="chp_11.html#loo-depth"><span class="std std-ref">11.5 深入理解留一交叉验证法</span></a> ），其主要目的是获得更稳健的估计，衍生效应是帕累托分布的 <span class="math notranslate nohighlight">\(\hat \kappa\)</span> 参数还可以用于检测影响力较大的观测点，即能够指示出那些 <em>如果不参与拟合就会严重影响预测分布的</em> 观测值。通常较高的 <span class="math notranslate nohighlight">\(\hat \kappa\)</span> 值可能表明数据或模型存在问题，尤其是当 <span class="math notranslate nohighlight">\(\hat \kappa &gt; 0.7\)</span> 时 <span id="id44">[<a class="reference internal" href="references.html#id20">16</a>, <a class="reference internal" href="references.html#id19">22</a>]</span> 。此时建议 <span id="id45">[<a class="reference internal" href="references.html#id170">23</a>]</span>：</p>
<ul class="simple">
<li><p>使用匹配矩方法 <span id="id46">[<a class="reference internal" href="references.html#id147">24</a>]</span> <a class="footnote-reference brackets" href="#id74" id="id47">17</a>。通过一些额外的计算，有可能通过对后验分布样本进行变换，获得更可靠的重要性采样估计。</p></li>
<li><p>对存在问题的观测点执行精确的留一交叉验证或使用 <span class="math notranslate nohighlight">\(k\)</span> 折交叉验证。</p></li>
<li><p>使用对异常观测更稳健的模型。</p></li>
</ul>
<p>当计算结果中存在至少一个 <span class="math notranslate nohighlight">\(\hat \kappa &gt; 0.7\)</span> 的值时，<code class="docutils literal notranslate"><span class="pre">az.loo(.)</span></code> 或 <code class="docutils literal notranslate"><span class="pre">az.compare(.)</span></code> 就会输出警告。 <a class="reference internal" href="#table-compare-00"><span class="std std-numref">Table 2</span></a> 中的 <code class="docutils literal notranslate"><span class="pre">warning</span></code> 列的值均是 <code class="docutils literal notranslate"><span class="pre">False</span></code>，是因为 <span class="math notranslate nohighlight">\(\hat \kappa\)</span> 的所有值都 <span class="math notranslate nohighlight">\(&lt; 0.7\)</span>，你可以通过 <a class="reference internal" href="#fig-loo-k-dummy"><span class="std std-numref">Fig. 29</span></a> 自行验证。</p>
<p>我们在 <a class="reference internal" href="#fig-loo-k-dummy"><span class="std std-numref">Fig. 29</span></a> 中对 <span class="math notranslate nohighlight">\(\hat \kappa &gt; 0.09\)</span> 观测进行了标记，<span class="math notranslate nohighlight">\(0.09\)</span> 是随意选择的值，没有特定含义。比较 <a class="reference internal" href="#fig-elpd-dummy"><span class="std std-numref">Fig. 28</span></a> 和 <a class="reference internal" href="#fig-loo-k-dummy"><span class="std std-numref">Fig. 29</span></a> ，可以看到 <span class="math notranslate nohighlight">\(\hat \kappa\)</span> 的最大值和 ELPD 的最大值并不对应，反之亦然。</p>
<div class="figure align-default" id="fig-loo-k-dummy">
<a class="reference internal image-reference" href="../_images/loo_k_dummy.png"><img alt="../_images/loo_k_dummy.png" src="../_images/loo_k_dummy.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 29 </span><span class="caption-text">逐观测点的 <span class="math notranslate nohighlight">\(\hat \kappa\)</span> 值。标记点对应于 <span class="math notranslate nohighlight">\(\hat \kappa &gt; 0.09\)</span> 的观测值，这是随意选取的一个阈值。</span><a class="headerlink" href="#fig-loo-k-dummy" title="Permalink to this image">¶</a></p>
</div>
<div class="figure align-default" id="fig-elpd-and-khat">
<a class="reference internal image-reference" href="../_images/elpd_and_khat.png"><img alt="../_images/elpd_and_khat.png" src="../_images/elpd_and_khat.png" style="width: 4.5in;"/></a>
<p class="caption"><span class="caption-number">Fig. 30 </span><span class="caption-text">被模型 <code class="docutils literal notranslate"><span class="pre">mA</span></code> 、<code class="docutils literal notranslate"><span class="pre">mB</span></code> 和 <code class="docutils literal notranslate"><span class="pre">mC</span></code> 拟合的观测值的核密度估计曲线。底部每条黑色竖线代表一个观测点。被标记的观测点与 <a class="reference internal" href="#fig-elpd-dummy"><span class="std std-numref">Fig. 28</span></a> 中突出显示的观测点相同，但观测 <span class="math notranslate nohighlight">\(78\)</span> 以粗体标记，仅在 <a class="reference internal" href="#fig-loo-k-dummy"><span class="std std-numref">Fig. 29</span></a> 中突出显示。</span><a class="headerlink" href="#fig-elpd-and-khat" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="section" id="hat-kappa-p-loo">
<span id="interpreting-p-loo-when-pareto-hat-kappa-is-large"></span><h3>2.5.5 当帕累托参数 <span class="math notranslate nohighlight">\(\hat \kappa\)</span> 较大时解读 <code class="docutils literal notranslate"><span class="pre">p_loo</span></code><a class="headerlink" href="#hat-kappa-p-loo" title="Permalink to this headline">¶</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">p_loo</span></code> 可以粗略地解释为模型中被估计的有效参数数量。然而，对于 <span class="math notranslate nohighlight">\(\hat\kappa\)</span> 值较大的模型，可以获得一些额外的信息。如果 <span class="math notranslate nohighlight">\(\hat \kappa &gt; 0.7\)</span>，那么将 <code class="docutils literal notranslate"><span class="pre">p_loo</span></code> 与参数数量 <span class="math notranslate nohighlight">\(p\)</span> 进行比较可以提供一些额外信息 <span id="id48">[<a class="reference internal" href="references.html#id170">23</a>]</span>：</p>
<ul class="simple">
<li><p>如果 <span class="math notranslate nohighlight">\(p\_loo &lt;&lt; p\)</span>，那么模型很可能被错误指定。你通常还会在后验预测检查中观察到后验预测样本与观测结果匹配不佳的现象。</p></li>
<li><p>如果 <span class="math notranslate nohighlight">\(p\_loo &lt; p\)</span> ，并且与观测次数 <span class="math notranslate nohighlight">\(N\)</span> 相比 <span class="math notranslate nohighlight">\(p\)</span> 相对较大（ 例如，<span class="math notranslate nohighlight">\(p &gt; \frac{N}{5}\)</span> ），这通常表明模型过于灵活或先验信息太少。因此，模型很难预测被留出的观测。</p></li>
<li><p>如果 <span class="math notranslate nohighlight">\(p\_loo &gt; p\)</span>，模型也很可能被严重错误指定。如果参数数量 <span class="math notranslate nohighlight">\(p &lt;&lt; N\)</span>，那么后验预测检查也可能已经揭示了一些问题 <a class="footnote-reference brackets" href="#id75" id="id49">18</a>。但是，如果 <span class="math notranslate nohighlight">\(p\)</span> 与观测次数相比相对较大，例如 <span class="math notranslate nohighlight">\(p &gt; \frac{N}{5}\)</span>，则你可能在后验预测检查中观察不到任何问题。</p></li>
</ul>
<p>你可以尝试修复模型错误指定的一些启发式方法：为模型添加更多结构。例如，添加非线性组件、使用不同的似然（例如，用 <code class="docutils literal notranslate"><span class="pre">NegativeBinomial</span></code> 这种过度分散的似然代替 <code class="docutils literal notranslate"><span class="pre">Poisson</span></code> ）、使用混合似然等。</p>
</div>
<div class="section" id="loo-loo-pit">
<span id="loo-pit"></span><h3>2.5.6 LOO – 概率积分变换（ LOO-PIT ）<a class="headerlink" href="#loo-loo-pit" title="Permalink to this headline">¶</a></h3>
<p>前面 <a class="reference internal" href="#elpd-plots"><span class="std std-ref">2.5.3 对数预测密度的期望</span></a> 、 <a class="reference internal" href="#k-paretto"><span class="std std-ref">2.5.4 帕累托形状参数 \hat \kappa</span></a> 等关于模型比较的内容中， LOO 除了声明某个模型的优劣外，还可以被用于实现其他目的，事实上可以将 <em>模型比较</em> 作为深入理解模型的一种途径。随着模型复杂性的增加，仅通过查看其数学定义或实现代码来理解模型会变得越加困难，此时使用 LOO 或其他工具（如后验预测检查）来进行模型比较，可以帮助我们更好地理解它们。</p>
<p>对后验预测检查的一种评判机制是使用两次数据，一次是为了拟合模型，一次是为了评判模型。 LOO-PIT 图为此提供了解决答案，其思想是直接将 LOO 作为交叉验证的一个快速而可靠近似，从而避免两次使用数据。 其中 <code class="docutils literal notranslate"><span class="pre">PIT</span></code> 部分表示概率积分变换 <a class="reference internal" href="chp_11.html#probability-integral-transform-pit"><span class="std std-ref">概率积分变换 (PIT)</span></a>，使得我们能够通过 CDF 获得任何连续随机变量的均匀分布 <span class="math notranslate nohighlight">\(\mathcal{U}(0, 1)\)</span> （ 详情参阅 <a class="reference internal" href="chp_11.html#loo-depth"><span class="std std-ref">11.5 深入理解留一交叉验证法</span></a> ）。在 LOO-PIT 中，我们不知道真正的 CDF，但可以用经验 CDF 来近似它。</p>
<p>暂时搁置这些数学细节，权且认为它是柯计算的。那么对于一个经过良好校准的模型，我们应该期望 LOO-PIT 表现为一个近似均匀的分布。你可能会有似曾相识的感觉，因为这与在 <a class="reference internal" href="#posterior-pd"><span class="std std-ref">2.3 后验预测检查</span></a> 中使用函数 <code class="docutils literal notranslate"><span class="pre">az.plot_bpv(idata,</span> <span class="pre">kind="u_value")</span></code> 绘制贝叶斯 <span class="math notranslate nohighlight">\(p\)</span> 值时有过类似讨论。</p>
<p>LOO-PIT 通过将观测数据 <span class="math notranslate nohighlight">\(y\)</span> 与后验预测数据 <span class="math notranslate nohighlight">\(\tilde y\)</span> 比较获得，该比较是逐点进行的。有：</p>
<div class="math notranslate nohighlight">
\[p_i = P(\tilde y_i \leq y_i \mid y_{-i})\]</div>
<p>从公式中可以直观地看到：当留出第 <span class="math notranslate nohighlight">\(i\)</span> 个观测点时，LOO-PIT 计算的是后验预测数据 <span class="math notranslate nohighlight">\(\tilde y_i &lt; y_i\)</span> 的概率。</p>
<p>因此，<code class="docutils literal notranslate"><span class="pre">az.plot_bpv(idata,</span> <span class="pre">kind="u_value")</span></code> 和 LOO-PIT 之间的区别在于，后者避免了两次使用数据，不过两者对图的总体解释大致相同。</p>
<p><a class="reference internal" href="#fig-loo-pit-dummy"><span class="std std-numref">Fig. 31</span></a> 展示了模型 <code class="docutils literal notranslate"><span class="pre">mA</span></code>、<code class="docutils literal notranslate"><span class="pre">mB</span></code> 和 <code class="docutils literal notranslate"><span class="pre">mC</span></code> 的 LOO-PIT。可以观察到，从模型 <code class="docutils literal notranslate"><span class="pre">mA</span></code> 的角度来看，低值的观测数据比预期的多，高值的数据少，即模型存在偏差（ Bias ）。相反，模型 <code class="docutils literal notranslate"><span class="pre">mB</span></code> 和 <code class="docutils literal notranslate"><span class="pre">mC</span></code> 似乎校准得较好。</p>
<div class="figure align-default" id="fig-loo-pit-dummy">
<a class="reference internal image-reference" href="../_images/loo_pit_dummy.png"><img alt="../_images/loo_pit_dummy.png" src="../_images/loo_pit_dummy.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 31 </span><span class="caption-text">黑线是 LOO-PIT 的核密度估计曲线，即小于或等于观测数据的预测值的比例，根据每次观测计算。白线表示预期的均匀分布，灰带表示数据集（大小与所用数据集相同）的预期偏差。</span><a class="headerlink" href="#fig-loo-pit-dummy" title="Permalink to this image">¶</a></p>
</div>
</div>
</div>
<div class="section" id="model-averaging">
<span id="id50"></span><h2>2.6 模型平均<a class="headerlink" href="#model-averaging" title="Permalink to this headline">¶</a></h2>
<p>模型平均可以被视为针对模型不确定性的贝叶斯，因为模型也和参数一样具有不确定性。如果我们不能确切地认定 <em>a</em> 模型就是那个想要的模型（通常不能），那么就应该以某种方式将这种不确定性考虑到模型分析中。处理模型不确定性的方法之一是对所有模型进行加权平均，将更大的权重赋予似乎能更好解释或预测数据的模型。</p>
<p><strong>（1）贝叶斯模型平均</strong></p>
<p>对贝叶斯模型进行赋权的一种自然而然的想法是利用边缘似然值（即贝叶斯公式的分母项），这也被称为贝叶斯模型平均 <span id="id51">[<a class="reference internal" href="references.html#id26">25</a>]</span>。 虽然其思想在理论上很有吸引力，但在实践中却存在很多问题，因为边缘似然的计算非常棘手（ 详情参阅 <a class="reference internal" href="chp_11.html#marginal-likelihood"><span class="std std-ref">11.7 边缘似然</span></a> ）。</p>
<p><strong>（2）伪贝叶斯模型平均</strong></p>
<p>直接计算边缘似然存在困难，因此有人提出了另外一种赋权方法，即使用 LOO 来估计模型的权重。可以使用以下公式：</p>
<div class="math notranslate nohighlight" id="equation-eq-pseudo-avg">
<span class="eqno">(22)<a class="headerlink" href="#equation-eq-pseudo-avg" title="Permalink to this equation">¶</a></span>\[w_i = \frac {e^{-\Delta_i }} {\sum_j^k e^{-\Delta_j }} \]</div>
<p>其中 <span class="math notranslate nohighlight">\(\Delta_i\)</span> 是排序后的第 <span class="math notranslate nohighlight">\(i\)</span> 个 LOO 值与最大 LOO 值之差。此处假设使用对数尺度，这也是 ArviZ 的默认值。</p>
<p>此方法被称为 <strong>伪贝叶斯模型平均</strong> 或 <strong>类 Akaike 加权</strong> <a class="footnote-reference brackets" href="#id76" id="id52">20</a> ，是一种从 LOO 计算（若干指定）模型相对概率的启发式方法<a class="footnote-reference brackets" href="#id77" id="id53">21</a>。注意分母只是一个归一化项，以确保权重总和为 <span class="math notranslate nohighlight">\(1\)</span> 。公式 <a class="reference internal" href="#equation-eq-pseudo-avg">(22)</a> 提供的权重计算方案简单且好用，但需要注意它没有考虑 LOO 计算本身的不确定性。对此，可以假设高斯近似来计算标准误差，并相应地修改公式 <a class="reference internal" href="#equation-eq-pseudo-avg">(22)</a>；或者可以做一些更稳健的事情，比如使用贝叶斯自举法。</p>
<p><strong>（3）预测分布的堆叠</strong></p>
<p>模型平均的另一个选择是堆叠多个预测分布 <span id="id54">[<a class="reference internal" href="references.html#id22">26</a>]</span>。其主要思想是将多个模型组合在一个 <strong>元模型（ Meta-Model ）</strong> 中，使元模型和 <em>真实</em> 生成模型之间的散度最小化。当使用对数评分规则时，这等效于计算：</p>
<div class="math notranslate nohighlight" id="equation-eq-stacking">
<span class="eqno">(23)<a class="headerlink" href="#equation-eq-stacking" title="Permalink to this equation">¶</a></span>\[\max_{n} \frac{1}{n} \sum_{i=1}^{n}log\sum_{j=1}^{k} w_j p(y_i \mid y_{-i}, M_j) \]</div>
<p>其中 <span class="math notranslate nohighlight">\(n\)</span> 是数据点数量，<span class="math notranslate nohighlight">\(k\)</span> 是模型数量。为了能够强制求解，我们将 <span class="math notranslate nohighlight">\(w\)</span> 限制为 <span class="math notranslate nohighlight">\(w_j \ge 0\)</span> 和 <span class="math notranslate nohighlight">\(\sum_{j=1}^{k} w_j = 1\)</span>。 <span class="math notranslate nohighlight">\(p(y_i \mid y_{-i}, M_j)\)</span> 是 <span class="math notranslate nohighlight">\(M_j\)</span> 模型的留一法预测分布。前面已经谈到过，该预测分布的计算成本过高，在实践中可以使用 LOO 来近似。</p>
<p><code class="docutils literal notranslate"><span class="pre">预测分布堆叠法</span></code>具有比<code class="docutils literal notranslate"><span class="pre">伪贝叶斯模型平均法</span></code>更有趣的特性。我们可以从其定义中看出：公式 <a class="reference internal" href="#equation-eq-pseudo-avg">(22)</a> 只是对每个模型权重的归一化，而且这些权重独立于其他模型计算得出。相反，在等式 <a class="reference internal" href="#equation-eq-stacking">(23)</a> 中，权重通过最大化组合对数评分来计算，即：即便在伪贝叶斯模型平均中独立地拟合模型，权重的计算也会同时考虑所有模型。这有助于解释为什么模型 <code class="docutils literal notranslate"><span class="pre">mB</span></code> 的权重为 <span class="math notranslate nohighlight">\(1\)</span> ，而 <code class="docutils literal notranslate"><span class="pre">mC</span></code> 的权重为 <span class="math notranslate nohighlight">\(0\)</span>（ 参见 <a class="reference internal" href="#table-compare-00"><span class="std std-numref">Table 2</span></a> ），虽然它们非常相似。为什么权重没有都在 <span class="math notranslate nohighlight">\(0.5\)</span> 左右呢？原因是根据堆叠过程，一旦 <code class="docutils literal notranslate"><span class="pre">mB</span></code> 包含在比较模型集合中，加入模型 <code class="docutils literal notranslate"><span class="pre">mC</span></code> 不会再提供新信息。也就是说，包含它是多余的。</p>
<p>函数 <code class="docutils literal notranslate"><span class="pre">pm.sample_posterior_predictive_w(.)</span></code> 输入参数为轨迹列表和权重列表，从而能够让我们轻松生成加权的后验预测样本。权重可以采用多种方式获取，但使用 <code class="docutils literal notranslate"><span class="pre">az.compare(.,</span> <span class="pre">method="stacking")</span></code> 计算的权重，可能更有意义。</p>
</div>
<div class="section" id="exercises2">
<span id="id55"></span><h2>2.7 练习<a class="headerlink" href="#exercises2" title="Permalink to this headline">¶</a></h2>
<p><strong>2E1.</strong> Using your own words, what are the main differences between prior predictive checks and posterior predictive checks? How are these empirical evaluations related to Equations <a class="reference internal" href="chp_01.html#equation-eq-prior-pred-dist">(5)</a> and <a class="reference internal" href="chp_01.html#equation-eq-post-pred-dist">(6)</a>.</p>
<p><strong>2E2.</strong> Using your own words explain: ESS, <span class="math notranslate nohighlight">\(\hat R\)</span> and MCSE. Focus your explanation on what these quantities are measuring and what potential issue with MCMC they are identifying.</p>
<p><strong>2E3.</strong> ArviZ includes precomputed InferenceData objects for a few models. We are going to load an InferenceData object generated from a classical example in Bayesian statistic, the eight schools model <span id="id56">[<a class="reference internal" href="references.html#id115">27</a>]</span>. The InferenceData object includes prior samples, prior predictive samples and posterior samples. We can load the InferenceData object using the command <code class="docutils literal notranslate"><span class="pre">az.load_arviz_data("centered_eight")</span></code>. Use ArviZ to:</p>
<ol class="simple">
<li><p>List all the groups available on the InferenceData object.</p></li>
<li><p>Identify the number of chains and the total number of posterior   samples.</p></li>
<li><p>Plot the posterior.</p></li>
<li><p>Plot the posterior predictive distribution.</p></li>
<li><p>Calculate the estimated mean of the parameters, and the Highest   Density Intervals.</p></li>
</ol>
<p>If necessary check the ArviZ documentation to help you do these tasks <a class="reference external" href="https://arviz-devs.github.io/arviz/">https://arviz-devs.github.io/arviz/</a></p>
<p><strong>2E4.</strong> Load <code class="docutils literal notranslate"><span class="pre">az.load_arviz_data("non_centered_eight")</span></code>, which is a reparametrized version of the “centered_eight” model in the previous exercise. Use ArviZ to assess the MCMC sampling convergence for both models by using:</p>
<ol class="simple">
<li><p>Autocorrelation plots</p></li>
<li><p>Rank plots.</p></li>
<li><p><span class="math notranslate nohighlight">\(\hat R\)</span> values.</p></li>
</ol>
<p>Focus on the plots for the mu and tau parameters. What do these three different diagnostics show? Compare these to the InferenceData results loaded from <code class="docutils literal notranslate"><span class="pre">az.load_arviz_data("centered_eight")</span></code>. Do all three diagnostics tend to agree on which model is preferred? Which one of the models has better convergence diagnostics?</p>
<p><strong>2E5.</strong> InferenceData object can store statistics related to the sampling algorithm. You will find them in the <code class="docutils literal notranslate"><span class="pre">sample_stats</span></code> group, including divergences (<code class="docutils literal notranslate"><span class="pre">diverging</span></code>):</p>
<ol class="simple">
<li><p>Count the number of divergences for “centered_eight” and   “non_centered_eight” models.</p></li>
<li><p>Use <code class="docutils literal notranslate"><span class="pre">az.plot_parallel</span></code> to identify where the divergences tend to   concentrate in the parameter space.</p></li>
</ol>
<p><strong>2E6.</strong> In the GitHub repository we have included an InferenceData object with a Poisson model and one with a NegativeBinomial, both models are fitted to the same dataset. Use <code class="docutils literal notranslate"><span class="pre">az.load_arviz_data(.)</span></code> to load them, and then use ArviZ functions to answer the following questions:</p>
<ol class="simple">
<li><p>Which model provides a better fit to the data? Use the functions   <code class="docutils literal notranslate"><span class="pre">az.compare(.)</span></code> and <code class="docutils literal notranslate"><span class="pre">az.plot_compare(.)</span></code></p></li>
<li><p>Explain why one model provides a better fit than the other. Use   <code class="docutils literal notranslate"><span class="pre">az.plot_ppc(.)</span></code> and <code class="docutils literal notranslate"><span class="pre">az.plot_loo_pit(.)</span></code></p></li>
<li><p>Compare both models in terms of their pointwise ELPD values.</p></li>
</ol>
<p>Identify the 5 observations with the largest (absolute) difference.</p>
<p>Which model is predicting them better? For which model p_loo is   closer to the actual number of parameters? Could you explain why?   Hint: the Poisson model has a single parameter that controls both   the variance and mean. Instead, the NegativeBinomial has two   parameters.</p>
<ol class="simple">
<li><p>Diagnose LOO using the <span class="math notranslate nohighlight">\(\hat \kappa\)</span> values. Is there any reason to   be concerned about the accuracy of LOO for this particular case?</p></li>
</ol>
<p><strong>2E7.</strong> Reproduce <a class="reference internal" href="#fig-posterior-predictive-many-examples"><span class="std std-numref">Fig. 18</span></a>, but using <code class="docutils literal notranslate"><span class="pre">az.plot_loo(ecdf=True)</span></code> in place of <code class="docutils literal notranslate"><span class="pre">az.plot_bpv(.)</span></code>. Interpret the results. Hint: when using the option <code class="docutils literal notranslate"><span class="pre">ecdf=True</span></code>, instead of the LOO-PIT KDE you will get a plot of the difference between the LOO-PIT Empirical Cumulative Distribution Function (ECDF) and the Uniform CDF. The ideal plot will be one with a difference of zero.</p>
<p><strong>2E8.</strong> In your own words explain why MCMC posterior estimation techniques need convergence diagnostics. In particular contrast these to the conjugate methods described in Section <a class="reference internal" href="chp_01.html#conjugate-priors"><span class="std std-ref">1.4.1 共轭先验</span></a> which do not need those diagnostics. What is different about the two inference methods?</p>
<p><strong>2E9.</strong> Visit the ArviZ plot gallery at <a class="reference external" href="https://arviz-devs.github.io/arviz/examples/index.html">https://arviz-devs.github.io/arviz/examples/index.html</a>. What diagnoses can you find there that are not covered in this chapter? From the documentation what is this diagnostic assessing?</p>
<p><strong>2E10.</strong> List some plots and numerical quantities that are useful at each step during the Bayesian workflow (shown visually in <a class="reference internal" href="chp_09.html#fig-bayesianworkflow"><span class="std std-numref">Fig. 152</span></a>). Explain how they work and what they are assessing. Feel free to use anything you have seen in this chapter or in the ArviZ documentation.</p>
<ol class="simple">
<li><p>Prior selection.</p></li>
<li><p>MCMC sampling.</p></li>
<li><p>Posterior predictions.</p></li>
</ol>
<p><strong>2M11.</strong> We want to model a football league with <span class="math notranslate nohighlight">\(N\)</span> teams. As usual, we start with a simpler version of the model in mind, just a single team. We assume the scores are Poisson distributed according to a scoring rate <span class="math notranslate nohighlight">\(\mu\)</span>. We choose the prior <span class="math notranslate nohighlight">\(\text{Gamma}(0.5, 0.00001)\)</span> because this is sometimes recommend as an objective prior.</p>
<div class="literal-block-wrapper docutils container" id="poisson-football">
<div class="code-block-caption"><span class="caption-number">Listing 13 </span><span class="caption-text">poisson_football</span><a class="headerlink" href="#poisson-football" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">model</span><span class="p">:</span>
    <span class="n">μ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Gamma</span><span class="p">(</span><span class="s2">"μ"</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.00001</span><span class="p">)</span>
    <span class="n">score</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Poisson</span><span class="p">(</span><span class="s2">"score"</span><span class="p">,</span> <span class="n">μ</span><span class="p">)</span>
    <span class="n">trace</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample_prior_predictive</span><span class="p">()</span>
</pre></div>
</div>
</div>
<ol class="simple">
<li><p>Generate and plot the prior predictive distribution. How reasonable   it looks to you?</p></li>
<li><p>Use your knowledge of sports in order to refine the prior choice.</p></li>
<li><p>Instead of soccer you now want to model basketball. Could you come with a reasonable prior for that instance? Define the prior in a model and generate a prior predictive distribution to validate your intuition.</p></li>
</ol>
<p>Hint: You can parameterize the Gamma distribution using the rate and   shape parameters as in Code Block   <a class="reference internal" href="#poisson-football"><span class="std std-ref">poisson_football</span></a> or alternatively   using the mean and standard deviation.</p>
<p><strong>2M12.</strong> In Code Block <a class="reference internal" href="chp_01.html#metropolis-hastings"><span class="std std-ref">metropolis_hastings</span></a> from Chapter <a class="reference internal" href="chp_01.html#chap1"><span class="std std-ref">1</span></a>, change the value of <code class="docutils literal notranslate"><span class="pre">can_sd</span></code> and run the Metropolis sampler. Try values like 0.2 and 1.</p>
<ol class="simple">
<li><p>Use ArviZ to compare the sampled values using diagnostics such as   the autocorrelation plot, trace plot and the ESS. Explain the   observed differences.</p></li>
<li><p>Modify Code Block <a class="reference internal" href="chp_01.html#metropolis-hastings"><span class="std std-ref">metropolis_hastings</span></a> so you get more than one   independent chain. Use ArviZ to compute rank plots and <span class="math notranslate nohighlight">\(\hat R\)</span>.</p></li>
</ol>
<p><strong>2M13.</strong> Generate a random sample using <code class="docutils literal notranslate"><span class="pre">np.random.binomial(n=1,</span> <span class="pre">p=0.5,</span> <span class="pre">size=200)</span></code> and fit it using a Beta-Binomial model.</p>
<p>Use <code class="docutils literal notranslate"><span class="pre">pm.sample(.,</span> <span class="pre">step=pm.Metropolis())</span></code> (Metropolis-Hastings sampler) and <code class="docutils literal notranslate"><span class="pre">pm.sample(.)</span></code> (the standard sampler). Compare the results in terms of the ESS, <span class="math notranslate nohighlight">\(\hat R\)</span>, autocorrelation, trace plots and rank plots.</p>
<p>Reading the PyMC3 logging statements what sampler is autoassigned? What is your conclusion about this sampler performance compared to Metropolis-Hastings?</p>
<p><strong>2M14.</strong> Generate your own example of a synthetic posterior with convergence issues, let us call it <code class="docutils literal notranslate"><span class="pre">bad_chains3</span></code>.</p>
<ol class="simple">
<li><p>Explain why the synthetic posterior you generated is “bad”. What   about it would we not want to see in an actual modeling scenario?</p></li>
<li><p>Run the same diagnostics we run in the book for <code class="docutils literal notranslate"><span class="pre">bad_chains0</span></code> and   <code class="docutils literal notranslate"><span class="pre">bad_chains1</span></code>. Compare your results with those in the book and   explain the differences and similarities.</p></li>
<li><p>Did the results of the diagnostics from the previous point made you   reconsider why <code class="docutils literal notranslate"><span class="pre">bad_chains3</span></code> is a “bad chain”?</p></li>
</ol>
<p><strong>2H15.</strong> Generate a random sample using <code class="docutils literal notranslate"><span class="pre">np.random.binomial(n=1,</span> <span class="pre">p=0.5,</span> <span class="pre">size=200)</span></code> and fit it using a Beta-Binomial model.</p>
<ol class="simple">
<li><p>Check that LOO-PIT is approximately Uniform.</p></li>
<li><p>Tweak the prior to make the model a bad fit and get a LOO-PIT that   is low for values closer to zero and high for values closer to one.</p></li>
</ol>
<p>Justify your prior choice.</p>
<ol class="simple">
<li><p>Tweak the prior to make the model a bad fit and get a LOO-PIT that   is high for values closer to zero and low for values closer to one.</p></li>
</ol>
<p>Justify your prior choice.</p>
<ol class="simple">
<li><p>Tweak the prior to make the model a bad fit and get a LOO-PIT that   is high for values close to 0.5 and low for values closer to zero   and one. Could you do it? Explain why.</p></li>
</ol>
<p><strong>2H16.</strong> Use PyMC3 to write a model with Normal likelihood. Use the following random samples as data and the following priors for the mean. Fix the standard deviation parameter in the likelihood at 1.</p>
<ol class="simple">
<li><p>A random sample of size 200 from a <span class="math notranslate nohighlight">\(\mathcal{N}(0,1)\)</span> and prior   distribution <span class="math notranslate nohighlight">\(\mathcal{N}(0,20)\)</span></p></li>
<li><p>A random sample of size 2 from a <span class="math notranslate nohighlight">\(\mathcal{N}(0,1)\)</span> and prior   distribution <span class="math notranslate nohighlight">\(\mathcal{N}(0,20)\)</span></p></li>
<li><p>A random sample of size 200 from a <span class="math notranslate nohighlight">\(\mathcal{N}(0,1)\)</span> and prior   distribution <span class="math notranslate nohighlight">\(\mathcal{N}(20 1)\)</span></p></li>
<li><p>A random sample of size 200 from a <span class="math notranslate nohighlight">\(\mathcal{U}(0,1)\)</span> and prior   distribution <span class="math notranslate nohighlight">\(\mathcal{N}(10, 20)\)</span></p></li>
<li><p>A random sample of size 200 from a <span class="math notranslate nohighlight">\(\mathcal{HN}(0,1)\)</span> and a prior   distribution <span class="math notranslate nohighlight">\(\mathcal{N}(10,20)\)</span></p></li>
</ol>
<p>Assess convergence by running the same diagnostics we run in the book for <code class="docutils literal notranslate"><span class="pre">bad_chains0</span></code> and <code class="docutils literal notranslate"><span class="pre">bad_chains1</span></code>. Compare your results with those in the book and explain the differences and similarities.</p>
<p><strong>2H17.</strong> Each of the four sections in this chapter, prior predictive checks, posterior predictive checks, numerical inference diagnostics, and model comparison, detail a specific step in the Bayesian workflow. In your own words explain what the purpose of each step is, and conversely what is lacking if the step is omitted. What does each tell us about our statistical models?</p>
<hr class="footnotes docutils"/>
<dl class="footnote brackets">
<dt class="label" id="id57"><span class="brackets"><a class="fn-backref" href="#id2">1</a></span></dt>
<dd><p><a class="reference external" href="https://www.countbayesie.com/blog/2015/2/18/bayes-theorem-with-lego">https://www.countbayesie.com/blog/2015/2/18/bayes-theorem-with-lego</a></p>
</dd>
<dt class="label" id="id58"><span class="brackets"><a class="fn-backref" href="#id4">2</a></span></dt>
<dd><p>We are omitting tasks related to obtaining the data in the first   place, but experimental design can be as critical if not more than   other aspects in the statistical analysis, see Chapter   <a class="reference internal" href="chp_10.html#chap10"><span class="std std-ref">9</span></a>.</p>
</dd>
<dt class="label" id="id59"><span class="brackets"><a class="fn-backref" href="#id8">3</a></span></dt>
<dd><p><a class="reference external" href="https://arviz-devs.github.io/arviz/">https://arviz-devs.github.io/arviz/</a></p>
</dd>
<dt class="label" id="id60"><span class="brackets"><a class="fn-backref" href="#id10">4</a></span></dt>
<dd><p>This example has been adapted from   <a class="reference external" href="https://mc-stan.org/users/documentation/case-studies/golf.html">https://mc-stan.org/users/documentation/case-studies/golf.html</a> and   <a class="reference external" href="https://docs.pymc.io/notebooks/putting_workflow.html">https://docs.pymc.io/notebooks/putting_workflow.html</a></p>
</dd>
<dt class="label" id="id61"><span class="brackets"><a class="fn-backref" href="#id11">5</a></span></dt>
<dd><p>The example has been adapted from <span id="id62">[<a class="reference internal" href="references.html#id78">17</a>]</span>.</p>
</dd>
<dt class="label" id="id63"><span class="brackets"><a class="fn-backref" href="#id12">6</a></span></dt>
<dd><p>See Chapter <a class="reference internal" href="chp_03.html#chap2"><span class="std std-ref">3</span></a> for details of the logistic   regression model.</p>
</dd>
<dt class="label" id="id64"><span class="brackets"><a class="fn-backref" href="#id16">7</a></span></dt>
<dd><p>Posterior predictive checks are a very general idea. These figures   do not try to show the only available choices, just some of the   options offered by ArviZ.</p>
</dd>
<dt class="label" id="id65"><span class="brackets"><a class="fn-backref" href="#id17">8</a></span></dt>
<dd><p>Unless you realize you need to collect data again, but that is   another story.</p>
</dd>
<dt class="label" id="id66"><span class="brackets"><a class="fn-backref" href="#id20">9</a></span></dt>
<dd><p>Try <a class="reference external" href="https://www.timeanddate.com/sun/ecuador/quito">https://www.timeanddate.com/sun/ecuador/quito</a></p>
</dd>
<dt class="label" id="id67"><span class="brackets"><a class="fn-backref" href="#id26">10</a></span></dt>
<dd><p>Do not confuse with the standard deviation of the MCSE for the   mean.</p>
</dd>
<dt class="label" id="id68"><span class="brackets"><a class="fn-backref" href="#id32">11</a></span></dt>
<dd><p>Most useful and commonly used sampling methods for Bayesian   inference are variants of HMC, including for example, the default   method for continuous variables in PyMC3. For more details of this   method, see Section <a class="reference internal" href="chp_11.html#hmc"><span class="std std-ref">汉密尔顿蒙特卡洛采样器（ HMC ）</span></a>).</p>
</dd>
<dt class="label" id="id69"><span class="brackets"><a class="fn-backref" href="#id34">12</a></span></dt>
<dd><p>A function which is zero everywhere and infinite at zero.</p>
</dd>
<dt class="label" id="id70"><span class="brackets"><a class="fn-backref" href="#id36">13</a></span></dt>
<dd><p>For a sampler like Sequential Monte Carlo, increasing the number   of draws also increases the number of particles, and thus it could   actually provide better convergence. See Section <a class="reference internal" href="chp_11.html#smc-details"><span class="std std-ref">序贯蒙塔卡洛采样器</span></a>.</p>
</dd>
<dt class="label" id="id71"><span class="brackets"><a class="fn-backref" href="#id39">14</a></span></dt>
<dd><p>Strictly speaking we should use probabilities for discrete   models, but that distinction rapidly becomes annoying in practice.</p>
</dd>
<dt class="label" id="id72"><span class="brackets"><a class="fn-backref" href="#id40">15</a></span></dt>
<dd><p>In non-Bayesians contexts <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span> is a point   estimate obtained, for example, by maximizing the likelihood.</p>
</dd>
<dt class="label" id="id73"><span class="brackets"><a class="fn-backref" href="#id42">16</a></span></dt>
<dd><p>We are also computing samples from the posterior predictive   distribution to use them to compute LOO-PIT.</p>
</dd>
<dt class="label" id="id74"><span class="brackets"><a class="fn-backref" href="#id47">17</a></span></dt>
<dd><p>At time of writing this book the method has not been yet   implemented in ArviZ, but it may be already available by the time   you are reading this.</p>
</dd>
<dt class="label" id="id75"><span class="brackets"><a class="fn-backref" href="#id49">18</a></span></dt>
<dd><p>See the case study   <a class="reference external" href="https://avehtari.github.io/modelselection/roaches.html">https://avehtari.github.io/modelselection/roaches.html</a> for an   example.</p>
</dd>
<dt class="label" id="id76"><span class="brackets"><a class="fn-backref" href="#id52">20</a></span></dt>
<dd><p>The Akaike information criterion (AIC) is an estimator of the   generalization error, it is commonly used in frequentists   statistics, but their assumptions are generally not adequate enough   for general use with Bayesians models.</p>
</dd>
<dt class="label" id="id77"><span class="brackets"><a class="fn-backref" href="#id53">21</a></span></dt>
<dd><p>This formula also works for WAIC [^22] and other information   criteria</p>
</dd>
</dl>
</div>
</div>
<script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./zh_CN"
        },
        predefinedOutput: true
    }
    </script>
<script>kernelName = 'python3'</script>
</div>
<!-- Previous / next buttons -->
<div class="prev-next-area">
<a class="left-prev" href="chp_01.html" id="prev-link" title="previous page">
<i class="fas fa-angle-left"></i>
<div class="prev-next-info">
<p class="prev-next-subtitle">previous</p>
<p class="prev-next-title">第一章: 贝叶斯推断</p>
</div>
</a>
<a class="right-next" href="chp_03.html" id="next-link" title="next page">
<div class="prev-next-info">
<p class="prev-next-subtitle">next</p>
<p class="prev-next-title">第三章：线性模型与概率编程语言</p>
</div>
<i class="fas fa-angle-right"></i>
</a>
</div>
</div>
</div>
<footer class="footer">
<p>
    
      By Martin, Kumar, Lao<br/>
    
        © Copyright 2021.<br/>
</p>
</footer>
</main>
</div>
</div>
<script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>
</body>
</html>