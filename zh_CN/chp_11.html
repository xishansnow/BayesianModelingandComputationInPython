
<!DOCTYPE html>

<html>
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>第十一章: 附加主题 — Bayesian Modeling and Computation in Python</title>
<link href="../_static/css/theme.css" rel="stylesheet"/>
<link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet"/>
<link href="../_static/vendor/fontawesome/5.13.0/css/all.min.css" rel="stylesheet"/>
<link as="font" crossorigin="" href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2" rel="preload" type="font/woff2"/>
<link href="../_static/pygments.css" rel="stylesheet" type="text/css">
<link href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" rel="stylesheet" type="text/css">
<link href="../_static/togglebutton.css" rel="stylesheet" type="text/css">
<link href="../_static/copybutton.css" rel="stylesheet" type="text/css">
<link href="../_static/mystnb.css" rel="stylesheet" type="text/css">
<link href="../_static/sphinx-thebe.css" rel="stylesheet" type="text/css"/>
<link href="../_static/sphinx-codeautolink.css" rel="stylesheet" type="text/css"/>
<link href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" rel="stylesheet" type="text/css"/>
<link href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" rel="stylesheet" type="text/css"/>
<link as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js" rel="preload"/>
<script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
<script src="../_static/jquery.js"></script>
<script src="../_static/underscore.js"></script>
<script src="../_static/doctools.js"></script>
<script src="../_static/togglebutton.js"></script>
<script src="../_static/clipboard.min.js"></script>
<script src="../_static/copybutton.js"></script>
<script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
<script src="../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
<script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
<script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
<script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
<script async="async" src="../_static/sphinx-thebe.js"></script>
<link href="../_static/favicon.ico" rel="shortcut icon">
<link href="../genindex.html" rel="index" title="Index"/>
<link href="../search.html" rel="search" title="Search"/>
<link href="glossary.html" rel="next" title="词汇表"/>
<link href="chp_10.html" rel="prev" title="第十章: 概率编程语言"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="None" name="docsearch:language"/>
<!-- Google Analytics -->
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-702QMHG8ST"></script>
<script>
                    window.dataLayer = window.dataLayer || [];
                    function gtag(){ dataLayer.push(arguments); }
                    gtag('js', new Date());
                    gtag('config', 'G-702QMHG8ST');
                </script>
</link></link></link></link></link></link></head>
<body data-offset="80" data-spy="scroll" data-target="#bd-toc-nav">
<div class="container-fluid" id="banner"></div>
<div class="container-xl">
<div class="row">
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
<div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
<h1 class="site-logo" id="site-title">Bayesian Modeling and Computation in Python</h1>
</a>
</div><form action="../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="icon fas fa-search"></i>
<input aria-label="Search this book..." autocomplete="off" class="form-control" id="search-input" name="q" placeholder="Search this book..." type="search"/>
</form><nav aria-label="Main" class="bd-links" id="bd-docs-nav">
<div class="bd-toc-item active">
<ul class="current nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="dedication.html">
   贡献
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="foreword.html">
   序言
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="preface.html">
   前言
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="symbollist.html">
   符号表
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chp_01.html">
   第一章: 贝叶斯推断
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chp_02.html">
   第二章: 贝叶斯模型的探索性分析
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chp_03.html">
   第三章：线性模型与概率编程语言
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chp_04.html">
   第四章：扩展线性模型
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chp_05.html">
   第五章: 样条
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chp_06.html">
   第六章: 时间序列
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chp_07.html">
   第七章：贝叶斯加性回归树
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chp_08.html">
   第八章：近似贝叶斯计算
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chp_09.html">
   第九章: 端到端的贝叶斯工作流
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chp_10.html">
   第十章: 概率编程语言
  </a>
</li>
<li class="toctree-l1 current active">
<a class="current reference internal" href="#">
   第十一章: 附加主题
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="glossary.html">
   词汇表
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="references.html">
   References
  </a>
</li>
</ul>
</div>
</nav> <!-- To handle the deprecated key -->
<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>
</div>
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
<div class="topbar container-xl fixed-top">
<div class="topbar-contents row">
<div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
<div class="col pl-md-4 topbar-main">
<button aria-controls="site-navigation" aria-expanded="true" aria-label="Toggle navigation" class="navbar-toggler ml-0" data-placement="left" data-target=".site-navigation" data-toggle="tooltip" id="navbar-toggler" title="Toggle navigation" type="button">
<i class="fas fa-bars"></i>
<i class="fas fa-arrow-left"></i>
<i class="fas fa-arrow-up"></i>
</button>
<!-- Source interaction buttons -->
<div class="dropdown-buttons-trigger">
<button aria-label="Connect with source repository" class="btn btn-secondary topbarbtn" id="dropdown-buttons-trigger"><i class="fab fa-github"></i></button>
<div class="dropdown-buttons sourcebuttons">
<a class="repository-button" href="https://github.com/BayesianModelingandComputationInPython/BookCode_Edition1"><button class="btn btn-secondary topbarbtn" data-placement="left" data-toggle="tooltip" title="Source repository" type="button"><i class="fab fa-github"></i>repository</button></a>
<a class="issues-button" href="https://github.com/BayesianModelingandComputationInPython/BookCode_Edition1/issues/new?title=Issue%20on%20page%20%2Fzh_CN/chp_11.html&amp;body=Your%20issue%20content%20here."><button class="btn btn-secondary topbarbtn" data-placement="left" data-toggle="tooltip" title="Open an issue" type="button"><i class="fas fa-lightbulb"></i>open issue</button></a>
</div>
</div>
<!-- Full screen (wrap in <a> to have style consistency -->
<a class="full-screen-button"><button aria-label="Fullscreen mode" class="btn btn-secondary topbarbtn" data-placement="bottom" data-toggle="tooltip" onclick="toggleFullScreen()" title="Fullscreen mode" type="button"><i class="fas fa-expand"></i></button></a>
<!-- Launch buttons -->
</div>
<!-- Table of contents -->
<div class="d-none d-md-block col-md-2 bd-toc show noprint">
<div class="tocsection onthispage pt-5 pb-3">
<i class="fas fa-list"></i> Contents
            </div>
<nav aria-label="Page" id="bd-toc-nav">
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#probability-background">
   11.1 概率背景
  </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#probability">
     11.1.1 概率
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#conditional-probability">
     11.1.2 条件概率
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#probability-distribution">
     11.1.3 概率分布
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#discrete-random-variables-and-distributions">
     11.1.4 离散型随机变量及其分布
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#discrete-uniform-distribution">
       ( 1 ) 离散型均匀分布
      </a>
</li>
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#binomial-distribution">
       ( 2 ) 二项分布
      </a>
</li>
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#poisson-distribution">
       ( 3 ) 泊松分布
      </a>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#cont-rvs">
     11.1.5 连续型随机变量及其分布
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#continuous-uniform-distribution">
       ( 1 ) 连续型均匀分布
      </a>
</li>
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#gaussian-or-normal-distribution">
       ( 2 ) 高斯（正态）分布
      </a>
</li>
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#t">
       ( 3 ) 学生
       <span class="math notranslate nohighlight">
        \(t\)
       </span>
       分布
      </a>
</li>
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#beta-distribution">
       ( 4 ) 贝塔分布
      </a>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#joint-conditional-and-marginal-distributions">
     11.1.6 联合分布、条件分布和边缘分布
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#pit">
     11.1.7 概率积分变换 (PIT)
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#expectations">
     11.1.8 期望
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#transformations">
     11.1.9 变换
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#limits">
     11.1.10 极限
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#the-law-of-large-numbers">
       ( 1 ) 大数定律
      </a>
</li>
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#appendix-clt">
       ( 2 ) 中心极限定律
      </a>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#markov-chains">
     11.1.11 马尔可夫链
    </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#entropy">
   11.2 熵
  </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#kl">
   11.3 KL 散度
  </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#information-criterion">
   11.4 信息准则
  </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#loo-depth">
   11.5 深入理解留一交叉验证法
  </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#jeffreys">
   11.6 Jeffreys 先验的推导
  </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#theta-jeffreys">
     11.6.1 依据
     <span class="math notranslate nohighlight">
      \(\theta\)
     </span>
     的二项似然 Jeffreys 先验
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#kappa-jeffreys">
     11.6.2 依据
     <span class="math notranslate nohighlight">
      \(\kappa\)
     </span>
     的二项似然 Jeffreys 先验
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#jeffreys-posterior-for-the-binomial-likelihood">
     11.6.3 二项似然的 Jeffreys 后验
    </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#marginal-likelihood">
   11.7
   <code class="docutils literal notranslate">
<span class="pre">
     边缘似然
    </span>
</code>
</a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#harmonic-mean">
     11.7.1 调和平均估计器
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#bayes-factors">
     11.7.2
     <code class="docutils literal notranslate">
<span class="pre">
       边缘似然
      </span>
</code>
     与模型比较
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#waic-loo">
     11.7.3 贝叶斯因子与
     <code class="docutils literal notranslate">
<span class="pre">
       WAIC
      </span>
</code>
     和
     <code class="docutils literal notranslate">
<span class="pre">
       LOO
      </span>
</code>
</a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#high-dimensions">
   11.8 走出平地
  </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#inference-methods">
   11.9 推断方法
  </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#grid-method">
     11.9.1 网格方法
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#metropolis-hastings">
     11.9.2 Metropolis-Hastings 采样器
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#hmc">
     11.9.3 汉密尔顿蒙特卡洛采样器（ HMC ）
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#smc-details">
     11.9.4 序贯蒙塔卡洛采样器
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#vi-details">
     11.9.5 变分推断
    </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#programming-ref">
   11.10 编程参考
  </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#which-programming-language">
     11.10.1 哪种编程语言 ?
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#version-control">
     11.10.2 版本控制
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#dependency-management-and-package-repositories">
     11.10.3 依赖管理和包仓库
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#environment-management">
     11.10.4 环境管理
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#vs-vs-notebook">
     11.10.5 文本编辑器 vs 集成开发环境 vs Notebook
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#the-specific-tools-used-for-this-book">
     11.10.6 本书用到的特定工具
    </a>
</li>
</ul>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="row" id="main-content">
<div class="col-12 col-md-9 pl-md-3 pr-md-0">
<!-- Table of contents that is only displayed when printing the page -->
<div class="onlyprint" id="jb-print-docs-body">
<h1>第十一章: 附加主题</h1>
<!-- Table of contents -->
<div id="print-main-content">
<div id="jb-print-toc">
<div>
<h2> Contents </h2>
</div>
<nav aria-label="Page">
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#probability-background">
   11.1 概率背景
  </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#probability">
     11.1.1 概率
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#conditional-probability">
     11.1.2 条件概率
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#probability-distribution">
     11.1.3 概率分布
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#discrete-random-variables-and-distributions">
     11.1.4 离散型随机变量及其分布
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#discrete-uniform-distribution">
       ( 1 ) 离散型均匀分布
      </a>
</li>
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#binomial-distribution">
       ( 2 ) 二项分布
      </a>
</li>
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#poisson-distribution">
       ( 3 ) 泊松分布
      </a>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#cont-rvs">
     11.1.5 连续型随机变量及其分布
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#continuous-uniform-distribution">
       ( 1 ) 连续型均匀分布
      </a>
</li>
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#gaussian-or-normal-distribution">
       ( 2 ) 高斯（正态）分布
      </a>
</li>
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#t">
       ( 3 ) 学生
       <span class="math notranslate nohighlight">
        \(t\)
       </span>
       分布
      </a>
</li>
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#beta-distribution">
       ( 4 ) 贝塔分布
      </a>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#joint-conditional-and-marginal-distributions">
     11.1.6 联合分布、条件分布和边缘分布
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#pit">
     11.1.7 概率积分变换 (PIT)
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#expectations">
     11.1.8 期望
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#transformations">
     11.1.9 变换
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#limits">
     11.1.10 极限
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#the-law-of-large-numbers">
       ( 1 ) 大数定律
      </a>
</li>
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#appendix-clt">
       ( 2 ) 中心极限定律
      </a>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#markov-chains">
     11.1.11 马尔可夫链
    </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#entropy">
   11.2 熵
  </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#kl">
   11.3 KL 散度
  </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#information-criterion">
   11.4 信息准则
  </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#loo-depth">
   11.5 深入理解留一交叉验证法
  </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#jeffreys">
   11.6 Jeffreys 先验的推导
  </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#theta-jeffreys">
     11.6.1 依据
     <span class="math notranslate nohighlight">
      \(\theta\)
     </span>
     的二项似然 Jeffreys 先验
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#kappa-jeffreys">
     11.6.2 依据
     <span class="math notranslate nohighlight">
      \(\kappa\)
     </span>
     的二项似然 Jeffreys 先验
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#jeffreys-posterior-for-the-binomial-likelihood">
     11.6.3 二项似然的 Jeffreys 后验
    </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#marginal-likelihood">
   11.7
   <code class="docutils literal notranslate">
<span class="pre">
     边缘似然
    </span>
</code>
</a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#harmonic-mean">
     11.7.1 调和平均估计器
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#bayes-factors">
     11.7.2
     <code class="docutils literal notranslate">
<span class="pre">
       边缘似然
      </span>
</code>
     与模型比较
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#waic-loo">
     11.7.3 贝叶斯因子与
     <code class="docutils literal notranslate">
<span class="pre">
       WAIC
      </span>
</code>
     和
     <code class="docutils literal notranslate">
<span class="pre">
       LOO
      </span>
</code>
</a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#high-dimensions">
   11.8 走出平地
  </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#inference-methods">
   11.9 推断方法
  </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#grid-method">
     11.9.1 网格方法
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#metropolis-hastings">
     11.9.2 Metropolis-Hastings 采样器
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#hmc">
     11.9.3 汉密尔顿蒙特卡洛采样器（ HMC ）
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#smc-details">
     11.9.4 序贯蒙塔卡洛采样器
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#vi-details">
     11.9.5 变分推断
    </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#programming-ref">
   11.10 编程参考
  </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#which-programming-language">
     11.10.1 哪种编程语言 ?
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#version-control">
     11.10.2 版本控制
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#dependency-management-and-package-repositories">
     11.10.3 依赖管理和包仓库
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#environment-management">
     11.10.4 环境管理
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#vs-vs-notebook">
     11.10.5 文本编辑器 vs 集成开发环境 vs Notebook
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#the-specific-tools-used-for-this-book">
     11.10.6 本书用到的特定工具
    </a>
</li>
</ul>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div>
<div class="tex2jax_ignore mathjax_ignore section" id="app">
<span id="id1"></span><h1>第十一章: 附加主题<a class="headerlink" href="#app" title="Permalink to this headline">¶</a></h1>
<style>p{text-indent:2em;2}</style>
<p>本章与其他章节不同，它不是关于任何特定主题的。相反，它是不同主题的集合，通过补充其他章节中讨论的主题，为本书的其余部分提供支撑。这些主题适用于有兴趣深入了解每种理论和方法的读者。就写作风格而言，本章将比其他章节更具理论性和抽象性。</p>
<div class="section" id="probability-background">
<span id="id2"></span><h2>11.1 概率背景<a class="headerlink" href="#probability-background" title="Permalink to this headline">¶</a></h2>
<p>西班牙语单词 <code class="docutils literal notranslate"><span class="pre">azahar</span></code> 和 <code class="docutils literal notranslate"><span class="pre">azar</span></code> 含义不同并非纯属运气，因为它们都来自于阿拉伯语 <a class="footnote-reference brackets" href="#id104" id="id3">1</a>。从远古时代开始至今，一些机会游戏会使用具有两个面的骨头，这种骨头类似于硬币或双面骰子。为了更容易区分一侧和另一侧，其中至少一侧有明显的标记，古代阿拉伯人常用一朵花做标记。随着时间推移，西班牙语逐步采用了 <code class="docutils literal notranslate"><span class="pre">azahar</span></code> 一词来表示某些花，而用 <code class="docutils literal notranslate"><span class="pre">azar</span></code> 表示随机性。</p>
<p>概率论发展的动机之一可以追溯到理解机会游戏，并试图在此过程中发点小财。因此，让我们简要从六面骰子（ Die With Six Faces ）开始，介绍概率论中一些核心概念<a class="footnote-reference brackets" href="#id105" id="id4">2</a>。每次掷骰子时，只能获得一个从 <span class="math notranslate nohighlight">\(1\)</span> 到 <span class="math notranslate nohighlight">\(6\)</span> 的整数，而且他们之间相互没有依从喜好。使用 Python，可以通过以下方式编写这样的骰子游戏：</p>
<div class="literal-block-wrapper docutils container" id="die">
<div class="code-block-caption"><span class="caption-number">Listing 161 </span><span class="caption-text">die</span><a class="headerlink" href="#die" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">die</span><span class="p">():</span>
    <span class="n">outcomes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]</span>
    <span class="k">return</span> <a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/random/generated/numpy.random.choice.html#numpy.random.choice" title="numpy.random.choice"><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span></a><span class="p">(</span><span class="n">outcomes</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>假设我们怀疑骰子有偏差，如何才能评估这种可能性？回答此问题的科学方法是收集并分析数据。使用 Python，我们可以模拟代码 <a class="reference internal" href="#experiment"><span class="std std-ref">experiment</span></a> 中的数据收集过程。</p>
<div class="literal-block-wrapper docutils container" id="experiment">
<div class="code-block-caption"><span class="caption-number">Listing 162 </span><span class="caption-text">实验</span><a class="headerlink" href="#experiment" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">experiment</span><span class="p">(</span><span class="n">N</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">sample</span> <span class="o">=</span> <span class="p">[</span><span class="n">die</span><span class="p">()</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">)]</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">7</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">sample</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="o">/</span><span class="n">N</span><span class="si">:</span><span class="s2">.2g</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="n">experiment</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>1: 0
2: 0.1
3: 0.4
4: 0.1
5: 0.4
6: 0
</pre></div>
</div>
<p>第一列中的数字是可能的结果。第二列对应于每个数字出现的频率。频率是每个可能结果出现的次数除以掷骰子的总次数（即 “N” ）。</p>
<p>在这个例子中至少有两点需要注意。</p>
<p>首先如果执行 <code class="docutils literal notranslate"><span class="pre">experiment()</span></code> 几次，我们每次都会得到不同的结果。这正是在机会游戏中使用骰子的原因，每次掷骰子都会得到一个我们无法预测的数字。</p>
<p>其次，即使多次掷同一个骰子，预测每个结果的能力也并没有提高。</p>
<p>尽管如此，数据收集和分析还是可以帮助我们估计结果的频率列表 ，事实上，随着 “N” 值的增加，这种能力会有所提高。运行实验 <code class="docutils literal notranslate"><span class="pre">N=10000</span></code> 次，你会看到获得的频率约为 <span class="math notranslate nohighlight">\(0.17\)</span> 。如果骰子上的每个数字有同样的机会，该结果也表明 <span class="math notranslate nohighlight">\(0.17 \approx \frac{1}{6}\)</span> 正是我们所预期的。</p>
<p>上述两点观测不仅限于骰子和机会游戏。</p>
<p>如果每天称体重，我们会得到不同的值，因为体重与吃的食物量、喝的水、上厕所的次数、秤的精度、穿的衣服和许多其他因素有关。因此，单次测量可能无法代表我们的体重，但重要的是，数据测量和/或收集伴随着不确定性。</p>
<p>统计学基本上是关于如何处理实际问题中的不确定性的领域，概率论是统计学的理论支柱之一。概率论帮助我们将讨论的内容形式化，就像刚刚讨论的那样，并将其扩展到骰子之外。这样我们就可以更好地提出和解答与预期结果相关的问题，例如当增加实验次数时会发生什么？什么事件比另一个事件更有机会？</p>
<div class="section" id="probability">
<span id="id5"></span><h3>11.1.1 概率<a class="headerlink" href="#probability" title="Permalink to this headline">¶</a></h3>
<p>概率是一种允许我们量化不确定性的理论数学工具。像其他数学对象和理论一样，它们完全可以从纯数学角度来证明。然而，从实践角度来看，我们可以证明概率是通过进行实验、收集观测数据甚至在进行计算模拟时自然产生的。为简单起见，我们将讨论实验，因为我们在非常广泛的意义上在使用该术语。</p>
<p>我们可以用数学集合来思考概率。 <strong>样本空间</strong> <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> 是来自<strong>实验</strong>的所有可能事件的集合。 <strong>事件</strong> <span class="math notranslate nohighlight">\(A\)</span> 是 <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> 的子集。在我们进行实验时，称 <span class="math notranslate nohighlight">\(A\)</span> 事件发生，并得到集合 <span class="math notranslate nohighlight">\(A\)</span> 作为结果。对于典型的六面骰子，可以写为：</p>
<div class="math notranslate nohighlight" id="equation-eq-sample-space-dice">
<span class="eqno">(85)<a class="headerlink" href="#equation-eq-sample-space-dice" title="Permalink to this equation">¶</a></span>\[\mathcal{X} = \{1, 2, 3, 4, 5, 6\}
  \]</div>
<p>我们可以将事件 <span class="math notranslate nohighlight">\(A\)</span> 定义为 <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> 的任何子集，例如，得到偶数 <span class="math notranslate nohighlight">\(A = \{2, 4, 6\}\)</span>。我们将概率与事件联系起来，如果想表示事件 <span class="math notranslate nohighlight">\(A\)</span> 的概率，可以写成 <span class="math notranslate nohighlight">\(P(A=\{2, 4, 6\})\)</span> 或更简洁的 <span class="math notranslate nohighlight">\(P(A)\)</span> 。概率函数 <span class="math notranslate nohighlight">\(P\)</span> 将事件 <span class="math notranslate nohighlight">\(A\)</span> 作为输入并返回 <span class="math notranslate nohighlight">\(P(A)\)</span> 。概率 <span class="math notranslate nohighlight">\(P(A)\)</span> 可以取区间 <span class="math notranslate nohighlight">\([0,1]\)</span> 中的任何数字。如果事件从未发生，则该事件的概率为 <span class="math notranslate nohighlight">\(0\)</span>，例如 <span class="math notranslate nohighlight">\(P(A=-1)=0\)</span> ；如果事件总是发生，则概率为 <span class="math notranslate nohighlight">\(1\)</span> ，例如 <span class="math notranslate nohighlight">\(P(A=\{1, 2,3,4,5,6\})=1\)</span> 。如果事件不能一起发生，我们就称事件是互斥的，例如，如果事件 <span class="math notranslate nohighlight">\(A_1​​\)</span> 代表奇数， <span class="math notranslate nohighlight">\(A_2\)</span> 代表偶数数字，那么掷骰子同时得到 <span class="math notranslate nohighlight">\(A_1​​\)</span> 和 <span class="math notranslate nohighlight">\(A_2\)</span> 的概率为 <span class="math notranslate nohighlight">\(0\)</span> 。如果事件 <span class="math notranslate nohighlight">\(A_1, A_2, \cdots A_n\)</span> 是互斥的，意味着这些事件不能同时发生，那么 <span class="math notranslate nohighlight">\(\sum_i^n P(A_i) = 1\)</span> 。继续 <span class="math notranslate nohighlight">\(A_1​​\)</span> 表示奇数、 <span class="math notranslate nohighlight">\(A_2\)</span> 表示偶数的示例，掷骰子的结果为 <span class="math notranslate nohighlight">\(A_1​​\)</span> 或 <span class="math notranslate nohighlight">\(A_2\)</span> 的概率为 <span class="math notranslate nohighlight">\(1\)</span> 。满足此性质的任何函数都是有效的概率函数。我们可以将概率视为分配给可能事件的正守恒量 <a class="footnote-reference brackets" href="#id107" id="id6">3</a> 。</p>
<p>正如刚刚看到的，概率有一个明确的数学定义。如何解释概率有着不同的故事，也有着不同的思想流派。作为贝叶斯主义者，我们倾向于将概率解释为不确定性的程度。例如，对于一个公平的骰子，掷骰子时得到奇数的概率是 <span class="math notranslate nohighlight">\(50\%\)</span> ，这意味着我们有一半把握会得到一个奇数。或者可以将这个数字解释为，如果无限次掷骰子，有一半的时间会得到奇数，一半的时间会得到偶数，而这是频率主义者的解释。如果你不想无限次掷骰子，也可以多次掷骰子，然后获得大约一半的几率。这实际上就是在代码 <a class="reference internal" href="#experiment"><span class="std std-ref">experiment</span></a> 中做的。最后，我们注意到对于公平骰子，期望得到任何单个数字的概率为 <span class="math notranslate nohighlight">\(\frac{1}{6}\)</span>，但对于非公平骰子，此概率可能有所不同，而等概率结果只是一个特例。</p>
<p>如果概率反映了不确定性，那么提出 “火星的质量是 <span class="math notranslate nohighlight">\(6.39 \times 10^{23}\)</span> 公斤的概率是多少？”，或者“赫尔辛基 <span class="math notranslate nohighlight">\(5\)</span> 月 <span class="math notranslate nohighlight">\(1\)</span> 日下雨的概率是多少？”，或者“未来三年资本主义被其他社会经济制度取代的概率是多少？” 等问题，都是非常自然的。我们说概率的定义是认知层面的，因为它不是一个关于真实世界的属性，而是一个关于我们对世界认知的属性。我们收集并分析数据，因为我们认为根据外部信息，我们能够更新内心里的知识状态。</p>
<p>我们注意到现实世界中可能发生的事情取决于实验的所有细节，包括我们无法控制或不知道的那些。而样本空间是我们隐式或显式定义的数学对象。例如，通过将骰子的样本空间定义为方程 <a class="reference internal" href="#equation-eq-sample-space-dice">(85)</a>，我们排除了骰子落在边缘的可能性，虽然这实际上在非平面中滚动骰子时有可能发生。</p>
<p>我们必须意识到：包含所有数学概念的柏拉图思想世界与现实世界是不同的，在统计建模时，我们需要不断在这两个世界之间来回切换。</p>
</div>
<div class="section" id="conditional-probability">
<span id="id7"></span><h3>11.1.2 条件概率<a class="headerlink" href="#conditional-probability" title="Permalink to this headline">¶</a></h3>
<p>给定两个事件 <span class="math notranslate nohighlight">\(A\)</span> 和 <span class="math notranslate nohighlight">\(B\)</span> 且 <span class="math notranslate nohighlight">\(P(B) &gt; 0\)</span>，给定 <span class="math notranslate nohighlight">\(B\)</span> 时事件 <span class="math notranslate nohighlight">\(A\)</span> 发生的概率，被记为 <span class="math notranslate nohighlight">\(P(A \mid B)\)</span> ，定义为：</p>
<div class="math notranslate nohighlight">
\[P(A \mid B) = \frac{P(A, B)}{P(B)}\]</div>
<p><span class="math notranslate nohighlight">\(P(A, B)\)</span> 是事件 <span class="math notranslate nohighlight">\(A\)</span> 和 <span class="math notranslate nohighlight">\(B\)</span> 同时发生的概率，通常也记为 <span class="math notranslate nohighlight">\(P(A \cap B)\)</span>（ 符号 <span class="math notranslate nohighlight">\(\cap\)</span> 表示集合的交集）， 即事件 <span class="math notranslate nohighlight">\(A\)</span> 和事件 <span class="math notranslate nohighlight">\(B\)</span> 同时发生的概率。</p>
<p><span class="math notranslate nohighlight">\(P(A \mid B)\)</span> 被称为条件概率，它是指在 <span class="math notranslate nohighlight">\(B\)</span> 已经发生的条件下，事件 <span class="math notranslate nohighlight">\(A\)</span> 发生的概率。例如，“人行道潮湿的概率” 与 “在下雨的情况下人行道潮湿的概率” 是完全不同的。</p>
<p>条件概率可以看作是样本空间的缩减或限制。 <a class="reference internal" href="#fig-cond"><span class="std std-numref">Fig. 171</span></a> 展示了从左图的样本空间 <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> 中的事件 <span class="math notranslate nohighlight">\(A\)</span> 和 <span class="math notranslate nohighlight">\(B\)</span> ，到右图中将 <span class="math notranslate nohighlight">\(B\)</span> 作为样本空间而 <span class="math notranslate nohighlight">\(A\)</span> 为其子集。当我们说 <span class="math notranslate nohighlight">\(B\)</span> 已经发生，不一定是在谈论过去发生的事情，它只是 “一旦我们以 <span class="math notranslate nohighlight">\(B\)</span> 为条件” 或 “一旦我们将样本空间限制为与证据 <span class="math notranslate nohighlight">\(B\)</span> 一致” 的通俗说法。</p>
<div class="figure align-default" id="fig-cond">
<a class="reference internal image-reference" href="../_images/cond.png"><img alt="../_images/cond.png" src="../_images/cond.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 171 </span><span class="caption-text">条件化就是重新定义样本空间。左图为样本空间 <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>，每个圆圈代表一个可能的结果。其中有 <span class="math notranslate nohighlight">\(A\)</span> 和 <span class="math notranslate nohighlight">\(B\)</span> 两个事件。右图代表 <span class="math notranslate nohighlight">\(P(A \mid B)\)</span> ，一旦知道 <span class="math notranslate nohighlight">\(B\)</span> ，我们就可以排除所有不在 <span class="math notranslate nohighlight">\(B\)</span>  中的事件。该图改编自《 Introduction to Probability 》 <span id="id8">[<a class="reference internal" href="references.html#id10">5</a>]</span>。</span><a class="headerlink" href="#fig-cond" title="Permalink to this image">¶</a></p>
</div>
<p>条件概率是统计学的核心，是思考如何根据新数据更新我们对事件的知识的核心。所有的概率相对于某些假设或模型都是有条件的。从来不存在不包含上下文语境的概率，即便我们并没有明确地把这个意思表达出来。</p>
</div>
<div class="section" id="probability-distribution">
<span id="id9"></span><h3>11.1.3 概率分布<a class="headerlink" href="#probability-distribution" title="Permalink to this headline">¶</a></h3>
<p>我们可能更感兴趣的是找出骰子上所有数字的<em>概率列表</em>，而不是计算掷骰子时获得数字 5 的概率。一旦计算出这个列表，我们就可以显示它或使用它来计算其他数量，比如得到数字 5 的概率，或者得到等于或大于 5 的数字的概率。这个 <em>list</em> 的正式名称是 <strong>probability分配</strong>。</p>
<p>使用 Code Block <a class="reference internal" href="#experiment"><span class="std std-ref">experiment</span></a> 我们得到了一个骰子的经验概率分布，即从数据中计算出来的分布。但也有理论分布，它们在统计学中很重要，因为它们允许构建概率模型。</p>
<p>理论概率分布具有精确的数学公式，类似于圆具有精确的数学定义。</p>
<p>圆是平面上与另一个称为中心的点等距的点的几何空间。给定参数半径，完美定义了一个圆 <a class="footnote-reference brackets" href="#id109" id="id10">4</a>。我们可以说不存在单个圆周，而是一个圆周族，其中每个成员与其他成员的区别仅在于参数 radius 的值，因为一旦还定义了此参数，则定义了圆周。</p>
<p>类似地，概率分布也出现在家族中，其成员完全由一个或多个参数定义。通常使用希腊字母来编写参数名称，尽管情况并非总是如此。 <a class="reference internal" href="#fig-dice-distribution"><span class="std std-numref">Fig. 172</span></a> 是此类分布系列的一个示例，我们可以用它来表示已加载的骰子。我们可以看到这个概率分布是如何由两个参数 <span class="math notranslate nohighlight">\(\alpha\)</span> 和 <span class="math notranslate nohighlight">\(\beta\)</span> 控制的。如果我们改变分布的<em>形状</em>，我们可以使其平坦或集中在一侧，将大部分质量推向极端，或将质量集中在中间。由于圆周半径被限制为正，分布的参数也有限制，实际上<span class="math notranslate nohighlight">\(\alpha\)</span>和<span class="math notranslate nohighlight">\(\beta\)</span>必须都是正的。</p>
<div class="figure align-default" id="fig-dice-distribution">
<a class="reference internal image-reference" href="../_images/dice_distribution.png"><img alt="../_images/dice_distribution.png" src="../_images/dice_distribution.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 172 </span><span class="caption-text">具有参数 <span class="math notranslate nohighlight">\(\alpha\)</span> 和 <span class="math notranslate nohighlight">\(\beta\)</span> 的离散分布族的四个成员。条形的高度代表每个 <span class="math notranslate nohighlight">\(x\)</span> 值的概率。未绘制的 <span class="math notranslate nohighlight">\(x\)</span> 的值的概率为 0，因为它们不受分布的支持。</span><a class="headerlink" href="#fig-dice-distribution" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="section" id="discrete-random-variables-and-distributions">
<span id="id11"></span><h3>11.1.4 离散型随机变量及其分布<a class="headerlink" href="#discrete-random-variables-and-distributions" title="Permalink to this headline">¶</a></h3>
<p>A random variable is a function that maps the sample space into the real numbers <span class="math notranslate nohighlight">\(\mathbb{R}\)</span>. Continuing with the die example if the events of interest were the number of the die, the mapping is very simple, we associate <span class="math notranslate nohighlight">\(\LARGE \unicode{x2680}\)</span> with the number 1, <span class="math notranslate nohighlight">\(\LARGE \unicode{x2681}\)</span> with 2, etc.</p>
<p>With two dice we could have an <span class="math notranslate nohighlight">\(S\)</span> random variable as the sum of the outcomes of both dice. Thus the domain of the random variable <span class="math notranslate nohighlight">\(S\)</span> is <span class="math notranslate nohighlight">\(\{2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12\}\)</span>, and if both dice are fair then their probability distribution is depicted in <a class="reference internal" href="#fig-sum-dice-distribution"><span class="std std-numref">Fig. 173</span></a>.</p>
<div class="figure align-default" id="fig-sum-dice-distribution">
<a class="reference internal image-reference" href="../_images/sum_dice_distribution.png"><img alt="../_images/sum_dice_distribution.png" src="../_images/sum_dice_distribution.png" style="width: 3.5in;"/></a>
<p class="caption"><span class="caption-number">Fig. 173 </span><span class="caption-text">If the sample space is the set of possible numbers rolled on two dice, and the random variable of interest is the sum <span class="math notranslate nohighlight">\(S\)</span> of the numbers on the two dice, then <span class="math notranslate nohighlight">\(S\)</span> is a discrete random variable whose distribution is described in this figure with the probability of each outcome represented as the height of the columns. This figure has been adapted from <a class="reference external" href="https://commons.wikimedia.org/wiki/File:Dice_Distribution_(bar).svg">https://commons.wikimedia.org/wiki/File:Dice_Distribution_(bar).svg</a></span><a class="headerlink" href="#fig-sum-dice-distribution" title="Permalink to this image">¶</a></p>
</div>
<p>We could also define another random variable <span class="math notranslate nohighlight">\(C\)</span> with sample space <span class="math notranslate nohighlight">\(\{\text{red}, \text{green}, \text{blue}\}\)</span>. We could map the sample space to <span class="math notranslate nohighlight">\(\mathbb{R}\)</span> in the following way:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
C(\text{red})\; = 0 \\
C(\text{green}) = 1 \\
C(\text{blue})\, = 2\end{aligned}\end{split}\]</div>
<p>This encoding is useful, because performing math with numbers is easier than with strings regardless of whether we are using analog computation on “pen and paper” or digital computation with a computer.</p>
<p>As we said a random variable is a function, and given that the mapping between the sample space and <span class="math notranslate nohighlight">\(\mathbb{R}\)</span> is deterministic it is not immediately clear where the randomness in a random variable comes from.</p>
<p>We say a variable is random in the sense that if we perform an experiment, i.e. we <em>ask</em> the variable for a value like we did in Code Block <a class="reference internal" href="#die"><span class="std std-ref">die</span></a> and <a class="reference internal" href="#experiment"><span class="std std-ref">experiment</span></a> we will get a different number each time without the succession of outcomes following a deterministic pattern. For example, if we ask for the value of random variable <span class="math notranslate nohighlight">\(C\)</span> 3 times in a row we may get red, red, blue or maybe blue, green, blue, etc.</p>
<p>A random variable <span class="math notranslate nohighlight">\(X\)</span> is said to be discrete if there is a finite list of values <span class="math notranslate nohighlight">\(a_1, a_2, \dots, a_n\)</span> or an infinite list of values <span class="math notranslate nohighlight">\(a_1, a_2, \dots\)</span> such that the total probability is <span class="math notranslate nohighlight">\(\sum_j P(X=a_j) = 1\)</span>. If <span class="math notranslate nohighlight">\(X\)</span> is a discrete random variable then a finite or countably infinite set of values <span class="math notranslate nohighlight">\(x\)</span> such that <span class="math notranslate nohighlight">\(P(X = x) &gt; 0\)</span> is called the <em>support</em> of <span class="math notranslate nohighlight">\(X\)</span>.</p>
<p>As we said before we can think of a probability distribution as a list associating a probability with each event. Additionally a random variable has a probability distribution associated to it. In the particular case of discrete random variables the probability distribution is also called a Probability Mass Function (PMF). It is important to note that the PMF is a function that returns probabilities.</p>
<p>The PMF of <span class="math notranslate nohighlight">\(X\)</span> is the function <span class="math notranslate nohighlight">\(P(X=x)\)</span> for <span class="math notranslate nohighlight">\(x \in \mathbb{R}\)</span>. For a PMF to be valid, it must be non-negative and sum to 1, i.e. all its values should be non-negative and the sum over all its domain should be 1.</p>
<p>It is important to remark that the term <em>random</em> in random variable does not implies that any value is allowed, only those in the sample space.</p>
<p>For example, we can not get the value orange from <span class="math notranslate nohighlight">\(C\)</span>, nor the value 13 from <span class="math notranslate nohighlight">\(S\)</span>. Another common source of confusion is that the term random implies equal probability, but that is not true, the probability of each event is given by the PMF, for example, we may have <span class="math notranslate nohighlight">\(P(C=\text{red}) = \frac{1}{2}, P(C=\text{green}) = \frac{1}{4}, P(C=\text{blue}) = \frac{1}{4}\)</span>.</p>
<p>The equiprobability is just a special case.</p>
<p>We can also define a discrete random variable using a cumulative distribution function (CDF). The CDF of a random variable <span class="math notranslate nohighlight">\(X\)</span> is the function <span class="math notranslate nohighlight">\(F_X\)</span> given by <span class="math notranslate nohighlight">\(F_X(x) = P(X \le x)\)</span>. For a CDF to be valid, it must be monotonically increasing <a class="footnote-reference brackets" href="#id110" id="id12">5</a>, right-continuous <a class="footnote-reference brackets" href="#id111" id="id13">6</a>, converge to 0 as <span class="math notranslate nohighlight">\(x\)</span> approaches to <span class="math notranslate nohighlight">\(- \infty\)</span>, and converge to 1 as <span class="math notranslate nohighlight">\(x\)</span> approaches <span class="math notranslate nohighlight">\(\infty\)</span>.</p>
<p>In principle, nothing prevents us from defining our own probability distribution. But there are many already defined distributions that are so commonly used, they have their own names. It is a good idea to become familiar with them as they appear quite often. If you check the models defined in this book you will see that most of them use combinations of predefined probability distributions and only a few examples used custom defined distribution. For example, in Section <a class="reference internal" href="chp_08.html#abc-ma"><span class="std std-ref">8.6 移动平均模型的近似</span></a> Code Block <a class="reference internal" href="chp_08.html#ma2-abc"><span class="std std-ref">MA2_abc</span></a> we used a Uniform distribution and two potentials to define a 2D triangular distribution.</p>
<p>Figures <a class="reference internal" href="#fig-discrete-uniform-pmf-cdf"><span class="std std-numref">Fig. 174</span></a>, <a class="reference internal" href="#fig-binomial-pmf-cdf"><span class="std std-numref">Fig. 175</span></a>, and <a class="reference internal" href="#fig-poisson-pmf-cdf"><span class="std std-numref">Fig. 176</span></a>, are example of some common discrete distribution represented with their PMF and CDF. On the left we have the PMFs, the height of the bars represents the probability of each <span class="math notranslate nohighlight">\(x\)</span>. On the right we have the CDF, here the <em>jump</em> between two horizontal lines at a value of <span class="math notranslate nohighlight">\(x\)</span> represents the probability of <span class="math notranslate nohighlight">\(x\)</span>. The figure also includes the values of the mean and standard deviation of the distributions, is important to remark that these values are properties of the distributions, like the length of a circumference, and not something that we compute from a finite sample (see Section <a class="reference internal" href="#expectations"><span class="std std-ref">11.1.8 期望</span></a> for details).</p>
<p>Another way to describe random variables is to use stories. A story for <span class="math notranslate nohighlight">\(X\)</span> describes an experiment that could give rise to a random variable with the same distribution as <span class="math notranslate nohighlight">\(X\)</span>. Stories are not formal devices, but they are useful anyway. Stories have helped humans to make sense of their surrounding for millennia and they continue to be useful today, even in statistics. In the book Introduction to Probability <span id="id14">[<a class="reference internal" href="references.html#id10">5</a>]</span> Joseph K. Blitzstein and Jessica Hwang make extensive use of this device. They even use story proofs extensively, these are similar to mathematical proof but they can be more intuitive. Stories are also very useful devices to create statistical models, you can think about how the data may have been generated, and then try to write that down in statistical notation and/or code. We do this, for example, in Chapter [9]](chap9) with our flight delay example.</p>
<div class="section" id="discrete-uniform-distribution">
<span id="id15"></span><h4>( 1 ) 离散型均匀分布<a class="headerlink" href="#discrete-uniform-distribution" title="Permalink to this headline">¶</a></h4>
<p>This distribution assigns equal probability to a finite set of consecutive integers from interval a to b inclusive. Its PMF is:</p>
<div class="math notranslate nohighlight" id="equation-eq-pmf-uniform">
<span class="eqno">(86)<a class="headerlink" href="#equation-eq-pmf-uniform" title="Permalink to this equation">¶</a></span>\[P(X = x) = {\frac {1}{b - a + 1}} = \frac{1}{n}\]</div>
<p>for values of <span class="math notranslate nohighlight">\(x\)</span> in the interval <span class="math notranslate nohighlight">\([a, b]\)</span>, otherwise <span class="math notranslate nohighlight">\(P(X = x) = 0\)</span>, where <span class="math notranslate nohighlight">\(n=b-a+1\)</span> is the total number values that <span class="math notranslate nohighlight">\(x\)</span> can take.</p>
<p>We can use this distribution to model, for example, a fair die. Code Block <a class="reference internal" href="#scipy-unif"><span class="std std-ref">scipy_unif</span></a> shows how we can use Scipy to define a distribution and then compute useful quantities such as the PMF, CDF, and moments (see Section <a class="reference internal" href="#expectations"><span class="std std-ref">11.1.8 期望</span></a>).</p>
<div class="literal-block-wrapper docutils container" id="scipy-unif">
<div class="code-block-caption"><span class="caption-number">Listing 163 </span><span class="caption-text">scipy_unif</span><a class="headerlink" href="#scipy-unif" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">a</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">b</span> <span class="o">=</span> <span class="mi">6</span>
<span class="n">rv</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.randint.html#scipy.stats.randint" title="scipy.stats.randint"><span class="n">stats</span><span class="o">.</span><span class="n">randint</span></a><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.arange.html#numpy.arange" title="numpy.arange"><span class="n">np</span><span class="o">.</span><span class="n">arange</span></a><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">b</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>

<span class="n">x_pmf</span> <span class="o">=</span> <span class="n">rv</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># evaluate the pmf at the x values</span>
<span class="n">x_cdf</span> <span class="o">=</span> <span class="n">rv</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># evaluate the cdf at the x values</span>
<span class="n">mean</span><span class="p">,</span> <span class="n">variance</span> <span class="o">=</span> <span class="n">rv</span><span class="o">.</span><span class="n">stats</span><span class="p">(</span><span class="n">moments</span><span class="o">=</span><span class="s2">"mv"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Using Code Block <a class="reference internal" href="#scipy-unif"><span class="std std-ref">scipy_unif</span></a> plus a few lines of Matplotlib we generate <a class="reference internal" href="#fig-discrete-uniform-pmf-cdf"><span class="std std-numref">Fig. 174</span></a>. On the left panel we have the PMF where the height of each point indicates the probability of each event, we use points and dotted lines to highlight that the distribution is discrete. On the right we have the CDF, the height of the jump at each value of <span class="math notranslate nohighlight">\(x\)</span> indicates the probability of that value.</p>
<div class="figure align-default" id="fig-discrete-uniform-pmf-cdf">
<a class="reference internal image-reference" href="../_images/discrete_uniform_pmf_cdf.png"><img alt="../_images/discrete_uniform_pmf_cdf.png" src="../_images/discrete_uniform_pmf_cdf.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 174 </span><span class="caption-text">Discrete Uniform with parameters (1, 6). On the left the PMF. The height of the lines represents the probabilities for each value of <span class="math notranslate nohighlight">\(x\)</span>. On the right the CDF. The height of the jump at each value of <span class="math notranslate nohighlight">\(x\)</span> represent its probability. Values outside of the support of the distribution are not represented. The filled dots represent the inclusion of the CDF value at a particular <span class="math notranslate nohighlight">\(x\)</span> value, the open dots reflect the exclusion.</span><a class="headerlink" href="#fig-discrete-uniform-pmf-cdf" title="Permalink to this image">¶</a></p>
</div>
<p>In this specific example the discrete Uniform distribution is defined on the interval <span class="math notranslate nohighlight">\([1, 6]\)</span>. Therefore, all values less than 1 and greater than 6 have probability 0. Being a Uniform distribution, all the points have the same height and that height is <span class="math notranslate nohighlight">\(\frac{1}{6}\)</span>. There are two parameters of the Uniform discrete distribution, the lower limit <span class="math notranslate nohighlight">\(a\)</span> and upper limit <span class="math notranslate nohighlight">\(b\)</span>.</p>
<p>As we already mentioned in this chapter if we change the parameters of a distribution the <em>particular shape</em> of the distribution will change (try for example, replacing <code class="docutils literal notranslate"><span class="pre">stats.randint(1,</span> <span class="pre">7)</span></code> in Code Block <a class="reference internal" href="#scipy-unif"><span class="std std-ref">scipy_unif</span></a> with <code class="docutils literal notranslate"><span class="pre">stats.randint(1,</span> <span class="pre">4)</span></code>. That is why we usually talk about family of distributions, each member of that family is a distribution with a particular and valid combination of parameters. Equation <a class="reference internal" href="#equation-eq-pmf-uniform">(86)</a> defines the family of discrete Uniform distributions as long as <span class="math notranslate nohighlight">\(a &lt; b\)</span> and both <span class="math notranslate nohighlight">\(a\)</span> and <span class="math notranslate nohighlight">\(b\)</span> are integers.</p>
<p>When using probability distributions to create statistical applied models it is common to link the parameters with quantities that make physical sense. For example, in a 6 sided die it makes sense that <span class="math notranslate nohighlight">\(a=1\)</span> and <span class="math notranslate nohighlight">\(b=6\)</span>. In probability we generally know the values of these parameters while in statistics we generally do not know these values and we use data to infer them.</p>
</div>
<div class="section" id="binomial-distribution">
<span id="id16"></span><h4>( 2 ) 二项分布<a class="headerlink" href="#binomial-distribution" title="Permalink to this headline">¶</a></h4>
<p>A Bernoulli trial is an experiment with only two possible outcomes yes/no (success/failure, happy/sad, ill/healthy, etc). Suppose we perform <span class="math notranslate nohighlight">\(n\)</span> independent <a class="footnote-reference brackets" href="#id112" id="id17">7</a> Bernoulli trials, each with the same success probability <span class="math notranslate nohighlight">\(p\)</span> and let us call <span class="math notranslate nohighlight">\(X\)</span> the number of success. Then the distribution of <span class="math notranslate nohighlight">\(X\)</span> is called the Binomial distribution with parameters <span class="math notranslate nohighlight">\(n\)</span> and <span class="math notranslate nohighlight">\(p\)</span>, where <span class="math notranslate nohighlight">\(n\)</span> is a positive integer and <span class="math notranslate nohighlight">\(p \in [0, 1]\)</span>. Using statistical notation we can write <span class="math notranslate nohighlight">\(X \sim Bin(n, p)\)</span> to mean that <span class="math notranslate nohighlight">\(X\)</span> has the Binomial distribution with parameters <span class="math notranslate nohighlight">\(n\)</span> and <span class="math notranslate nohighlight">\(p\)</span>, with the PMF being:</p>
<div class="math notranslate nohighlight">
\[P(X = x) = \frac{n!}{x!(n-x)!}p^x(1-p)^{n-x}\]</div>
<p>The term <span class="math notranslate nohighlight">\(p^x(1-p)^{n-x}\)</span> counts the number of <span class="math notranslate nohighlight">\(x\)</span> success in <span class="math notranslate nohighlight">\(n\)</span> trials. This term only considers the total number of success but not the precise sequence, for example, <span class="math notranslate nohighlight">\((0,1)\)</span> is the same as <span class="math notranslate nohighlight">\((1,0)\)</span>, as both have one success in two trials. The first term is known as Binomial Coefficient and computes all the possible combinations of <span class="math notranslate nohighlight">\(x\)</span> elements taken from a set of <span class="math notranslate nohighlight">\(n\)</span> elements.</p>
<p>The Binomial PMFs are often written omitting the values that return 0, that is the values outside of the support. Nevertheless it is important to be sure what the support of a random variable is in order to avoid mistakes. A good practice is to check that PMFs are valid, and this is essential if we are proposing a new PMFs instead of using one off the <em>shelf</em>.</p>
<p>When <span class="math notranslate nohighlight">\(n=1\)</span> the Binomial distribution is also known as the Bernoulli distribution. Many distributions are special cases of other distributions or can be obtained somehow from other distributions.</p>
<div class="figure align-default" id="fig-binomial-pmf-cdf">
<a class="reference internal image-reference" href="../_images/binomial_pmf_cdf.png"><img alt="../_images/binomial_pmf_cdf.png" src="../_images/binomial_pmf_cdf.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 175 </span><span class="caption-text"><span class="math notranslate nohighlight">\(\text{Bin}(n=4, p=0.5)\)</span> On the left the PMF. The height of the lines represents the probabilities for each value of <span class="math notranslate nohighlight">\(x\)</span>. On the right the CDF. The height of the jump at each value of <span class="math notranslate nohighlight">\(x\)</span> represent its probability. Values outside of the support of the distribution are not represented.</span><a class="headerlink" href="#fig-binomial-pmf-cdf" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="section" id="poisson-distribution">
<span id="id18"></span><h4>( 3 ) 泊松分布<a class="headerlink" href="#poisson-distribution" title="Permalink to this headline">¶</a></h4>
<p>This distribution expresses the probability that <span class="math notranslate nohighlight">\(x\)</span> events happen during a fixed time interval (or space interval) if these events occur with an average rate <span class="math notranslate nohighlight">\(\mu\)</span> and independently from each other. It is generally used when there are a large number of trials, each with a small probability of success. For example</p>
<ul class="simple">
<li><p>Radioactive decay, the number of atoms in a given material is huge,   the actual number that undergo nuclear fission is low compared to   the total number of atoms.</p></li>
<li><p>The daily number of car accidents in a city. Even when we may   consider this number to be high relative to what we would prefer, it   is low in the sense that every maneuver that the driver performs,   including turns, stopping at lights, and parking, is an independent   trial where an accident could occur.</p></li>
</ul>
<p>The PMF of a Poisson is defined as:</p>
<div class="math notranslate nohighlight" id="equation-eq-poisson-pmf">
<span class="eqno">(87)<a class="headerlink" href="#equation-eq-poisson-pmf" title="Permalink to this equation">¶</a></span>\[P(X = x)  = \frac{\mu^{x} e^{-\mu}}{x!}, x = 0, 1, 2, \dots
  \]</div>
<p>Notice that the support of this PMF are all the natural numbers, which is an infinite set. So we have to be careful with our <em>list</em> of probabilities analogy, as summing an infinite series can be tricky. In fact Equation <a class="reference internal" href="#equation-eq-poisson-pmf">(87)</a> is a valid PMF because of the Taylor series <span class="math notranslate nohighlight">\(\sum_0^{\infty} \frac{\mu^{x}}{x!} = e^{\mu}\)</span></p>
<p>Both the mean and variance of the Poisson distribution are defined by <span class="math notranslate nohighlight">\(\mu\)</span>. As <span class="math notranslate nohighlight">\(\mu\)</span> increases, the Poisson distribution approximates to a Normal distribution, although the latter is continuous and the Poisson is discrete. The Poisson distribution is also closely related to the Binomial distribution. A Binomial distribution can be approximated with a Poisson, when <span class="math notranslate nohighlight">\(n &gt;&gt; p\)</span> <a class="footnote-reference brackets" href="#id113" id="id19">8</a>, that is, when the probability of success (<span class="math notranslate nohighlight">\(p\)</span>) is low compared with the number o trials (<span class="math notranslate nohighlight">\(n\)</span>) then <span class="math notranslate nohighlight">\(\text{Pois}(\mu=np) \approx \text{Bin}(n, p)\)</span>. For this reason the Poisson distribution is also known as <em>the law of small numbers</em> or the <em>law of rare events</em>. As we previously mentioned this does not mean that <span class="math notranslate nohighlight">\(\mu\)</span> has to be small, but instead that <span class="math notranslate nohighlight">\(p\)</span> is low with respect to <span class="math notranslate nohighlight">\(n\)</span>.</p>
<div class="figure align-default" id="fig-poisson-pmf-cdf">
<a class="reference internal image-reference" href="../_images/poisson_pmf_cdf.png"><img alt="../_images/poisson_pmf_cdf.png" src="../_images/poisson_pmf_cdf.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 176 </span><span class="caption-text"><span class="math notranslate nohighlight">\(\text{Pois}(2.3)\)</span> On the left the PMF. The height of the lines represents the probabilities for each value of <span class="math notranslate nohighlight">\(x\)</span>. On the right the CDF. The height of the jump at each value of <span class="math notranslate nohighlight">\(x\)</span> represent its probability. Values outside of the support of the distribution are not represented.</span><a class="headerlink" href="#fig-poisson-pmf-cdf" title="Permalink to this image">¶</a></p>
</div>
</div>
</div>
<div class="section" id="cont-rvs">
<span id="id20"></span><h3>11.1.5 连续型随机变量及其分布<a class="headerlink" href="#cont-rvs" title="Permalink to this headline">¶</a></h3>
<p>So far we have seen discrete random variables. There is another type of random variable that is widely used called continuous random variables, whose support takes values in <span class="math notranslate nohighlight">\(\mathbb {R}\)</span>. The most important difference between discrete and continuous random variables is that the latter can take on any <span class="math notranslate nohighlight">\(x\)</span> value in an interval, although the probability of any <span class="math notranslate nohighlight">\(x\)</span> value is exactly 0. Introduced this way you may think that these are the most useless probability distributions ever.</p>
<p>But that is not the case, the actual problem is that our analogy of treating a probability distribution as a finite list is a very limited analogy and it fails badly with continuous random variables <a class="footnote-reference brackets" href="#id114" id="id21">9</a>.</p>
<p>In Figures <a class="reference internal" href="#fig-discrete-uniform-pmf-cdf"><span class="std std-numref">Fig. 174</span></a>, <a class="reference internal" href="#fig-binomial-pmf-cdf"><span class="std std-numref">Fig. 175</span></a>, and <a class="reference internal" href="#fig-poisson-pmf-cdf"><span class="std std-numref">Fig. 176</span></a>, to represent PMFs (discrete variables), we used the height of the lines to represent the probability of each event. If we add the heights we always get 1, that is, the total sum of the probabilities. In a continuous distribution we do not have <em>lines</em> but rather we have a continuous curve, the height of that curve is not a probability but a <strong>probability density</strong> and instead of of a PMF we use a Probability Density Function (PDF). One important difference is that height of <span class="math notranslate nohighlight">\(\text{PDF}(x)\)</span> can be larger than 1, as is not the probability value but a probability density. To obtain a probability from a PDF instead we must integrate over some interval:</p>
<div class="math notranslate nohighlight">
\[P(a &lt; X &lt; b) =  \int_a^b pdf(x) dx\]</div>
<p>Thus, we can say that the area below the curve of the PDF (and not the height as in the PMF) gives us a probability, the total area under the curve, i.e. evaluated over the entire support of the PDF, must integrate to 1. Notice that if we want to find out how much more likely the value <span class="math notranslate nohighlight">\(x_1\)</span> is compared to <span class="math notranslate nohighlight">\(x_2\)</span> we can just compute <span class="math notranslate nohighlight">\(\frac{pdf(x_1)}{pdf(x_2)}\)</span>.</p>
<p>In many texts, including this one, it is common to use the symbol <span class="math notranslate nohighlight">\(p\)</span> to talk about the <span class="math notranslate nohighlight">\(pmf\)</span> or <span class="math notranslate nohighlight">\(pdf\)</span>. This is done in favour of generality and hoping to avoid being very rigorous with the notation which can be an actual burden when the difference can be more or less clear from the context.</p>
<p>For a discrete random variable, the CDF jumps at every point in the support, and is flat everywhere else. Working with the CDF of a discrete random variable is awkward because of this jumpiness. Its derivative is almost useless since it is undefined at the jumps and 0 everywhere else.</p>
<p>This is a problem for gradient-based sampling methods like Hamiltonian Monte Carlo (Section <a class="reference internal" href="#inference-methods"><span class="std std-ref">11.9 推断方法</span></a>). On the contrary for continuous random variables, the CDF is often very convenient to work with, and its derivative is precisely the probability density function (PDF) that we have discussed before.</p>
<p><a class="reference internal" href="#fig-cmf-pdf-pmf"><span class="std std-numref">Fig. 177</span></a> summarize the relationship between the CDF, PDF and PMF. The transformations between discrete CDF and PMF on one side and continuous CDF and PMF on the other are well defined and thus we used arrows with solid lines. Instead the transformations between discrete and continuous variables are more about numerical approximation than well defined mathematical operations. To approximately get from a discrete to a continuous distribution we use a smoothing method. One form of smoothing is to use a continuous distribution instead of a discrete one. To go from continuous to discrete we can discretize or bin the continuous outcomes. For example, a Poisson distribution with a large value of <span class="math notranslate nohighlight">\(\mu\)</span> approximately Gaussian <a class="footnote-reference brackets" href="#id115" id="id22">10</a>, while still being discrete. For those cases using a scenarios using a Poisson or a Gaussian maybe be interchangeable from a practical point of view. Using ArviZ you can use <code class="docutils literal notranslate"><span class="pre">az.plot_kde</span></code> with discrete data to approximate a continuous functions, how nice the results of this operation look depends on many factors. As we already said it may look good for a Poisson distribution with a relatively large value of <span class="math notranslate nohighlight">\(\mu\)</span>. When calling <code class="docutils literal notranslate"><span class="pre">az.plot_bpv(.)</span></code> for a discrete variable, ArviZ will smooth it, using an interpolation method, because the probability integral transform only works for continuous variables.</p>
<div class="figure align-default" id="fig-cmf-pdf-pmf">
<a class="reference internal image-reference" href="../_images/cmf_pdf_pmf.png"><img alt="../_images/cmf_pdf_pmf.png" src="../_images/cmf_pdf_pmf.png" style="width: 5.5in;"/></a>
<p class="caption"><span class="caption-number">Fig. 177 </span><span class="caption-text">Relationship between the CDF, PDF and PMF. Adapted from the book Think Stats <span id="id23">[<a class="reference internal" href="references.html#id92">131</a>]</span>.</span><a class="headerlink" href="#fig-cmf-pdf-pmf" title="Permalink to this image">¶</a></p>
</div>
<p>As we did with the discrete random variables, now we will see a few example of continuous random variables with their PDF and CDF.</p>
<div class="section" id="continuous-uniform-distribution">
<span id="id24"></span><h4>( 1 ) 连续型均匀分布<a class="headerlink" href="#continuous-uniform-distribution" title="Permalink to this headline">¶</a></h4>
<p>A continuous random variable is said to have a Uniform distribution on the interval <span class="math notranslate nohighlight">\((a, b)\)</span> if its PDF is:</p>
<div class="math notranslate nohighlight">
\[\begin{split}p(x \mid a,b)=\begin{cases} \frac{1}{b-a} &amp; if a \le x \le b \\ 0 &amp;  \text{otherwise} \end{cases}\end{split}\]</div>
<div class="figure align-default" id="fig-uniform-pdf-cdf">
<a class="reference internal image-reference" href="../_images/uniform_pdf_cdf.png"><img alt="../_images/uniform_pdf_cdf.png" src="../_images/uniform_pdf_cdf.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 178 </span><span class="caption-text"><span class="math notranslate nohighlight">\(\mathcal{U}(0, 1)\)</span> On the left the PDF, the black line represents the probability density, the gray shaded area represents the probability <span class="math notranslate nohighlight">\(P(0.25 &lt; X &lt; 0.75) =0.5\)</span>. On the right the CDF, the height of the gray continuous segment represents <span class="math notranslate nohighlight">\(P(0.25 &lt; X &lt; 0.75) =0.5\)</span>. Values outside of the support of the distribution are not represented.</span><a class="headerlink" href="#fig-uniform-pdf-cdf" title="Permalink to this image">¶</a></p>
</div>
<p>The most commonly used Uniform distribution in statistics is <span class="math notranslate nohighlight">\(\mathcal{U}(0, 1)\)</span> also known as the standard Uniform. The PDF and CDF for the standard Uniform are very simple: <span class="math notranslate nohighlight">\(p(x) = 1\)</span> and <span class="math notranslate nohighlight">\(F_{(x)} = x\)</span> respectively, <a class="reference internal" href="#fig-uniform-pdf-cdf"><span class="std std-numref">Fig. 178</span></a> represents both of them, this figure also indicated how to compute probabilities from the PDF and CDF.</p>
</div>
<div class="section" id="gaussian-or-normal-distribution">
<span id="id25"></span><h4>( 2 ) 高斯（正态）分布<a class="headerlink" href="#gaussian-or-normal-distribution" title="Permalink to this headline">¶</a></h4>
<p>This is perhaps the best known distribution <a class="footnote-reference brackets" href="#id116" id="id26">11</a>. On the one hand, because many phenomena can be described approximately using this distribution (thanks to central limit theorem, see Subsection <a class="reference internal" href="#appendix-clt"><span class="std std-ref">( 2 ) 中心极限定律</span></a> below). On the other hand, because it has certain mathematical properties that make it easier to work with it analytically.</p>
<p>The Gaussian distribution is defined by two parameters, the mean <span class="math notranslate nohighlight">\(\mu\)</span> and the standard deviation <span class="math notranslate nohighlight">\(\sigma\)</span> as shown in Equation <a class="reference internal" href="#equation-eq-gaussian-pdf">(88)</a>. A Gaussian distribution with <span class="math notranslate nohighlight">\(\mu=0\)</span> and <span class="math notranslate nohighlight">\(\sigma=1\)</span> is known as the <strong>standard Gaussian distribution</strong>.</p>
<div class="math notranslate nohighlight" id="equation-eq-gaussian-pdf">
<span class="eqno">(88)<a class="headerlink" href="#equation-eq-gaussian-pdf" title="Permalink to this equation">¶</a></span>\[    p (x \mid \mu, \sigma) = \frac {1} {\sigma \sqrt {2 \pi}} e^{-\frac {(x -\mu)^2} {2 \sigma^2}}\]</div>
<p>On the left panel of <a class="reference internal" href="#fig-normal-pdf-cdf"><span class="std std-numref">Fig. 179</span></a> we have the PDF, and on the right we have the CDF. Both the PDF and CDF are represented for the invertal -4, 4, but notice that the support of the Gaussian distribution is the entire real line.</p>
<div class="figure align-default" id="fig-normal-pdf-cdf">
<a class="reference internal image-reference" href="../_images/normal_pdf_cdf.png"><img alt="../_images/normal_pdf_cdf.png" src="../_images/normal_pdf_cdf.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 179 </span><span class="caption-text">Representation of <span class="math notranslate nohighlight">\(\mathcal{N}(0, 1)\)</span>, on the left the PDF, on the right the CDF. The support of the Gaussian distribution is the entire real line.</span><a class="headerlink" href="#fig-normal-pdf-cdf" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="section" id="t">
<span id="students-t-distribution"></span><h4>( 3 ) 学生 <span class="math notranslate nohighlight">\(t\)</span> 分布<a class="headerlink" href="#t" title="Permalink to this headline">¶</a></h4>
<p>Historically this distribution arose to estimate the mean of a normally distributed population when the sample size is small <a class="footnote-reference brackets" href="#id117" id="id27">12</a>. In Bayesian statistics, a common use case is to generate models that are robust against aberrant data as we discussed in Section <a class="reference internal" href="chp_04.html#robust-regression"><span class="std std-ref">4.4 更稳健的回归</span></a>.</p>
<div class="math notranslate nohighlight">
\[p (x \mid \nu, \mu, \sigma) = \frac {\Gamma (\frac {\nu + 1} {2})} {\Gamma (\frac{\nu} {2}) \sqrt {\pi \nu} \sigma} \left (1+ \frac{1}{\nu} \left (\frac {x- \mu} {\sigma} \right)^2 \right)^{-\frac{\nu + 1}{2}}\]</div>
<p>where <span class="math notranslate nohighlight">\(\Gamma\)</span> is the gamma function <a class="footnote-reference brackets" href="#id118" id="id28">13</a> and <span class="math notranslate nohighlight">\(\nu\)</span> is commonly called degrees of freedom. We also like the name degree of normality, since as <span class="math notranslate nohighlight">\(\nu\)</span> increases, the distribution approaches a Gaussian. In the extreme case of <span class="math notranslate nohighlight">\(\lim_{\nu \to \infty}\)</span> the distribution is exactly equal to a Gaussian distribution with the same mean and standard deviation equal to <span class="math notranslate nohighlight">\(\sigma\)</span>.</p>
<p>When <span class="math notranslate nohighlight">\(\nu=1\)</span> we get the Cauchy distribution <a class="footnote-reference brackets" href="#id119" id="id29">14</a>. Which is similar to a Gaussian but with tails decreasing very slowly, so slowly that this distribution does not have a defined mean or variance. That is, it is possible to calculate a mean from a data set, but if the data came from a Cauchy distribution, the spread around the mean will be high and this spread will not decrease as the sample size increases. The reason for this strange behavior is that distributions, like the Cauchy, are dominated by the tail behavior of the distribution, contrary to what happens with, for example, the Gaussian distribution.</p>
<p>For this distribution <span class="math notranslate nohighlight">\(\sigma\)</span> is not the standard deviation, which as already said could be undefined, <span class="math notranslate nohighlight">\(\sigma\)</span> is the scale. As <span class="math notranslate nohighlight">\(\nu\)</span> increases the scale converges to the standard deviation of a Gaussian distribution.</p>
<p>On the left panel of <a class="reference internal" href="#fig-student-t-pdf-cdf"><span class="std std-numref">Fig. 180</span></a> we have the PDF, and on the right we have the CDF. Compare with <a class="reference internal" href="#fig-normal-pdf-cdf"><span class="std std-numref">Fig. 179</span></a>, a standard normal and see how the tails are heavier for the Student T distribution with parameter <span class="math notranslate nohighlight">\(\mathcal{T}(\nu=4, \mu=0, \sigma=1)\)</span></p>
<div class="figure align-default" id="fig-student-t-pdf-cdf">
<a class="reference internal image-reference" href="../_images/student_t_pdf_cdf.png"><img alt="../_images/student_t_pdf_cdf.png" src="../_images/student_t_pdf_cdf.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 180 </span><span class="caption-text"><span class="math notranslate nohighlight">\(\mathcal{T}(\nu=4, \mu=0, \sigma=1)\)</span> On the left the PDF, on the right the CDF. The support of the Students T distribution is the entire real line.</span><a class="headerlink" href="#fig-student-t-pdf-cdf" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="section" id="beta-distribution">
<span id="id30"></span><h4>( 4 ) 贝塔分布<a class="headerlink" href="#beta-distribution" title="Permalink to this headline">¶</a></h4>
<p>The Beta distribution is defined in the interval <span class="math notranslate nohighlight">\([0, 1]\)</span>. It can be used to model the behavior of random variables limited to a finite interval, for example, modeling proportions or percentages.</p>
<div class="math notranslate nohighlight">
\[p (x \mid \alpha, \beta) = \frac {\Gamma (\alpha + \beta)} {\Gamma(\alpha) \Gamma (\beta)} \, x^{\alpha-1} (1 -x)^{\beta-1}\]</div>
<p>The first term is a normalization constant that ensures that the PDF integrates to 1. <span class="math notranslate nohighlight">\(\Gamma\)</span> is the Gamma function. When <span class="math notranslate nohighlight">\(\alpha = 1\)</span> and <span class="math notranslate nohighlight">\(\beta = 1\)</span> the Beta distribution reduces to the standard Uniform distribution. In <a class="reference internal" href="#fig-beta-pdf-cdf"><span class="std std-numref">Fig. 181</span></a> we show a <span class="math notranslate nohighlight">\(\text{Beta}(\alpha=5, \beta=2)\)</span> distribution.</p>
<div class="figure align-default" id="fig-beta-pdf-cdf">
<a class="reference internal image-reference" href="../_images/beta_pdf_cdf.png"><img alt="../_images/beta_pdf_cdf.png" src="../_images/beta_pdf_cdf.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 181 </span><span class="caption-text"><span class="math notranslate nohighlight">\(\text{Beta}(\alpha=5, \beta=2)\)</span> On the left the PDF, on the right the CDF. The support of the Beta distribution is on the interval <span class="math notranslate nohighlight">\([0, 1]\)</span>.</span><a class="headerlink" href="#fig-beta-pdf-cdf" title="Permalink to this image">¶</a></p>
</div>
<p>If we want to express the Beta distribution as a function of the mean and the dispersion around the mean, we can do it in the following way.</p>
<p><span class="math notranslate nohighlight">\(\alpha = \mu \kappa\)</span>, <span class="math notranslate nohighlight">\(\beta = (1 - \mu) \kappa\)</span> where <span class="math notranslate nohighlight">\(\mu\)</span> the mean and <span class="math notranslate nohighlight">\(\kappa\)</span> a parameter called concentration as <span class="math notranslate nohighlight">\(\kappa\)</span> increases the dispersion decreases. Also note that <span class="math notranslate nohighlight">\(\kappa = \alpha + \beta\)</span>.</p>
</div>
</div>
<div class="section" id="joint-conditional-and-marginal-distributions">
<span id="id31"></span><h3>11.1.6 联合分布、条件分布和边缘分布<a class="headerlink" href="#joint-conditional-and-marginal-distributions" title="Permalink to this headline">¶</a></h3>
<p>假设我们有两个具有相同 PMF <span class="math notranslate nohighlight">\(\text{Bin}(1, 0.5)\)</span> 的随机变量 <span class="math notranslate nohighlight">\(X\)</span> 和 <span class="math notranslate nohighlight">\(Y\)</span>。他们是依赖的还是独立的？如果 <span class="math notranslate nohighlight">\(X\)</span> 代表抛硬币的正面，而 <span class="math notranslate nohighlight">\(Y\)</span> 代表另一次抛硬币的正面，那么它们是独立的。但是，如果它们在同一次抛硬币中分别代表正面和反面，那么它们是依赖的。因此，即使单个（正式称为单变量）PMF/PDF 完全表征单个随机变量，它们也没有关于单个随机变量如何与其他随机变量相关的信息。要回答这个问题，我们需要知道<strong>联合</strong>分布，也称为多元分布。如果我们认为 <span class="math notranslate nohighlight">\(p(X)\)</span> 提供了关于在实线上找到 <span class="math notranslate nohighlight">\(X\)</span> 的概率的所有信息，以类似的方式 <span class="math notranslate nohighlight">\(p(X, Y)\)</span>，<span class="math notranslate nohighlight">\(X\)</span> 和 <span class="math notranslate nohighlight">\(Y 的联合分布\)</span>, 提供有关在平面上找到元组 <span class="math notranslate nohighlight">\((X, Y)\)</span> 的概率的所有信息。联合分布允许我们描述来自同一个实验的多个随机变量的行为，例如，后验分布是我们根据观测数据调整模型后模型中所有参数的联合分布。</p>
<p>The joint PMF is given by</p>
<div class="math notranslate nohighlight">
\[p_{X,Y}(x, y) = P(X = x, Y = y)\]</div>
<p><span class="math notranslate nohighlight">\(n\)</span> 离散随机变量的定义类似，我们只需要包含 <span class="math notranslate nohighlight">\(n\)</span> 项。与单变量 PMF 类似，有效的联合 PMF 必须是非负的并且总和为 1，其中总和取自所有可能的值。</p>
<div class="math notranslate nohighlight">
\[\sum_x \sum_y P(X=x, Y=y) = 1\]</div>
<p>以类似的方式，<span class="math notranslate nohighlight">\(X\)</span> 和 <span class="math notranslate nohighlight">\(Y\)</span> 的联合 CDF 是</p>
<div class="math notranslate nohighlight" id="equation-eq-join-cdf">
<span class="eqno">(89)<a class="headerlink" href="#equation-eq-join-cdf" title="Permalink to this equation">¶</a></span>\[F_{X,Y}(x, y) = P(X \le x, Y \le y)\]</div>
<p>给定 <span class="math notranslate nohighlight">\(X\)</span> 和 <span class="math notranslate nohighlight">\(Y\)</span> 的联合分布，我们可以通过对 <span class="math notranslate nohighlight">\(Y\)</span> 的所有可能值求和来得到 <span class="math notranslate nohighlight">\(X\)</span> 的分布：</p>
<div class="math notranslate nohighlight">
\[P(X=x) = \sum_y P(X=x, Y=y)\]</div>
<div class="figure align-default" id="fig-joint-dist-marginal">
<a class="reference internal image-reference" href="../_images/joint_dist_marginal.png"><img alt="../_images/joint_dist_marginal.png" src="../_images/joint_dist_marginal.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 182 </span><span class="caption-text">黑线代表<span class="math notranslate nohighlight">\(x\)</span>和<span class="math notranslate nohighlight">\(y\)</span>的联合分布。 <span class="math notranslate nohighlight">\(x\)</span> 的边际分布中的蓝线是通过将 <span class="math notranslate nohighlight">\(x\)</span> 的每个值沿 y 轴的线的高度相加得到的。</span><a class="headerlink" href="#fig-joint-dist-marginal" title="Permalink to this image">¶</a></p>
</div>
<p>在上一节中，我们将 <span class="math notranslate nohighlight">\(P(X=x)\)</span> 称为 <span class="math notranslate nohighlight">\(X\)</span> 的 PMF，或者只是 <span class="math notranslate nohighlight">\(X\)</span> 的分布，在处理联合分布时，我们通常将其称为 <span class="math notranslate nohighlight">\(X\)</span> 的<strong>边际</strong>分布。我们这样做是为了强调我们谈论的是<em>个人</em> <span class="math notranslate nohighlight">\(X\)</span>，没有提及 <span class="math notranslate nohighlight">\(Y\)</span>。通过对 <span class="math notranslate nohighlight">\(Y\)</span> 的所有可能值求和，我们<em>摆脱了 <span class="math notranslate nohighlight">\(Y\)</span></em>。</p>
<p>正式地，这个过程被称为边缘化 <span class="math notranslate nohighlight">\(Y\)</span> 。为了获得 <span class="math notranslate nohighlight">\(Y\)</span> 的 PMF，我们可以以类似的方式进行，但将 <span class="math notranslate nohighlight">\(X\)</span> 的所有可能值相加。在超过 2 个变量的联合分布的情况下，我们只需要对所有<em>其他</em>变量求和。 <a class="reference internal" href="#fig-joint-dist-marginal"><span class="std std-numref">Fig. 182</span></a> 说明了这一点。</p>
<p>鉴于联合分布，很容易获得边际。</p>
<p>但是，除非我们做出进一步的假设，否则从边缘到联合分布通常是不可能的。在 <a class="reference internal" href="#fig-joint-dist-marginal"><span class="std std-numref">Fig. 182</span></a> 中，我们可以看到只有一种方法可以沿 y 轴或 x 轴添加条形高度，但要反过来我们必须 <em>split</em> 个条形，并且有无限种方法使这种分裂。</p>
<p>我们已经在 <a class="reference internal" href="#conditional-probability"><span class="std std-ref">11.1.2 条件概率</span></a> 节中介绍了条件分布，并且在 <a class="reference internal" href="#fig-cond"><span class="std std-numref">Fig. 171</span></a> 中我们展示了条件化正在重新定义样本空间。</p>
<p><a class="reference internal" href="#fig-joint-dist-conditional"><span class="std std-numref">Fig. 183</span></a> 演示了在 <span class="math notranslate nohighlight">\(X\)</span> 和 <span class="math notranslate nohighlight">\(Y\)</span> 联合分布的上下文中的条件反射。为了以 <span class="math notranslate nohighlight">\(Y=y\)</span> 为条件，我们采用 <span class="math notranslate nohighlight">\(Y=y\)</span> 值处的联合分布，而忽略其余部分。即那些 <span class="math notranslate nohighlight">\(Y \ne y\)</span>，这类似于索引二维数组并选择单个列或行。 <span class="math notranslate nohighlight">\(X\)</span> 的 <em>remaining</em> 值，<a class="reference internal" href="#fig-joint-dist-conditional"><span class="std std-numref">Fig. 183</span></a> 中的粗体值需要总和为 1 才能成为有效的 PMF，因此我们通过除以 <span class="math notranslate nohighlight">\(P(Y=y)\)</span> 重新归一化。</p>
<div class="figure align-default" id="fig-joint-dist-conditional">
<a class="reference internal image-reference" href="../_images/joint_dist_conditional.png"><img alt="../_images/joint_dist_conditional.png" src="../_images/joint_dist_conditional.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 183 </span><span class="caption-text">左边是 <span class="math notranslate nohighlight">\(x\)</span> 和 <span class="math notranslate nohighlight">\(y\)</span> 的联合分布。蓝线代表条件分布 <span class="math notranslate nohighlight">\(p(x \ mid y=3)\)</span>。在右侧，我们分别绘制了相同的条件分布。请注意，<span class="math notranslate nohighlight">\(x\)</span> 的条件 PMF 与 <span class="math notranslate nohighlight">\(​​y\)</span> 的值一样多，反之亦然。我们只是强调一种可能性。</span><a class="headerlink" href="#fig-joint-dist-conditional" title="Permalink to this image">¶</a></p>
</div>
<p>我们将连续联合 CDF 定义为方程 <a class="reference internal" href="#equation-eq-join-cdf">(89)</a>，与离散变量相同，联合 PDF 作为 CDF 关于 <span class="math notranslate nohighlight">\(x\)</span> 和 <span class="math notranslate nohighlight">\(y\)</span> 的导数。我们要求有效的联合 PDF 是非负的并且积分为 1。对于连续变量，我们可以以与离散变量类似的方式将变量边缘化，不同之处在于我们需要计算积分而不是总和。</p>
<div class="math notranslate nohighlight">
\[pdf_X(x) = \int pdf_{X,Y} (x, y)dy\]</div>
<div class="figure align-default" id="fig-joint-marginal-cond-continuous">
<a class="reference internal image-reference" href="../_images/joint_marginal_cond_continuous.png"><img alt="../_images/joint_marginal_cond_continuous.png" src="../_images/joint_marginal_cond_continuous.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 184 </span><span class="caption-text">在图的中心，我们有联合概率 <span class="math notranslate nohighlight">\(p(x, y)\)</span> 用灰度表示，概率密度越高越暗。在顶部和右侧 <em>margins</em> 我们分别有边际分布 <span class="math notranslate nohighlight">\(p(x)\)</span> 和 <span class="math notranslate nohighlight">\(p(y)\)</span>。虚线表示 3 个不同的 <span class="math notranslate nohighlight">\(y\)</span> 值的条件概率 <span class="math notranslate nohighlight">\(p(x \mid y)\)</span>。我们可以将这些视为在给定值 <span class="math notranslate nohighlight">\(y\)</span> 处的联合 <span class="math notranslate nohighlight">\(p(x, y)\)</span> 的（重新归一化的）切片。</span><a class="headerlink" href="#fig-joint-marginal-cond-continuous" title="Permalink to this image">¶</a></p>
</div>
<p><a class="reference internal" href="#fig-colin-joint-marginals"><span class="std std-numref">Fig. 185</span></a> 显示了另一个带有边缘分布的连接分布示例。这也是一个明显的例子，从联合到边缘很简单，因为有一种独特的方式来做这件事，但是除非我们引入进一步的假设，否则逆向是不可能的。联合分布也可以是离散分布和连续分布的混合。</p>
<p><a class="reference internal" href="#fig-mix-joint"><span class="std std-numref">Fig. 186</span></a> 显示了一个示例。</p>
<div class="figure align-default" id="fig-colin-joint-marginals">
<a class="reference internal image-reference" href="../_images/colin_joint_marginals.png"><img alt="../_images/colin_joint_marginals.png" src="../_images/colin_joint_marginals.png" style="width: 5.50in;"/></a>
<p class="caption"><span class="caption-number">Fig. 185 </span><span class="caption-text">PyMC3 徽标作为带有边缘的联合分布的样本。该图是使用 imcmc <a class="reference external" href="https://github.com/ColCarroll/imcmc">https://github.com/ColCarroll/imcmc</a> 创建的，该库用于将 2D 图像转换为概率分布，然后从中采样以创建图像和 gif。</span><a class="headerlink" href="#fig-colin-joint-marginals" title="Permalink to this image">¶</a></p>
</div>
<div class="figure align-default" id="fig-mix-joint">
<a class="reference internal image-reference" href="../_images/mix_joint.png"><img alt="../_images/mix_joint.png" src="../_images/mix_joint.png" style="width: 5.50in;"/></a>
<p class="caption"><span class="caption-number">Fig. 186 </span><span class="caption-text">黑色的混合联合分布。边际以蓝色表示，<span class="math notranslate nohighlight">\(X\)</span> 分布为高斯分布，<span class="math notranslate nohighlight">\(Y\)</span> 分布为泊松分布。很容易看出对于 <span class="math notranslate nohighlight">\(Y\)</span> 的每个值，我们如何具有（高斯）条件分布。</span><a class="headerlink" href="#fig-mix-joint" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="section" id="pit">
<span id="probability-integral-transform-pit"></span><h3>11.1.7 概率积分变换 (PIT)<a class="headerlink" href="#pit" title="Permalink to this headline">¶</a></h3>
<p>概率积分变换 (PIT)，也称为均匀分布的普遍性，它指出给定具有连续分布的随机变量 <span class="math notranslate nohighlight">\(X\)</span>，具有累积分布 <span class="math notranslate nohighlight">\(F_X\)</span>，我们可以计算具有标准均匀分布的随机变量 <span class="math notranslate nohighlight">\(Y\)</span>分布为：</p>
<div class="math notranslate nohighlight" id="equation-eq-pit">
<span class="eqno">(90)<a class="headerlink" href="#equation-eq-pit" title="Permalink to this equation">¶</a></span>\[Y = F_X (X)\]</div>
<p>通过 <span class="math notranslate nohighlight">\(Y\)</span> 的 CDF 的定义，我们可以看到这是真的</p>
<div class="math notranslate nohighlight">
\[F_Y (y) = P(Y \leq y)\]</div>
<p>替换前一个中的方程 <a class="reference internal" href="#equation-eq-pit">(90)</a></p>
<div class="math notranslate nohighlight">
\[\begin{split}P(F_X (X) \leq y) \\\end{split}\]</div>
<p>取 <span class="math notranslate nohighlight">\(F_X\)</span> 的倒数到不等式的两边</p>
<div class="math notranslate nohighlight">
\[\begin{split}P(X \leq F^{-1}_X (y)) \\\end{split}\]</div>
<p>根据 CDF 的定义</p>
<div class="math notranslate nohighlight">
\[F_X (F^{-1}_X (y))\]</div>
<p>简化后，我们得到标准均匀分布 <span class="math notranslate nohighlight">\(\mathcal{U}(0, 1)\)</span> 的 CDF。</p>
<div class="math notranslate nohighlight">
\[F_Y(y) = y\]</div>
<p>如果我们不知道 CDF <span class="math notranslate nohighlight">\(F_X\)</span> 但我们有来自 <span class="math notranslate nohighlight">\(X\)</span> 的样本，我们可以用经验 CDF 来近似它。 <a class="reference internal" href="#fig-pit"><span class="std std-numref">Fig. 187</span></a> 显示了使用代码块 <a class="reference internal" href="#id32"><span class="std std-ref">pit</span></a> 生成的此属性的示例。</p>
<div class="literal-block-wrapper docutils container" id="id32">
<div class="code-block-caption"><span class="caption-number">Listing 164 </span><span class="caption-text">pit</span><a class="headerlink" href="#id32" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">xs</span> <span class="o">=</span> <span class="p">(</span><a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.linspace.html#numpy.linspace" title="numpy.linspace"><span class="n">np</span><span class="o">.</span><span class="n">linspace</span></a><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">200</span><span class="p">),</span> <a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.linspace.html#numpy.linspace" title="numpy.linspace"><span class="n">np</span><span class="o">.</span><span class="n">linspace</span></a><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">200</span><span class="p">),</span> <a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.linspace.html#numpy.linspace" title="numpy.linspace"><span class="n">np</span><span class="o">.</span><span class="n">linspace</span></a><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">200</span><span class="p">))</span>
<span class="n">dists</span> <span class="o">=</span> <span class="p">(</span><a class="sphinx-codeautolink-a" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.expon.html#scipy.stats.expon" title="scipy.stats.expon"><span class="n">stats</span><span class="o">.</span><span class="n">expon</span></a><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span> <a class="sphinx-codeautolink-a" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.beta.html#scipy.stats.beta" title="scipy.stats.beta"><span class="n">stats</span><span class="o">.</span><span class="n">beta</span></a><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <a class="sphinx-codeautolink-a" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html#scipy.stats.norm" title="scipy.stats.norm"><span class="n">stats</span><span class="o">.</span><span class="n">norm</span></a><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>


<span class="n">_</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.subplots.html#matplotlib.pyplot.subplots" title="matplotlib.pyplot.subplots"><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span></a><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="p">(</span><span class="n">dist</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">dists</span><span class="p">,</span> <span class="n">xs</span><span class="p">)):</span>
    <span class="n">draws</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="mi">100000</span><span class="p">)</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">draws</span><span class="p">)</span>
    <span class="c1"># PDF original distribution</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dist</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="c1"># Empirical CDF</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.sort.html#numpy.sort" title="numpy.sort"><span class="n">np</span><span class="o">.</span><span class="n">sort</span></a><span class="p">(</span><span class="n">data</span><span class="p">),</span> <a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.linspace.html#numpy.linspace" title="numpy.linspace"><span class="n">np</span><span class="o">.</span><span class="n">linspace</span></a><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)))</span>
    <span class="c1"># Kernel Density Estimation</span>
    <a class="sphinx-codeautolink-a" href="https://arviz-devs.github.io/arviz/api/generated/arviz.plot_kde.html#arviz.plot_kde" title="arviz.plot_kde"><span class="n">az</span><span class="o">.</span><span class="n">plot_kde</span></a><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="figure align-default" id="fig-pit">
<a class="reference internal image-reference" href="../_images/pit.png"><img alt="../_images/pit.png" src="../_images/pit.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 187 </span><span class="caption-text">在第一列，我们有 3 种不同分布的 PDF。为了生成中间列中的图，我们从相应的 PDF 中抽取 100000 次绘图，计算这些绘图的 CDF。我们可以看到这些是均匀分布的 CDF。最后一列与中间一列类似，不同之处在于我们使用核密度估计器来近似 PDF，而不是绘制经验 CDF，我们可以看到它近似于 Uniform。该图是使用代码块 <a class="reference internal" href="#id32"><span class="std std-ref">pit</span></a> 生成的。</span><a class="headerlink" href="#fig-pit" title="Permalink to this image">¶</a></p>
</div>
<p>概率积分变换用作测试的一部分，以评估给定数据集是否可以建模为来自指定分布（或概率模型）。在本书中，我们已经看到 PIT 在视觉测试 <code class="docutils literal notranslate"><span class="pre">az.plot_loo_pit()</span></code> 和 <code class="docutils literal notranslate"><span class="pre">az.plot_pbv(kind="u_values")</span></code> 后面使用。</p>
<p>PIT 也可用于从分布中采样。如果随机变量 <span class="math notranslate nohighlight">\(X\)</span> 分布为 <span class="math notranslate nohighlight">\(\mathcal{U}(0,1)\)</span>，则 <span class="math notranslate nohighlight">\(Y = F^{-1}(X)\)</span> 具有分布 <span class="math notranslate nohighlight">\(F\)</span>。因此，要从分布中获取样本，我们只需要（伪）随机数生成器，如“np.random.rand()”和感兴趣分布的逆 CDF。这可能不是最有效的方法，但它的通用性和简单性很难被击败。</p>
</div>
<div class="section" id="expectations">
<span id="id33"></span><h3>11.1.8 期望<a class="headerlink" href="#expectations" title="Permalink to this headline">¶</a></h3>
<p>期望值是总结分布质心的单个数字。例如，如果 <span class="math notranslate nohighlight">\(X\)</span> 是一个离散随机变量，那么我们可以将其期望计算为：</p>
<div class="math notranslate nohighlight">
\[\mathbb{E}(X) = \sum_x x P(X = x)\]</div>
<p>与统计中的常见情况一样，我们还希望测量分布的散布或离散度，例如，以表示像平均值这样的点估计周围的不确定性。我们可以用方差来做到这一点，这本身也是一种期望：</p>
<div class="math notranslate nohighlight">
\[\mathbb{V}(X) = \mathbb{E}(X - \mathbb{E}X)^2 = \mathbb{E}(X^2 ) - (\mathbb{E}X)^2\]</div>
<p>在许多计算中，方差通常<em>自然地</em>出现，但要报告结果，取方差的平方根（称为标准差）通常更有用，因为它与随机变量的单位相同。</p>
<p>图 <a class="reference internal" href="#fig-discrete-uniform-pmf-cdf"><span class="std std-numref">Fig. 174</span></a>, <a class="reference internal" href="#fig-binomial-pmf-cdf"><span class="std std-numref">Fig. 175</span></a>, <a class="reference internal" href="#fig-poisson-pmf-cdf"><span class="std std-numref">Fig. 176</span></a>, <a class="reference internal" href="#fig-uniform-pdf-cdf"><span class="std std-numref">Fig. 178</span></a>, <a class="reference internal" href="#fig-normal-pdf-cdf"><span class="std std-numref">Fig. 179</span></a>, <code class="xref std std-numref docutils literal notranslate"> <span class="pre">fig:student_t_pdf_cdf</span></code> 和 <a class="reference internal" href="#fig-beta-pdf-cdf"><span class="std std-numref">Fig. 181</span></a> 显示了不同分布的期望值和标准差。</p>
<p>请注意，这些不是从样本计算的值，而是理论数学对象的属性。</p>
<p>期望是线性的，这意味着：</p>
<div class="math notranslate nohighlight">
\[\mathbb{E}(cX) = c\mathbb{E}(X)\]</div>
<p>其中 <span class="math notranslate nohighlight">\(c\)</span> 是一个常数并且</p>
<div class="math notranslate nohighlight">
\[\mathbb{E}(X + Y) = \mathbb{E}(X) + \mathbb{E}(Y)\]</div>
<p>即使在 <span class="math notranslate nohighlight">\(X\)</span> 和 <span class="math notranslate nohighlight">\(Y\)</span> 依赖的情况下也是如此。相反，方差不是线性的：</p>
<div class="math notranslate nohighlight">
\[\mathbb{V}(cX) = c^2\mathbb{V}(X)\]</div>
<p>一般来说：</p>
<div class="math notranslate nohighlight">
\[\mathbb{V}(X + Y) \neq \mathbb{V}(X) + \mathbb{V}(Y)\]</div>
<p>除非，例如，当 <span class="math notranslate nohighlight">\(X\)</span> 和 <span class="math notranslate nohighlight">\(Y\)</span> 是独立的。</p>
<p>我们将随机变量 <span class="math notranslate nohighlight">\(X\)</span> 的第 n 个矩表示为 <span class="math notranslate nohighlight">\(\mathbb{E}(​​X^n)\)</span>，因此期望值和方差也称为分布的一阶矩和二阶矩。第三个时刻，偏斜，告诉我们分布的不对称性。具有均值 <span class="math notranslate nohighlight">\(\mu\)</span> 和方差 <span class="math notranslate nohighlight">\(\sigma^2\)</span> 的随机变量 <span class="math notranslate nohighlight">\(X\)</span> 的偏度是 <span class="math notranslate nohighlight">\(X\)</span> 的第三个（标准化矩）：</p>
<div class="math notranslate nohighlight">
\[\text{skew}(X) = \mathbb{E}\left(\frac{X -\mu}{\sigma}\right)^3\]</div>
<p>将偏斜计算为标准化量的原因，即减去均值并除以标准差是为了使偏斜独立于 <span class="math notranslate nohighlight">\(X\)</span> 的定位和规模，这是合理的，因为我们已经从均值中获得了该信息和方差，并且它会使偏度独立于 <span class="math notranslate nohighlight">\(X\)</span> 的单位，因此比较偏度变得更容易。</p>
<p>例如，<span class="math notranslate nohighlight">\(\text{Beta}(2, 2)\)</span> 的偏斜为 0，而 <span class="math notranslate nohighlight">\(\text{Beta}(2, 5)\)</span> 的偏斜为正，对于 <span class="math notranslate nohighlight">\(\text{Beta}(5, 2 )\)</span> 负数。对于单峰分布，正偏斜通常意味着右尾较长，而负偏斜则相反。</p>
<p>情况并非总是如此，原因是 0 偏斜意味着两侧尾部的<em>总质量</em>是平衡的。所以我们也可以通过一条又长又细的尾巴和另一条又短又肥的尾巴来平衡质量。</p>
<p>第四矩，称为峰度，告诉我们尾部的行为或<em>极端值</em> <span id="id34">[<a class="reference internal" href="references.html#id94">132</a>]</span>。它被定义为</p>
<div class="math notranslate nohighlight" id="equation-kurtosis">
<span class="eqno">(91)<a class="headerlink" href="#equation-kurtosis" title="Permalink to this equation">¶</a></span>\[\text{Kurtosis}(X) = \mathbb{E}\left(\frac{X -\mu}{\sigma}\right)^4 - 3  \]</div>
<p>减去 3 的原因是为了让高斯的峰度为 0，因为经常将峰度与高斯分布进行比较来讨论，但有时它通常在没有 <span class="math notranslate nohighlight">\(-3\)</span> 的情况下计算，所以当有疑问时问，或阅读，以了解在特定情况下使用的确切定义。通过检查方程 <a class="reference internal" href="#equation-kurtosis">(91)</a> 中的峰度定义，我们可以看到我们实际上是在计算标准化数据的四次方的期望值。因此，任何小于 1 的标准化值对峰度几乎没有任何贡献。相反，唯一有贡献的值是 <em>extreme</em> 值。</p>
<p>随着我们在 Student t 分布中增加 <span class="math notranslate nohighlight">\(\nu\)</span> 的值，峰度减小（高斯分布为零），并且随着我们减少 <span class="math notranslate nohighlight">\(\nu\)</span> 峰度增加。峰态仅在 <span class="math notranslate nohighlight">\(\nu &gt; 4\)</span> 时定义，实际上对于 Student T 分布，第 <span class="math notranslate nohighlight">\(n\)</span> 时刻仅在 <span class="math notranslate nohighlight">\(\nu &gt; n\)</span> 时定义。</p>
<p>SciPy 的 stats 模块提供了一种方法 <code class="docutils literal notranslate"><span class="pre">stats(moments)</span></code> 来计算分布的矩，正如你在代码块 <a class="reference internal" href="#scipy-unif"><span class="std std-ref">scipy_unif</span></a> 中看到的那样，它用于获取均值和方差。我们注意到，我们在本节中讨论的只是从概率分布而不是样本计算期望和矩，因此我们讨论的是理论分布的属性。当然，在实践中，我们通常希望从数据中估计分布的矩，因此统计学家有研究估计量，例如，样本均值和样本中位数是 <span class="math notranslate nohighlight">\(\mathbb{E}(​​X)\)</span> 的估计量。</p>
</div>
<div class="section" id="transformations">
<span id="id35"></span><h3>11.1.9 变换<a class="headerlink" href="#transformations" title="Permalink to this headline">¶</a></h3>
<p>如果我们有一个随机变量 <span class="math notranslate nohighlight">\(X\)</span> 并且我们将函数 <span class="math notranslate nohighlight">\(g\)</span> 应用于它，我们将获得另一个随机变量 <span class="math notranslate nohighlight">\(Y = g(X)\)</span>。这样做之后，我们可能会问，既然我们知道 <span class="math notranslate nohighlight">\(X\)</span> 的分布，我们如何找出 <span class="math notranslate nohighlight">\(Y\)</span> 的分布。一种简单的方法是从 <span class="math notranslate nohighlight">\(X\)</span> 中采样并应用转换，然后绘制结果。但是当然有正式的方式来做到这一点。其中一种方法是应用<strong>变量更改</strong>技术。</p>
<p>如果 <span class="math notranslate nohighlight">\(X\)</span> 是一个连续随机变量并且 <span class="math notranslate nohighlight">\(Y = g(X)\)</span>，其中 <span class="math notranslate nohighlight">\(g\)</span> 是一个可微的严格递增或递减函数，则 <span class="math notranslate nohighlight">\(Y\)</span> 的 PDF 为：</p>
<div class="math notranslate nohighlight" id="equation-eq-changeofvariable">
<span class="eqno">(92)<a class="headerlink" href="#equation-eq-changeofvariable" title="Permalink to this equation">¶</a></span>\[p_Y(y) = p_X(x) \left| \frac{dx}{dy} \right|\]</div>
<p>我们可以看到这是正确的，如下所示。令 <span class="math notranslate nohighlight">\(g\)</span> 严格递增，则 <span class="math notranslate nohighlight">\(Y\)</span> 的 CDF 为：</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{split}
   F_Y(y) =&amp; P(Y \le y) \\
  =&amp; P(g(X) \le y) \\
  =&amp; P(X \le g^{-1}(y)) \\
  =&amp; F_X(g^{-1}(y)) \\
  =&amp; F_X(x) \\
\end{split}\end{split}\]</div>
<p>然后通过链式法则，<span class="math notranslate nohighlight">\(Y\)</span> 的 PDF 可以从 <span class="math notranslate nohighlight">\(X\)</span> 的 PDF 计算为：</p>
<div class="math notranslate nohighlight">
\[p_Y(y) = p_X(x) \frac{dx}{dy}\]</div>
<p><span class="math notranslate nohighlight">\(g\)</span> 严格递减的证明是相似的，但我们最终在右手项上有一个减号，因此我们在方程 <a class="reference internal" href="#equation-eq-changeofvariable">(92)</a> 中计算绝对值的原因。</p>
<p>对于多元随机变量（即更高维度）而不是导数，我们需要计算雅可比行列式，因此通常引用术语 <span class="math notranslate nohighlight">\(\left| \frac{dx}{dy} \right|\)</span> 即使在一维情况下也是雅可比行列式。点 <span class="math notranslate nohighlight">\(p\)</span> 的雅可比行列式的绝对值为我们提供了函数 <span class="math notranslate nohighlight">\(g\)</span> 在 <span class="math notranslate nohighlight">\(p\)</span> 附近扩大或缩小交易量的因子。雅可比行列式的这种解释也适用于概率密度。如果变换 <span class="math notranslate nohighlight">\(g\)</span> 不是线性的，那么受影响的概率分布将在某些区域缩小并在其他区域扩大。因此，当从已知的 PDF 中的 <span class="math notranslate nohighlight">\(X\)</span> 计算 <span class="math notranslate nohighlight">\(Y\)</span> 时，我们需要适当地考虑这些变形。像下面这样稍微重写方程 <a class="reference internal" href="#equation-eq-changeofvariable">(92)</a> 也有帮助：</p>
<div class="math notranslate nohighlight">
\[p_Y(y)dy = p_X(x)dx\]</div>
<p>正如我们现在可以看到的，在微小的区间 <span class="math notranslate nohighlight">\(p_Y(y)dy\)</span> 中找到 <span class="math notranslate nohighlight">\(Y\)</span> 的概率等于在微小的区间 <span class="math notranslate nohighlight">\(p_X(x)dx\)</span> 中找到 <span class="math notranslate nohighlight">\(X\)</span> 的概率。所以雅可比行列式告诉我们如何将与 <span class="math notranslate nohighlight">\(X\)</span> 相关联的空间中的概率与与 <span class="math notranslate nohighlight">\(Y\)</span> 相关联的概率重新映射。</p>
</div>
<div class="section" id="limits">
<span id="id36"></span><h3>11.1.10 极限<a class="headerlink" href="#limits" title="Permalink to this headline">¶</a></h3>
<p>两个最著名和最广泛使用的概率定理是大数定律和中心极限定理。它们都告诉我们随着样本量的增加，样本均值会发生什么变化。它们都可以在重复实验的背景下被理解，其中实验的结果可以被视为来自某些潜在分布的样本。</p>
<div class="section" id="the-law-of-large-numbers">
<span id="id37"></span><h4>( 1 ) 大数定律<a class="headerlink" href="#the-law-of-large-numbers" title="Permalink to this headline">¶</a></h4>
<p>大数定律告诉我们，一个独立同分布随机变量的样本均值随着样本数量的增加而收敛到随机变量的期望值。对于某些分布，例如柯西分布（没有均值或有限方差），情况并非如此。</p>
<p>大数定律经常被误解，导致赌徒谬误。这种悖论的一个例子是相信在彩票中投注一个很长时间没有出现的号码是明智的。这里的错误推理是，如果某个特定数字有一段时间没有出现，那么一定有某种力量会增加该数字在下一次抽取中出现的概率。重新建立数字的等概率性和宇宙的<em>自然秩序</em>的力量。</p>
<div class="figure align-default" id="fig-law-of-large-numbers">
<a class="reference internal image-reference" href="../_images/law_of_large_numbers.png"><img alt="../_images/law_of_large_numbers.png" src="../_images/law_of_large_numbers.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 188 </span><span class="caption-text">来自 <span class="math notranslate nohighlight">\(\mathcal{U}(0, 1)\)</span> 分布的运行值。 0.5 处的虚线表示预期值。随着抽样次数的增加，经验均值接近预期值。每条线代表一个不同的样本。</span><a class="headerlink" href="#fig-law-of-large-numbers" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="section" id="appendix-clt">
<span id="id38"></span><h4>( 2 ) 中心极限定律<a class="headerlink" href="#appendix-clt" title="Permalink to this headline">¶</a></h4>
<p>中心极限定理指出：如果我们从任意分布中独立地采样得到 <span class="math notranslate nohighlight">\(n\)</span> 个值，则随着 <span class="math notranslate nohighlight">\({n \rightarrow \infty}\)</span> ，这些采样点的均值 <span class="math notranslate nohighlight">\(\bar X\)</span> 将近似呈高斯分布：</p>
<div class="math notranslate nohighlight" id="equation-eq-central-limit">
<span class="eqno">(93)<a class="headerlink" href="#equation-eq-central-limit" title="Permalink to this equation">¶</a></span>\[\bar X_n \dot \sim \mathcal{N} \left (\mu, \frac{\sigma^2} {n} \right)\]</div>
<p>其中 <span class="math notranslate nohighlight">\(\mu\)</span> 和 <span class="math notranslate nohighlight">\(\sigma^2\)</span> 是任意分布的均值和方差。</p>
<p>为了满足中心极限定理，必须满足以下假设：</p>
<ul class="simple">
<li><p>这些值是独立采样的</p></li>
<li><p>每个值都来自相同的分布</p></li>
<li><p>分布的均值和标准差必须是有限的</p></li>
</ul>
<p>标准 1 和 2 可以放宽一些<em>相当多</em>，我们仍然会得到大致的高斯分布，但没有办法摆脱标准 3。对于没有定义均值或方差的分布，例如 Cauchy 分布，这个定理不适用。来自 Cauchy 分布的 <span class="math notranslate nohighlight">\(N\)</span> 值的均值不遵循高斯分布，而是遵循 Cauchy 分布。</p>
<p>中心极限定理解释了自然界中高斯分布的普遍性。我们研究的许多现象可以解释为围绕均值的波动，或者是许多不同因素总和的结果。</p>
<p><a class="reference internal" href="#fig-central-limit"><span class="std std-numref">Fig. 189</span></a> 显示了 3 种不同分布的中心极限定理，<span class="math notranslate nohighlight">\(\text{Pois}(2.3)\)</span>, <span class="math notranslate nohighlight">\(\mathcal{U}(0, 1)\)</span>, <span class="math notranslate nohighlight">\(\text{Beta} (1, 10)\)</span>，随着 <span class="math notranslate nohighlight">\(n\)</span> 的增加。</p>
<div class="figure align-default" id="fig-central-limit">
<a class="reference internal image-reference" href="../_images/central_limit.png"><img alt="../_images/central_limit.png" src="../_images/central_limit.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 189 </span><span class="caption-text">左边距显示的分布直方图。每个直方图基于 <span class="math notranslate nohighlight">\(\bar{X_n}\)</span> 的 1000 个模拟值。随着我们增加 <span class="math notranslate nohighlight">\(n\)</span>，<span class="math notranslate nohighlight">\(\bar{X_n}\)</span> 的分布接近高斯分布。黑色曲线对应于根据中心极限定理的高斯分布。</span><a class="headerlink" href="#fig-central-limit" title="Permalink to this image">¶</a></p>
</div>
</div>
</div>
<div class="section" id="markov-chains">
<span id="id39"></span><h3>11.1.11 马尔可夫链<a class="headerlink" href="#markov-chains" title="Permalink to this headline">¶</a></h3>
<p>A Markov Chain is a sequence of random variables <span class="math notranslate nohighlight">\(X_0, X_1, \dots\)</span> for which the future state is conditionally independent from all past ones given the current state. In other words, knowing the current state is enough to know the probabilities for all future states. This is known as the Markov property and we can write it as:</p>
<div class="math notranslate nohighlight" id="equation-markov-property">
<span class="eqno">(94)<a class="headerlink" href="#equation-markov-property" title="Permalink to this equation">¶</a></span>\[P(X_{n+1} = j \mid X_n = i, X_{n-1} = i_{n-1} , \dots, X_0 = i_0) = P(X_{n+1} = j \mid X_n = i)   \]</div>
<p>A rather effective way to visualize Markov Chains is imagining you or some object moving in space <a class="footnote-reference brackets" href="#id120" id="id40">15</a>. The analogy is easier to grasp if the space is finite, for example, moving a piece in a square board like checkers or a salesperson visiting different cities. Given this scenarios you can ask questions like, how likely is to visit one state (specific squares in the board, cities, etc)? Or maybe more interesting if we keep moving from state to state how much time will we spend at each state in the long-run?</p>
<p><a class="reference internal" href="#fig-markov-chains-graph"><span class="std std-numref">Fig. 190</span></a> shows four examples of Markov Chains, the first one show a classical example, an oversimplified weather model, where the states are rainy or sunny, the second example shows a deterministic die. The last two example are more abstract as we have not assigned any concrete representation to them.</p>
<div class="figure align-default" id="fig-markov-chains-graph">
<a class="reference internal image-reference" href="../_images/markov_chains_graph.png"><img alt="../_images/markov_chains_graph.png" src="../_images/markov_chains_graph.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 190 </span><span class="caption-text">Markov Chains examples. (a) An oversimplified weather model, representing the probability of a rainy or sunny day, the arrows indicate the transition between states, the arrows are annotated with their corresponding transition probabilities. (b) An example of periodic Markov Chain. (c) An example of a disjoint chain. The states 1, 2, and 3 are disjoint from states A and B. If we start at the state 1, 2, or 3 we will never reach state A or B and vice versa. Transition probabilities are omitted in this example. (d) A Markov chain representing the gambler’s ruin problem, two gamblers, A and B, start with <span class="math notranslate nohighlight">\(i\)</span> and <span class="math notranslate nohighlight">\(N-i\)</span> units of money respectively. At any given money they bet 1 unit, gambler A has probability <span class="math notranslate nohighlight">\(p\)</span> of and probability <span class="math notranslate nohighlight">\(q = 1 - p\)</span> of losing. If <span class="math notranslate nohighlight">\(X_n\)</span> is the total money of gambler A at time <span class="math notranslate nohighlight">\(n\)</span>. Then <span class="math notranslate nohighlight">\(X_0, X_1, \dots\)</span> is a Markov chain as the one represented.</span><a class="headerlink" href="#fig-markov-chains-graph" title="Permalink to this image">¶</a></p>
</div>
<p>A convenient way to study Markov Chains is to collect the probabilities of moving between states in one step in a transition matrix <span class="math notranslate nohighlight">\(\mathbf{T} = (t_{ij})\)</span>. For example, the transition matrix of example A in <a class="reference internal" href="#fig-markov-chains-graph"><span class="std std-numref">Fig. 190</span></a> is</p>
<!---
```{math} 
\begin{blockarray}{ccc}
\; & \text{sunny} & \text{rainy} \\
\begin{block}{c(cc)}
\text{sunny} & 0.9 & 0.1 \\
\text{rainy} & 0.8 & 0.2 \\
\end{block}
```
-->
<div class="math notranslate nohighlight">
\[\begin{split}\begin{bmatrix}
0.9 &amp; 0.1 \\
0.8 &amp; 0.2
\end{bmatrix}\end{split}\]</div>
<p>and, for example, the transition matrix of example B in <a class="reference internal" href="#fig-markov-chains-graph"><span class="std std-numref">Fig. 190</span></a> is</p>
<!---
```{math} 
\begin{blockarray}{ccccccc}
\; & 0 & 1 & 2 & 3 & 4 & 5\\
\begin{block}{c(cccccc)}
0 & 0 & 1 & 0 & 0 & 0 & 0\\
1 & 0 & 0 & 1 & 0 & 0 & 0\\
2 & 0 & 0 & 0 & 1 & 0 & 0\\
3 & 0 & 0 & 0 & 0 & 1 & 0\\
4 & 0 & 0 & 0 & 0 & 0 & 1\\
5 & 1 & 0 & 0 & 0 & 0 & 0\\
\end{block}
\end{blockarray}
```
-->
<div class="math notranslate nohighlight">
\[\begin{split}\begin{bmatrix}
0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
1 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\
2 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 \\
3 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 \\
4 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 \\
5 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
\end{bmatrix}\end{split}\]</div>
<p>The <span class="math notranslate nohighlight">\(i\)</span>th row of the transition matrix represents the conditional probability distribution of moving from state <span class="math notranslate nohighlight">\(X_{n}\)</span> to the state <span class="math notranslate nohighlight">\(X_{n+1}\)</span>. That is, <span class="math notranslate nohighlight">\(p(X_{n+1} \mid X_n = i)\)</span>. For example, if we are at state <em>sunny</em> we can move to <em>sunny</em> (i.e. stay at the same state) with probability 0.9 and move to state <em>rainy</em> with probability 0.1. Notice how the total probability of moving from <em>sunny</em> to somewhere is 1, as expected for a PMF.</p>
<p>Because of the Markov property we can compute the probability of <span class="math notranslate nohighlight">\(n\)</span> consecutive steps by taking the <span class="math notranslate nohighlight">\(n\)</span>th power of <span class="math notranslate nohighlight">\(\mathbf{T}\)</span>.</p>
<p>We can also specify the starting point of the Markov chain, i.e. the initial conditions <span class="math notranslate nohighlight">\(s_i = P(X_0 = i)\)</span> and let <span class="math notranslate nohighlight">\(\mathbf{s}=(s_1, \dots, s_M)\)</span>. With this information we can compute the marginal PMF of <span class="math notranslate nohighlight">\(X_n\)</span> as <span class="math notranslate nohighlight">\(\mathbf{s}\mathbf{T}^n\)</span>.</p>
<p>When studying Markov chains it makes sense to define properties of individual states and also properties on the entire chain. For example, if a chain returns to a state over and over again we call that state recurrent. Instead a transient state is one that the chain will eventually leave forever, in example (d) in <a class="reference internal" href="#fig-markov-chains-graph"><span class="std std-numref">Fig. 190</span></a> all states other than 0 or <span class="math notranslate nohighlight">\(N\)</span> are transient. Also, we can call a chain irreducible if it is possible to get from any state to any other state in a finite number of steps example (c) in <a class="reference internal" href="#fig-markov-chains-graph"><span class="std std-numref">Fig. 190</span></a> is not irreducible, as states 1,2 and 3 are disconnected from states A and B.</p>
<p>Understanding the long-term behavior of Markov chains is of interest. In fact, they were introduced by Andrey Markov with the purpose of demonstrating that the law of large numbers can be applied also to non-independent random variables. The previously mentioned concepts of recurrence and transience are important for understanding this long-term run behavior. If we have a chain with transient and recurrent states, the chain may spend time in the transient states, but it will eventually spend all the eternity in the recurrent states. A natural question we can ask is how much time the chain is going to be at each state. The answer is provided by finding the <strong>stationary distribution</strong> of the chain.</p>
<p>For a finite Markov chain, the stationary distribution <span class="math notranslate nohighlight">\(\mathbf{s}\)</span> is a PMF such that <span class="math notranslate nohighlight">\(\mathbf{s}\mathbf{T} = \mathbf{s}\)</span> <a class="footnote-reference brackets" href="#id121" id="id41">16</a>. That is a distribution that is not changed by the transition matrix <span class="math notranslate nohighlight">\(\mathbf{T}\)</span>.</p>
<p>Notice that this does not mean the chain is not moving anymore, it means that the chain moves in such a way that the time it will spend at each state is the one defined by <span class="math notranslate nohighlight">\(\mathbf{s}\)</span>. Maybe a physical analogy could helps here. Imagine we have a glass not completely filled with water at a given temperature. If we seal it with a cover, the water molecules will evaporate into the air as moisture. Interestingly it is also the case that the water molecules in the air will move to the liquid water.</p>
<p>Initially more molecules might be going one way or another, but at a given point the system will find a dynamic equilibrium, with the same amount of water molecules moving to the air from the liquid water, as the number of water molecules moving from the liquid water to the air.</p>
<p>In physics/chemistry this is called a steady-state, locally things are moving, but globally nothing changes <a class="footnote-reference brackets" href="#id122" id="id42">17</a>. Steady state is also an alternative name to stationary distribution.</p>
<p>Interestingly, under various conditions, the stationary distribution of a finite Markov chain exists and is unique, and the PMF of <span class="math notranslate nohighlight">\(X_n\)</span> converges to <span class="math notranslate nohighlight">\(\mathbf{s}\)</span> as <span class="math notranslate nohighlight">\(n \to \infty\)</span>. Example (d) in <a class="reference internal" href="#fig-markov-chains-graph"><span class="std std-numref">Fig. 190</span></a> does not have a unique stationary distribution. We notice that once this chain reaches the states 0 or <span class="math notranslate nohighlight">\(N\)</span>, meaning gambler A or B lost all the money, the chain stays in that state forever, so both <span class="math notranslate nohighlight">\(s_0=(1, 0, \dots , 0)\)</span> and <span class="math notranslate nohighlight">\(s_N=(0, 0, \dots , 1)\)</span> are both stationary distributions. On the contrary example B in <a class="reference internal" href="#fig-markov-chains-graph"><span class="std std-numref">Fig. 190</span></a> has a unique stationary distribution which is <span class="math notranslate nohighlight">\(s=(1/6, 1/6, 1/6, 1/6, 1/6, 1/6)\)</span>, event thought the transition is deterministic.</p>
<p>If a PMF <span class="math notranslate nohighlight">\(\mathbf{s}\)</span> satisfies the reversibility condition (also known as detailed balance), that is <span class="math notranslate nohighlight">\(s_i t_{ij} = s_j t_{ji}\)</span> for all <span class="math notranslate nohighlight">\(i\)</span> and <span class="math notranslate nohighlight">\(j\)</span>, we have the guarantee that <span class="math notranslate nohighlight">\(\mathbf{s}\)</span> is a stationary distribution of the Markov chain with transition matrix <span class="math notranslate nohighlight">\(\mathbf{T} = t_{ij}\)</span>. Such Markov chains are called reversible. In Section <a class="reference internal" href="#inference-methods"><span class="std std-ref">11.9 推断方法</span></a> we will use this property to show why Metropolis-Hastings is guaranteed to, asymptotically, work.</p>
<p>Markov chains satisfy a central limit theorem which is similar to Equation <a class="reference internal" href="#equation-eq-central-limit">(93)</a> except that instead of dividing by <span class="math notranslate nohighlight">\(n\)</span> we need to divide by the effective sample size (ESS). In Section <a class="reference internal" href="chp_02.html#ess"><span class="std std-ref">2.4.1 有效样本数量</span></a> we discussed how to estimate the effective sample size from a Markov Chain and how to use it to diagnose the quality of the chain. The square root of <span class="math notranslate nohighlight">\(\frac{\sigma^2} {\text{ESS}}\)</span> is the Monte Carlo standard error (MCSE) that we also discussed in Section <a class="reference internal" href="chp_02.html#monte-carlo-standard-error"><span class="std std-ref">2.4.3 蒙特卡洛标准误差</span></a>.</p>
</div>
</div>
<div class="section" id="entropy">
<span id="id43"></span><h2>11.2 熵<a class="headerlink" href="#entropy" title="Permalink to this headline">¶</a></h2>
<p>In the <em>Zentralfriedhof</em>, Vienna, we can find the grave of Ludwig Boltzmann. His tombstone has the legend <span class="math notranslate nohighlight">\(S = k \log W\)</span>, which is a beautiful way of saying that the second law of thermodynamics is a consequence of the laws of probability. With this equation Boltzmann contributed to the development of one of the pillars of modern physics, statistical mechanics. Statistical mechanics describes how macroscopic observations such as temperature are related to the microscopic world of molecules. Imagine a glass with water, what we perceive with our senses is basically the average behavior of a huge number water molecules inside that glass <a class="footnote-reference brackets" href="#id123" id="id44">18</a>. At a given temperature there is a given number of arrangements of the water molecules compatible with that temperature (Figure <a class="reference internal" href="#fig-entropy-t"><span class="std std-numref">Fig. 191</span></a>). As we decrease the temperature we will find that less and less arrangements are possible until we find a single one. We have just reached 0 Kelvin, the lowest possible temperature in the universe! If we move into the other direction we will find that molecules can be found in more and more arrangements.</p>
<div class="figure align-default" id="fig-entropy-t">
<a class="reference internal image-reference" href="../_images/entropy_T.png"><img alt="../_images/entropy_T.png" src="../_images/entropy_T.png" style="width: 7.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 191 </span><span class="caption-text">The number of possible arrangements particles can take is related to the temperature of the system. Here we represent discrete system of 3 equivalent particles, the number of possible arrangements is represented by the available cells (gray high lines). increasing the temperature is equivalent to increasing the number of available cells. At <span class="math notranslate nohighlight">\(T=0\)</span> only one arrangement is possible, as the temperature increase the particles can occupy more and more states.</span><a class="headerlink" href="#fig-entropy-t" title="Permalink to this image">¶</a></p>
</div>
<p>We can analyze this mental experiment in terms of uncertainty. If we know a system is at 0 Kelvin we know the system can only be in a single possible arrangement, our certainty is absolute <a class="footnote-reference brackets" href="#id124" id="id45">19</a>, as we increase the temperature the number of possible arrangements will increase and then it will become more and more difficult to say, “Hey look! Water molecules are in this particular arrangement at this particular time!” Thus our uncertainty about the microscopic state will increase. We will still be able to characterize the system by averages such the temperature, volume, etc, but at the microscopic level the certainty about particular arrangements will decrease. Thus, we can think of entropy as a way of measuring uncertainty.</p>
<p>The concept of entropy is not only valid for molecules. It could also be applies to arrangements of pixels, characters in a text, musical notes, socks, bubbles in a sourdough bread and more. The reason that entropy is so flexible is because it quantifies the arrangements of objects - it is a property of the underlying distributions. The larger the entropy of a distribution the less informative that distribution will be and the more evenly it will assign probabilities to its events. Getting an answer of “<span class="math notranslate nohighlight">\(42\)</span>” is more certain than “<span class="math notranslate nohighlight">\(42 \pm 5\)</span>”, which again more certain than “any real number”. Entropy can translate this qualitative observation into numbers.</p>
<p>The concept of entropy applies to continue and discrete distributions, but it is easier to think about it using discrete states and we will see some example in the rest of this section. But keep in mind the same concepts apply to the continuous cases.</p>
<p>For a probability distribution <span class="math notranslate nohighlight">\(p\)</span> with <span class="math notranslate nohighlight">\(n\)</span> possible different events which each possible event <span class="math notranslate nohighlight">\(i\)</span> having probability <span class="math notranslate nohighlight">\(p_i\)</span>, the entropy is defined as:</p>
<div class="math notranslate nohighlight" id="equation-eq-entropy">
<span class="eqno">(95)<a class="headerlink" href="#equation-eq-entropy" title="Permalink to this equation">¶</a></span>\[H(p) = - \mathbb{E}[\log{p}] = -\sum_{i}^n p_i \log{p_i}\]</div>
<p>Equation <a class="reference internal" href="#equation-eq-entropy">(95)</a> is just a different way of writing the entropy engraved on Boltzmann’s tombstone. We annotate entropy using <span class="math notranslate nohighlight">\(H\)</span> instead of <span class="math notranslate nohighlight">\(S\)</span> and set <span class="math notranslate nohighlight">\(k=1\)</span>. Notice that the multiplicity <span class="math notranslate nohighlight">\(W\)</span> from Boltzmann’s version is the total number of ways in which different outcomes can possibly occur:</p>
<div class="math notranslate nohighlight">
\[W = \frac{N!}{n_1!n_2! \cdots n_t!}\]</div>
<p>You can think of this as rolling a t-sided die <span class="math notranslate nohighlight">\(N\)</span> times, where <span class="math notranslate nohighlight">\(n_i\)</span> is the number of times we obtain side <span class="math notranslate nohighlight">\(i\)</span>. As <span class="math notranslate nohighlight">\(N\)</span> is large we can use Stirling’s approximation <span class="math notranslate nohighlight">\(x! \approx (\frac{x}{e})^x\)</span>.</p>
<div class="math notranslate nohighlight">
\[W =  \frac{N^N}{n_1^{n_1} n_2^{n_2} \cdots n_t^{n_t}} e^{(n_1 n_2 \cdots n_t-N)}\]</div>
<p>noticing that <span class="math notranslate nohighlight">\(p_i = \frac{n_i}{N}\)</span> we can write:</p>
<div class="math notranslate nohighlight">
\[W = \frac{1}{p_1^{n_1} p_2^{n_2} \cdots p_t^{n_t}}\]</div>
<p>And finally by taking the logarithm we obtain</p>
<div class="math notranslate nohighlight">
\[\log W = -\sum_{i}^n p_i \log{p_i}\]</div>
<p>which is exactly the definition of entropy.</p>
<p>We will now show how to compute entropy in Python using Code Block <a class="reference internal" href="#entropy-dist"><span class="std std-ref">entropy_dist</span></a>, with the result shown in <a class="reference internal" href="#fig-entropy"><span class="std std-numref">Fig. 192</span></a>.</p>
<div class="literal-block-wrapper docutils container" id="entropy-dist">
<div class="code-block-caption"><span class="caption-number">Listing 165 </span><span class="caption-text">entropy_dist</span><a class="headerlink" href="#entropy-dist" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">26</span><span class="p">)</span>
<span class="n">q_pmf</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.binom.html#scipy.stats.binom" title="scipy.stats.binom"><span class="n">stats</span><span class="o">.</span><span class="n">binom</span></a><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">)</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">qu_pmf</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.randint.html#scipy.stats.randint" title="scipy.stats.randint"><span class="n">stats</span><span class="o">.</span><span class="n">randint</span></a><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.nonzero.html#numpy.nonzero" title="numpy.nonzero"><span class="n">np</span><span class="o">.</span><span class="n">nonzero</span></a><span class="p">(</span><span class="n">q_pmf</span><span class="p">))</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">r_pmf</span> <span class="o">=</span> <span class="p">(</span><span class="n">q_pmf</span> <span class="o">+</span> <a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.roll.html#numpy.roll" title="numpy.roll"><span class="n">np</span><span class="o">.</span><span class="n">roll</span></a><span class="p">(</span><span class="n">q_pmf</span><span class="p">,</span> <span class="mi">12</span><span class="p">))</span> <span class="o">/</span> <span class="mi">2</span>
<span class="n">ru_pmf</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.randint.html#scipy.stats.randint" title="scipy.stats.randint"><span class="n">stats</span><span class="o">.</span><span class="n">randint</span></a><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.nonzero.html#numpy.nonzero" title="numpy.nonzero"><span class="n">np</span><span class="o">.</span><span class="n">nonzero</span></a><span class="p">(</span><span class="n">r_pmf</span><span class="p">))</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">s_pmf</span> <span class="o">=</span> <span class="p">(</span><span class="n">q_pmf</span> <span class="o">+</span> <a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.roll.html#numpy.roll" title="numpy.roll"><span class="n">np</span><span class="o">.</span><span class="n">roll</span></a><span class="p">(</span><span class="n">q_pmf</span><span class="p">,</span> <span class="mi">15</span><span class="p">))</span> <span class="o">/</span> <span class="mi">2</span>
<span class="n">su_pmf</span> <span class="o">=</span> <span class="p">(</span><span class="n">qu_pmf</span> <span class="o">+</span> <a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.roll.html#numpy.roll" title="numpy.roll"><span class="n">np</span><span class="o">.</span><span class="n">roll</span></a><span class="p">(</span><span class="n">qu_pmf</span><span class="p">,</span> <span class="mi">15</span><span class="p">))</span> <span class="o">/</span> <span class="mi">2</span>

<span class="n">_</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.subplots.html#matplotlib.pyplot.subplots" title="matplotlib.pyplot.subplots"><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span></a><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                     <span class="n">constrained_layout</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.ravel.html#numpy.ravel" title="numpy.ravel"><span class="n">np</span><span class="o">.</span><span class="n">ravel</span></a><span class="p">(</span><span class="n">ax</span><span class="p">)</span>

<span class="n">zipped</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">([</span><span class="n">q_pmf</span><span class="p">,</span> <span class="n">qu_pmf</span><span class="p">,</span> <span class="n">r_pmf</span><span class="p">,</span> <span class="n">ru_pmf</span><span class="p">,</span> <span class="n">s_pmf</span><span class="p">,</span> <span class="n">su_pmf</span><span class="p">],</span>
             <span class="p">[</span><span class="s2">"q"</span><span class="p">,</span> <span class="s2">"qu"</span><span class="p">,</span> <span class="s2">"r"</span><span class="p">,</span> <span class="s2">"ru"</span><span class="p">,</span> <span class="s2">"s"</span><span class="p">,</span> <span class="s2">"su"</span><span class="p">])</span>
<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="p">(</span><span class="n">dist</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">zipped</span><span class="p">):</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">vlines</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">dist</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">"H = </span><span class="si">{</span><a class="sphinx-codeautolink-a" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.entropy.html#scipy.stats.entropy" title="scipy.stats.entropy"><span class="n">stats</span><span class="o">.</span><span class="n">entropy</span></a><span class="p">(</span><span class="n">dist</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">handlelength</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="figure align-default" id="fig-entropy">
<a class="reference internal image-reference" href="../_images/entropy.png"><img alt="../_images/entropy.png" src="../_images/entropy.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 192 </span><span class="caption-text">Discrete distributions defined in Code Block <a class="reference internal" href="#entropy-dist"><span class="std std-ref">entropy_dist</span></a> and their entropy values <span class="math notranslate nohighlight">\(H\)</span>.</span><a class="headerlink" href="#fig-entropy" title="Permalink to this image">¶</a></p>
</div>
<p><a class="reference internal" href="#fig-entropy"><span class="std std-numref">Fig. 192</span></a> shows six distributions, one per subplot with its corresponding entropy. There are a lot of things moving on in this figure, so before diving in be sure to set aside an adequate amount of time (this maybe a good time to check your e-mails before going on). The most peaked, or least spread distribution is <span class="math notranslate nohighlight">\(q\)</span>, and this is the distribution with the lowest value of entropy among the six plotted distributions. <span class="math notranslate nohighlight">\(q \sim \text{binom}({n=10, p=0.75})\)</span>, and thus there are 11 possible events. <span class="math notranslate nohighlight">\(qu\)</span> is a Uniform distribution with also 11 possible events. We can see that the entropy of <span class="math notranslate nohighlight">\(qu\)</span> is larger than <span class="math notranslate nohighlight">\(q\)</span>, in fact we can compute the entropy for binomial distributions with <span class="math notranslate nohighlight">\(n=10\)</span> and different values of <span class="math notranslate nohighlight">\(p\)</span> and we will see that none of them have larger entropy than <span class="math notranslate nohighlight">\(qu\)</span>. We will need to increase <span class="math notranslate nohighlight">\(n\)</span> <span class="math notranslate nohighlight">\(\approx 3\)</span> times to find <em>the first</em> binomial distribution with larger entropy than <span class="math notranslate nohighlight">\(qu\)</span>.</p>
<p>Let us move to the next row. We generate distribution <span class="math notranslate nohighlight">\(r\)</span> by taking <span class="math notranslate nohighlight">\(q\)</span> and <em>shifting</em> it to the right and then normalizing (to ensure the sum of all probabilities is 1). As <span class="math notranslate nohighlight">\(r\)</span> is more spread than <span class="math notranslate nohighlight">\(q\)</span> its entropy is larger. <span class="math notranslate nohighlight">\(ru\)</span> is the Uniform distribution with the same number of possible events as <span class="math notranslate nohighlight">\(r\)</span> (22), notice we are including as possible values those <em>in the valley between both peaks</em>. Once again the entropy of the <em>Uniform</em> version is the one with the largest entropy. So far entropy seems to be proportional to the variance of a distribution, but before jumping to conclusions let us check the last two distributions in <a class="reference internal" href="#fig-entropy"><span class="std std-numref">Fig. 192</span></a>. <span class="math notranslate nohighlight">\(s\)</span> is essentially the same as <span class="math notranslate nohighlight">\(r\)</span> but with a more extensive <em>valley between both peaks</em> and as we can see the entropy remains the same. The reason is basically that entropy does not care about those events in the <em>valley</em> with probability zero, it only cares about possible events. <span class="math notranslate nohighlight">\(su\)</span> is constructed by replacing the two peaks in <span class="math notranslate nohighlight">\(s\)</span> with <span class="math notranslate nohighlight">\(qu\)</span> (and normalizing). We can see that <span class="math notranslate nohighlight">\(su\)</span> has lower entropy than <span class="math notranslate nohighlight">\(ru\)</span> even when it looks more spread, after a more careful inspection we can see that <span class="math notranslate nohighlight">\(su\)</span> spread the total probability between fewer events (22) than <span class="math notranslate nohighlight">\(ru\)</span> (with 23 events), and thus it makes totally sense for it to have lower entropy.</p>
</div>
<div class="section" id="kl">
<span id="dkl"></span><h2>11.3 KL 散度<a class="headerlink" href="#kl" title="Permalink to this headline">¶</a></h2>
<p>统计学中常用一个概率分布<span class="math notranslate nohighlight">\(q\)</span>来表示另一个<span class="math notranslate nohighlight">\(p\)</span>，我们通常在不知道<span class="math notranslate nohighlight">\(p\)</span>但可以用<span class="math notranslate nohighlight">\(q\)</span>近似的情况下这样做。或者 <span class="math notranslate nohighlight">\(p\)</span> 很复杂，我们想找到一个更简单或更方便的分布 <span class="math notranslate nohighlight">\(q\)</span>。在这种情况下，我们可能会问通过使用 <span class="math notranslate nohighlight">\(q\)</span> 来表示 <span class="math notranslate nohighlight">\(p\)</span>，我们丢失了多少信息，或者等效地，我们引入了多少额外的不确定性。直观地说，我们希望数量只有在 <span class="math notranslate nohighlight">\(q\)</span> 等于 <span class="math notranslate nohighlight">\(p\)</span> 时才变为零，否则为正值。根据方程 <a class="reference internal" href="#equation-eq-entropy">(95)</a> 中的熵定义，我们可以通过计算 <span class="math notranslate nohighlight">\(\log(p)\)</span> 和 <span class="math notranslate nohighlight">\(\log(q)\)</span> 之间的差值的期望值来实现这一点。这被称为 Kullback-Leibler (KL) 散度：</p>
<div class="math notranslate nohighlight" id="equation-eq-kl-divergence">
<span class="eqno">(96)<a class="headerlink" href="#equation-eq-kl-divergence" title="Permalink to this equation">¶</a></span>\[\mathbb{KL}(p \parallel q) = \mathbb{E}_p[\log{p}-\log{q}]   \]</div>
<p>因此，<span class="math notranslate nohighlight">\(\mathbb{KL}(p \parallel q)\)</span> 给出了当使用 <span class="math notranslate nohighlight">\(q\)</span> 来近似 <span class="math notranslate nohighlight">\(p\)</span> 时对数概率的平均差异。因为事件根据 <span class="math notranslate nohighlight">\(p\)</span> 出现在我们面前，我们需要计算关于 <span class="math notranslate nohighlight">\(p\)</span> 的期望。对于离散分布，我们有：</p>
<div class="math notranslate nohighlight">
\[\mathbb{KL}(p \parallel q) = \sum_{i}^n p_i (\log{p_i} - \log{q_i})\]</div>
<p>使用对数属性，我们可以将其写成可能是表示 KL 散度的最常见方式：</p>
<div class="math notranslate nohighlight">
\[\mathbb{KL}(p \parallel q)  = \sum_{i}^n p_i \log{\frac{p_i}{q_i}}\]</div>
<p>我们还可以安排项并将 <span class="math notranslate nohighlight">\(\mathbb{KL}(p \parallel q)\)</span> 写为：</p>
<div class="math notranslate nohighlight">
\[\mathbb{KL}(p \parallel q) = - \sum_{i}^n p_i (\log{q_i} - \log{p_i})\]</div>
<p>当我们扩展上述重新排列时，我们发现：</p>
<div class="math notranslate nohighlight">
\[\mathbb{KL}(p \parallel q) =  \overbrace{-\sum_{i}^n p_i \log{q_i}}^{H(p, q)} -  \overbrace{\left(-\sum_{i}^n p_i \log{p_i}\right)}^{H(p)}\]</div>
<p>正如我们在上一节中已经看到的，<span class="math notranslate nohighlight">\(H(p)\)</span> 是 <span class="math notranslate nohighlight">\(p\)</span> 的熵。</p>
<p><span class="math notranslate nohighlight">\(H(p,q) = - \mathbb{E}_p[\log{q}]\)</span> 类似于 <span class="math notranslate nohighlight">\(q\)</span> 的熵，但根据 <span class="math notranslate nohighlight">\(p\)</span> 的值进行评估。</p>
<p>重新排序上面我们得到：</p>
<div class="math notranslate nohighlight">
\[H(p, q) = H(p) + D_\text{KL}(p \parallel q)\]</div>
<p>这表明，当使用 <span class="math notranslate nohighlight">\(q\)</span> 表示 <span class="math notranslate nohighlight">\(p\)</span> 时，KL 散度可以有效地解释为关于 <span class="math notranslate nohighlight">\(H(p)\)</span> 的额外熵。</p>
<p>为了获得一点直觉，我们将计算 KL 散度的一些值并绘制它们。我们将使用与 <a class="reference internal" href="#fig-entropy"><span class="std std-numref">Fig. 192</span></a> 中相同的分布。</p>
<div class="literal-block-wrapper docutils container" id="kl-varies-dist">
<div class="code-block-caption"><span class="caption-number">Listing 166 </span><span class="caption-text">kl_varies_dist</span><a class="headerlink" href="#kl-varies-dist" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dists</span> <span class="o">=</span> <span class="p">[</span><span class="n">q_pmf</span><span class="p">,</span> <span class="n">qu_pmf</span><span class="p">,</span> <span class="n">r_pmf</span><span class="p">,</span> <span class="n">ru_pmf</span><span class="p">,</span> <span class="n">s_pmf</span><span class="p">,</span> <span class="n">su_pmf</span><span class="p">]</span>
<span class="n">names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"q"</span><span class="p">,</span> <span class="s2">"qu"</span><span class="p">,</span> <span class="s2">"r"</span><span class="p">,</span> <span class="s2">"ru"</span><span class="p">,</span> <span class="s2">"s"</span><span class="p">,</span> <span class="s2">"su"</span><span class="p">]</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.subplots.html#matplotlib.pyplot.subplots" title="matplotlib.pyplot.subplots"><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span></a><span class="p">()</span>
<span class="n">KL_matrix</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">((</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">dist_i</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dists</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">dist_j</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dists</span><span class="p">):</span>
        <span class="n">KL_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.entropy.html#scipy.stats.entropy" title="scipy.stats.entropy"><span class="n">stats</span><span class="o">.</span><span class="n">entropy</span></a><span class="p">(</span><span class="n">dist_i</span><span class="p">,</span> <span class="n">dist_j</span><span class="p">)</span>

<span class="n">im</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">KL_matrix</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">"cet_gray"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>代码块 <a class="reference internal" href="#kl-varies-dist"><span class="std std-ref">kl_varies_dist</span></a> 的结果显示在 <a class="reference internal" href="#fig-kl-heatmap"><span class="std std-numref">Fig. 193</span></a> 中。 <a class="reference internal" href="#fig-kl-heatmap"><span class="std std-numref">Fig. 193</span></a> 有两个特征立即弹出。首先，图形不是对称的，原因是<span class="math notranslate nohighlight">\(\mathbb{KL}(p \parallel q)\)</span>不一定和<span class="math notranslate nohighlight">\(\mathbb{KL}(q \parallel p)\)</span>一样。其次，我们有很多白细胞。它们代表 <span class="math notranslate nohighlight">\(\infty\)</span> 值。 KL 散度的定义使用以下约定 <span id="id46">[<a class="reference internal" href="references.html#id17">133</a>]</span>：</p>
<div class="math notranslate nohighlight">
\[0 \log \frac{0}{0} = 0, \quad
0 \log \frac{0}{q(\boldsymbol{x})} = 0, \quad
p(\boldsymbol{x}) \log \frac{p(\boldsymbol{x})}{0} = \infty\]</div>
<div class="figure align-default" id="fig-kl-heatmap">
<a class="reference internal image-reference" href="../_images/KL_heatmap.png"><img alt="../_images/KL_heatmap.png" src="../_images/KL_heatmap.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 193 </span><span class="caption-text">在 <a class="reference internal" href="#fig-entropy"><span class="std std-numref">Fig. 192</span></a> 中显示的分布 q、qu、r、ru、s 和 su 的所有成对组合的 KL 散度，白色用于表示无穷大值。</span><a class="headerlink" href="#fig-kl-heatmap" title="Permalink to this image">¶</a></p>
</div>
<p>基于 KL 散度，我们可以激励使用对数分数来计算预期的对数逐点预测密度（ 在 <a class="reference internal" href="chp_02.html#chap1bis"><span class="std std-ref"> 第 2 章</span></a> 方程 <a class="reference internal" href="chp_02.html#equation-eq-elpd-practice">(20)</a> 中介绍 ）。</p>
<p>让我们假设我们有 <span class="math notranslate nohighlight">\(k\)</span> 模型后验 <span class="math notranslate nohighlight">\(\{q_{M_1}, q_{M_2}, \cdots q_{M_k}\}\)</span>，让我们进一步假设我们知道 <em>true</em> 模型 <span class="math notranslate nohighlight">\(M_0\)</span> 然后我们可以计算：</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{split}
  \mathbb{KL}(p_{M_0} \parallel q_{M_1}) =&amp;\; \mathbb{E}[\log{p_{M_0}}] - \mathbb{E}[\log{q_{M_1}}] \\
  \mathbb{KL}(p_{M_0} \parallel q_{M_2}) =&amp;\; \mathbb{E}[\log{p_{M_0}}] - \mathbb{E}[\log{q_{M_2}}] \\
  &amp;\cdots \\
  \mathbb{KL}(p_{M_0} \parallel q_{M_k}) =&amp;\; \mathbb{E}[\log{p_{M_0}}] - \mathbb{E}[\log{q_{M_k}}]
  \end{split}\end{split}\]</div>
<p>这似乎是一种徒劳的练习，因为在现实生活中我们不知道真正的模型 <span class="math notranslate nohighlight">\(M_0\)</span>。诀窍是要意识到 <span class="math notranslate nohighlight">\(p_{M_0}\)</span> 对于所有比较都是相同的，因此基于 KL-divergence 构建排名等同于基于 log-score 进行排名。</p>
</div>
<div class="section" id="information-criterion">
<span id="id47"></span><h2>11.4 信息准则<a class="headerlink" href="#information-criterion" title="Permalink to this headline">¶</a></h2>
<p>信息标准是统计模型预测准确性的度量。它考虑了模型对数据的拟合程度并惩罚模型的复杂性。根据他们如何计算这两个术语，有许多不同的信息标准。最著名的家庭成员，尤其是对于非贝叶斯主义者，是 Akaike 信息准则 (AIC) <span id="id48">[<a class="reference internal" href="references.html#id23">134</a>]</span>。它被定义为两项之和。 <span class="math notranslate nohighlight">\(\log p(y_i \mid \hat{\theta}_{mle})\)</span> 衡量模型对数据的拟合程度以及惩罚项 <span class="math notranslate nohighlight">\(p_{AIC}\)</span> 以说明我们使用相同数据的事实拟合模型并评估模型。</p>
<div class="math notranslate nohighlight">
\[AIC = -2 \sum_{i}^{n} \log p(y_i \mid \hat{\theta}_{mle}) + 2 p_{AIC}\]</div>
<p>其中 <span class="math notranslate nohighlight">\(\hat{\theta}_{mle}\)</span> 是 <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span> 的最大似然估计，<span class="math notranslate nohighlight">\(p_{AIC}\)</span> 只是模型中参数的数量。</p>
<p>AIC 在非贝叶斯设置中非常流行，但不能很好地处理贝叶斯模型的一般性。它不使用完整的后验分布，因此丢弃了可能有用的信息。</p>
<p>平均而言，当我们从平面先验转向弱信息或信息先验时，和/或如果我们在模型中添加更多结构，比如分层模型，AIC 的表现会越来越差。 AIC 假设后验可以由高斯分布很好地表示（至少渐近地），但是对于许多模型来说，这并不正确，包括层次模型、混合模型、神经网络等。总之我们希望使用一些更好的备择方案。</p>
<p>广泛适用的信息准则 (<code class="docutils literal notranslate"><span class="pre">WAIC</span></code> <a class="footnote-reference brackets" href="#id125" id="id49">20</a>) <span id="id50">[<a class="reference internal" href="references.html#id14">135</a>]</span> 可以看作是 AIC 的完全贝叶斯扩展。它还包含两个术语，与 Akaike 标准的解释大致相同。最重要的区别是这些项是使用完整的后验分布计算的。</p>
<div class="math notranslate nohighlight" id="equation-eq-waic">
<span class="eqno">(97)<a class="headerlink" href="#equation-eq-waic" title="Permalink to this equation">¶</a></span>\[WAIC =  \sum_i^n \log \left(\frac{1}{s} \sum_{j}^S p(y_i \mid \boldsymbol{\theta}^j) \right) \; - \sum_i^n  \left(\mathop{\mathbb{V}}_{j}^s \log p(Y_i \mid \boldsymbol{\theta}^j) \right)   \]</div>
<p>方程 <a class="reference internal" href="#equation-eq-waic">(97)</a> 中的第一项只是 AIC 中的对数似然，但逐点评估，即在 <span class="math notranslate nohighlight">\(n\)</span> 观测值上的每个 <span class="math notranslate nohighlight">\(i\)</span> 观测数据点。我们通过取后验 <span class="math notranslate nohighlight">\(s\)</span> 样本的平均值来考虑后验的不确定性。第一项是计算公式 <a class="reference internal" href="chp_02.html#equation-eq-elpd">(19)</a> 中定义的理论预期对数逐点预测密度 (ELPD) 及其在公式 <a class="reference internal" href="chp_02.html#equation-eq-elpd-practice">(20)</a> 中的近似值的实用方法。</p>
<p>第二项可能看起来有点奇怪，<span class="math notranslate nohighlight">\(​​s\)</span> 后验样本（每个观测）的方差也是如此。直观地，我们可以看到，对于每个观测，如果后验分布的对数似然相似，则方差会很低，如果后验分布中不同样本的对数似然变化更大，则方差会更大。我们发现对后验<em>细节</em>敏感的观测越多，惩罚就越大。我们也可以从另一个等效的角度来看待这一点；更灵活的模型是可以有效容纳更多数据集的模型。例如，包含直线但也包含向上曲线的模型比只允许直线的模型更灵活；因此，在后一个模型上评估的那些观测值的对数似然平均将具有更高的方差。如果更灵活的模型不能用更高的估计 ELPD 来补偿这种惩罚，那么我们会将更简单的模型列为更好的选择。因此，方程 <a class="reference internal" href="#equation-eq-waic">(97)</a> 中的方差项通过惩罚过于复杂的模型来防止过度拟合，并且可以松散地解释为 AIC 中的有效参数数量。</p>
<p>AIC 和 <code class="docutils literal notranslate"><span class="pre">WAIC</span></code> 都没有试图衡量模型是否<em>真实</em>，它们只是比较替代模型的相对衡量。</p>
<p>从贝叶斯的角度来看，先验是模型的一部分，但 <code class="docutils literal notranslate"><span class="pre">WAIC</span></code> 是在后验上评估的，并且先验效果只是通过影响结果后验的方式间接考虑在内。还有其他信息标准，如 BIC 和 WBIC，试图回答这个问题，可以看作是边际似然的近似值，但我们不会在本书中讨论它们。</p>
</div>
<div class="section" id="loo-depth">
<span id="id51"></span><h2>11.5 深入理解留一交叉验证法<a class="headerlink" href="#loo-depth" title="Permalink to this headline">¶</a></h2>
<p>正如本书 <a class="reference internal" href="chp_02.html#cv-and-loo"><span class="std std-ref">2.5.2 交叉验证和留一法</span></a> 部分所讨论的，我们使用术语 <code class="docutils literal notranslate"><span class="pre">LOO</span></code> 来指代一种特定的方法来近似留一法交叉验证 (LOO-CV)，称为帕累托平滑重要性抽样留一法交叉验证(PSIS-LOO-CV)。在本节中，我们将讨论此方法的一些细节。</p>
<p><code class="docutils literal notranslate"><span class="pre">LOO</span></code> 是 <code class="docutils literal notranslate"><span class="pre">WAIC</span></code> 的替代方案，实际上可以证明它们渐近收敛到相同的数值 <span id="id52">[<a class="reference internal" href="references.html#id14">135</a>, <a class="reference internal" href="references.html#id21">136</a>]</span>。尽管如此，<code class="docutils literal notranslate"><span class="pre">LOO</span></code> 为从业者带来了两个重要的优势。它在有限样本设置中更加稳健，并且在计算期间提供有用的诊断 <span id="id53">[<a class="reference internal" href="references.html#id20">16</a>, <a class="reference internal" href="references.html#id21">136</a>]</span>。</p>
<p>在 LOO-CV 下，新数据集的预期对数逐点预测密度为：</p>
<div class="math notranslate nohighlight">
\[\text{ELPD}_\text{LOO-CV} = \sum_{i=1}^{n} \log
  \int \ p(y_i \mid \boldsymbol{\theta}) \; p(\boldsymbol{\theta} \mid y_{-i}) d\boldsymbol{\theta}
  \tag{\ref{eq:elpd_loo_cv}}\]</div>
<p>其中 <span class="math notranslate nohighlight">\(y_{-i}\)</span> 表示不包括 <span class="math notranslate nohighlight">\(i\)</span> 观测的数据集。</p>
<p>鉴于在实践中我们不知道 <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span> 的值，我们可以使用来自后验的 <span class="math notranslate nohighlight">\(s\)</span> 样本来近似方程 <span class="math notranslate nohighlight">\(\ref{eq:elpd_loo_cv}\)</span>：</p>
<div class="math notranslate nohighlight" id="equation-eq-loo-cv-naive">
<span class="eqno">(98)<a class="headerlink" href="#equation-eq-loo-cv-naive" title="Permalink to this equation">¶</a></span>\[\sum_{i}^{n} \log
  \left(\frac{1}{s}\sum_j^s \ p(y_i \mid \boldsymbol{\theta_{-i}^j}) \right)
  \]</div>
<p>请注意，这个术语看起来类似于方程 <a class="reference internal" href="#equation-eq-waic">(97)</a> 中的第一项，除了我们每次都在计算 <span class="math notranslate nohighlight">\(n\)</span> 后验，删除一个观测值。因此，与 <code class="docutils literal notranslate"><span class="pre">WAIC</span></code> 相反，我们不需要添加惩罚项。在 <a class="reference internal" href="#equation-eq-loo-cv-naive">(98)</a> 中计算 <span class="math notranslate nohighlight">\(\text{ELPD}_\text{LOO-CV}\)</span> 非常昂贵，因为我们需要计算 <span class="math notranslate nohighlight">\(n\)</span> 后验。幸运的是，如果 <span class="math notranslate nohighlight">\(n\)</span> 观测是条件独立的，我们可以用方程 <a class="reference internal" href="#equation-eq-loo">(99)</a> <span id="id54">[<a class="reference internal" href="references.html#id21">136</a>, <a class="reference internal" href="references.html#id24">137</a>]</span> 来近似方程 <a class="reference internal" href="#equation-eq-loo-cv-naive">(98)</a>：</p>
<div class="math notranslate nohighlight" id="equation-eq-loo">
<span class="eqno">(99)<a class="headerlink" href="#equation-eq-loo" title="Permalink to this equation">¶</a></span>\[\text{ELPD}_{psis-loo} = \sum_i^n \log \sum_j^s w_i^j p(y_i \mid \boldsymbol{\theta}^j)
  \]</div>
<p>其中 <span class="math notranslate nohighlight">\(w\)</span> 是归一化权重的向量。</p>
<p>为了计算 <span class="math notranslate nohighlight">\(w\)</span>，我们使用了重要性抽样，这是一种估计感兴趣的特定分布 <span class="math notranslate nohighlight">\(f\)</span> 的属性的技术，因为我们只有来自不同分布 <span class="math notranslate nohighlight">\(g\)</span> 的样本。当从 <span class="math notranslate nohighlight">\(g\)</span> 采样比从 <span class="math notranslate nohighlight">\(f\)</span> 采样更容易时，使用重要性采样是有意义的。如果我们有一组来自随机变量 <span class="math notranslate nohighlight">\(X\)</span> 的样本，并且我们能够逐点评估 <span class="math notranslate nohighlight">\(g\)</span> 和 <span class="math notranslate nohighlight">\(f\)</span>，我们可以将重要性权重计算为：</p>
<div class="math notranslate nohighlight" id="equation-eq-importance-weights">
<span class="eqno">(100)<a class="headerlink" href="#equation-eq-importance-weights" title="Permalink to this equation">¶</a></span>\[w_i =  \frac{f(x_i)}{g(x_i)}\]</div>
<p>在计算上，它是这样的：</p>
<ul class="simple">
<li><p>从 <span class="math notranslate nohighlight">\(g\)</span> 中抽取 <span class="math notranslate nohighlight">\(N\)</span> 个样本 <span class="math notranslate nohighlight">\(x_i\)</span></p></li>
<li><p>计算每个样本的概率<span class="math notranslate nohighlight">\(g(x_i)\)</span></p></li>
<li><p>在 <span class="math notranslate nohighlight">\(N\)</span> 个样本 <span class="math notranslate nohighlight">\(f(x_i)\)</span> 上评估 <span class="math notranslate nohighlight">\(f\)</span></p></li>
<li><p>计算重要性权重 <span class="math notranslate nohighlight">\(w_i = \frac{f(x_i)}{g(x_i)}\)</span></p></li>
<li><p>从 <span class="math notranslate nohighlight">\(g\)</span> 中返回 <span class="math notranslate nohighlight">\(N\)</span> 个样本，权重为 <span class="math notranslate nohighlight">\(w\)</span>、<span class="math notranslate nohighlight">\((x_i, w_i)\)</span>，可以插入到一些估计器中</p></li>
</ul>
<p><a class="reference internal" href="#fig-importance-sampling"><span class="std std-numref">Fig. 194</span></a> 显示了使用两个不同的提案分布来近似相同目标分布（虚线）的示例。在第一行，提案比目标分布更宽。在第二行，提案比目标分布窄。正如我们所见，第一种情况下的近似值更好。这是重要性抽样的一般特征。</p>
<div class="figure align-default" id="fig-importance-sampling">
<a class="reference internal image-reference" href="../_images/importance_sampling.png"><img alt="../_images/importance_sampling.png" src="../_images/importance_sampling.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 194 </span><span class="caption-text">重要性抽样。在左侧，我们有来自建议分布 <span class="math notranslate nohighlight">\(g\)</span> 的样本的 KDE，在右侧，虚线表示目标分布，实线表示在重新加权来自建议分布的样本后的近似分布，其权重计算如下<a class="reference internal" href="#equation-eq-importance-weights">(100)</a>。</span><a class="headerlink" href="#fig-importance-sampling" title="Permalink to this image">¶</a></p>
</div>
<p>回到 <code class="docutils literal notranslate"><span class="pre">LOO</span></code>，我们计算的分布是后验分布。为了评估模型，我们需要从留一后验分布中抽取样本，因此我们要计算的重要性权重为：</p>
<div class="math notranslate nohighlight">
\[w_i^j = \frac{p(\theta^j \mid y{-i} )}{p(\theta^j \mid y)} \propto \frac{1}{p(y_i \mid \theta^j)}\]</div>
<p>请注意，这种比例是个好消息，因为它允许我们几乎免费计算 <span class="math notranslate nohighlight">\(w\)</span>。但是，后验分布的尾部可能比留一法分布更细，正如我们在 <a class="reference internal" href="#fig-importance-sampling"><span class="std std-numref">Fig. 194</span></a> 中看到的那样，这可能导致估计不佳。</p>
<p>从数学上讲，问题在于重要性权重可能具有很高甚至无限的方差。为了控制方差，<code class="docutils literal notranslate"><span class="pre">LOO</span></code> 应用了一个平滑过程，该过程涉及用估计的帕累托分布中的值替换最大的重要性权重。这有助于使 <code class="docutils literal notranslate"><span class="pre">LOO</span></code> 更加健壮 <span id="id55">[<a class="reference internal" href="references.html#id21">136</a>]</span>。</p>
<p>此外，帕累托分布的估计 <span class="math notranslate nohighlight">\(\hat\kappa\)</span> 参数可用于检测高度影响的观测，即被排除在外时对预测分布有很大影响的观测值。通常，较高的 <span class="math notranslate nohighlight">\(\hat \kappa\)</span> 值可能表明数据或模型存在问题，尤其是当 <span class="math notranslate nohighlight">\(\hat \kappa &gt; 0.7\)</span> <span id="id56">[<a class="reference internal" href="references.html#id20">16</a>, <a class="reference internal" href="references.html#id19">22</a>]</span> 时。</p>
</div>
<div class="section" id="jeffreys">
<span id="jeffreys-prior-derivation"></span><h2>11.6 Jeffreys 先验的推导<a class="headerlink" href="#jeffreys" title="Permalink to this headline">¶</a></h2>
<p>在本节中，我们将展示如何找到二项似然的 Jeffreys 先验，首先是成功次数参数 <span class="math notranslate nohighlight">\(\theta\)</span>，然后是几率参数 <span class="math notranslate nohighlight">\(\kappa\)</span>，其中 <span class="math notranslate nohighlight">\(\kappa = \frac{\ theta}{1-\theta}\)</span>。</p>
<p>回想一下 <a class="reference internal" href="chp_01.html#chap1"><span class="std std-ref">第 1 章</span></a> ，对于 <span class="math notranslate nohighlight">\(\theta\)</span> 的一维情况 JP 定义为：</p>
<div class="math notranslate nohighlight">
\[p(\theta) \propto \sqrt{I(\theta)}   \]</div>
<p>其中 <span class="math notranslate nohighlight">\(I(\theta)\)</span> 是 Fisher 信息：</p>
<div class="math notranslate nohighlight">
\[I(\theta) = - \mathbb{E_{Y}}\left[\frac{d^2}{d\theta^2} \log p(Y \mid \theta)\right]\]</div>
<div class="section" id="theta-jeffreys">
<span id="jeffreys-prior-for-the-binomial-likelihood-in-terms-of-theta"></span><h3>11.6.1 依据 <span class="math notranslate nohighlight">\(\theta\)</span> 的二项似然 Jeffreys 先验<a class="headerlink" href="#theta-jeffreys" title="Permalink to this headline">¶</a></h3>
<p>二项式似然可以表示为：</p>
<div class="math notranslate nohighlight" id="equation-eq-binomial-kernel">
<span class="eqno">(101)<a class="headerlink" href="#equation-eq-binomial-kernel" title="Permalink to this equation">¶</a></span>\[p(Y \mid \theta) \propto \theta^{y} (1-\theta)^{n-y} \]</div>
<p>其中 <span class="math notranslate nohighlight">\(y\)</span> 是成功的次数，<span class="math notranslate nohighlight">\(n\)</span> 是试验的总数，因此 <span class="math notranslate nohighlight">\(n-y\)</span> 是失败的次数。我们写成比例，因为似然中的二项式系数不依赖于 <span class="math notranslate nohighlight">\(\theta\)</span>。</p>
<p>为了计算 Fisher 信息，我们需要取似然的对数：</p>
<div class="math notranslate nohighlight">
\[\ell = \log(p(Y \mid \theta)) \propto y \log(\theta) + (n-y) \log(1-\theta)\]</div>
<p>然后计算二阶导数：</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\begin{split}
\frac{d \ell}{d\theta} &amp;= \frac{y}{\theta} - \frac{n-y}{1-\theta} \\
\frac{d^{2} \ell}{d \theta^{2}} &amp;= -\frac{y}{\theta^{2}} - \frac{n-y}{ (1-\theta)^{2}}
\end{split}\end{aligned}\end{split}\]</div>
<p>Fisher信息是似然二阶导数的期望值，则：</p>
<div class="math notranslate nohighlight">
\[I(\theta) = - \mathbb{E}_{Y}\left[-\frac{y}{\theta^{2}} + \frac{n-y}{ (1-\theta)^{2}} \right]\]</div>
<p>由于 <span class="math notranslate nohighlight">\(\mathbb{E}[y] = n\theta\)</span>，我们可以写成：</p>
<div class="math notranslate nohighlight">
\[I(\theta)= \frac{n\theta}{\theta^{2}} - \frac{n - n \theta}{(1-\theta)^{2}}\]</div>
<p>我们可以重写为：</p>
<div class="math notranslate nohighlight">
\[I(\theta)= \frac{n}{\theta} - \frac{n (1 -\theta)}{(1-\theta)^{2}} = \frac{n}{\theta} - \frac{n}{(1-\theta)}\]</div>
<p>我们可以用一个共同的分母来表达这些分数，</p>
<div class="math notranslate nohighlight">
\[I(\theta)= n \left[ \frac{1 - \theta}{\theta (1 - \theta)} - \frac{\theta}{\theta (1-\theta)}\right]\]</div>
<p>通过重组：</p>
<div class="math notranslate nohighlight">
\[I(\theta) = n \frac{1}{\theta (1-\theta)}\]</div>
<p>如果我们省略 <span class="math notranslate nohighlight">\(n\)</span> 那么我们可以这样写：</p>
<div class="math notranslate nohighlight" id="equation-eq-fisher-info">
<span class="eqno">(102)<a class="headerlink" href="#equation-eq-fisher-info" title="Permalink to this equation">¶</a></span>\[I(\theta) \propto \frac{1}{\theta (1-\theta)} = \theta^{-1} (1-\theta)^{-1} \]</div>
<p>最后，我们需要对方程 <a class="reference internal" href="#equation-eq-fisher-info">(102)</a> 中的 Fisher 信息取平方根，从而得出二项式似然的 <span class="math notranslate nohighlight">\(\theta\)</span> 的 Jeffreys 先验如下：</p>
<div class="math notranslate nohighlight" id="equation-eq-alice-prior">
<span class="eqno">(103)<a class="headerlink" href="#equation-eq-alice-prior" title="Permalink to this equation">¶</a></span>\[\begin{aligned}
p(\theta) \propto \theta^{-0.5} (1-\theta)^{-0.5}
\end{aligned}\]</div>
</div>
<div class="section" id="kappa-jeffreys">
<span id="jeffreys-prior-for-the-binomial-likelihood-in-terms-of-kappa"></span><h3>11.6.2 依据 <span class="math notranslate nohighlight">\(\kappa\)</span> 的二项似然 Jeffreys 先验<a class="headerlink" href="#kappa-jeffreys" title="Permalink to this headline">¶</a></h3>
<p>现在让我们看看如何根据赔率 <span class="math notranslate nohighlight">\(\kappa\)</span> 获得二项式似然的 Jeffreys 先验。我们首先替换表达式 <a class="reference internal" href="#equation-eq-binomial-kernel">(101)</a> 中的 <span class="math notranslate nohighlight">\(\theta = \frac{\kappa}{\kappa + 1}\)</span>：</p>
<div class="math notranslate nohighlight">
\[p(Y \mid \kappa) \propto \left({\frac{\kappa}{\kappa + 1}}\right)^{y} \left(1-{\frac{\kappa}{\kappa +1}}\right)^{n-y}\]</div>
<p>也可以写成：</p>
<div class="math notranslate nohighlight">
\[p(Y \mid \kappa) \propto \kappa^y (\kappa + 1)^{-y} (\kappa +1)^{-n + y}\]</div>
<p>并进一步简化为：</p>
<div class="math notranslate nohighlight" id="equation-eq-likelihood-binom-odds">
<span class="eqno">(104)<a class="headerlink" href="#equation-eq-likelihood-binom-odds" title="Permalink to this equation">¶</a></span>\[p(Y \mid \kappa) \propto \kappa^y (\kappa + 1)^{-n} \]</div>
<p>现在我们需要取对数：</p>
<div class="math notranslate nohighlight">
\[\ell = \log(p(Y \mid \kappa)) \propto y \log{\kappa} -n \log{(\kappa + 1)}\]</div>
<p>然后我们计算二阶导数：</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\begin{split}
\frac{d \ell}{d{\kappa}} &amp;= \frac{y}{\kappa} - \frac{n}{\kappa + 1} \\
\frac{d^2 \ell}{d {\kappa^2}} &amp;= -\frac{y}{\kappa^2} + \frac{n}{(\kappa+1)^2}
\end{split}\end{aligned}\end{split}\]</div>
<p>Fisher 信息是似然二阶导数的期望值，则：</p>
<div class="math notranslate nohighlight">
\[I(\kappa) = - \mathbb{E}_Y\left[-\frac{y}{\kappa^2} + \frac{n}{ (\kappa+1)^2} \right]\]</div>
<p>由于 <span class="math notranslate nohighlight">\(\mathbb{E}[y] = n \theta = n \frac{\kappa}{\kappa + 1}\)</span>，我们可以写成：</p>
<div class="math notranslate nohighlight">
\[I(\kappa) = \frac{n}{\kappa (\kappa + 1)} - \frac{n}{(\kappa + 1)^2}\]</div>
<p>我们可以用一个共同的分母来表达这些分数，</p>
<div class="math notranslate nohighlight">
\[I(\kappa) = \frac{n (\kappa + 1)}{\kappa (\kappa + 1)^2} - \frac{n \kappa}{\kappa (\kappa + 1)^2}\]</div>
<p>然后我们合并成一个分数：</p>
<div class="math notranslate nohighlight">
\[I(\kappa) = \frac{n (\kappa + 1) - n \kappa}{\kappa (\kappa + 1)^2}\]</div>
<p>然后我们将 <span class="math notranslate nohighlight">\(n\)</span> 分配给 <span class="math notranslate nohighlight">\((\kappa + 1)\)</span> 并简化：</p>
<div class="math notranslate nohighlight">
\[I(\kappa) = \frac{n}{\kappa (\kappa + 1)^2}\]</div>
<p>最后，通过取平方根，我们得到 Jeffreys 在由几率参数化时的二项似然先验：</p>
<div class="math notranslate nohighlight" id="equation-eq-bob-prior">
<span class="eqno">(105)<a class="headerlink" href="#equation-eq-bob-prior" title="Permalink to this equation">¶</a></span>\[p(\kappa) \propto \kappa^{-0.5} (1 + \kappa)^{-1} \]</div>
</div>
<div class="section" id="jeffreys-posterior-for-the-binomial-likelihood">
<span id="id57"></span><h3>11.6.3 二项似然的 Jeffreys 后验<a class="headerlink" href="#jeffreys-posterior-for-the-binomial-likelihood" title="Permalink to this headline">¶</a></h3>
<p>为了在根据 <span class="math notranslate nohighlight">\(\theta\)</span> 参数化似然性时获得 Jeffrey 的后验，我们可以将方程 <a class="reference internal" href="#equation-eq-binomial-kernel">(101)</a> 与方程 <a class="reference internal" href="#equation-eq-alice-prior">(103)</a> 结合起来</p>
<div class="math notranslate nohighlight" id="equation-eq-alice-posterior">
<span class="eqno">(106)<a class="headerlink" href="#equation-eq-alice-posterior" title="Permalink to this equation">¶</a></span>\[p(\theta \mid Y) \propto  \theta^{y} (1-\theta)^{n-y} \theta^{-0.5} (1-\theta)^{-0.5} = \theta^{y-0.5} (1-\theta)^{n-y-0.5} \]</div>
<p>类似地，当似然用 <span class="math notranslate nohighlight">\(\kappa\)</span> 参数化时，Jeffreys 的后验我们可以将 <a class="reference internal" href="#equation-eq-likelihood-binom-odds">(104)</a> 与 <a class="reference internal" href="#equation-eq-bob-prior">(105)</a> 结合起来</p>
<div class="math notranslate nohighlight" id="equation-eq-bob-posterior">
<span class="eqno">(107)<a class="headerlink" href="#equation-eq-bob-posterior" title="Permalink to this equation">¶</a></span>\[p(\kappa \mid Y) \propto \kappa^y (\kappa + 1)^{-n}  \kappa^{-0.5} (1 + \kappa)^{-1} = \kappa^{(y-0.5)}  (\kappa + 1)^{(-n-1)}) \]</div>
</div>
</div>
<div class="section" id="marginal-likelihood">
<span id="id58"></span><h2>11.7 <code class="docutils literal notranslate"><span class="pre">边缘似然</span></code><a class="headerlink" href="#marginal-likelihood" title="Permalink to this headline">¶</a></h2>
<p>对于某些模型，例如使用共轭先验的模型，<code class="docutils literal notranslate"><span class="pre">边缘似然</span></code>在分析上是易于处理的。其余的，数值计算这个积分是出了名的困难，因为这涉及对通常复杂且高度可变的函数 <span id="id59">[<a class="reference internal" href="references.html#id30">138</a>]</span> 的高维积分。在本节中，我们将尝试直观地了解为什么这通常是一项艰巨的任务。</p>
<p>在数值上，在低维度上，我们可以通过在网格上评估先验和似然的乘积，然后应用梯形规则或其他类似方法来计算<code class="docutils literal notranslate"><span class="pre">边缘似然</span></code>。正如我们将在 <a class="reference internal" href="#high-dimensions"><span class="std std-ref">11.8 走出平地</span></a> 部分中看到的，使用网格不能很好地随维度缩放，因为随着模型中变量数量的增加，所需的网格点的数量会迅速增加。</p>
<p>因此，基于网格的方法对于具有多个变量的问题变得不切实际。蒙特卡洛积分也可能存在问题，至少在最简单的实现中是这样（参见第 <a class="reference internal" href="#high-dimensions"><span class="std std-ref">11.8 走出平地</span></a> 节）。</p>
<p>出于这个原因，已经提出了许多专门的方法来计算<code class="docutils literal notranslate"><span class="pre">边缘似然</span></code> <span id="id60">[<a class="reference internal" href="references.html#id30">138</a>]</span>。这里我们只讨论其中之一。我们主要关心的不是学习如何在实践中计算<code class="docutils literal notranslate"><span class="pre">边缘似然</span></code>，而是说明为什么很难做到。</p>
<div class="section" id="harmonic-mean">
<span id="id61"></span><h3>11.7.1 调和平均估计器<a class="headerlink" href="#harmonic-mean" title="Permalink to this headline">¶</a></h3>
<p>一个相当臭名昭著的<code class="docutils literal notranslate"><span class="pre">边缘似然</span></code>估计器是调和平均估计器 <span id="id62">[<a class="reference internal" href="references.html#id29">139</a>]</span>。这个估计器的一个非常吸引人的特性是它只需要来自后验的样本 <span class="math notranslate nohighlight">\(s\)</span> ：</p>
<div class="math notranslate nohighlight" id="equation-eq-harmonic-mean-approx">
<span class="eqno">(108)<a class="headerlink" href="#equation-eq-harmonic-mean-approx" title="Permalink to this equation">¶</a></span>\[p(Y) \approx \left(\frac{1}{s} \sum_{i=1}^{s} \frac{1}{p(Y \mid \boldsymbol{\theta}_i)} \right)^{-1} \]</div>
<p>我们可以看到，我们正在对取自后验的样本的似然倒数进行平均，然后计算结果的倒数。原则上，这是以下期望的有效蒙特卡洛估计：</p>
<div class="math notranslate nohighlight" id="equation-eq-harmonic-mean-expectation">
<span class="eqno">(109)<a class="headerlink" href="#equation-eq-harmonic-mean-expectation" title="Permalink to this equation">¶</a></span>\[\mathbb{E} \left[\frac{1}{p(Y \mid \boldsymbol{\theta})}\right] = \int_{\boldsymbol{\Theta}} \frac{1}{p(Y \mid \boldsymbol{\theta)}} p(\boldsymbol{\theta} \mid Y) d\boldsymbol{\theta} \]</div>
<p>请注意，公式 <a class="reference internal" href="#equation-eq-harmonic-mean-expectation">(109)</a> 是公式 <a class="reference internal" href="chp_01.html#equation-eq-posterior-expectation">(4)</a> 的一个特定实例，这似乎表明我们通过非常贝叶斯来做正确的事情。
如果我们扩展后项，我们可以写：</p>
<div class="math notranslate nohighlight">
\[\mathbb{E} \left[\frac{1}{p(Y \mid \boldsymbol{\theta})}\right] = \int_{\boldsymbol{\Theta}} \frac{1}{p(Y \mid \boldsymbol{\theta})} \frac{{p(Y \mid \boldsymbol{\theta})} p(\theta)}{p(Y)} d\boldsymbol{\theta}\]</div>
<p>我们可以简化为：</p>
<div class="math notranslate nohighlight">
\[\mathbb{E} \left[\frac{1}{p(Y \mid \boldsymbol{\theta})}\right] =  \frac{1}{p(Y)} \underbrace{\int_{\boldsymbol{\Theta}} p(\boldsymbol{\theta}) d\boldsymbol{\boldsymbol{\theta}}}_{=1} = \frac{1}{p(Y)}\]</div>
<p>我们假设先验是正确的，因此它的积分应该是 1。</p>
<p>我们可以看到公式 <a class="reference internal" href="#equation-eq-harmonic-mean-approx">(108)</a> 实际上是<code class="docutils literal notranslate"><span class="pre">边缘似然</span></code>的近似值。</p>
<p>不幸的是，好消息不会持续太久。为了接近正确答案，输入公式 <a class="reference internal" href="#equation-eq-harmonic-mean-approx">(108)</a> 所需的样本 <span class="math notranslate nohighlight">\(s\)</span> 的数量通常非常大，以至于调和平均估计器在实践中不是很有用 {cite :p}<code class="docutils literal notranslate"><span class="pre">Neal_1994,</span> <span class="pre">Friel_2011</span></code>。直观地，我们可以看到总和将由似然非常低的样本主导。更糟糕的是，调和平均估计器可以有无限的方差。无限方差意味着即使我们增加 <span class="math notranslate nohighlight">\(s\)</span> 也不会得到更好的答案，因此有时即使是大量的样本仍然可能不够用。调和平均估计器的另一个问题是它对先验的变化相当不敏感。但即使是精确的<code class="docutils literal notranslate"><span class="pre">边缘似然</span></code>实际上也对先验分布的变化非常敏感（我们稍后会展示，参见 <a class="reference internal" href="#fig-posterior-ml"><span class="std std-numref">Fig. 196</span></a>）。</p>
<p>当似然相对于先验变得更加集中时，或者当似然和先验集中到参数空间的不同区域时，这两个问题将更加严重。</p>
<p>通过使用来自峰值更高的后验的样本，相对于先验，我们将丢失先验中具有低后验密度的所有区域。粗略地说，我们可以将贝叶斯推理视为使用数据将先验更新为后验。只有在数据不是很丰富的情况下，先验和后验才会相似。</p>
<p><a class="reference internal" href="#fig-harmonic-mean-heatmap"><span class="std std-numref">Fig. 195</span></a> 显示了一个热图，其中计算调和平均估计量的相对误差与分析值相比。我们可以看到，即使对于像 <code class="docutils literal notranslate"><span class="pre">Beta-Binomial</span> <span class="pre">模型</span></code>这样的简单一维问题，谐波估计器也可能会严重失败。</p>
<div class="figure align-default" id="fig-harmonic-mean-heatmap">
<a class="reference internal image-reference" href="../_images/harmonic_mean_heatmap.png"><img alt="../_images/harmonic_mean_heatmap.png" src="../_images/harmonic_mean_heatmap.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 195 </span><span class="caption-text">热图显示使用调和平均估计器逼近 <code class="docutils literal notranslate"><span class="pre">Beta-Binomial</span> <span class="pre">模型</span></code>的<code class="docutils literal notranslate"><span class="pre">边缘似然</span></code>时的相对误差。行对应于不同的先验分布。每列是不同的观测场景，括号中的数字对应于成功和失败的数量。</span><a class="headerlink" href="#fig-harmonic-mean-heatmap" title="Permalink to this image">¶</a></p>
</div>
<p>正如我们将在 <a class="reference internal" href="#high-dimensions"><span class="std std-ref">11.8 走出平地</span></a> 部分中看到的那样，当我们增加模型的维度时，后验更多地集中在一个薄的超壳中。从这个薄壳外部获取样本与计算良好的后验近似无关。相反，当计算<code class="docutils literal notranslate"><span class="pre">边缘似然</span></code>时，仅从这个薄壳中获取样本是不够的。相反，我们需要对整个先验分布进行采样，而以正确的方式完成这可能是一项非常艰巨的任务。</p>
<p>有一些计算方法更适合计算<code class="docutils literal notranslate"><span class="pre">边缘似然</span></code>，但即使是那些也不是万无一失的。在 <a class="reference internal" href="chp_08.html#chap8"><span class="std std-ref"> 第 8 章 </span></a> 中，我们讨论了序列蒙特卡罗（SMC）方法，主要是为了进行近似贝叶斯计算，但这种方法也可以计算<code class="docutils literal notranslate"><span class="pre">边缘似然</span></code>。它起作用的主要原因是因为 SMC 使用一系列中间分布来表示从先验分布到后验分布的过渡。拥有这些<em>桥接</em>分布缓解了从广泛的先验采样和在更集中的后验进行评估的问题。</p>
</div>
<div class="section" id="bayes-factors">
<span id="id63"></span><h3>11.7.2 <code class="docutils literal notranslate"><span class="pre">边缘似然</span></code>与模型比较<a class="headerlink" href="#bayes-factors" title="Permalink to this headline">¶</a></h3>
<p>在执行推理时，<code class="docutils literal notranslate"><span class="pre">边缘似然</span></code>通常被视为归一化常数，并且在计算过程中通常可以省略或取消。相反，在模型比较 <span id="id64">[<a class="reference internal" href="references.html#id156">140</a>, <a class="reference internal" href="references.html#id158">141</a>, <a class="reference internal" href="references.html#id157">142</a>]</span> 中，<code class="docutils literal notranslate"><span class="pre">边缘似然</span></code>通常被视为至关重要。</p>
<p>为了更好地理解为什么让我们以明确表明我们的推论依赖于模型的方式编写贝叶斯定理：</p>
<div class="math notranslate nohighlight">
\[p(\boldsymbol{\theta} \mid Y, M) = {\frac {p(Y \mid \boldsymbol{\theta}, M)\; p(\boldsymbol{\theta} \mid M)}{p(Y \mid M)}}\]</div>
<p>其中 <span class="math notranslate nohighlight">\(Y\)</span> 代表数据，<span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span> 代表模型 <span class="math notranslate nohighlight">\(M\)</span> 中的参数。</p>
<p>如果我们有一组 <span class="math notranslate nohighlight">\(k\)</span> 模型并且我们的主要目标是只选择其中一个，我们可以选择<code class="docutils literal notranslate"><span class="pre">边缘似然</span></code> <span class="math notranslate nohighlight">\(p(Y \mid M)\)</span> 的最大值的一个。在假设所比较的<span class="math notranslate nohighlight">\(k\)</span>模型的离散均匀先验分布的假设下，从贝叶斯定理中选择具有最大<code class="docutils literal notranslate"><span class="pre">边缘似然</span></code>的模型是完全合理的。</p>
<div class="math notranslate nohighlight" id="equation-eq-posterior-model">
<span class="eqno">(110)<a class="headerlink" href="#equation-eq-posterior-model" title="Permalink to this equation">¶</a></span>\[p(M \mid Y) \propto p(Y \mid M)\; p(M) \]</div>
<p>如果所有模型具有相同的先验概率，则计算 <span class="math notranslate nohighlight">\(p(Y \mid M)\)</span> 等价于计算 <span class="math notranslate nohighlight">\(p(M \mid Y)\)</span>。请注意，我们讨论的是我们分配给模型 <span class="math notranslate nohighlight">\(p(M)\)</span> 的先验概率，而不是我们分配给每个模型 <span class="math notranslate nohighlight">\(p(\theta \mid M)\)</span> 参数的先验概率。</p>
<p>由于 <span class="math notranslate nohighlight">\(p(Y \mid M_k)\)</span> 的值本身并不能告诉我们任何事情，实际上人们通常会计算两个<code class="docutils literal notranslate"><span class="pre">边缘似然</span></code>的比率。</p>
<p>这个比率称为贝叶斯因子：</p>
<div class="math notranslate nohighlight">
\[BF = \frac{p(Y \mid M_0)}{p(Y \mid M_1)}\]</div>
<p><span class="math notranslate nohighlight">\(BF &gt; 1\)</span> 的值表明模型 <span class="math notranslate nohighlight">\(M_0\)</span> 与模型 <span class="math notranslate nohighlight">\(M_1\)</span> 相比更能解释数据。在实践中，通常使用经验法则来指示 BF 何时小、大、不是那么大等 <a class="footnote-reference brackets" href="#id126" id="id65">21</a>。</p>
<p>贝叶斯因子很有吸引力，因为它是贝叶斯定理的直接应用，正如我们从公式 <a class="reference internal" href="#equation-eq-posterior-model">(110)</a> 中看到的那样，但对于调和平均估计器也是如此（参见第 <a class="reference internal" href="#harmonic-mean"><span class="std std-ref">11.7.1 调和平均估计器</span></a> 节）和这不会自动使它成为一个好的估计器。贝叶斯因子也很有吸引力，因为与模型的似然性相反，<code class="docutils literal notranslate"><span class="pre">边缘似然</span></code>不一定会随着模型的复杂性而增加。直观的原因是，参数的数量越多，关于似然性的先验就越 * 散布 *。或者换句话说，一个更“分散”的先验是一个比一个更集中的数据集更合理的数据集。这将反映在<code class="docutils literal notranslate"><span class="pre">边缘似然</span></code>中，因为我们将在更广泛的先验比更集中的先验得到更小的值。</p>
<p>除了计算问题之外，<code class="docutils literal notranslate"><span class="pre">边缘似然</span></code>还有一个特征，它通常被认为是一个错误。它对先验的选择<em>非常敏感</em>。 “非常敏感”是指虽然与推理无关，但对<code class="docutils literal notranslate"><span class="pre">边缘似然</span></code>值有实际影响的变化。为了举例说明这一点，假设我们有模型：</p>
<div class="math notranslate nohighlight" id="equation-eq-normal-normal">
<span class="eqno">(111)<a class="headerlink" href="#equation-eq-normal-normal" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{split}
  \mu \sim&amp;\; \mathcal{N}(0, \sigma_0) \\
  Y \sim&amp;\; \mathcal{N}(\mu, \sigma_1)
\end{split}\end{split}\]</div>
<p>该模型的边缘对数似然可以分析计算如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">σ_0</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">σ_1</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">y</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="mi">0</span><span class="p">])</span>
<span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">logpdf</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="p">(</span><span class="n">σ_0</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">σ_1</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">**</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>-1.2655121234846454
</pre></div>
</div>
<p>如果你将先前参数 <span class="math notranslate nohighlight">\(\sigma_0\)</span> 的值更改为 2.5 而不是 1，<code class="docutils literal notranslate"><span class="pre">边缘似然</span></code>将小约 2 倍，而将其更改为 10 将小约 7 倍。你可以使用概率编程语言计算此模型的后验，并亲自了解先验在后验中的变化有多大影响。此外，你可以在下一节中检查 <a class="reference internal" href="#fig-posterior-ml"><span class="std std-numref">Fig. 196</span></a>。</p>
</div>
<div class="section" id="waic-loo">
<span id="bayes-factor-vs-waic-and-loo"></span><h3>11.7.3 贝叶斯因子与 <code class="docutils literal notranslate"><span class="pre">WAIC</span></code> 和 <code class="docutils literal notranslate"><span class="pre">LOO</span></code><a class="headerlink" href="#waic-loo" title="Permalink to this headline">¶</a></h3>
<p>在本书中，我们不使用贝叶斯因子来比较模型，而是更倾向于使用 <code class="docutils literal notranslate"><span class="pre">LOO</span></code>。因此，更好地理解贝叶斯因子与其他估计量的关系很有用。如果忽略细节，我们可以说：</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">WAIC</span></code> 是后验平均的对数似然</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">LOO</span></code> 是后验平均的对数似然</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">边缘似然</span></code>是先验平均的（对数）似然 <a class="footnote-reference brackets" href="#id127" id="id66">22</a>。</p></li>
</ul>
<p>这有助于理解三个量之间的异同。</p>
<p>它们都使用对数分值作为不同计算方法拟合度的度量。 <code class="docutils literal notranslate"><span class="pre">WAIC</span></code> 使用从后验方差计算的惩罚项。虽然 <code class="docutils literal notranslate"><span class="pre">LOO</span></code> 和<code class="docutils literal notranslate"><span class="pre">边缘似然</span></code>都避免了需要使用明确的惩罚项。 <code class="docutils literal notranslate"><span class="pre">LOO</span></code> 通过近似留一法交叉验证过程来实现这一点。也就是说，它使用一个数据集来拟合数据并使用不同的数据集来评估它的拟合度。<code class="docutils literal notranslate"><span class="pre">边缘似然</span></code>的惩罚来自对整个先验的平均，先验（相对地）到作为内置惩罚器工作的似然的传播。<code class="docutils literal notranslate"><span class="pre">边缘似然</span></code>中使用的惩罚似乎在某种程度上类似于 <code class="docutils literal notranslate"><span class="pre">WAIC</span></code> 中的惩罚，尽管 <code class="docutils literal notranslate"><span class="pre">WAIC</span></code> 使用后验方差，因此接近交叉验证中的惩罚。因为，如前所述，与更集中的数据集相比，更宽泛的先验承认更多的数据集是合理的，因此计算<code class="docutils literal notranslate"><span class="pre">边缘似然</span></code>就像对先验承认的所有数据集进行隐式平均。</p>
<p>概念化<code class="docutils literal notranslate"><span class="pre">边缘似然</span></code>的另一种等效方法是注意它是在特定数据集 <span class="math notranslate nohighlight">\(Y\)</span> 上评估的先验预测分布。因此，它告诉我们数据在模型下的似然有多大。该模型包括先验和似然。</p>
<p>对于 <code class="docutils literal notranslate"><span class="pre">WAIC</span></code> 和 <code class="docutils literal notranslate"><span class="pre">LOO</span></code>，先验的作用是间接的。先验仅通过对后验的影响来影响 <code class="docutils literal notranslate"><span class="pre">WAIC</span></code> 和 <code class="docutils literal notranslate"><span class="pre">LOO</span></code> 的值。关于先验的数据信息越多，或者换句话说，先验和后验之间的差异越大，<code class="docutils literal notranslate"><span class="pre">WAIC</span></code> 和 <code class="docutils literal notranslate"><span class="pre">LOO</span></code> 对先验细节的敏感度就越低。相反，<code class="docutils literal notranslate"><span class="pre">边缘似然</span></code>直接使用先验，因为我们需要对先验的可能性进行平均。从概念上讲，我们可以说贝叶斯因子专注于识别最佳模型（并且先验是模型的一部分），而 <code class="docutils literal notranslate"><span class="pre">WAIC</span></code> 和 <code class="docutils literal notranslate"><span class="pre">LOO</span></code> 则专注于哪个（拟合）模型和参数将给出最佳预测。 <a class="reference internal" href="#fig-posterior-ml"><span class="std std-numref">Fig. 196</span></a> 显示公式 <a class="reference internal" href="#equation-eq-normal-normal">(111)</a> 中定义的模型的 3 个后验，对于 <span class="math notranslate nohighlight">\(\sigma_0=1\)</span>、<span class="math notranslate nohighlight">\(\sigma_0=10\)</span> 和 <span class="math notranslate nohighlight">\(\sigma_0=100\)</span>。正如我们所看到的，后验彼此非常接近，尤其是最后两个。</p>
<p>我们可以看到，对于不同的后验，<code class="docutils literal notranslate"><span class="pre">WAIC</span></code> 和 <code class="docutils literal notranslate"><span class="pre">LOO</span></code> 的值仅略有变化，而对数<code class="docutils literal notranslate"><span class="pre">边缘似然</span></code>对先验的选择很敏感。分析计算后验和对数<code class="docutils literal notranslate"><span class="pre">边缘似然</span></code>，<code class="docutils literal notranslate"><span class="pre">WAIC</span></code> 和 <code class="docutils literal notranslate"><span class="pre">LOO</span></code> 是从后验样本计算的（有关详细信息，请参阅随附的代码）。</p>
<div class="figure align-default" id="fig-posterior-ml">
<a class="reference internal image-reference" href="../_images/ml_waic_loo.png"><img alt="../_images/ml_waic_loo.png" src="../_images/ml_waic_loo.png" style="width: 7.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 196 </span><span class="caption-text">公式 <a class="reference internal" href="#equation-eq-normal-normal">(111)</a> 中模型​​的先验（灰线）和后验（蓝线）。 <code class="docutils literal notranslate"><span class="pre">WAIC</span></code> 和 <code class="docutils literal notranslate"><span class="pre">LOO</span></code> 反映了后验分布几乎相同，而<code class="docutils literal notranslate"><span class="pre">边缘似然</span></code>反映了先验不同。</span><a class="headerlink" href="#fig-posterior-ml" title="Permalink to this image">¶</a></p>
</div>
<p>上述讨论有助于解释为什么贝叶斯因子在某些领域被广泛使用而在其他领域不受欢迎。当先验更接近反映一些潜在的<em>真实</em>模型时，<code class="docutils literal notranslate"><span class="pre">边缘似然</span></code>对先验规范的敏感性就不那么令人担忧了。当先验主要用于它们的正则化属性并且可能提供一些背景知识时，这种敏感性可能会被视为有问题。</p>
<p>因此，我们认为 <code class="docutils literal notranslate"><span class="pre">WAIC</span></code>，尤其是 <code class="docutils literal notranslate"><span class="pre">LOO</span></code>，具有更大的实用价值，因为它们的计算通常更健壮，并且不需要使用特殊的推理方法。在 <code class="docutils literal notranslate"><span class="pre">LOO</span></code> 的情况下，我们也有很好的诊断。</p>
</div>
</div>
<div class="section" id="high-dimensions">
<span id="id67"></span><h2>11.8 走出平地<a class="headerlink" href="#high-dimensions" title="Permalink to this headline">¶</a></h2>
<p>埃德温·阿博特 <span id="id68">[<a class="reference internal" href="references.html#id154">143</a>]</span> 的《平地：多维浪漫》中，讲述了一个生活在平地的 Square 的故事，这是一个由 <span class="math notranslate nohighlight">\(n\)</span> 边多边形居住的二维世界，其中状态由边数定义；女性是简单的线段，牧师坚持认为她们是圆，即使那时只是高阶多边形。这部小说于 <span class="math notranslate nohighlight">\(1984\)</span> 年首次出版，同样有效地讽刺了理解超出我们共同经验的想法的困难。</p>
<p>正如平地中的 Square 所发生的那样，我们现在要证明高维空间的怪异之处。</p>
<p>假设我们要估计 <span class="math notranslate nohighlight">\(\pi\)</span> 的值。执行此操作的简单过程如下。将一个圆刻入一个正方形，在该正方形内均匀地生成 <span class="math notranslate nohighlight">\(N\)</span> 个点，然后计算落在圆内的比例。从技术上讲，这是蒙特卡洛积分，因为我们正在使用（伪）随机数生成器计算定积分的值。</p>
<p>圆和正方形的面积与圆内的点数和总点数成正比。如果正方形的边是 <span class="math notranslate nohighlight">\(2R\)</span>，那么它的面积是 <span class="math notranslate nohighlight">\((2R)^2\)</span>，而在正方形里面的圆的面积是 <span class="math notranslate nohighlight">\(\pi R^2\)</span>。我们有：</p>
<div class="math notranslate nohighlight">
\[\frac{\text{inside}}{N} \propto \frac{\pi R^2}{(2R)^2}\]</div>
<p>通过简化和重新排列，可以将 <span class="math notranslate nohighlight">\(\pi\)</span> 近似为：</p>
<div class="math notranslate nohighlight">
\[\hat \pi = 4 \frac{\text{Count}_{inside}}{N}\]</div>
<p>我们可以在代码块 <a class="reference internal" href="#montecarlo"><span class="std std-ref">montecarlo</span></a> 中用几行 Python 代码来实现这一点，估计值为 <span class="math notranslate nohighlight">\(\pi\)</span> 的模拟点和近似误差显示在 <code class="xref std std-numref docutils literal notranslate"><span class="pre">fig:monte_carlo</span> </code>。</p>
<div class="literal-block-wrapper docutils container" id="montecarlo">
<div class="code-block-caption"><span class="caption-number">Listing 167 </span><span class="caption-text">montecarlo</span><a class="headerlink" href="#montecarlo" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">N</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/random/generated/numpy.random.uniform.html#numpy.random.uniform" title="numpy.random.uniform"><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span></a><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">N</span><span class="p">))</span>
<span class="n">inside</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">y</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="mi">1</span>
<span class="n">pi</span> <span class="o">=</span> <span class="n">inside</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">*</span><span class="mi">4</span><span class="o">/</span><span class="n">N</span>
<span class="n">error</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">((</span><span class="n">pi</span> <span class="o">-</span> <a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/constants.html#numpy.pi" title="numpy.pi"><span class="n">np</span><span class="o">.</span><span class="n">pi</span></a><span class="p">)</span> <span class="o">/</span> <span class="n">pi</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span>
</pre></div>
</div>
</div>
<div class="figure align-default" id="fig-monte-carlo">
<a class="reference internal image-reference" href="../_images/monte_carlo.png"><img alt="../_images/monte_carlo.png" src="../_images/monte_carlo.png" style="width: 5.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 197 </span><span class="caption-text">使用 Monte Carlo 采样估计 <span class="math notranslate nohighlight">\(\pi\)</span>，图例显示了估计和百分比误差。</span><a class="headerlink" href="#fig-monte-carlo" title="Permalink to this image">¶</a></p>
</div>
<p>由于采样是独立同分布的，我们可以在这里应用中心极限定理，然后我们知道误差以 <span class="math notranslate nohighlight">\(\frac{1}{\sqrt{N}}\)</span>) 的速度减少，这意味着每增加一个小数位精度，我们需要将抽奖次数 “N” 增加 <span class="math notranslate nohighlight">\(100\)</span> 倍。</p>
<p>我们刚刚所做的是蒙特卡洛方法 <a class="footnote-reference brackets" href="#id128" id="id69">23</a> 的一个示例，基本上是任何使用（伪）随机样本来计算某些东西的方法。从技术上讲，我们所做的是蒙特卡洛积分，因为我们正在使用样本计算定积分（面积）的值。蒙特卡洛方法在统计学中无处不在。</p>
<p>在贝叶斯统计中，我们需要计算积分以获得后验或计算期望。你可能会建议我们可以使用这个想法的变体来计算比 <span class="math notranslate nohighlight">\(\pi\)</span> 更有趣的数量。</p>
<p>事实证明，随着我们增加问题的维度，这种方法通常不会很好地工作。在代码块 <a class="reference internal" href="#inside-out"><span class="std std-ref">inside_out</span></a> 中，我们计算从正方形采样时圆内点的数量，但从 <span class="math notranslate nohighlight">\(2\)</span> 到 <span class="math notranslate nohighlight">\(15\)</span> 维。结果在 <a class="reference internal" href="#fig-inside-out"><span class="std std-numref">Fig. 198</span></a> 中，奇怪的是，随着增加问题的维度，即使超球体 <em>接触</em> 超立方体的壁，内部点的比例也会迅速下降。从某种意义上说，在更高维度上，超立方体的所有体积都在角落 <a class="footnote-reference brackets" href="#id129" id="id70">24</a>。</p>
<div class="literal-block-wrapper docutils container" id="inside-out">
<div class="code-block-caption"><span class="caption-number">Listing 168 </span><span class="caption-text">inside_out</span><a class="headerlink" href="#inside-out" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">total</span> <span class="o">=</span> <span class="mi">100000</span>

<span class="n">dims</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">prop</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">15</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/random/generated/numpy.random.random.html#numpy.random.random" title="numpy.random.random"><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span></a><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">total</span><span class="p">))</span>
    <span class="n">inside</span> <span class="o">=</span> <span class="p">((</span><span class="n">x</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="n">dims</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
    <span class="n">prop</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">inside</span> <span class="o">/</span> <span class="n">total</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="figure align-default" id="fig-inside-out">
<a class="reference internal image-reference" href="../_images/inside_out.png"><img alt="../_images/inside_out.png" src="../_images/inside_out.png" style="width: 5.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 198 </span><span class="caption-text">当增加维度时，在超球体内获得一个点并写入超立方体的机会变为零。这表明在更高维度上，几乎所有超立方体的体积都在角落里。</span><a class="headerlink" href="#fig-inside-out" title="Permalink to this image">¶</a></p>
</div>
<p>让我们看另一个使用多元高斯的例子。<a class="reference internal" href="#fig-distance-to-mode"><span class="std std-numref">Fig. 199</span></a> 表明，随着增加高斯的维数，该高斯的大部分质量都位于离众数越来越远的位置。事实上，大部分质量都在众数半径 <span class="math notranslate nohighlight">\(\sqrt{d}\)</span> 处的一个 <em>环</em> 周围。换句话说，随着增加高斯的维数，众数变得越来越不典型。在更高的维度中，众数实际上是一个异常值，因为任何给定点在所有维度上都是众数是非常不寻常的！</p>
<p>我们也可以从另一个角度来看待这一点。即使在高维空间中，众数始终是密度最高的点。关键的见解是注意到它是独一无二的（就像来自平地的点！）。如果远离该众数，我们会发现单独不太可能但数量很多的点。正如在 <a class="reference internal" href="#cont-rvs"><span class="std std-ref">11.1.5 连续型随机变量及其分布</span></a> 中看到的，概率被计算为体积上密度的积分，所以要找出分布的所有质量在哪里，必须平衡密度和体积。随着增加高斯的维度，我们最有可能从不包括该众数的 <em>环</em> 中选择一个点。</p>
<p>包含概率分布中大部分质量的区域被称为典型集。在贝叶斯统计中，我们非常重视它，因为如果要用样本来近似高维后验，那么样本来自典型集合就足够了。</p>
<div class="figure align-default" id="fig-distance-to-mode">
<a class="reference internal image-reference" href="../_images/distance_to_mode.png"><img alt="../_images/distance_to_mode.png" src="../_images/distance_to_mode.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 199 </span><span class="caption-text">当增加高斯的维度时，大部分质量分布在离该高斯众数越来越远的地方。</span><a class="headerlink" href="#fig-distance-to-mode" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="section" id="inference-methods">
<span id="id71"></span><h2>11.9 推断方法<a class="headerlink" href="#inference-methods" title="Permalink to this headline">¶</a></h2>
<p>有无数种计算后验的方法。如果我们在讨论共轭先验时排除我们在第 [1]](chap1) 章中已经讨论过的精确解析解，我们可以将推理方法分为 3 大类：</p>
<ol class="simple">
<li><p>确定性集成方法，我们还没有在书中看到，但我们接下来会做</p></li>
<li><p>模拟方法，也在第[1]章（第一章）中介绍，以及贯穿全书的选择方法，最后</p></li>
<li><p>逼近方法，例如第[8]章（chap8）中讨论的ABC方法，在似然函数没有封闭形式表达式的情况下。</p></li>
</ol>
<p>虽然某些方法可能是这些类别的组合，但我们仍然认为对过多的可用方法进行排序是有用的。</p>
<p>对于过去两个半世纪的贝叶斯计算方法的一个很好的时间顺序之旅，特别强调那些改变贝叶斯推理的方法，我们建议你阅读计算贝叶斯：从 1763 年到 21 世纪的贝叶斯计算 <span id="id72">[<a class="reference internal" href="references.html#id116">144</a>]</span>。</p>
<div class="section" id="grid-method">
<span id="id73"></span><h3>11.9.1 网格方法<a class="headerlink" href="#grid-method" title="Permalink to this headline">¶</a></h3>
<p>The grid method is a simple brute-force approach. We want to know the value of posterior distribution over its domain to be able to use it (finding the maximum, computing expectation, etc). Even if you are not able to compute the whole posterior, you may be able to evaluate the prior and the likelihood density function point-wise; this is a pretty common scenario, if not the most common one. For a single parameter model, the grid approximation is:</p>
<ul class="simple">
<li><p>Find a reasonable interval for the parameter (the prior should give   some hints).</p></li>
<li><p>Define a grid of points (generally equidistant) on that interval.</p></li>
<li><p>For each point in the grid, multiply the likelihood and the prior.</p></li>
</ul>
<p>Optionally, we may normalize the computed values so the posterior   sum to 1 by dividing the result at each point by the sum of all   points</p>
<p>Code Block <a class="reference internal" href="#id74"><span class="std std-ref">grid_method</span></a> computes the posterior the Beta-Binomial model:</p>
<div class="literal-block-wrapper docutils container" id="id74">
<div class="code-block-caption"><span class="caption-number">Listing 169 </span><span class="caption-text">grid_method</span><a class="headerlink" href="#id74" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">posterior_grid</span><span class="p">(</span><span class="n">ngrid</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">α</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">β</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">heads</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">trials</span><span class="o">=</span><span class="mi">9</span><span class="p">):</span>
    <span class="n">grid</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.linspace.html#numpy.linspace" title="numpy.linspace"><span class="n">np</span><span class="o">.</span><span class="n">linspace</span></a><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">ngrid</span><span class="p">)</span>
    <span class="n">prior</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.beta.html#scipy.stats.beta" title="scipy.stats.beta"><span class="n">stats</span><span class="o">.</span><span class="n">beta</span></a><span class="p">(</span><span class="n">α</span><span class="p">,</span> <span class="n">β</span><span class="p">)</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">grid</span><span class="p">)</span>
    <span class="n">likelihood</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">binom</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">heads</span><span class="p">,</span> <span class="n">trials</span><span class="p">,</span> <span class="n">grid</span><span class="p">)</span>
    <span class="n">posterior</span> <span class="o">=</span> <span class="n">likelihood</span> <span class="o">*</span> <span class="n">prior</span>
    <span class="n">posterior</span> <span class="o">/=</span> <span class="n">posterior</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">posterior</span>
</pre></div>
</div>
</div>
<div class="figure align-default" id="fig-grid-method">
<a class="reference internal image-reference" href="../_images/grid_method.png"><img alt="../_images/grid_method.png" src="../_images/grid_method.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 200 </span><span class="caption-text">By evaluating the prior and the likelihood pointwise over a grid we can approximate the posterior.</span><a class="headerlink" href="#fig-grid-method" title="Permalink to this image">¶</a></p>
</div>
<p>We can get a better approximation by increasing the number of points of the grid. In fact if we use infinite number of points we will get the exact posterior, at the cost of needing infinite computing resources.</p>
<p>The biggest caveat of the grid approach is that this method scales poorly with the number of parameters as explained in <a class="reference internal" href="#high-dimensions"><span class="std std-ref">11.8 走出平地</span></a>.</p>
</div>
<div class="section" id="metropolis-hastings">
<span id="sec-metropolis-hastings"></span><h3>11.9.2 Metropolis-Hastings 采样器<a class="headerlink" href="#metropolis-hastings" title="Permalink to this headline">¶</a></h3>
<p>We introduced Metropolis-Hastings algorithm <span id="id75">[<a class="reference internal" href="references.html#id106">7</a>, <a class="reference internal" href="references.html#id107">8</a>, <a class="reference internal" href="references.html#id108">9</a>]</span> very early in Section <a class="reference internal" href="chp_01.html#sampling-methods-intro"><span class="std std-ref">1.2 一个自制的采样器</span></a> and show a simple Python implementation in Code Block <a class="reference internal" href="chp_01.html#metropolis-hastings"><span class="std std-ref">metropolis_hastings</span></a>. We will now provide more detail about why this method works. We will do it using the language of Markov Chains introduced in Section <a class="reference internal" href="#markov-chains"><span class="std std-ref">11.1.11 马尔可夫链</span></a>.</p>
<p>The Metropolis-Hastings algorithm is a general method that allow us to start with any irreducible Markov chain on the state space of interest and then modify it into a new Markov chain that has the stationary distribution that we really care. In other words we take samples from an easy to sample distribution like a Multivariate Normal and we turn those samples into samples from our target distribution. The way we modify the original chain is by being selective, we only accept some of the samples and reject the others. As we saw in Chapter <a class="reference internal" href="chp_01.html#chap1"><span class="std std-ref">1</span></a>. The probability of accepting a new proposal is:</p>
<div class="math notranslate nohighlight" id="equation-eq-acceptance-prob">
<span class="eqno">(112)<a class="headerlink" href="#equation-eq-acceptance-prob" title="Permalink to this equation">¶</a></span>\[p_a (x_{i + 1} \mid x_i) = \min \left (1, \frac{p(x_{i + 1}) \;  q(x_i \mid x_{i + 1})} {p(x_i) \; q (x_{i + 1} \mid x_i)} \right)\]</div>
<p>Let us rewrite this in a shorter form, for easier manipulation.</p>
<div class="math notranslate nohighlight">
\[a_{ij} = \min \left (1, \frac{p_j q_{ji}}{{p_i q_{ij}}} \right)\]</div>
<p>That is we propose with probability <span class="math notranslate nohighlight">\(q_{ij}\)</span> (read the subscript <span class="math notranslate nohighlight">\(ij\)</span> as from <span class="math notranslate nohighlight">\(i\)</span> to <span class="math notranslate nohighlight">\(j\)</span>) and accepts the proposal with probability <span class="math notranslate nohighlight">\(a_{ij}\)</span>. One of the nice feature of this method is that we do not need to know the normalizing constant of the distribution we want to sample, as it will be cancelled out when we compute <span class="math notranslate nohighlight">\(\frac{p_j}{p_i}\)</span>. This is very important because in may many problems, including Bayesian inference, computing that normalization constant (the marginal likelihood) is very difficult.</p>
<p>We will now show that the Metropolis-Hastings chain is reversible with stationary distribution <span class="math notranslate nohighlight">\(p\)</span> as we mentioned in Section <a class="reference internal" href="#markov-chains"><span class="std std-ref">11.1.11 马尔可夫链</span></a>. We need to proof that the detailed balance condition i.e. the reversibility condition holds, that is:</p>
<p>Let <span class="math notranslate nohighlight">\(\mathbf{T}\)</span> be the transition matrix, we just need to show that <span class="math notranslate nohighlight">\(p_i t_{ij} = p_j t_{ji}\)</span> for all <span class="math notranslate nohighlight">\(i\)</span> and <span class="math notranslate nohighlight">\(j\)</span>, this is trivial when <span class="math notranslate nohighlight">\(i = j\)</span> so we assume that <span class="math notranslate nohighlight">\(i \neq j\)</span>, we can write:</p>
<div class="math notranslate nohighlight" id="equation-eq-transition">
<span class="eqno">(113)<a class="headerlink" href="#equation-eq-transition" title="Permalink to this equation">¶</a></span>\[t_{ij} = q_{ij} a_{ij} \]</div>
<p>Meaning that the probability to transition from <span class="math notranslate nohighlight">\(i\)</span> to <span class="math notranslate nohighlight">\(j\)</span> is the probability of proposing the move times the probability of accepting it.</p>
<p>Let us first see the case where the probability of acceptance is less that 1, this happens when <span class="math notranslate nohighlight">\(p_j q_{ji} \le p_i q_{ij}\)</span>, then we have that</p>
<div class="math notranslate nohighlight" id="equation-eq-acceptance-ij">
<span class="eqno">(114)<a class="headerlink" href="#equation-eq-acceptance-ij" title="Permalink to this equation">¶</a></span>\[a_{ij} = \frac{p_j q_{ji}}{p_i q_{ij}} \]</div>
<p>and also</p>
<div class="math notranslate nohighlight">
\[a_{ji} = 1\]</div>
<p>Using Equation <a class="reference internal" href="#equation-eq-transition">(113)</a>, we have</p>
<div class="math notranslate nohighlight">
\[p_i t_{ij} = p_i q_{ij} a_{ij}\]</div>
<p>replacing <span class="math notranslate nohighlight">\(a_{ij}\)</span> in Equation <a class="reference internal" href="#equation-eq-acceptance-ij">(114)</a></p>
<div class="math notranslate nohighlight">
\[p_i t_{ij} = p_i q_{ij} \frac{p_j q_{ji}}{p_i q_{ij}}\]</div>
<p>simplifying above we get:</p>
<div class="math notranslate nohighlight">
\[p_i t_{ij} = p_j q_{ji}\]</div>
<p>Because <span class="math notranslate nohighlight">\(a_{ji} = 1\)</span> we can include it without changing the validity of the equation.</p>
<div class="math notranslate nohighlight">
\[p_i t_{ij} = p_j q_{ji} a_{ji}\]</div>
<p>which finally we get that</p>
<div class="math notranslate nohighlight">
\[p_i t_{ij} = p_j t_{ji}\]</div>
<p>By symmetry when <span class="math notranslate nohighlight">\(p_j q_{ji} &gt; p_i q_{ij}\)</span> we will arrive at the same result. As the reversibility condition holds, <span class="math notranslate nohighlight">\(p\)</span> is the stationary distribution of our Markov chain with transition matrix <span class="math notranslate nohighlight">\(\mathbf{T}\)</span>.</p>
<p>The above proof gives us the theoretical confidence that we can use Metropolis-Hastings to sample from virtually any distribution we want.</p>
<p>We can also see that while this is a very general result, it does not help us to choose a proposal distribution. In practice the proposal distribution is very important as the efficiency of the method depends heavily on this choice. In general it is observed that if the proposal makes large jumps the probability of acceptance is very low, and the method spend most of the time rejecting new states and thus stuck in one place. On the contrary if the proposal takes too small jumps the acceptance rate is high but the exploration is poor, as the new states are in a small neighborhood of the old state. A good proposal distribution is one that generates new putative states far away from the old state with high acceptance rate. This is generally difficult to do if we do not know the geometry of the posterior distribution, but that is precisely what we want to find out. In practice useful Metropolis-Hastings methods are those that are adaptive <span id="id76">[<a class="reference internal" href="references.html#id101">145</a>, <a class="reference internal" href="references.html#id104">146</a>, <a class="reference internal" href="references.html#id103">147</a>, <a class="reference internal" href="references.html#id102">148</a>]</span>. For example, we can use a Multivariate Gaussian distribution as proposal distribution. During tuning we can compute the empirical covariance from the posterior samples and use it as the covariance matrix of the proposal distribution. We can also scale the covariance matrix so that the average acceptance rate approach a predefined acceptance rate <span id="id77">[<a class="reference internal" href="references.html#id105">149</a>, <a class="reference internal" href="references.html#id109">150</a>, <a class="reference internal" href="references.html#id110">151</a>]</span>. In fact there is evidence that under certain circumstances and when the dimensionality of the posterior increases the optimal acceptance rate converges to the magic number 0.234 <span id="id78">[<a class="reference internal" href="references.html#id105">149</a>]</span>. In practice it seems that an acceptance rate around 0.234 or a little bit higher gives more or less the same performance but the general validity and useful of this result has also been disputed <span id="id79">[<a class="reference internal" href="references.html#id111">152</a>, <a class="reference internal" href="references.html#id112">153</a>]</span>.</p>
<p>In the next section we will discuss a clever way to generate proposals that help to correct most of the problems with basic Metropolis-Hastings.</p>
</div>
<div class="section" id="hmc">
<span id="id80"></span><h3>11.9.3 汉密尔顿蒙特卡洛采样器（ HMC ）<a class="headerlink" href="#hmc" title="Permalink to this headline">¶</a></h3>
<p>Hamiltonian Monte Carlo (HMC) <a class="footnote-reference brackets" href="#id130" id="id81">25</a> <span id="id82">[<a class="reference internal" href="references.html#id95">154</a>, <a class="reference internal" href="references.html#id96">155</a>, <a class="reference internal" href="references.html#id97">156</a>]</span> is a type of MCMC method that makes use of gradients to generate new proposed states. The gradients of the log-probability of the posterior evaluated at some state provides information of the geometry of the posterior density function. HMC attempts to avoid the random walk behavior typical of Metropolis-Hastings by using the gradient to propose new positions far from the current one with high acceptance probability. This allows HMC to better scale to higher dimensions and in principle more complex geometries, than alternatives.</p>
<p>In simple terms, a Hamiltonian is a description of the total energy of a physical system. We can decompose the total energy into two terms, the kinetic and the potential energy. For a real system like rolling a ball down a hill, the potential energy is given by the position of the ball.</p>
<p>The higher the ball the higher the potential energy. The kinetic energy is given by the velocity of the ball, or more correctly by its momentum (which takes into account both the velocity and the mass of the object).</p>
<p>We will assume the total energy preserves, meaning that if the system gains kinetic energy then is because it has lost the same amount of potential energy. We can write the Hamiltonian of such a systems as:</p>
<div class="math notranslate nohighlight">
\[H(\mathbf{q}, \mathbf{p})  = K(\mathbf{p}, \mathbf{q}) + V(\mathbf{q})\]</div>
<p>where <span class="math notranslate nohighlight">\(K(\mathbf{p}, \mathbf{q})\)</span> is called the kinetic energy, and <span class="math notranslate nohighlight">\(V(\mathbf{q})\)</span> is the potential energy. The probability of finding the ball at a particular position with a particular momentum is then given by:</p>
<div class="math notranslate nohighlight" id="equation-eq-canonical">
<span class="eqno">(115)<a class="headerlink" href="#equation-eq-canonical" title="Permalink to this equation">¶</a></span>\[p(\mathbf{q}, \mathbf{p}) = e^{-H(\mathbf{q}, \mathbf{p})} \]</div>
<p>To simulate such a systems we need to solve the so called Hamiltonian equations:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\frac{d \mathbf{q}}{dt} =&amp; \quad \frac{\partial H}{\partial \mathbf{p}} = \frac{\partial K}{\partial \mathbf{p}} + \frac{\partial V}{\partial \mathbf{p}} \\
\frac{d \mathbf{p}}{dt} =&amp; -\frac{\partial H}{\partial \mathbf{q}}= -\frac{\partial K}{\partial \mathbf{q}} - \frac{\partial V}{\partial \mathbf{q}}\end{aligned}\end{split}\]</div>
<p>Note that <span class="math notranslate nohighlight">\(\frac{\partial V}{\partial \mathbf{p}} = \mathbf{0}\)</span>.</p>
<p>Because we are not interested in modeling an idealized ball rolling down an idealized hill, but to model an idealized particle along the posterior distribution, we need to make a few adjustments. First the potential energy is given by the probability density we are trying to sample from <span class="math notranslate nohighlight">\(p(\mathbf{q})\)</span>. For the momentum we are just going to invoke an auxiliary variable. That is, a made up variable that will help us. If we choose <span class="math notranslate nohighlight">\(p(\mathbf{p} \mid \mathbf{q})\)</span> then we can write:</p>
<div class="math notranslate nohighlight" id="equation-eq-auxiliary">
<span class="eqno">(116)<a class="headerlink" href="#equation-eq-auxiliary" title="Permalink to this equation">¶</a></span>\[p(\mathbf{q}, \mathbf{p}) =  p(\mathbf{p} | \mathbf{q}) p(\mathbf{q}) \]</div>
<p>This ensures us that we can recover our target distribution by marginalize out the momentum. By introducing the auxiliary variable, we can keep working with the physical analogy, and later remove the auxiliary variable and go back to our problem, sampling the posterior.</p>
<p>If we replace Equation <a class="reference internal" href="#equation-eq-auxiliary">(116)</a> in Equation <a class="reference internal" href="#equation-eq-canonical">(115)</a> we got:</p>
<div class="math notranslate nohighlight">
\[H(\mathbf{q}, \mathbf{p}) = \overbrace{-\log p(\mathbf{p} \mid \mathbf{q})}^{K(\mathbf{p}, \mathbf{q})} \overbrace{- \log p(\mathbf{q})}^{ + V(\mathbf{q})}\]</div>
<p>As explained previously, the potential energy <span class="math notranslate nohighlight">\(V(\mathbf{q})\)</span> is given by the <span class="math notranslate nohighlight">\(p(\mathbf{q})\)</span> the density function of the target posterior distribution, and we are free to choose the kinetic energy. If we choose it to be Gaussian, and drop the normalization constant, we have:</p>
<div class="math notranslate nohighlight">
\[K(\mathbf{p}, \mathbf{q}) = \frac{1}{2}\mathbf{p}^T M^{-1}\mathbf{p} + \log |M|\]</div>
<p>where <span class="math notranslate nohighlight">\(M\)</span> is the <strong>precision matrix</strong> that parameterized the Gaussian distribution (also referred to as the mass matrix in Hamiltonian Monte Carlo literature). And if we choose <span class="math notranslate nohighlight">\(M = I\)</span>, i.e. the identity matrix which is <span class="math notranslate nohighlight">\(n \times n\)</span> square matrix with ones on the main diagonal and zeros elsewhere, we have:</p>
<div class="math notranslate nohighlight">
\[K(\mathbf{p}, \mathbf{q}) = \frac{1}{2}\mathbf{p}^T \mathbf{p}\]</div>
<p>This makes calculations easier as now</p>
<div class="math notranslate nohighlight">
\[\frac{\partial K}{\partial \mathbf{p}} = \mathbf{p}\]</div>
<p>and</p>
<div class="math notranslate nohighlight">
\[\frac{\partial K}{\partial \mathbf{q}} = \mathbf{0}\]</div>
<p>We can then simplify Hamilton’s equations to:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\frac{d \mathbf{q}}{dt} =&amp; \mathbf{p} \\
\frac{d \mathbf{p}}{dt} =&amp; - \frac{\partial V}{\partial \mathbf{q}}\end{aligned}\end{split}\]</div>
<p>Summarizing,the HMC algorithm is then:</p>
<ol class="simple">
<li><p>Sample a <span class="math notranslate nohighlight">\(\mathbf{p} \sim \mathcal{N}(0, I)\)</span></p></li>
<li><p>Simulate <span class="math notranslate nohighlight">\(\mathbf{q}_t\)</span> and <span class="math notranslate nohighlight">\(\mathbf{p}_t\)</span> for some amount of time   <span class="math notranslate nohighlight">\(T\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{q}_T\)</span> is our new proposed state</p></li>
<li><p>Use the Metropolis acceptance criterion to accept or reject   <span class="math notranslate nohighlight">\(\mathbf{q}_T\)</span>.</p></li>
</ol>
<p>Why we still need to use the Metropolis acceptance criterion? Intuitively because we can think of HMC as a Metropolis-Hasting algorithm with a better proposal distribution. But there is also a very good numerical justification, because this steps corrects for errors introduced by the numerical simulation of the Hamiltonian equations.</p>
<p>To compute the Hamiltonian equations we have to compute a trajectory of the particle, i.e. all the intermediate points between one state and the next. In practice this involves computing a series of small <em>integration</em> steps using an integrator method. The most popular one is the leapfrog integrator. Leapfrog integration is equivalent to updating positions <span class="math notranslate nohighlight">\(q_t\)</span> momentum <span class="math notranslate nohighlight">\(q_t\)</span> at interleaved time points, staggered in such a way that they <em>leapfrog</em> over each other.</p>
<p>Code Block <a class="reference internal" href="#leapfrog"><span class="std std-ref">leapfrog</span></a> shows a leapfrog integrator implemented in Python <a class="footnote-reference brackets" href="#id131" id="id83">26</a>. The arguments are: <code class="docutils literal notranslate"><span class="pre">q</span></code> and <code class="docutils literal notranslate"><span class="pre">p</span></code> the initial position and momentum respectively. <code class="docutils literal notranslate"><span class="pre">dVdq</span></code> is a Python function that returns the gradient of the position of some target density function at position <code class="docutils literal notranslate"><span class="pre">q</span></code> <span class="math notranslate nohighlight">\(\frac{\partial V}{\partial \mathbf{q}}\)</span>. We used JAX <span id="id84">[<a class="reference internal" href="references.html#id155">115</a>]</span> auto-differentiation ability to generate this function. <code class="docutils literal notranslate"><span class="pre">path_len</span></code> indicates how long to integrate for and <code class="docutils literal notranslate"><span class="pre">step_size</span></code> how large each integration step should be. As a result we obtain a new position and momentum as output of the function <code class="docutils literal notranslate"><span class="pre">leapfrog</span></code>.</p>
<div class="literal-block-wrapper docutils container" id="leapfrog">
<div class="code-block-caption"><span class="caption-number">Listing 170 </span><span class="caption-text">leapfrog</span><a class="headerlink" href="#leapfrog" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">leapfrog</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">dVdq</span><span class="p">,</span> <span class="n">path_len</span><span class="p">,</span> <span class="n">step_size</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">-=</span> <span class="n">step_size</span> <span class="o">*</span> <span class="n">dVdq</span><span class="p">(</span><span class="n">q</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>  <span class="c1"># half step</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">path_len</span> <span class="o">/</span> <span class="n">step_size</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">q</span> <span class="o">+=</span> <span class="n">step_size</span> <span class="o">*</span> <span class="n">p</span>  <span class="c1"># whole step</span>
        <span class="n">p</span> <span class="o">-=</span> <span class="n">step_size</span> <span class="o">*</span> <span class="n">dVdq</span><span class="p">(</span><span class="n">q</span><span class="p">)</span>  <span class="c1"># whole step</span>
    <span class="n">q</span> <span class="o">+=</span> <span class="n">step_size</span> <span class="o">*</span> <span class="n">p</span>  <span class="c1"># whole step</span>
    <span class="n">p</span> <span class="o">-=</span> <span class="n">step_size</span> <span class="o">*</span> <span class="n">dVdq</span><span class="p">(</span><span class="n">q</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>  <span class="c1"># half step</span>

    <span class="k">return</span> <span class="n">q</span><span class="p">,</span> <span class="o">-</span><span class="n">p</span>  <span class="c1"># momentum flip at end</span>
</pre></div>
</div>
</div>
<p>Note that in function <code class="docutils literal notranslate"><span class="pre">leapfrog</span></code> we flip the sign of the output momentum. This is the simplest way to achieve a reversible Metropolis-Hastings proposal, as it augment the numerical integration with a negative step.</p>
<p>We have now all the ingredients to implement a HMC method in Python, as in Code Block <a class="reference internal" href="#hamiltonian-mc"><span class="std std-ref">hamiltonian_mc</span></a>. Like our previous Metropolis-Hasting example in Code Block <a class="reference internal" href="chp_01.html#metropolis-hastings"><span class="std std-ref">metropolis_hastings</span></a> this is not meant to be use for serious model inference but instead a simple example to demonstrate the method. The arguments are <code class="docutils literal notranslate"><span class="pre">n_samples</span></code> the number of samples to return, <code class="docutils literal notranslate"><span class="pre">negative_log_prob</span></code> the negative log probability to sample from, <code class="docutils literal notranslate"><span class="pre">initial_position</span></code> the initial position to start sampling, <code class="docutils literal notranslate"><span class="pre">path_len</span></code>, <code class="docutils literal notranslate"><span class="pre">step_size</span></code>, as a result we obtain sample from the target distribution.</p>
<div class="literal-block-wrapper docutils container" id="hamiltonian-mc">
<div class="code-block-caption"><span class="caption-number">Listing 171 </span><span class="caption-text">hamiltonian_mc</span><a class="headerlink" href="#hamiltonian-mc" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">hamiltonian_monte_carlo</span><span class="p">(</span>
    <span class="n">n_samples</span><span class="p">,</span> <span class="n">negative_log_prob</span><span class="p">,</span> <span class="n">initial_position</span><span class="p">,</span> 
    <span class="n">path_len</span><span class="p">,</span> <span class="n">step_size</span><span class="p">):</span>
    <span class="c1"># autograd magic</span>
    <span class="n">dVdq</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">negative_log_prob</span><span class="p">)</span>

    <span class="c1"># collect all our samples in a list</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="p">[</span><span class="n">initial_position</span><span class="p">]</span>

    <span class="c1"># Keep a single object for momentum resampling</span>
    <span class="n">momentum</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html#scipy.stats.norm" title="scipy.stats.norm"><span class="n">stats</span><span class="o">.</span><span class="n">norm</span></a><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="c1"># If initial_position is a 10d vector and n_samples is 100, we want</span>
    <span class="c1"># 100 x 10 momentum draws. We can do this in one call to momentum.rvs, and</span>
    <span class="c1"># iterate over rows</span>
    <span class="n">size</span> <span class="o">=</span> <span class="p">(</span><span class="n">n_samples</span><span class="p">,)</span> <span class="o">+</span> <span class="n">initial_position</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">p0</span> <span class="ow">in</span> <span class="n">momentum</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">):</span>
        <span class="c1"># Integrate over our path to get a new position and momentum</span>
        <span class="n">q_new</span><span class="p">,</span> <span class="n">p_new</span> <span class="o">=</span> <span class="n">leapfrog</span><span class="p">(</span>
            <span class="n">samples</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">p0</span><span class="p">,</span> <span class="n">dVdq</span><span class="p">,</span> <span class="n">path_len</span><span class="o">=</span><span class="n">path_len</span><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="n">step_size</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Check Metropolis acceptance criterion</span>
        <span class="n">start_log_p</span> <span class="o">=</span> <span class="n">negative_log_prob</span><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="o">-</span> <a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.sum.html#numpy.sum" title="numpy.sum"><span class="n">np</span><span class="o">.</span><span class="n">sum</span></a><span class="p">(</span><span class="n">momentum</span><span class="o">.</span><span class="n">logpdf</span><span class="p">(</span><span class="n">p0</span><span class="p">))</span>
        <span class="n">new_log_p</span> <span class="o">=</span> <span class="n">negative_log_prob</span><span class="p">(</span><span class="n">q_new</span><span class="p">)</span> <span class="o">-</span> <a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.sum.html#numpy.sum" title="numpy.sum"><span class="n">np</span><span class="o">.</span><span class="n">sum</span></a><span class="p">(</span><span class="n">momentum</span><span class="o">.</span><span class="n">logpdf</span><span class="p">(</span><span class="n">p_new</span><span class="p">))</span>
        <span class="k">if</span> <a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.log.html#numpy.log" title="numpy.log"><span class="n">np</span><span class="o">.</span><span class="n">log</span></a><span class="p">(</span><a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/random/generated/numpy.random.rand.html#numpy.random.rand" title="numpy.random.rand"><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span></a><span class="p">())</span> <span class="o">&lt;</span> <span class="n">start_log_p</span> <span class="o">-</span> <span class="n">new_log_p</span><span class="p">:</span>
            <span class="n">samples</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">q_new</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">samples</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.copy.html#numpy.copy" title="numpy.copy"><span class="n">np</span><span class="o">.</span><span class="n">copy</span></a><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>

    <span class="k">return</span> <a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
</pre></div>
</div>
</div>
<p><a class="reference internal" href="#fig-normal-leapgrog"><span class="std std-numref">Fig. 201</span></a> shows 3 different trajectories around the same 2D normal distribution. For practical sampling we do not want the trajectories to be circular, because they will arrive at the same position that we started at. Instead we want to move as far as possible from our starting point, for example, by avoiding U-turns in the trajectory, and hence the name of one of the most popular dynamic HMC method No U-Turn Sampling (NUTS).</p>
<div class="figure align-default" id="fig-normal-leapgrog">
<a class="reference internal image-reference" href="../_images/normal_leapfrog.png"><img alt="../_images/normal_leapfrog.png" src="../_images/normal_leapfrog.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 201 </span><span class="caption-text">Three HMC trajectories <em>around</em> a 2D multivariate normal. The momentum is indicated by the size and direction of the arrows, with small arrows indicating small kinetic energy. All these trajectories are computed in such a way that they end at their starting position, which completing an elliptical trajectory.</span><a class="headerlink" href="#fig-normal-leapgrog" title="Permalink to this image">¶</a></p>
</div>
<p>We show another example in <a class="reference internal" href="#fig-funnel-leapgrog"><span class="std std-numref">Fig. 202</span></a>, which contains 3 different trajectory around the same Neal’s funnel, a common geometry arising in (centered) hierarchical models as we showed in Section <a class="reference internal" href="chp_04.html#model-geometry"><span class="std std-ref">4.6.2 分层模型的问题 — 后验几何形态的复杂性带来的采样难题</span></a>.  This is an example of a trajectory failing to properly simulate following the correct distribution, we call such trajectories divergent trajectories, or simply divergences. They are useful diagnostics as explained in Section <a class="reference internal" href="chp_02.html#divergences"><span class="std std-ref">2.4.7 发散性</span></a>. Usually, Symplectic integrators like leapfrog integrator are highly accurate even for long trajectories, as they tend to be tolerant of small errors and <em>oscillate</em> around the correct trajectory. Moreover, these small errors can be corrected exactly by applying the metropolis criteria to accept or reject the Hamiltonian proposal. However, there is an importance exception to this ability to generate small, easy to fix errors: when the exact trajectories lie on regions of high curvature, the numerical trajectories generated by symplectic integrators can diverge, generating trajectory that rapidly get off towards the boundaries of the distribution we are trying to explore.</p>
<div class="figure align-default" id="fig-funnel-leapgrog">
<a class="reference internal image-reference" href="../_images/funnel_leapfrog.png"><img alt="../_images/funnel_leapfrog.png" src="../_images/funnel_leapfrog.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 202 </span><span class="caption-text">Three HMC trajectories <em>around</em> a 2D Neal’s funnel. This kind geometry turns up in centered hierarchical models. We can see that all these trajectories when wrong. We call this kind these divergences and we can used as diagnostics of the HMC samplers.</span><a class="headerlink" href="#fig-funnel-leapgrog" title="Permalink to this image">¶</a></p>
</div>
<p>Both Figures <a class="reference internal" href="#fig-normal-leapgrog"><span class="std std-numref">Fig. 201</span></a> and <a class="reference internal" href="#fig-funnel-leapgrog"><span class="std std-numref">Fig. 202</span></a> highlight the fact that an efficient HMC method requires proper tuning of its hyperparameters. HMC has three hyparameters:</p>
<ul class="simple">
<li><p>the time discretization (step size of the leapfrog)</p></li>
<li><p>the integration time (number of leapfrog steps)</p></li>
<li><p>the precision matrix <span class="math notranslate nohighlight">\(M\)</span> that parameterized the kinetic energy</p></li>
</ul>
<p>For example, if the step size is too large, the leapfrog integrator will be inaccurate and too many proposals will be rejected. However, if it is too small we will waste computation resources. If the number of steps is too small, the simulated trajectory at each iteration will be too short and sampling will fall back to random walk. But if it is too large the trajectory might runs in circles and we again waste computation resources. If the estimated covariance (inverse of the precision matrix) is too different from the posterior covariance, the proposal momentum will be suboptimal and the movement in the position space will be too large or too small in some dimension.</p>
<p>Adaptive dynamics Hamiltonian Monte Carlo methods, like those used by default in PyMC3, Stan and other PPLs can adapt these hyperparameters automatically during the warm-up or tuning phase. The step size can be learning automatically by adjusting it to match a predefined acceptance-rate target. For example, in PyMC3 you set the argument <code class="docutils literal notranslate"><span class="pre">target_accept</span></code> <a class="footnote-reference brackets" href="#id132" id="id85">27</a> The precision matrix <span class="math notranslate nohighlight">\(M\)</span> or its inverse can be estimated from the samples during warm-up phase and the number of steps can be dynamically adapted at each MCMC step using the NUTS algorithm <span id="id86">[<a class="reference internal" href="references.html#id98">157</a>]</span>. In order to avoid too long trajectory that could go near the initialization point, NUTS extends the trajectory backward and forwards until a U-turn criterion is met. Additionally, NUTS applies a multinomial sampling to choose from all the generated points from the trajectory, as this provides a better criteria for efficient exploration of the target distribution (sampling from the trajectory could be done with fixed integration time HMC as well).</p>
</div>
<div class="section" id="smc-details">
<span id="id87"></span><h3>11.9.4 序贯蒙塔卡洛采样器<a class="headerlink" href="#smc-details" title="Permalink to this headline">¶</a></h3>
<p>Sequential Monte Carlo is a family of Monte Carlo methods also known as particle filters. It has wide application to Bayesian inference for static models and dynamic models such as sequential time series inference and signal processing <span id="id88">[<a class="reference internal" href="references.html#id38">63</a>, <a class="reference internal" href="references.html#id37">158</a>, <a class="reference internal" href="references.html#id36">159</a>, <a class="reference internal" href="references.html#id35">160</a>]</span>. There are many variations and implementation under the same or similar name, with different application. Thus you might at times find the literature a bit confusing. We will give a brief description of the SMC/SMC-ABC method as implemented in PyMC3 and TFP. For a detailed discussion of SMC methods under a unified framework we recommend the book An Introduction to Sequential Monte Carlo <span id="id89">[<a class="reference internal" href="references.html#id38">63</a>]</span>.</p>
<p>First note that we can write the posterior in the following way:</p>
<div class="math notranslate nohighlight">
\[p(\boldsymbol{\theta} \mid Y)_{\beta}  \propto  p(Y \mid \boldsymbol{\theta})^{\beta} \; p(\boldsymbol{\theta})\]</div>
<p>When <span class="math notranslate nohighlight">\(\beta = 0\)</span> we see that <span class="math notranslate nohighlight">\(p(\boldsymbol{\theta} \mid Y)_{\beta}\)</span> is the prior and when <span class="math notranslate nohighlight">\(\beta = 1\)</span> we see that <span class="math notranslate nohighlight">\(p(\boldsymbol{\theta} \mid Y)_{\beta}\)</span> is the <em>true</em> posterior <a class="footnote-reference brackets" href="#id133" id="id90">28</a>.</p>
<p>SMC proceeds by increasing the value of <span class="math notranslate nohighlight">\(\beta\)</span> in <span class="math notranslate nohighlight">\(s\)</span> successive stages <span class="math notranslate nohighlight">\(\{\beta_0=0 &lt; \beta_1  &lt; ...  &lt; \beta_s=1\}\)</span>. Why is this a good idea? There are two related ways to justify it. First, the stepping stones analogy. Instead of directly trying to sample from the posterior we begin by sampling from the prior, which is generally easier to do. Then we add some intermediate distributions until we reach the posterior (see <a class="reference internal" href="chp_08.html#fig-smc-tempering"><span class="std std-numref">Fig. 135</span></a>). Second is the temperature analogy. The <span class="math notranslate nohighlight">\(\beta\)</span> parameters is analogue to the inverse temperature of a physical system, as we decrease its value (increase the temperature) the system is able to access to more states, and as we decrease its value (decrease the temperature) the system “freezes” into the posterior <a class="footnote-reference brackets" href="#id134" id="id91">29</a>. <a class="reference internal" href="chp_08.html#fig-smc-tempering"><span class="std std-numref">Fig. 135</span></a> shows an hypothetical sequence of tempered posteriors. The use of the temperature (or its inverse) as an auxiliary parameter is known as tempering, the term annealing is also common <a class="footnote-reference brackets" href="#id135" id="id92">30</a>.</p>
<p>The SMC method, as implemented in PyMC3 and TFP, can be summarized as follows:</p>
<ol class="simple">
<li><p>Initialize <span class="math notranslate nohighlight">\(\beta\)</span> at zero.</p></li>
<li><p>Generate <span class="math notranslate nohighlight">\(N\)</span> samples <span class="math notranslate nohighlight">\(s_{\beta}\)</span> from the tempered posterior.</p></li>
<li><p>Increase <span class="math notranslate nohighlight">\(\beta\)</span> in order to keep the effective sample size <a class="footnote-reference brackets" href="#id136" id="id93">31</a> at   a predefined value.</p></li>
<li><p>Compute a set of <span class="math notranslate nohighlight">\(N\)</span> importance weights <span class="math notranslate nohighlight">\(W\)</span>. The weights are   computed according to the new and old tempered posterior.</p></li>
<li><p>Obtain <span class="math notranslate nohighlight">\(s_w\)</span> by resampling <span class="math notranslate nohighlight">\(s_{\beta}\)</span> according to <span class="math notranslate nohighlight">\(W\)</span>.</p></li>
<li><p>Run <span class="math notranslate nohighlight">\(N\)</span> MCMC chains for <span class="math notranslate nohighlight">\(k\)</span> steps, starting each one from a   different sample in <span class="math notranslate nohighlight">\(s_w\)</span> and retaining only the samples in the last   step.</p></li>
<li><p>Repeat from step 3 until <span class="math notranslate nohighlight">\(\beta=1\)</span></p></li>
</ol>
<p>The resampling step works by removing samples with a low probability and replacing them with samples with a higher probability. This step decreases the diversity of the samples. Then, the MCMC step perturbs the samples, hopefully increasing the diversity and therefore helping SMC to explore the parameter space. Any valid MCMC transition kernel could be used in SMC, and depending on your problem you might find some perform better than others. For example, with ABC methods we generally need to rely on gradient-free methods such as Random Walk Metropolis-Hasting as the simulators are generally not differentiable.</p>
<p>The efficiency of the tempered method depends heavily on the intermediate values of <span class="math notranslate nohighlight">\(\beta\)</span>. The smaller the difference between two successive values of <span class="math notranslate nohighlight">\(\beta\)</span>, the closer the two successive tempered posteriors will be, and thus the easier the transition from one stage to the next. But if the steps are too small, we will need many intermediate stages, and beyond some point this will waste a lot of computational resources without really improving the accuracy of the results. Another important factor is the efficiency of the MCMC transitional kernel that adds diversity to the samples. To help improve the efficiency of the transition, PyMC3 and TFP uses the samples from the previous stage to tune the proposal distribution of the current stage and also the number of steps taken by the MCMC, with the number of steps being the same across all chains.</p>
</div>
<div class="section" id="vi-details">
<span id="id94"></span><h3>11.9.5 变分推断<a class="headerlink" href="#vi-details" title="Permalink to this headline">¶</a></h3>
<p>While we do not use variational inference in this book, it is a useful approach to know about. Compared to MCMC, VI tends to be easier to scale to large data and is faster to run computationally, but with less theoretical guarantees of convergence <span id="id95">[<a class="reference internal" href="references.html#id162">161</a>]</span>.</p>
<p>As we previously mentioned in Section <a class="reference internal" href="#dkl"><span class="std std-ref">11.3 KL 散度</span></a>, we can use one distribution to approximate another and then use the Kullback-Leibler (KL) divergence to measure how good the approximation is. Turns out we can use this approach to do Bayesian inference as well! Such approach is called variational inference (VI) <span id="id96">[<a class="reference internal" href="references.html#id159">162</a>]</span>. The goal of VI is to approximate the target probability density, in our case the posterior distribution <span class="math notranslate nohighlight">\(p(\boldsymbol{\theta} \mid Y)\)</span>, with a surrogate distribution <span class="math notranslate nohighlight">\(q(\boldsymbol{\theta})\)</span>. In practice we usually choose <span class="math notranslate nohighlight">\(q(\boldsymbol{\theta})\)</span> to be of simpler form than <span class="math notranslate nohighlight">\(p(\boldsymbol{\theta} \mid Y)\)</span>, and we find the member of that family of distributions, which is the closest to the target in the KL divergence sense, using optimization. With small rewrite to Equation <a class="reference internal" href="#equation-eq-kl-divergence">(96)</a>, we have:</p>
<div class="math notranslate nohighlight" id="equation-eq-kl-divergence2">
<span class="eqno">(117)<a class="headerlink" href="#equation-eq-kl-divergence2" title="Permalink to this equation">¶</a></span>\[\mathbb{KL}(q(\boldsymbol{\theta}) \parallel p(\boldsymbol{\theta} \mid Y)) = \mathbb{E}_q[\log{q(\boldsymbol{\theta})}-\log{p(\boldsymbol{\theta} \mid Y)}]   \]</div>
<p>However, this objective is hard to compute because it requires the marginal likelihood of <span class="math notranslate nohighlight">\(p(Y)\)</span>. To see that let us expand Equation <a class="reference internal" href="#equation-eq-kl-divergence2">(117)</a>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{split}
  \mathbb{KL}(q(\boldsymbol{\theta}) \parallel p(\boldsymbol{\theta} \mid Y)) &amp;= \mathbb{E}[\log{q(\boldsymbol{\theta})}] - \mathbb{E}[\log{p(\boldsymbol{\theta} \mid Y)}] \\
   &amp;= \mathbb{E}[\log{q(\boldsymbol{\theta})}] - \mathbb{E}[\log{p(\boldsymbol{\theta},  Y)}] + \log{p(Y)}
\end{split}\end{split}\]</div>
<p>Luckily, since <span class="math notranslate nohighlight">\(\log{p(Y)}\)</span> is a constant with respect to <span class="math notranslate nohighlight">\(q(\boldsymbol{\theta})\)</span>, we can omit it during optimization. Thus, in practice, we maximize the evidence lower bound (ELBO) as shown in Equation <a class="reference internal" href="#equation-eq-elbo-vi">(118)</a>, which is equivalent to minimizing the KL divergence:</p>
<div class="math notranslate nohighlight" id="equation-eq-elbo-vi">
<span class="eqno">(118)<a class="headerlink" href="#equation-eq-elbo-vi" title="Permalink to this equation">¶</a></span>\[\text{ELBO}(q) = \mathbb{E}[\log{p(\boldsymbol{\theta},  Y)}] - \mathbb{E}[\log{q(\boldsymbol{\theta})}]   \]</div>
<p>The last piece of the puzzle is to figure out how to compute the expectation in Equation <a class="reference internal" href="#equation-eq-elbo-vi">(118)</a>. Instead of solving an expensive integration, we compute the average using Monte Carlo samples drawn from the surrogate distribution <span class="math notranslate nohighlight">\(q(\boldsymbol{\theta})\)</span> and plug them into <a class="reference internal" href="#equation-eq-elbo-vi">(118)</a>.</p>
<p>The performance of VI depends on many factors. One of them being the family of surrogate distributions we choose from. For example, a more expressive surrogate distribution helps capture more complex, nonlinear dependencies among components of the target posterior distribution, and thus usually gives better result (see <a class="reference internal" href="#fig-vi-in-tfp"><span class="std std-numref">Fig. 203</span></a>).</p>
<p>Automatically choosing a good surrogate family distribution and efficiently optimizing it is currently an active research area. Code Block <a class="reference internal" href="#vi-in-tfp"><span class="std std-ref">vi_in_tfp</span></a> shows a simple example of using VI in TFP, with two different types of surrogate posterior distributions. The result is shown in <a class="reference internal" href="#fig-vi-in-tfp"><span class="std std-numref">Fig. 203</span></a>.</p>
<div class="literal-block-wrapper docutils container" id="vi-in-tfp">
<div class="code-block-caption"><span class="caption-number">Listing 172 </span><span class="caption-text">vi_in_tfp</span><a class="headerlink" href="#vi-in-tfp" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tfpe</span> <span class="o">=</span> <span class="n">tfp</span><span class="o">.</span><span class="n">experimental</span>
<span class="c1"># An arbitrary density function as target</span>
<span class="n">target_logprob</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="o">-</span><span class="p">(</span><span class="mf">1.</span><span class="o">-</span><span class="n">x</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">-</span> <span class="mf">1.5</span><span class="o">*</span><span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>

<span class="c1"># Set up two different surrogate posterior distribution</span>
<span class="n">event_shape</span> <span class="o">=</span> <span class="p">[(),</span> <span class="p">()]</span>  <span class="c1"># theta is 2 scalar</span>
<span class="n">mean_field_surrogate_posterior</span> <span class="o">=</span> <span class="n">tfpe</span><span class="o">.</span><span class="n">vi</span><span class="o">.</span><span class="n">build_affine_surrogate_posterior</span><span class="p">(</span>
    <span class="n">event_shape</span><span class="o">=</span><span class="n">event_shape</span><span class="p">,</span> <span class="n">operators</span><span class="o">=</span><span class="s2">"diag"</span><span class="p">)</span>
<span class="n">full_rank_surrogate_posterior</span> <span class="o">=</span> <span class="n">tfpe</span><span class="o">.</span><span class="n">vi</span><span class="o">.</span><span class="n">build_affine_surrogate_posterior</span><span class="p">(</span>
    <span class="n">event_shape</span><span class="o">=</span><span class="n">event_shape</span><span class="p">,</span> <span class="n">operators</span><span class="o">=</span><span class="s2">"tril"</span><span class="p">)</span>

<span class="c1"># Optimization</span>
<span class="n">losses</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">posterior_samples</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">approx</span> <span class="ow">in</span> <span class="p">[</span><span class="n">mean_field_surrogate_posterior</span><span class="p">,</span> <span class="n">full_rank_surrogate_posterior</span><span class="p">]:</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">tfp</span><span class="o">.</span><span class="n">vi</span><span class="o">.</span><span class="n">fit_surrogate_posterior</span><span class="p">(</span>
        <span class="n">target_logprob</span><span class="p">,</span> <span class="n">approx</span><span class="p">,</span> <span class="n">num_steps</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="mf">0.1</span><span class="p">),</span>
        <span class="n">sample_size</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
    <span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
    <span class="c1"># approx is a tfp distribution, we can sample from it after training</span>
    <span class="n">posterior_samples</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">approx</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">10000</span><span class="p">))</span>
</pre></div>
</div>
</div>
<p>seperator!</p>
<div class="figure align-default" id="fig-vi-in-tfp">
<a class="reference internal image-reference" href="../_images/vi_in_tfp.png"><img alt="../_images/vi_in_tfp.png" src="../_images/vi_in_tfp.png" style="width: 8.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 203 </span><span class="caption-text">Using variational inference to approximate a target density function.</span><a class="headerlink" href="#fig-vi-in-tfp" title="Permalink to this image">¶</a></p>
<div class="legend">
<p>The target density is a 2D banana shaped function plotted using contour lines. Two types of surrogate posterior distributions are used for the approximation: on the left panel a mean-field Gaussian (one univariate Gaussian for each dimension with trainable location and scale) and on the right panel a full-rank Gaussian (a 2D multivariate Gaussian with trainable mean and covariance matrix) <span id="id97">[<a class="reference internal" href="references.html#id163">163</a>]</span>.</p>
<p>Samples from the approximation after optimization are plotted as dots overlay on top of the true density. Comparing the two, you can see that while both approximations does not fully capture the shape of the target density, full-rank Gaussian is a better approximation thanks to its more complex structure.</p>
</div>
</div>
</div>
</div>
<div class="section" id="programming-ref">
<span id="id98"></span><h2>11.10 编程参考<a class="headerlink" href="#programming-ref" title="Permalink to this headline">¶</a></h2>
<p>计算贝叶斯的一部分很好，计算机和软件工具现在可用。使用这些工具可以帮助现代贝叶斯从业者共享模型、减少错误并加快模型构建和推理过程。为了让计算机为我们工作，我们需要对其进行编程，但这通常说起来容易做起来难。要有效地使用它们仍然需要思考和理解。在最后一节中，我们将为主要概念提供一些高级指导。</p>
<div class="section" id="which-programming-language">
<span id="id99"></span><h3>11.10.1 哪种编程语言 ?<a class="headerlink" href="#which-programming-language" title="Permalink to this headline">¶</a></h3>
<p>有许多编程语言。我们主要使用 Python，但其他流行的语言，如 Julia、R、C/C++ 也存在用于贝叶斯计算的专门应用程序。那么你应该使用哪种编程语言呢？这里没有普遍的正确或错误答案。相反，你应该始终考虑完整的生态系统。在本书中，我们使用 Python，因为像 ArviZ、Matplotlib 和 Pandas 这样的包可以使数据处理和显示变得容易。这不是 Python 独有的。对于贝叶斯主义者，请特别考虑该特定语言中可用的 PPL，因为如果不存在，那么你可能需要重新考虑你选择的编程语言。还要考虑你要与之合作的社区以及他们使用的语言。这本书的作者之一住在南加州，所以会英语和一点西班牙语很有意义，因为他可以在常见的情况下进行交流。编程语言也是如此，如果你未来的实验室组使用 R，那么学习 R 是一个好主意。</p>
<p>计算纯粹主义者可能会惊呼某些语言在计算上比其他语言更快。这当然是正确的，但我们建议不要过于专注于“哪个是最快的 ppl\”的讨论。在现实生活场景中，不同的模型需要不同的时间来运行。</p>
<p>此外，还有“人类时间”，即迭代并提出模型的时间，以及“模型运行时间”，即计算机返回有用结果所需的时间。这些是不一样的，在不同的情况下，一个比另一个更重要。这就是说，不要太担心选择“正确”的前门语言，如果你有效地学习一种，概念就会转移到另一种。</p>
</div>
<div class="section" id="version-control">
<span id="id100"></span><h3>11.10.2 版本控制<a class="headerlink" href="#version-control" title="Permalink to this headline">¶</a></h3>
<p>版本控制不是必需的，但绝对推荐使用，如果使用会带来很大的好处。单独工作时，版本控制可让你迭代模型设计，而不必担心丢失代码或进行更改或试验会破坏模型。这本身就可以让你更快、更有信心地进行迭代，以及在不同模型定义之间来回切换的能力。</p>
<p>与他人合作时，版本控制支持协作和代码共享，如果没有版本控制系统允许的快照或比较功能，这将是具有挑战性或不可能执行的。</p>
<p>有许多不同的版本控制系统（Mercurial、SVN、Perforce），但 git 目前是最流行的。版本控制通常不依赖于特定的编程语言。</p>
</div>
<div class="section" id="dependency-management-and-package-repositories">
<span id="id101"></span><h3>11.10.3 依赖管理和包仓库<a class="headerlink" href="#dependency-management-and-package-repositories" title="Permalink to this headline">¶</a></h3>
<p>几乎所有代码都依赖于其他代码来运行（一直是海龟）。 PPL 尤其依赖于许多不同的库来运行。</p>
<p>我们强烈建议你熟悉一个需求管理工具，它可以帮助你查看、列出和冻结你的分析所依赖的包。此外，包存储库是从中获取这些需求包的地方。这些通常特定于该语言，例如，Python 中的一个需求管理工具是 pip，而流行的云存储库是 pypi。在 Scala 中，sbt 是一种帮助解决依赖关系的工具，而 Maven 是一种流行的包存储库。</p>
<p>所有成熟的语言都会有这种工具，但你必须有意识地选择使用它们。</p>
</div>
<div class="section" id="environment-management">
<span id="id102"></span><h3>11.10.4 环境管理<a class="headerlink" href="#environment-management" title="Permalink to this headline">¶</a></h3>
<p>所有代码都在一个环境中执行。大多数人会忘记这一点，直到他们的代码突然停止工作，或者不能在另一台计算机上工作。</p>
<p>环境管理是用于创建可重现计算环境的一组工具。这对于在模型中处理足够随机性并且不希望计算机添加额外的可变性的贝叶斯建模者来说尤其重要。</p>
<p>不幸的是，环境管理也是编程中最令人困惑的部分之一。一般来说，有两种粗略的环境控制类型，语言特定的和语言不可知的。在 Python 中，virtualenv 是一个特定于 Python 的环境管理器，而容器化和虚拟化与语言无关。我们在这里没有具体建议，因为选择很大程度上取决于你对这些工具的舒适度，以及你计划在哪里运行代码。不过，我们绝对建议你在这里做出慎重的选择，因为它可以确保你获得可重复的结果。</p>
</div>
<div class="section" id="vs-vs-notebook">
<span id="dev-environment"></span><h3>11.10.5 文本编辑器 vs 集成开发环境 vs Notebook<a class="headerlink" href="#vs-vs-notebook" title="Permalink to this headline">¶</a></h3>
<p>编写代码时，你必须将其写在某个地方。对于有数据意识的人来说，通常有三个接口。</p>
<p>第一个也是最简单的是文本编辑器。最基本的文本编辑器允许你惊喜地编辑文本并保存它。使用这些编辑器，你可以编写 python 程序，保存它，然后运行它。通常，文本编辑器非常“轻量级”，除了查找和替换等基本功能之外不包含太多额外功能。把文本编辑器想象成一辆自行车。它们很简单，它们的界面基本上是一个车把和一些踏板，它们会让你从这里到那里，但主要是由你来完成工作。</p>
<p>与现代飞机相比，集成开发环境 (IDE)。它们具有大量的功能、大量的按钮和大量的自动化。 IDE 允许你在其核心编辑文本，但顾名思义，它们也集成了开发的许多其他方面。例如，运行代码、单元测试、linting 代码、版本控制、代码版本比较等功能。在编写跨多个模块的大量复杂代码时，IDE 通常最有用。
虽然我们很乐意提供文本编辑器与 IDE 的简单定义，但如今这条线非常模糊。我们的建议是更多地从文本编辑器开始，一旦熟悉了代码的工作原理，就转向 IDE。否则，你将很难说出 IDE 在“幕后”为你做什么。</p>
<p>笔记本是一个完全不同的界面。笔记本的特殊之处在于它们混合了代码、输出和文档，并允许非线性代码执行。对于本书，大部分代码和图形都以 Jupyter Notebook 文件的形式呈现。我们还提供了 Google Colab 的链接，这是一个云笔记本环境。笔记本通常最适合用于探索性数据分析和解释型情况，例如本书。它们不太适合运行生产代码。我们对笔记本的建议类似于 IDE。如果不熟悉统计计算，请先从文本编辑器开始。一旦你掌握了如何从单个文件运行代码，然后转移到笔记本环境，无论是云托管的 Google colab、Binder 实例还是本地 Jupyter Notebook 。</p>
</div>
<div class="section" id="the-specific-tools-used-for-this-book">
<span id="id103"></span><h3>11.10.6 本书用到的特定工具<a class="headerlink" href="#the-specific-tools-used-for-this-book" title="Permalink to this headline">¶</a></h3>
<p>这是我们用于这本书的内容。这并不意味着这些是你可以使用的唯一工具，这些只是我们使用的工具。</p>
<ul class="simple">
<li><p><strong>编程语言</strong>: Python</p></li>
<li><p><strong>概率编程语言</strong>: PyMC3, TensorFlow   Probability. Stan and Numpyro are displayed briefly as well.</p></li>
<li><p><strong>版本控制</strong>: git</p></li>
<li><p><strong>依赖管理</strong>: pip and conda</p></li>
<li><p><strong>包仓库</strong>: pypi, conda-forge</p></li>
<li><p><strong>环境管理</strong>: conda</p></li>
<li><p><strong>通用文档</strong>: LaTeX (for book writing), Markdown (for   code package), Jupyter Notebooks</p></li>
</ul>
<hr class="docutils"/>
<hr class="footnotes docutils"/>
<dl class="footnote brackets">
<dt class="label" id="id104"><span class="brackets"><a class="fn-backref" href="#id3">1</a></span></dt>
<dd><p>Most of the territory of what we now call Spain and Portugal was   part of Al-Andalus and Arabic state, this had a tremendous influence   in the Spanish/Portuguese culture, including food, music, language   and also in the genetic makeup.</p>
</dd>
<dt class="label" id="id105"><span class="brackets"><a class="fn-backref" href="#id4">2</a></span></dt>
<dd><p>For those who are interested in delving further into the subject,   we recommend reading the book Introduction to Probability by Joseph   K. Blitzstein and Jessica Hwang <span id="id106">[<a class="reference internal" href="references.html#id10">5</a>]</span>.</p>
</dd>
<dt class="label" id="id107"><span class="brackets"><a class="fn-backref" href="#id6">3</a></span></dt>
<dd><p>From this definition John K. Kruschke wonderfully states that   Bayesian inference is reallocation of credibility (probability)   across possibilities <span id="id108">[<a class="reference internal" href="references.html#id93">164</a>]</span>.</p>
</dd>
<dt class="label" id="id109"><span class="brackets"><a class="fn-backref" href="#id10">4</a></span></dt>
<dd><p>If we need to locate the circumference relative to other objects   in the plane, we would also need the coordinates of the center, but   let us omit that detail for now.</p>
</dd>
<dt class="label" id="id110"><span class="brackets"><a class="fn-backref" href="#id12">5</a></span></dt>
<dd><p>Increase or remain constant but never decrease.</p>
</dd>
<dt class="label" id="id111"><span class="brackets"><a class="fn-backref" href="#id13">6</a></span></dt>
<dd><p>Loosely speaking, a right-continuous function has no jump when the   limit point is approached from the right.</p>
</dd>
<dt class="label" id="id112"><span class="brackets"><a class="fn-backref" href="#id17">7</a></span></dt>
<dd><p>The result of one outcome does not affect the others.</p>
</dd>
<dt class="label" id="id113"><span class="brackets"><a class="fn-backref" href="#id19">8</a></span></dt>
<dd><p>Or more precisely if we take the limit of the Bin<span class="math notranslate nohighlight">\((n, p)\)</span>   distribution as <span class="math notranslate nohighlight">\(n \to \infty\)</span> and <span class="math notranslate nohighlight">\(p \to 0\)</span> with <span class="math notranslate nohighlight">\(np\)</span> fixed we get   a Poisson distribution.</p>
</dd>
<dt class="label" id="id114"><span class="brackets"><a class="fn-backref" href="#id21">9</a></span></dt>
<dd><p>A proper discussion that avoids non-sensical statements would   require a discussion of measure theory. But we will side-step this   requirement.</p>
</dd>
<dt class="label" id="id115"><span class="brackets"><a class="fn-backref" href="#id22">10</a></span></dt>
<dd><p>You can use check this statement yourself with the help of SciPy.</p>
</dd>
<dt class="label" id="id116"><span class="brackets"><a class="fn-backref" href="#id26">11</a></span></dt>
<dd><p>Not only on planet Earth, but even on other planets judging by   the Gaussian-shaped UFOs we have observed (just kidding, this is of   course a joke, just as ufology).</p>
</dd>
<dt class="label" id="id117"><span class="brackets"><a class="fn-backref" href="#id27">12</a></span></dt>
<dd><p>This distribution was discovered by William Gosset while trying   to improve the methods of quality control in a brewery. Employees of   that company were allow to publish scientific papers as long as they   did not use the word beer, the company name, and their own surname.Thus Gosset publish under the name Student.</p>
</dd>
<dt class="label" id="id118"><span class="brackets"><a class="fn-backref" href="#id28">13</a></span></dt>
<dd><p><a class="reference external" href="https://en.wikipedia.org/wiki/Gamma_function">https://en.wikipedia.org/wiki/Gamma_function</a></p>
</dd>
<dt class="label" id="id119"><span class="brackets"><a class="fn-backref" href="#id29">14</a></span></dt>
<dd><p><span class="math notranslate nohighlight">\(\nu\)</span> can take values below 1.</p>
</dd>
<dt class="label" id="id120"><span class="brackets"><a class="fn-backref" href="#id40">15</a></span></dt>
<dd><p>See, for example, <a class="reference external" href="https://www.youtube.com/watch?v=i5oND7rHtFs">https://www.youtube.com/watch?v=i5oND7rHtFs</a></p>
</dd>
<dt class="label" id="id121"><span class="brackets"><a class="fn-backref" href="#id41">16</a></span></dt>
<dd><p>For those familiar with eigenvectors and eigenvalues this should   ring a bell.</p>
</dd>
<dt class="label" id="id122"><span class="brackets"><a class="fn-backref" href="#id42">17</a></span></dt>
<dd><p>Another analogy comes from politics, when politicians/government   changes but pressing issues like inequality or climate change are   not properly addressed.</p>
</dd>
<dt class="label" id="id123"><span class="brackets"><a class="fn-backref" href="#id44">18</a></span></dt>
<dd><p>To be precise we should include the molecules of glass and the   molecules in the air, and… but let just focus on the water.</p>
</dd>
<dt class="label" id="id124"><span class="brackets"><a class="fn-backref" href="#id45">19</a></span></dt>
<dd><p>Do not let that Heisenberg guy and his uncertainty principle   spoil the party</p>
</dd>
<dt class="label" id="id125"><span class="brackets"><a class="fn-backref" href="#id49">20</a></span></dt>
<dd><p>Generally pronounced as W-A-I-C, even when something like   wæ[i]{.smallcaps}k is less of a mouthful</p>
</dd>
<dt class="label" id="id126"><span class="brackets"><a class="fn-backref" href="#id65">21</a></span></dt>
<dd><p>We do not like these rules of thumb, but you can check, for   example, here   <a class="reference external" href="https://en.wikipedia.org/wiki/Bayes_factor#Interpretation">https://en.wikipedia.org/wiki/Bayes_factor#Interpretation</a></p>
</dd>
<dt class="label" id="id127"><span class="brackets"><a class="fn-backref" href="#id66">22</a></span></dt>
<dd><p>In practice it is very common to actually compute the marginal   likelihood in log-scale for computational stability. In such a case   a Bayes factor becomes a difference of two log marginal likelihoods</p>
</dd>
<dt class="label" id="id128"><span class="brackets"><a class="fn-backref" href="#id69">23</a></span></dt>
<dd><p>The names derived from a famous casino with that name in the   Principality of Monaco.</p>
</dd>
<dt class="label" id="id129"><span class="brackets"><a class="fn-backref" href="#id70">24</a></span></dt>
<dd><p>This video shows a closely related example in a very calm and   clear way <a class="reference external" href="https://www.youtube.com/watch?v=zwAD6dRSVyI">https://www.youtube.com/watch?v=zwAD6dRSVyI</a></p>
</dd>
<dt class="label" id="id130"><span class="brackets"><a class="fn-backref" href="#id81">25</a></span></dt>
<dd><p>The name Hybrid Monte Carlo is also used because is was   originally conceived as a hybrid method combining molecular   mechanics, a widely-used simulation technique for molecular systems,   and Metropolis-Hastings.</p>
</dd>
<dt class="label" id="id131"><span class="brackets"><a class="fn-backref" href="#id83">26</a></span></dt>
<dd><p>Code copied from our good friend Colin Carroll’s blogpost on HMC   <a class="reference external" href="https://colindcarroll.com/2019/04/11/hamiltonian-monte-carlo-from-scratch/">https://colindcarroll.com/2019/04/11/hamiltonian-monte-carlo-from-scratch/</a></p>
</dd>
<dt class="label" id="id132"><span class="brackets"><a class="fn-backref" href="#id85">27</a></span></dt>
<dd><p>This value is in the interval <span class="math notranslate nohighlight">\([0, 1]\)</span>, and by default this value   is 0.8. See Section <a class="reference internal" href="chp_02.html#divergences"><span class="std std-ref">2.4.7 发散性</span></a>.</p>
</dd>
<dt class="label" id="id133"><span class="brackets"><a class="fn-backref" href="#id90">28</a></span></dt>
<dd><p>We mean true purely from a mathematical point of view, without   any reference to how adequate is such posterior to any particular   practical problem.</p>
</dd>
<dt class="label" id="id134"><span class="brackets"><a class="fn-backref" href="#id91">29</a></span></dt>
<dd><p>See <a class="reference internal" href="#entropy"><span class="std std-ref">11.2 熵</span></a> for more details on this analogy with physical   system.</p>
</dd>
<dt class="label" id="id135"><span class="brackets"><a class="fn-backref" href="#id92">30</a></span></dt>
<dd><p>These terms are borrowed from metallurgy in particular describing   specific processes where alloyed metal is heated and cooled to   obtain a particular molecular structure.</p>
</dd>
<dt class="label" id="id136"><span class="brackets"><a class="fn-backref" href="#id93">31</a></span></dt>
<dd><p>This effective sample size is computed from the importance   weights which is different from the ESS we have been computing to   diagnosing MCMC samplers, that is computed from the autocorrelation   of the samples.</p>
</dd>
</dl>
</div>
</div>
</div>
<script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./zh_CN"
        },
        predefinedOutput: true
    }
    </script>
<script>kernelName = 'python3'</script>
</div>
<!-- Previous / next buttons -->
<div class="prev-next-area">
<a class="left-prev" href="chp_10.html" id="prev-link" title="previous page">
<i class="fas fa-angle-left"></i>
<div class="prev-next-info">
<p class="prev-next-subtitle">previous</p>
<p class="prev-next-title">第十章: 概率编程语言</p>
</div>
</a>
<a class="right-next" href="glossary.html" id="next-link" title="next page">
<div class="prev-next-info">
<p class="prev-next-subtitle">next</p>
<p class="prev-next-title">词汇表</p>
</div>
<i class="fas fa-angle-right"></i>
</a>
</div>
</div>
</div>
<footer class="footer">
<p>
    
      By Martin, Kumar, Lao<br/>
    
        © Copyright 2021.<br/>
</p>
</footer>
</main>
</div>
</div>
<script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>
</body>
</html>