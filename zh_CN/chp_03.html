
<!DOCTYPE html>

<html>
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>第三章：线性模型与概率编程语言 — Bayesian Modeling and Computation in Python</title>
<link href="../_static/css/theme.css" rel="stylesheet"/>
<link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet"/>
<link href="../_static/vendor/fontawesome/5.13.0/css/all.min.css" rel="stylesheet"/>
<link as="font" crossorigin="" href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2" rel="preload" type="font/woff2"/>
<link href="../_static/pygments.css" rel="stylesheet" type="text/css">
<link href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" rel="stylesheet" type="text/css">
<link href="../_static/togglebutton.css" rel="stylesheet" type="text/css">
<link href="../_static/copybutton.css" rel="stylesheet" type="text/css">
<link href="../_static/mystnb.css" rel="stylesheet" type="text/css">
<link href="../_static/sphinx-thebe.css" rel="stylesheet" type="text/css"/>
<link href="../_static/sphinx-codeautolink.css" rel="stylesheet" type="text/css"/>
<link href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" rel="stylesheet" type="text/css"/>
<link href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" rel="stylesheet" type="text/css"/>
<link as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js" rel="preload"/>
<script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
<script src="../_static/jquery.js"></script>
<script src="../_static/underscore.js"></script>
<script src="../_static/doctools.js"></script>
<script src="../_static/togglebutton.js"></script>
<script src="../_static/clipboard.min.js"></script>
<script src="../_static/copybutton.js"></script>
<script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
<script src="../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
<script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
<script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
<script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
<script async="async" src="../_static/sphinx-thebe.js"></script>
<link href="../_static/favicon.ico" rel="shortcut icon">
<link href="../genindex.html" rel="index" title="Index"/>
<link href="../search.html" rel="search" title="Search"/>
<link href="chp_04.html" rel="next" title="第四章：扩展线性模型"/>
<link href="chp_02.html" rel="prev" title="第二章: 贝叶斯模型的探索性分析"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="None" name="docsearch:language"/>
<!-- Google Analytics -->
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-702QMHG8ST"></script>
<script>
                    window.dataLayer = window.dataLayer || [];
                    function gtag(){ dataLayer.push(arguments); }
                    gtag('js', new Date());
                    gtag('config', 'G-702QMHG8ST');
                </script>
</link></link></link></link></link></link></head>
<body data-offset="80" data-spy="scroll" data-target="#bd-toc-nav">
<div class="container-fluid" id="banner"></div>
<div class="container-xl">
<div class="row">
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
<div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
<h1 class="site-logo" id="site-title">Bayesian Modeling and Computation in Python</h1>
</a>
</div><form action="../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="icon fas fa-search"></i>
<input aria-label="Search this book..." autocomplete="off" class="form-control" id="search-input" name="q" placeholder="Search this book..." type="search"/>
</form><nav aria-label="Main" class="bd-links" id="bd-docs-nav">
<div class="bd-toc-item active">
<ul class="current nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="dedication.html">
   贡献
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="foreword.html">
   序言
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="preface.html">
   前言
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="symbollist.html">
   符号表
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chp_01.html">
   第一章: 贝叶斯推断
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chp_02.html">
   第二章: 贝叶斯模型的探索性分析
  </a>
</li>
<li class="toctree-l1 current active">
<a class="current reference internal" href="#">
   第三章：线性模型与概率编程语言
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chp_04.html">
   第四章：扩展线性模型
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chp_05.html">
   第五章: 样条
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chp_06.html">
   第六章: 时间序列
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chp_07.html">
   第七章：贝叶斯加性回归树
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chp_08.html">
   第八章：近似贝叶斯计算
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chp_09.html">
   第九章: 端到端的贝叶斯工作流
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chp_10.html">
   第十章: 概率编程语言
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chp_11.html">
   第十一章: 附加主题
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="glossary.html">
   词汇表
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="references.html">
   References
  </a>
</li>
</ul>
</div>
</nav> <!-- To handle the deprecated key -->
<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>
</div>
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
<div class="topbar container-xl fixed-top">
<div class="topbar-contents row">
<div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
<div class="col pl-md-4 topbar-main">
<button aria-controls="site-navigation" aria-expanded="true" aria-label="Toggle navigation" class="navbar-toggler ml-0" data-placement="left" data-target=".site-navigation" data-toggle="tooltip" id="navbar-toggler" title="Toggle navigation" type="button">
<i class="fas fa-bars"></i>
<i class="fas fa-arrow-left"></i>
<i class="fas fa-arrow-up"></i>
</button>
<!-- Source interaction buttons -->
<div class="dropdown-buttons-trigger">
<button aria-label="Connect with source repository" class="btn btn-secondary topbarbtn" id="dropdown-buttons-trigger"><i class="fab fa-github"></i></button>
<div class="dropdown-buttons sourcebuttons">
<a class="repository-button" href="https://github.com/BayesianModelingandComputationInPython/BookCode_Edition1"><button class="btn btn-secondary topbarbtn" data-placement="left" data-toggle="tooltip" title="Source repository" type="button"><i class="fab fa-github"></i>repository</button></a>
<a class="issues-button" href="https://github.com/BayesianModelingandComputationInPython/BookCode_Edition1/issues/new?title=Issue%20on%20page%20%2Fzh_CN/chp_03.html&amp;body=Your%20issue%20content%20here."><button class="btn btn-secondary topbarbtn" data-placement="left" data-toggle="tooltip" title="Open an issue" type="button"><i class="fas fa-lightbulb"></i>open issue</button></a>
</div>
</div>
<!-- Full screen (wrap in <a> to have style consistency -->
<a class="full-screen-button"><button aria-label="Fullscreen mode" class="btn btn-secondary topbarbtn" data-placement="bottom" data-toggle="tooltip" onclick="toggleFullScreen()" title="Fullscreen mode" type="button"><i class="fas fa-expand"></i></button></a>
<!-- Launch buttons -->
</div>
<!-- Table of contents -->
<div class="d-none d-md-block col-md-2 bd-toc show noprint">
<div class="tocsection onthispage pt-5 pb-3">
<i class="fas fa-list"></i> Contents
            </div>
<nav aria-label="Page" id="bd-toc-nav">
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#comparing-distributions">
   3.1 比较两个或多个组
  </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#comparing-two-ppls">
     3.1.1 比较两种概率编程语言
    </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#linear-regression">
   3.2 线性回归
  </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#linear-regression-intro">
     3.2.1 线性企鹅模型
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#chp2-predictions">
     3.2.2 预测
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#centering">
     3.2.3 中心化处理
    </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#multiple-linear-regression">
   3.3 多元线性回归
  </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#linear-counter-factuals">
     3.3.1 反事实分析
    </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#generalized-linear-models">
   3.4 广义线性模型
  </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#logistic-regression">
     3.4.1 逻辑斯谛回归
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#classifying-penguins">
     3.4.2 对企鹅进行分类
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#log-odds">
     3.4.3 解读对数赔率（ Log Odds ）
    </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#picking-priors-in-regression-models">
   3.5 选择回归模型中的先验
  </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#exercises3">
   3.6 练习
  </a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="row" id="main-content">
<div class="col-12 col-md-9 pl-md-3 pr-md-0">
<!-- Table of contents that is only displayed when printing the page -->
<div class="onlyprint" id="jb-print-docs-body">
<h1>第三章：线性模型与概率编程语言</h1>
<!-- Table of contents -->
<div id="print-main-content">
<div id="jb-print-toc">
<div>
<h2> Contents </h2>
</div>
<nav aria-label="Page">
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#comparing-distributions">
   3.1 比较两个或多个组
  </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#comparing-two-ppls">
     3.1.1 比较两种概率编程语言
    </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#linear-regression">
   3.2 线性回归
  </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#linear-regression-intro">
     3.2.1 线性企鹅模型
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#chp2-predictions">
     3.2.2 预测
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#centering">
     3.2.3 中心化处理
    </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#multiple-linear-regression">
   3.3 多元线性回归
  </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#linear-counter-factuals">
     3.3.1 反事实分析
    </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#generalized-linear-models">
   3.4 广义线性模型
  </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#logistic-regression">
     3.4.1 逻辑斯谛回归
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#classifying-penguins">
     3.4.2 对企鹅进行分类
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#log-odds">
     3.4.3 解读对数赔率（ Log Odds ）
    </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#picking-priors-in-regression-models">
   3.5 选择回归模型中的先验
  </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#exercises3">
   3.6 练习
  </a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div>
<div class="tex2jax_ignore mathjax_ignore section" id="chap2">
<span id="id1"></span><h1>第三章：线性模型与概率编程语言<a class="headerlink" href="#chap2" title="Permalink to this headline">¶</a></h1>
<style>p{text-indent:2em;2}</style>
<p>随着概率编程语言的出现，现代贝叶斯建模只需要编码一个模型和 “按一个按钮 “那样简单。然而，有效模型的建立和分析通常需要更多的工作。</p>
<p>随着本书的推进，我们将建立许多不同类型的模型，但在本章中将从最简单的线性模型开始。线性模型是一类广泛应用的模型，其中一个指定观测值（ 结果变量 ）的<strong>期望值</strong>是相关预测因子（ 预测变量 ）的<strong>线性组合</strong>。</p>
<p>深刻理解拟合和解释线性模型的方法，是后续很多模型的坚实基础；并将有助于我们巩固『贝叶斯推断（ <a class="reference internal" href="chp_01.html#chap1"><span class="std std-ref"> 第 1 章 </span></a> ）』和『贝叶斯模型的探索性分析（第 <a class="reference internal" href="chp_02.html#chap1bis"><span class="std std-ref">2</span></a> 章）』的基本知识。</p>
<p>本章将介绍两种概率编程语言：<code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 和 <code class="docutils literal notranslate"><span class="pre">TensorFlow</span> <span class="pre">Probability</span> <span class="pre">(TFP)</span></code>。当我们使用这两种概率编程语言构建模型时，应当重点关注同一基础统计思想是如何在两种概率编程语言中实现的。</p>
<p>我们将首先拟合一个仅包含截距的模型（ 即没有预测变量的模型 ），然后通过添加一个或多个预测变量来增加复杂性，并扩展到广义线性模型。在本章结束时，你将更加理解线性模型，更加熟悉贝叶斯工作流中的常见步骤，并且更轻松地使用 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code>、<code class="docutils literal notranslate"><span class="pre">TFP</span></code> 和 <code class="docutils literal notranslate"><span class="pre">ArviZ</span></code> 实施贝叶斯工作流。</p>
<div class="section" id="comparing-distributions">
<span id="id2"></span><h2>3.1 比较两个或多个组<a class="headerlink" href="#comparing-distributions" title="Permalink to this headline">¶</a></h2>
<p>如果你正在寻找一些可以比较的东西，那么企鹅是最合适不过的了。</p>
<p>我们的第一个问题可能是 “每个企鹅物种的平均体重是多少？”，或者可能是“它们的平均体重有什么不同？”，或者用统计学术语来说 “均值的离散度是多少？” 。</p>
<p><code class="docutils literal notranslate"><span class="pre">Kristen</span> <span class="pre">Gorman</span></code> 很喜欢研究企鹅，她访问了 <span class="math notranslate nohighlight">\(3\)</span> 个南极岛屿并收集了有关 <code class="docutils literal notranslate"><span class="pre">Adelie</span></code>、<code class="docutils literal notranslate"><span class="pre">Gentoo</span></code> 和 <code class="docutils literal notranslate"><span class="pre">Chinstrap</span></code> 三个物种的数据，这些数据被编撰进了 <code class="docutils literal notranslate"><span class="pre">Palmer</span> <span class="pre">Penguins</span> <span class="pre">数据集</span></code> 中 <span id="id3">[<a class="reference internal" href="references.html#id58">28</a>]</span>。观测数据包括企鹅的体重、鳍状肢长度、性别特征、所居住岛屿等。</p>
<p>我们首先通过代码 <a class="reference internal" href="#penguin-load"><span class="std std-ref">penguin_load</span></a> 加载数据，并过滤掉存在缺失数据的行。这种方式被称为<strong>完整案例分析（ complete case analysis ）</strong>，顾名思义，我们只使用所有观测值都存在的行。尽管有一些处理缺失数据的成熟方法，但此处将采用最简单的剔除法。</p>
<div class="literal-block-wrapper docutils container" id="penguin-load">
<div class="code-block-caption"><span class="caption-number">Listing 14 </span><span class="caption-text">penguin_load</span><a class="headerlink" href="#penguin-load" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">penguins</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">"../data/penguins.csv"</span><span class="p">)</span>
<span class="c1"># Subset to the columns needed</span>
<span class="n">missing_data</span> <span class="o">=</span> <span class="n">penguins</span><span class="o">.</span><span class="n">isnull</span><span class="p">()[</span>
    <span class="p">[</span><span class="s2">"bill_length_mm"</span><span class="p">,</span> <span class="s2">"flipper_length_mm"</span><span class="p">,</span> <span class="s2">"sex"</span><span class="p">,</span> <span class="s2">"body_mass_g"</span><span class="p">]</span>
<span class="p">]</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="c1"># Drop rows with any missing data</span>
<span class="n">penguins</span> <span class="o">=</span> <span class="n">penguins</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="o">~</span><span class="n">missing_data</span><span class="p">]</span>
</pre></div>
</div>
</div>
<p>然后，可以用代码 <a class="reference internal" href="#penguin-mass-empirical"><span class="std std-ref">penguin_mass_empirical</span></a> 计算企鹅体重的经验均值  <code class="docutils literal notranslate"><span class="pre">body_mass_g</span></code> ，其结果展示在 <a class="reference internal" href="#tab-penguin-mass-parameters-point-estimates"><span class="std std-numref">Table 3</span></a> 中。</p>
<div class="literal-block-wrapper docutils container" id="penguin-mass-empirical">
<div class="code-block-caption"><span class="caption-number">Listing 15 </span><span class="caption-text">penguin_mass_empirical</span><a class="headerlink" href="#penguin-mass-empirical" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">summary_stats</span> <span class="o">=</span> <span class="p">(</span><span class="n">penguins</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="p">[</span><span class="s2">"species"</span><span class="p">,</span> <span class="s2">"body_mass_g"</span><span class="p">]]</span>
                         <span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">"species"</span><span class="p">)</span>
                         <span class="o">.</span><span class="n">agg</span><span class="p">([</span><span class="s2">"mean"</span><span class="p">,</span> <span class="s2">"std"</span><span class="p">,</span> <span class="s2">"count"</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<table class="table" id="tab-penguin-mass-parameters-point-estimates">
<caption><span class="caption-number">Table 3 </span><span class="caption-text">企鹅体重的经验均值和标准差。计数栏表示观测到的各物种企鹅数量。</span><a class="headerlink" href="#tab-penguin-mass-parameters-point-estimates" title="Permalink to this table">¶</a></caption>
<colgroup>
<col style="width: 25%"/>
<col style="width: 25%"/>
<col style="width: 25%"/>
<col style="width: 25%"/>
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>species</strong></p></td>
<td><p><strong>mean (grams)</strong></p></td>
<td><p><strong>std (grams)</strong></p></td>
<td><p><strong>count</strong></p></td>
</tr>
<tr class="row-even"><td><p><strong>Adelie</strong></p></td>
<td><p>3706</p></td>
<td><p>459</p></td>
<td><p>146</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Chinstrap</strong></p></td>
<td><p>3733</p></td>
<td><p>384</p></td>
<td><p>68</p></td>
</tr>
<tr class="row-even"><td><p><strong>Gentoo</strong></p></td>
<td><p>5092</p></td>
<td><p>501</p></td>
<td><p>119</p></td>
</tr>
</tbody>
</table>
<p>现在有了均值和离散度（用标准差来描述）的点估计，但无法掌握这些统计数据的不确定性。获得不确定性估计的方法之一就是贝叶斯方法。为此，需要推测观测数据与参数之间的关系，例如：</p>
<div class="math notranslate nohighlight" id="equation-eq-gaussian-bayes">
<span class="eqno">(24)<a class="headerlink" href="#equation-eq-gaussian-bayes" title="Permalink to this equation">¶</a></span>\[\overbrace{p(\mu, \sigma \mid Y)}^{Posterior} \propto \overbrace{\mathcal{N}(Y \mid \mu, \sigma)}^{Likelihood}\;  \overbrace{\underbrace{\mathcal{N}(4000, 3000)}_{\mu}
\underbrace{\mathcal{H}\text{T}(100, 2000)}_{\sigma}}^{Prior}\]</div>
<p>公式 <a class="reference internal" href="#equation-eq-gaussian-bayes">(24)</a> 是公式 <a class="reference internal" href="chp_01.html#equation-eq-proportional-bayes">(3)</a> 的重述，其中明确列出了本例中的每个参数。由于没有特定理由选择信息性的先验，因此对 <span class="math notranslate nohighlight">\(\mu\)</span> 和 <span class="math notranslate nohighlight">\(\sigma\)</span> 使用了宽泛的无信息先验。目前情况下，先验的选择依据是观测数据的经验均值和标准差。然后我们从 <code class="docutils literal notranslate"><span class="pre">Adelie</span> <span class="pre">种企鹅</span></code> 的体重开始，而不是估计所有物种的体重。一般而言，高斯是企鹅体重（ 以及其他生物体重 ）似然函数的合理选择，因此根据公式 <a class="reference internal" href="#equation-eq-gaussian-bayes">(24)</a> 转换为如下计算模型：</p>
<div class="literal-block-wrapper docutils container" id="penguin-mass">
<div class="code-block-caption"><span class="caption-number">Listing 16 </span><span class="caption-text">penguin_mass</span><a class="headerlink" href="#penguin-mass" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">adelie_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">penguins</span><span class="p">[</span><span class="s2">"species"</span><span class="p">]</span> <span class="o">==</span> <span class="s2">"Adelie"</span><span class="p">)</span>
<span class="n">adelie_mass_obs</span> <span class="o">=</span> <span class="n">penguins</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">adelie_mask</span><span class="p">,</span> <span class="s2">"body_mass_g"</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>

<span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">model_adelie_penguin_mass</span><span class="p">:</span>
    <span class="n">σ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">HalfStudentT</span><span class="p">(</span><span class="s2">"σ"</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">2000</span><span class="p">)</span>
    <span class="n">μ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s2">"μ"</span><span class="p">,</span> <span class="mi">4000</span><span class="p">,</span> <span class="mi">3000</span><span class="p">)</span>
    <span class="n">mass</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s2">"mass"</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">μ</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">σ</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">adelie_mass_obs</span><span class="p">)</span>

    <span class="n">prior</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample_prior_predictive</span><span class="p">(</span><span class="n">samples</span><span class="o">=</span><span class="mi">5000</span><span class="p">)</span>
    <span class="n">trace</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">chains</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
    <span class="n">inf_data_adelie_penguin_mass</span> <span class="o">=</span> <span class="n">az</span><span class="o">.</span><span class="n">from_PyMC3</span><span class="p">(</span><span class="n">prior</span><span class="o">=</span><span class="n">prior</span><span class="p">,</span> <span class="n">trace</span><span class="o">=</span><span class="n">trace</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>在计算后验分布之前，我们有必要先检查一下先验。特别是，我们需要检查并确认当前模型的采样在计算上是否可行（ 这里的采样主要针对 MCMC 近似推断方法，对于变分推断等推断方法会有区别 ），并确认基于领域知识选择的先验是否合理。</p>
<p><a class="reference internal" href="#fig-singlespecies-prior-predictive"><span class="std std-numref">Fig. 32</span></a> 中绘制了先验样本。通过图形，我们可以判断该模型并没有“明显的”计算问题，例如，形状问题、错误指定的随机变量、错误指定的似然等。从先验样本可以看出，我们并没有过度限制企鹅可能的体重，尽管实际上可能会受到先验的限制，因为体重均值的先验目前还包括不合理的负值。</p>
<p>然而，这是一个简单的模型，并且有相当数量的观测结果，因此暂时只留意这种情况但不去处理它，继续估计后验分布。</p>
<div class="figure align-default" id="fig-singlespecies-prior-predictive">
<a class="reference internal image-reference" href="../_images/SingleSpecies_Prior_Predictive.png"><img alt="../_images/SingleSpecies_Prior_Predictive.png" src="../_images/SingleSpecies_Prior_Predictive.png" style="width: 7.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 32 </span><span class="caption-text">在代码 <a class="reference internal" href="#penguin-mass"><span class="std std-ref">penguin_mass</span></a> 中生成的先验样本。可以看出，企鹅体重的均值和标准差的分布估计涵盖了广泛的可能性。</span><a class="headerlink" href="#fig-singlespecies-prior-predictive" title="Permalink to this image">¶</a></p>
</div>
<p>从模型中做后验采样后，我们可以创建 <a class="reference internal" href="#fig-single-penguins-rank-kde-plot"><span class="std std-numref">Fig. 33</span></a>，其中包括 <span class="math notranslate nohighlight">\(4\)</span> 个子图，右边的两个是秩图，左边是参数的核密度估计，每条线为一个链。我们还可以参考 <a class="reference internal" href="#tab-penguin-mass-parameters-bayesian-estimates"><span class="std std-numref">Table 4</span></a> 中的数值诊断来了解采样链的收敛情况。根据第 <a class="reference internal" href="chp_02.html#chap1bis"><span class="std std-ref">2</span></a> 章建立的直觉，我们大致能够判断该拟合可以接受，可以继续进行分析。</p>
<table class="table" id="tab-penguin-mass-parameters-bayesian-estimates">
<caption><span class="caption-number">Table 4 </span><span class="caption-text">企鹅体重的均值 (μ) 和标准差 (σ) 的贝叶斯估计，以及采样诊断。</span><a class="headerlink" href="#tab-penguin-mass-parameters-bayesian-estimates" title="Permalink to this table">¶</a></caption>
<colgroup>
<col style="width: 10%"/>
<col style="width: 10%"/>
<col style="width: 10%"/>
<col style="width: 10%"/>
<col style="width: 10%"/>
<col style="width: 10%"/>
<col style="width: 10%"/>
<col style="width: 10%"/>
<col style="width: 10%"/>
<col style="width: 10%"/>
</colgroup>
<tbody>
<tr class="row-odd"><td></td>
<td><p><strong>mean</strong></p></td>
<td><p><strong>sd</strong></p></td>
<td><p><strong>hdi_3%</strong></p></td>
<td><p><strong>hdi_97%</strong></p></td>
<td><p><strong>mcse_mean</strong></p></td>
<td><p><strong>mcse_sd</strong></p></td>
<td><p><strong>ess_bulk</strong></p></td>
<td><p><strong>ess_tail</strong></p></td>
<td><p><strong>r_hat</strong></p></td>
</tr>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\(\mu\)</span></p></td>
<td><p>3707</p></td>
<td><p>38</p></td>
<td><p>3632</p></td>
<td><p>3772</p></td>
<td><p>0.6</p></td>
<td><p>0.4</p></td>
<td><p>3677.0</p></td>
<td><p>2754.0</p></td>
<td><p>1.0</p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\(\sigma\)</span></p></td>
<td><p>463</p></td>
<td><p>27</p></td>
<td><p>401</p></td>
<td><p>511</p></td>
<td><p>0.5</p></td>
<td><p>0.3</p></td>
<td><p>3553.0</p></td>
<td><p>2226.0</p></td>
<td><p>1.0</p></td>
</tr>
</tbody>
</table>
<div class="figure align-default" id="fig-single-penguins-rank-kde-plot">
<a class="reference internal image-reference" href="../_images/SingleSpecies_KDE_RankPlot.png"><img alt="../_images/SingleSpecies_KDE_RankPlot.png" src="../_images/SingleSpecies_KDE_RankPlot.png" style="width: 7.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 33 </span><span class="caption-text">代码 <a class="reference internal" href="#penguin-mass"><span class="std std-ref">penguin_mass</span></a> 中企鹅体重贝叶斯模型后验的核密度估计和秩图。该图用作采样的可视化诊断，以辅助判断在跨多个链的采样过程中是否存在问题。</span><a class="headerlink" href="#fig-single-penguins-rank-kde-plot" title="Permalink to this image">¶</a></p>
</div>
<p>为了理解拟合结果，我们在 <a class="reference internal" href="#fig-singlespecies-mass-posteriorplot"><span class="std std-numref">Fig. 34</span></a> 中绘制了一个结合所有链的后验图；并对 <a class="reference internal" href="#tab-penguin-mass-parameters-point-estimates"><span class="std std-numref">Table 3</span></a> 中均值和标准差的点估计值做了标记，以便与贝叶斯估计值进行比较。</p>
<div class="figure align-default" id="fig-singlespecies-mass-posteriorplot">
<a class="reference internal image-reference" href="../_images/SingleSpecies_Mass_PosteriorPlot.png"><img alt="../_images/SingleSpecies_Mass_PosteriorPlot.png" src="../_images/SingleSpecies_Mass_PosteriorPlot.png" style="width: 7.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 34 </span><span class="caption-text">代码 <a class="reference internal" href="#penguin-mass"><span class="std std-ref">penguin_mass</span></a> 中，<code class="docutils literal notranslate"><span class="pre">Adelie</span> <span class="pre">种企鹅</span></code>体重贝叶斯模型的后验分布图，其中，垂线是经验均值和标准差。</span><a class="headerlink" href="#fig-singlespecies-mass-posteriorplot" title="Permalink to this image">¶</a></p>
</div>
<p>通过贝叶斯估计，我们得到了合理的参数分布。使用 <a class="reference internal" href="#tab-penguin-mass-parameters-bayesian-estimates"><span class="std std-numref">Table 4</span></a> 中的汇总信息，以及来自 <a class="reference internal" href="#fig-single-penguins-rank-kde-plot"><span class="std std-numref">Fig. 33</span></a> 中的后验分布，该企鹅物种的体重均值从 <span class="math notranslate nohighlight">\(3632\)</span> 到 <span class="math notranslate nohighlight">\(3772\)</span> 克相当合理；此外边缘后验分布的标准差也比较大。</p>
<p>切记，后验分布是高斯分布参数（均值和标准差）的分布，而非高斯分布本身（即企鹅体重的分布），千万不要混淆。因此如果想要企鹅体重的分布估计，我们需要基于均值和标准差参数的后验样本生成后验预测分布。也就是说，根据当前模型设定，企鹅体重的分布应该是以 <span class="math notranslate nohighlight">\(\mu\)</span> 和 <span class="math notranslate nohighlight">\(\sigma\)</span> 的后验分布为条件的高斯分布。</p>
<p>现在已经描述了 <code class="docutils literal notranslate"><span class="pre">Adelie</span> <span class="pre">种企鹅</span></code>的体重，我们可以继续对其他物种做同样的工作。在编程上，我们可以编写三个独立的模型来实现，但也可以只编写一个模型，其中包含 <span class="math notranslate nohighlight">\(3\)</span> 个独立的组，每个物种对应一个组。</p>
<div class="literal-block-wrapper docutils container" id="nocovariate-mass">
<div class="code-block-caption"><span class="caption-number">Listing 17 </span><span class="caption-text">nocovariate_mass</span><a class="headerlink" href="#nocovariate-mass" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># pd.categorical makes it easy to index species below</span>
<span class="n">all_species</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Categorical</span><span class="p">(</span><span class="n">penguins</span><span class="p">[</span><span class="s2">"species"</span><span class="p">])</span>

<span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">model_penguin_mass_all_species</span><span class="p">:</span>
    <span class="c1"># Note the addition of the shape parameter</span>
    <span class="n">σ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">HalfStudentT</span><span class="p">(</span><span class="s2">"σ"</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">2000</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">μ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s2">"μ"</span><span class="p">,</span> <span class="mi">4000</span><span class="p">,</span> <span class="mi">3000</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">mass</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s2">"mass"</span><span class="p">,</span>
                     <span class="n">mu</span><span class="o">=</span><span class="n">μ</span><span class="p">[</span><span class="n">all_species</span><span class="o">.</span><span class="n">codes</span><span class="p">],</span>
                     <span class="n">sigma</span><span class="o">=</span><span class="n">σ</span><span class="p">[</span><span class="n">all_species</span><span class="o">.</span><span class="n">codes</span><span class="p">],</span>
                     <span class="n">observed</span><span class="o">=</span><span class="n">penguins</span><span class="p">[</span><span class="s2">"body_mass_g"</span><span class="p">])</span>

    <span class="n">trace</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
    <span class="n">inf_data_model_penguin_mass_all_species</span> <span class="o">=</span> <span class="n">az</span><span class="o">.</span><span class="n">from_PyMC3</span><span class="p">(</span>
        <span class="n">trace</span><span class="o">=</span><span class="n">trace</span><span class="p">,</span>
        <span class="n">coords</span><span class="o">=</span><span class="p">{</span><span class="s2">"μ_dim_0"</span><span class="p">:</span> <span class="n">all_species</span><span class="o">.</span><span class="n">categories</span><span class="p">,</span>
                <span class="s2">"σ_dim_0"</span><span class="p">:</span> <span class="n">all_species</span><span class="o">.</span><span class="n">categories</span><span class="p">})</span>
</pre></div>
</div>
</div>
<p>我们为每个参数使用了可选的 <strong>形状（ Shape ，Python 中描述多维张量各维度大小的术语 ）</strong> 参数，并在似然中添加一个索引，以告诉 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 我们希望独立调节每个物种的后验。在编程语言设计中，使表达思想更加无缝的小技巧被称为<strong>语法糖</strong>。概率编程开发人员也会使用一些语法糖；概率编程语言会努力让表达模型更容易且错误更少。</p>
<p>运行模型后，再次检查核密度估计曲线和秩图，参阅 <a class="reference internal" href="#fig-all-penguins-rank-kde-plot"><span class="std std-numref">Fig. 35</span></a>。与 <a class="reference internal" href="#fig-single-penguins-rank-kde-plot"><span class="std std-numref">Fig. 33</span></a> 相比，你将看到 <span class="math notranslate nohighlight">\(4\)</span> 个额外的图，每个物种添加了 <span class="math notranslate nohighlight">\(2\)</span> 个参数。花点时间将均值的估计与 <a class="reference internal" href="#tab-penguin-mass-parameters-point-estimates"><span class="std std-numref">Table 3</span></a> 中各物种的汇总均值进行比较。为了更好地可视化各物种分布之间的差异，可以使用代码 <a class="reference internal" href="#mass-forest-plot"><span class="std std-ref">mass_forest_plot</span></a> 来绘制多个后验分布的森林图。</p>
<p><a class="reference internal" href="#fig-forest-plot-means"><span class="std std-numref">Fig. 36</span></a> 使我们更容易对不同物种的估计做比较，注意 <code class="docutils literal notranslate"><span class="pre">Gentoo</span> <span class="pre">种企鹅</span></code> 似乎比 <code class="docutils literal notranslate"><span class="pre">Adelie</span> <span class="pre">种</span></code> 或 <code class="docutils literal notranslate"><span class="pre">Chinstrap</span> <span class="pre">种</span></code> 有更大的体重。</p>
<div class="figure align-default" id="fig-all-penguins-rank-kde-plot">
<a class="reference internal image-reference" href="../_images/AllSpecies_KDE_RankPlot.png"><img alt="../_images/AllSpecies_KDE_RankPlot.png" src="../_images/AllSpecies_KDE_RankPlot.png" style="width: 7.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 35 </span><span class="caption-text"><code class="docutils literal notranslate"><span class="pre">penguins_masses</span></code> 模型中的各种企鹅体重分布参数的后验估计核密度估计曲线和秩图 。注意各物种都有自己的一对估计值。</span><a class="headerlink" href="#fig-all-penguins-rank-kde-plot" title="Permalink to this image">¶</a></p>
</div>
<div class="literal-block-wrapper docutils container" id="mass-forest-plot">
<div class="code-block-caption"><span class="caption-number">Listing 18 </span><span class="caption-text">mass_forest_plot</span><a class="headerlink" href="#mass-forest-plot" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><a class="sphinx-codeautolink-a" href="https://arviz-devs.github.io/arviz/api/generated/arviz.plot_forest.html#arviz.plot_forest" title="arviz.plot_forest"><span class="n">az</span><span class="o">.</span><span class="n">plot_forest</span></a><span class="p">(</span><span class="n">inf_data_model_penguin_mass_all_species</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s2">"μ"</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="figure align-default" id="fig-forest-plot-means">
<a class="reference internal image-reference" href="../_images/Independent_Model_ForestPlotMeans.png"><img alt="../_images/Independent_Model_ForestPlotMeans.png" src="../_images/Independent_Model_ForestPlotMeans.png" style="width: 7.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 36 </span><span class="caption-text"><code class="docutils literal notranslate"><span class="pre">model_penguin_mass_all_species</span></code> 中各物种组体重均值参数的后验森林图。每条线代表采样器中的一条链，点代表点估计，目前情况下指经验均值，细线是后验的 <span class="math notranslate nohighlight">\(25\%\)</span> 到 <span class="math notranslate nohighlight">\(75\%\)</span> 四分位数范围，粗线是 <span class="math notranslate nohighlight">\(94\%\)</span> 最高密度区间 ( HDPI )。</span><a class="headerlink" href="#fig-forest-plot-means" title="Permalink to this image">¶</a></p>
</div>
<p><a class="reference internal" href="#fig-forest-plot-means"><span class="std std-numref">Fig. 36</span></a> 让我们更容易比较估计结果，并且很容易注意到 <code class="docutils literal notranslate"><span class="pre">Gentoo</span> <span class="pre">种</span></code>企鹅的体重比 <code class="docutils literal notranslate"><span class="pre">Adelie</span> <span class="pre">种</span></code> 或 <code class="docutils literal notranslate"><span class="pre">Chinstrap</span> <span class="pre">种</span></code> 企鹅更大。让我们也看看 <a class="reference internal" href="#fig-forest-plot-sigma"><span class="std std-numref">Fig. 37</span></a> 中的标准差。后验的 <span class="math notranslate nohighlight">\(94\%\)</span> 最高密度区间报告了大约存在 <span class="math notranslate nohighlight">\(100\)</span> 克的不确定性。</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><a class="sphinx-codeautolink-a" href="https://arviz-devs.github.io/arviz/api/generated/arviz.plot_forest.html#arviz.plot_forest" title="arviz.plot_forest"><span class="n">az</span><span class="o">.</span><span class="n">plot_forest</span></a><span class="p">(</span><span class="n">inf_data_model_penguin_mass_all_species</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s2">"σ"</span><span class="p">])</span> 
</pre></div>
</div>
<div class="figure align-default" id="fig-forest-plot-sigma">
<a class="reference internal image-reference" href="../_images/Independent_Model_ForestPlotSigma.png"><img alt="../_images/Independent_Model_ForestPlotSigma.png" src="../_images/Independent_Model_ForestPlotSigma.png" style="width: 7.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 37 </span><span class="caption-text"><code class="docutils literal notranslate"><span class="pre">model_penguin_mass_all_species</span></code> 中各物种组的体重标准差参数的后验森林图，描述了对各组企鹅体重离散度的估计，例如，给定 <code class="docutils literal notranslate"><span class="pre">Gentoo</span> <span class="pre">种企鹅</span></code>体重分布均值的估计后，相关标准差可能在 <span class="math notranslate nohighlight">\(450\)</span> 克到 <span class="math notranslate nohighlight">\(550\)</span> 克之间。</span><a class="headerlink" href="#fig-forest-plot-sigma" title="Permalink to this image">¶</a></p>
</div>
<div class="section" id="comparing-two-ppls">
<span id="id4"></span><h3>3.1.1 比较两种概率编程语言<a class="headerlink" href="#comparing-two-ppls" title="Permalink to this headline">¶</a></h3>
<p>在进一步扩展统计建模思想之前，我们先花点时间讨论概率编程语言，并介绍将在本书中使用的另一种概率编程语言：<code class="docutils literal notranslate"><span class="pre">TensorFlow</span> <span class="pre">Probability</span> <span class="pre">(TFP)</span></code>。我们将在代码 <a class="reference internal" href="#nocovariate-mass"><span class="std std-ref">nocovariate_mass</span></a> 中，将 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 的截距模型转换为 <code class="docutils literal notranslate"><span class="pre">TFP</span></code> ，以便于大家理解。</p>
<p>学习不同的概率编程语言似乎没有必要。但本书中选择使用两种概率编程语言有些特殊的原因：<em>在不同概率编程语言中看到相同的工作流程，将使你对贝叶斯建模和计算有更透彻的理解，帮助你将计算细节与统计思想分开，并使你成为一个更强大的建模者</em>。</p>
<p>此外，不同概率编程语言有不同的能力和重点。 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 是更高级别的概率编程语言，可以轻松地以更少代码表达模型，而 <code class="docutils literal notranslate"><span class="pre">TFP</span></code> 为建模和推断提供了更低级别的概率编程能力。并非所有概率编程语言都能够像彼此一样非常容易地表达所有模型。例如，时间序列模型（ <a class="reference internal" href="chp_06.html#chap4"><span class="std std-ref">第 6 章</span></a> ）在 <code class="docutils literal notranslate"><span class="pre">TFP</span></code> 中更容易定义，而贝叶斯加性回归树在 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 中更容易表达（ <a class="reference internal" href="chp_07.html#chap6"><span class="std std-ref">第 7 章</span></a> ）。通过对多种语言的接触，你将对贝叶斯建模的基本要素以及其在在计算上的实现有更深入了解。</p>
<p>概率编程语言由原语组成，在编程语言中，原语是用于构建更复杂程序的最简单元素。你可以将原语理解成自然语言中的单词，能够形成更复杂的结构，比如句子。由于不同语言使用不同的词，不同概率编程语言也会使用不同的原语。这些原语主要用于表达模型、执行推断或表达工作流的其他部分。</p>
<p>在 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 中，与模型构建相关的原语包含在命名空间 <code class="docutils literal notranslate"><span class="pre">pm</span></code> 下。例如，在代码 <a class="reference internal" href="#penguin-mass"><span class="std std-ref">penguin_mass</span></a> 中，可以看到 <code class="docutils literal notranslate"><span class="pre">pm.HalfStudentT(.)</span></code> 和 <code class="docutils literal notranslate"><span class="pre">pm.Normal(.)</span></code>，其中“ <span class="math notranslate nohighlight">\(.\)</span><code class="docutils literal notranslate"><span class="pre">”代表一个随机变量。</span></code>with pm.Model() as .<code class="docutils literal notranslate"> <span class="pre">语句调用</span> <span class="pre">Python</span> <span class="pre">的上下文环境管理器，</span></code>PyMC3<code class="docutils literal notranslate"><span class="pre">使用该语句来收集上下文管理器中的随机变量，并构建模型</span></code>model_adelie_penguin_mass<code class="docutils literal notranslate"><span class="pre">。然后可以使用</span> </code>pm.sample_prior_predictive(.)<code class="docutils literal notranslate"><span class="pre">和</span></code>pm.sample(.)` 分别获得先验预测分布和后验分布的样本。</p>
<p>类似地，TFP 为用户提供了在  <code class="docutils literal notranslate"><span class="pre">tfp.distributions</span></code> 中指定分布和模型、运行 MCMC 推断( <code class="docutils literal notranslate"><span class="pre">tfp.mcmc</span></code> ) 等原语。例如，为了构建贝叶斯模型，TensorFlow 提供了多个名为 <code class="docutils literal notranslate"><span class="pre">tfd.JointDistribution</span></code> 的 API 原语 <span id="id5">[<a class="reference internal" href="references.html#id128">29</a>]</span>。在本书的其余部分中，我们会主要使用 <code class="docutils literal notranslate"><span class="pre">tfd.JointDistributionCoroutine</span></code>，但读者应当知道还有 <code class="docutils literal notranslate"><span class="pre">tfd.JointDistribution</span></code> 的一些变体可能更适合你的应用 <a class="footnote-reference brackets" href="#id41" id="id6">1</a>。由于导入数据和计算汇总统计量的代码和 <a class="reference internal" href="#penguin-load"><span class="std std-ref">penguin_load</span></a> 和 <a class="reference internal" href="#penguin-mass-empirical"><span class="std std-ref">penguin_mass_empirical</span></a> 一致，因此这里我们专注于模型构建和推断。</p>
<p><code class="docutils literal notranslate"><span class="pre">model_penguin_mass_all_species</span></code> 以 <code class="docutils literal notranslate"><span class="pre">TFP</span></code> 表示为代码 <a class="reference internal" href="#penguin-mass-tfp"><span class="std std-ref">penguin_mass_tfp</span></a> ：</p>
<div class="literal-block-wrapper docutils container" id="penguin-mass-tfp">
<div class="code-block-caption"><span class="caption-number">Listing 19 </span><span class="caption-text">penguin_mass_tfp</span><a class="headerlink" href="#penguin-mass-tfp" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">tensorflow_probability</span> <span class="k">as</span> <span class="nn">tfp</span>

<span class="n">tfd</span> <span class="o">=</span> <span class="n">tfp</span><span class="o">.</span><span class="n">distributions</span>
<span class="n">root</span> <span class="o">=</span> <span class="n">tfd</span><span class="o">.</span><span class="n">JointDistributionCoroutine</span><span class="o">.</span><span class="n">Root</span>

<span class="n">species_idx</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">all_species</span><span class="o">.</span><span class="n">codes</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="n">body_mass_g</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">penguins</span><span class="p">[</span><span class="s2">"body_mass_g"</span><span class="p">],</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="nd">@tfd</span><span class="o">.</span><span class="n">JointDistributionCoroutine</span>
<span class="k">def</span> <span class="nf">jd_penguin_mass_all_species</span><span class="p">():</span>
    <span class="n">σ</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">root</span><span class="p">(</span><span class="n">tfd</span><span class="o">.</span><span class="n">Sample</span><span class="p">(</span>
            <span class="n">tfd</span><span class="o">.</span><span class="n">HalfStudentT</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">2000</span><span class="p">),</span>
            <span class="n">sample_shape</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="s2">"sigma"</span><span class="p">))</span>
    <span class="n">μ</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">root</span><span class="p">(</span><span class="n">tfd</span><span class="o">.</span><span class="n">Sample</span><span class="p">(</span>
            <span class="n">tfd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">4000</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">3000</span><span class="p">),</span>
            <span class="n">sample_shape</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="s2">"mu"</span><span class="p">))</span>
    <span class="n">mass</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Independent</span><span class="p">(</span>
        <span class="n">tfd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">μ</span><span class="p">,</span> <span class="n">species_idx</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span>
                   <span class="n">scale</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">σ</span><span class="p">,</span> <span class="n">species_idx</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)),</span>
        <span class="n">reinterpreted_batch_ndims</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">"mass"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>这是我们第一次遇到用 <code class="docutils literal notranslate"><span class="pre">TFP</span></code> 编写的贝叶斯模型，所以花点时间来详细介绍一下。 <code class="docutils literal notranslate"><span class="pre">tfp.distributions</span></code> 是原语中的分布类，我们通常为其赋予一个较短的别名 <code class="docutils literal notranslate"><span class="pre">tfd</span> <span class="pre">=</span> <span class="pre">tfp.distributions</span></code> 。 <code class="docutils literal notranslate"><span class="pre">tfd</span></code> 中包含了常用的分布，例如高斯分布 <code class="docutils literal notranslate"><span class="pre">tfd.Normal(.)</span></code> 。代码中还使用了 <code class="docutils literal notranslate"><span class="pre">tfd.Sample</span></code>，它返回来自基础分布的多个独立副本（ 从概念上讲，实现了 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 语法糖 <code class="docutils literal notranslate"><span class="pre">shape=(.)</span></code> 的功能 ）。 <code class="docutils literal notranslate"><span class="pre">tfd.Independent</span></code> 用于指示该分布包含多少个副本，我们希望在计算对数似然时在某个轴上对这些副本求和，这由 <code class="docutils literal notranslate"><span class="pre">reinterpreted_batch_ndims</span></code> 函参指定。通常用 <code class="docutils literal notranslate"><span class="pre">tfd.Independent</span></code> 封装与观测相关的分布 <a class="footnote-reference brackets" href="#id42" id="id7">2</a> 。你可以在 <a class="reference internal" href="chp_10.html#shape-ppl"><span class="std std-ref">10.8.1 PPL 中的形状处理</span></a> 部分阅读更多关于 <code class="docutils literal notranslate"><span class="pre">TFP</span></code> 和概率编程语言中的形状处理的信息。</p>
<p>代码中的模型签名 <code class="docutils literal notranslate"><span class="pre">@tfd.JointDistributionCoroutine</span></code> 很有意思，顾名思义，就是在 Python 中使用协程（ Coroutine ），不过我们在此不过多地介绍生成器和协程的概念。</p>
<p><code class="docutils literal notranslate"><span class="pre">yield</span></code> 语句会为你提供模型函数内部的一些随机变量，你可以将 <code class="docutils literal notranslate"><span class="pre">y</span> <span class="pre">=</span> <span class="pre">yield</span> <span class="pre">Normal(.)</span></code> 视为 <span class="math notranslate nohighlight">\(y \sim \text{Normal(.)}\)</span> 的代码表达方式。</p>
<p>此外，我们通过 <code class="docutils literal notranslate"><span class="pre">tfd.JointDistributionCoroutine.Root</span></code> 来包装没有依赖关系的随机变量。</p>
<p>该模型被编写为没有输入参数和返回值的 Python 函数，将 <code class="docutils literal notranslate"><span class="pre">@tfd.JointDistributionCoroutine</span></code> 放在 Python 函数之上作为装饰器，以方便直接获取模型（即 <code class="docutils literal notranslate"><span class="pre">tfd.JointDistribution</span></code>）。</p>
<p>结果的 <code class="docutils literal notranslate"><span class="pre">jd_penguin_mass_all_species</span></code> 是代码 <a class="reference internal" href="#nocovariate-mass"><span class="std std-ref">nocovariate_mass</span></a> 中的截距回归模型在 <code class="docutils literal notranslate"><span class="pre">TFP</span></code> 中的重写。它具有与其他 <code class="docutils literal notranslate"><span class="pre">tfd.Distribution</span></code> 类似的、可以在贝叶斯工作流中使用的方法。例如，抽取先验和先验预测样本可以调用 <code class="docutils literal notranslate"><span class="pre">.sample(.)</span></code> 方法，该方法返回一个类似于 <code class="docutils literal notranslate"><span class="pre">namedtuple</span></code> 的自定义嵌套 Python 结构体。在代码 <a class="reference internal" href="#penguin-mass-tfp-prior-predictive"><span class="std std-ref">penguin_mass_tfp_prior_predictive</span></a> 中，我们抽取了 $10004 个先验和先验预测样本。</p>
<div class="literal-block-wrapper docutils container" id="penguin-mass-tfp-prior-predictive">
<div class="code-block-caption"><span class="caption-number">Listing 20 </span><span class="caption-text">penguin_mass_tfp_prior_predictive</span><a class="headerlink" href="#penguin-mass-tfp-prior-predictive" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">prior_predictive_samples</span> <span class="o">=</span> <span class="n">jd_penguin_mass_all_species</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">tfd.JointDistribution</span></code> 的 <code class="docutils literal notranslate"><span class="pre">.sample(.)</span></code> 方法也可以抽取条件样本，这也是将来抽取后验预测样本时采用的机制。你可以运行代码 <a class="reference internal" href="#penguin-mass-tfp-prior-predictive2"><span class="std std-ref">penguin_mass_tfp_prior_predictive2</span></a> ，检查输出，查看将模型中某些随机变量被设置为特定值时，随机样本的变化情况。总体来说，我们在调用 <code class="docutils literal notranslate"><span class="pre">.sample(.)</span></code> 函数时，会调用 <em>前向</em> 的数据生成过程。</p>
<div class="literal-block-wrapper docutils container" id="penguin-mass-tfp-prior-predictive2">
<div class="code-block-caption"><span class="caption-number">Listing 21 </span><span class="caption-text">penguin_mass_tfp_prior_predictive2</span><a class="headerlink" href="#penguin-mass-tfp-prior-predictive2" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">jd_penguin_mass_all_species</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">sigma</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mf">.1</span><span class="p">,</span> <span class="mf">.2</span><span class="p">,</span> <span class="mf">.3</span><span class="p">]))</span>
<span class="n">jd_penguin_mass_all_species</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">mu</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mf">.1</span><span class="p">,</span> <span class="mf">.2</span><span class="p">,</span> <span class="mf">.3</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<p>一旦将生成模型 <code class="docutils literal notranslate"><span class="pre">jd_penguin_mass_all_species</span></code> 调整为企鹅体重的观测值（即为模型指定数据），就能够获得模型参数的后验分布。</p>
<p>从计算角度来看，我们希望生成一个能够返回输入点处后验对数概率的函数。这可以通过创建 Python 函数闭包或使用 <code class="docutils literal notranslate"><span class="pre">.experimental_pin</span></code> 方法来实现，如代码 <a class="reference internal" href="#tfp-posterior-generation"><span class="std std-ref">tfp_posterior_generation</span></a> 所示：</p>
<div class="literal-block-wrapper docutils container" id="tfp-posterior-generation">
<div class="code-block-caption"><span class="caption-number">Listing 22 </span><span class="caption-text">tfp_posterior_generation</span><a class="headerlink" href="#tfp-posterior-generation" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">target_density_function</span> <span class="o">=</span> <span class="k">lambda</span> <span class="o">*</span><span class="n">x</span><span class="p">:</span> <span class="n">jd_penguin_mass_all_species</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span>
    <span class="o">*</span><span class="n">x</span><span class="p">,</span> <span class="n">mass</span><span class="o">=</span><span class="n">body_mass_g</span><span class="p">)</span>

<span class="n">jd_penguin_mass_observed</span> <span class="o">=</span> <span class="n">jd_penguin_mass_all_species</span><span class="o">.</span><span class="n">experimental_pin</span><span class="p">(</span>
    <span class="n">mass</span><span class="o">=</span><span class="n">body_mass_g</span><span class="p">)</span>
<span class="n">target_density_function</span> <span class="o">=</span> <span class="n">jd_penguin_mass_observed</span><span class="o">.</span><span class="n">unnormalized_log_prob</span>
</pre></div>
</div>
</div>
<p>推断是使用 <code class="docutils literal notranslate"><span class="pre">target_density_function</span></code> 完成的，例如，我们可以找到函数的最大值，这给出了<strong>最大后验概率</strong>（MAP）估计。我们还可以使用 <code class="docutils literal notranslate"><span class="pre">tfp.mcmc</span></code> <span id="id8">[<a class="reference internal" href="references.html#id133">30</a>]</span> 中的方法从后验采样。或者更方便的是，使用类似于 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> <a class="footnote-reference brackets" href="#id43" id="id9">3</a> 中当前使用的标准采样例程，如代码 <a class="reference internal" href="#tfp-posterior-inference"><span class="std std-ref">tfp_posterior_inference</span></a> 所示：</p>
<div class="literal-block-wrapper docutils container" id="tfp-posterior-inference">
<div class="code-block-caption"><span class="caption-number">Listing 23 </span><span class="caption-text">tfp_posterior_inference</span><a class="headerlink" href="#tfp-posterior-inference" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">run_mcmc</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">function</span><span class="p">(</span>
    <span class="n">tfp</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">mcmc</span><span class="o">.</span><span class="n">windowed_adaptive_nuts</span><span class="p">,</span>
    <span class="n">autograph</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">jit_compile</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">mcmc_samples</span><span class="p">,</span> <span class="n">sampler_stats</span> <span class="o">=</span> <span class="n">run_mcmc</span><span class="p">(</span>
    <span class="mi">1000</span><span class="p">,</span> <span class="n">jd_penguin_mass_all_species</span><span class="p">,</span> <span class="n">n_chains</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">num_adaptation_steps</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
    <span class="n">mass</span><span class="o">=</span><span class="n">body_mass_g</span><span class="p">)</span>

<span class="n">inf_data_model_penguin_mass_all_species2</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="https://arviz-devs.github.io/arviz/api/generated/arviz.from_dict.html#arviz.from_dict" title="arviz.from_dict"><span class="n">az</span><span class="o">.</span><span class="n">from_dict</span></a><span class="p">(</span>
    <span class="n">posterior</span><span class="o">=</span><span class="p">{</span>
        <span class="c1"># TFP mcmc returns (num_samples, num_chains, ...), we swap</span>
        <span class="c1"># the first and second axis below for each RV so the shape</span>
        <span class="c1"># is what ArviZ expected.</span>
        <span class="n">k</span><span class="p">:</span><a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.swapaxes.html#numpy.swapaxes" title="numpy.swapaxes"><span class="n">np</span><span class="o">.</span><span class="n">swapaxes</span></a><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">mcmc_samples</span><span class="o">.</span><span class="n">_asdict</span><span class="p">()</span><span class="o">.</span><span class="n">items</span><span class="p">()},</span>
    <span class="n">sample_stats</span><span class="o">=</span><span class="p">{</span>
        <span class="n">k</span><span class="p">:</span><a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.swapaxes.html#numpy.swapaxes" title="numpy.swapaxes"><span class="n">np</span><span class="o">.</span><span class="n">swapaxes</span></a><span class="p">(</span><span class="n">sampler_stats</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">"target_log_prob"</span><span class="p">,</span> <span class="s2">"diverging"</span><span class="p">,</span> <span class="s2">"accept_ratio"</span><span class="p">,</span> <span class="s2">"n_steps"</span><span class="p">]}</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<p>在代码 <a class="reference internal" href="#tfp-posterior-inference"><span class="std std-ref">tfp_posterior_inference</span></a> 中，我们运行了 4 个 MCMC 链，每条链在 1000 个适应步骤后有 1000 个后验样本。在内部，它通过使用观测到的（附加关键字参数“mass=body_mass_g”最后）调节模型（作为参数传递给函数）来调用“experimental_pin”方法。</p>
<p>第 8-18 行将采样结果解析为 ArviZ InferenceData，我们现在可以在 ArviZ 中对贝叶斯模型进行诊断和探索性分析。我们还可以在下面的代码 <a class="reference internal" href="#tfp-idata-additional"><span class="std std-ref">tfp_idata_additional</span></a> 中以透明的方式将先验和后验预测样本和数据对数似然添加到<code class="docutils literal notranslate"><span class="pre">inf_data_model_penguin_mass_all_species2</span></code>。请注意，我们使用了 <code class="docutils literal notranslate"><span class="pre">tfd.JointDistribution</span></code> 的 <code class="docutils literal notranslate"><span class="pre">sample_distributions</span></code> 方法，该方法抽取样本<em>并</em>生成以后验样本为条件的分布。</p>
<div class="literal-block-wrapper docutils container" id="tfp-idata-additional">
<div class="code-block-caption"><span class="caption-number">Listing 24 </span><span class="caption-text">tfp_idata_additional</span><a class="headerlink" href="#tfp-idata-additional" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">prior_predictive_samples</span> <span class="o">=</span> <span class="n">jd_penguin_mass_all_species</span><span class="o">.</span><span class="n">sample</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1000</span><span class="p">])</span>
<span class="n">dist</span><span class="p">,</span> <span class="n">samples</span> <span class="o">=</span> <span class="n">jd_penguin_mass_all_species</span><span class="o">.</span><span class="n">sample_distributions</span><span class="p">(</span>
    <span class="n">value</span><span class="o">=</span><span class="n">mcmc_samples</span><span class="p">)</span>
<span class="n">ppc_samples</span> <span class="o">=</span> <span class="n">samples</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">ppc_distribution</span> <span class="o">=</span> <span class="n">dist</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">distribution</span>
<span class="n">data_log_likelihood</span> <span class="o">=</span> <span class="n">ppc_distribution</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">body_mass_g</span><span class="p">)</span>

<span class="c1"># Be careful not to run this code twice during REPL workflow.</span>
<span class="n">inf_data_model_penguin_mass_all_species2</span><span class="o">.</span><span class="n">add_groups</span><span class="p">(</span>
    <span class="n">prior</span><span class="o">=</span><span class="n">prior_predictive_samples</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">_asdict</span><span class="p">(),</span>
    <span class="n">prior_predictive</span><span class="o">=</span><span class="p">{</span><span class="s2">"mass"</span><span class="p">:</span> <span class="n">prior_predictive_samples</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]},</span>
    <span class="n">posterior_predictive</span><span class="o">=</span><span class="p">{</span><span class="s2">"mass"</span><span class="p">:</span> <a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.swapaxes.html#numpy.swapaxes" title="numpy.swapaxes"><span class="n">np</span><span class="o">.</span><span class="n">swapaxes</span></a><span class="p">(</span><span class="n">ppc_samples</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)},</span>
    <span class="n">log_likelihood</span><span class="o">=</span><span class="p">{</span><span class="s2">"mass"</span><span class="p">:</span> <a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.swapaxes.html#numpy.swapaxes" title="numpy.swapaxes"><span class="n">np</span><span class="o">.</span><span class="n">swapaxes</span></a><span class="p">(</span><span class="n">data_log_likelihood</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)},</span>
    <span class="n">observed_data</span><span class="o">=</span><span class="p">{</span><span class="s2">"mass"</span><span class="p">:</span> <span class="n">body_mass_g</span><span class="p">}</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<p>我们对 TensorFlow Probability 的旋风之旅到此结束。像任何语言一样，你在初次接触时可能不会流利。但是通过比较这两个模型，你现在应该更好地了解哪些概念是<em>以贝叶斯为中心</em>，哪些概念是<em>以概率编程语言为中心</em>。在本章的剩余部分和下一章中，我们将在 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 和 <code class="docutils literal notranslate"><span class="pre">TFP</span></code> 之间切换，以继续帮助你识别这种差异并查看更多工作示例。我们包括将代码示例从一个翻译到另一个的练习，以帮助你在成为概率编程语言 多语种的过程中进行练习。</p>
</div>
</div>
<div class="section" id="linear-regression">
<span id="id10"></span><h2>3.2 线性回归<a class="headerlink" href="#linear-regression" title="Permalink to this headline">¶</a></h2>
<p>在上一节中，我们通过在高斯分布的均值和标准差上设置先验分布来模拟企鹅体重的分布。重要的是，我们假设体重不随数据中的其他特征而变化。然而，我们希望其他观测数据点可以提供有关预期企鹅体重的信息。直观地说，如果我们看到两只企鹅，一只长鳍，一只短鳍，我们会认为较大的企鹅，即长鳍的企鹅，即使我们手头没有秤来精确测量它们的体重，也会有更大的体重。估计观测到的鳍状肢长度与估计体重的关系的最简单方法之一是拟合线性回归模型，其中均值<em>有条件</em>建模为其他变量的线性组合。</p>
<div class="math notranslate nohighlight" id="equation-eq-expanded-regression">
<span class="eqno">(25)<a class="headerlink" href="#equation-eq-expanded-regression" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{split}
  \mu =&amp; \beta_0 + \beta_1 X_1 + \dots + \beta_m X_m \\
Y \sim&amp; \mathcal{N}(\mu, \sigma)
\end{split}\end{split}\]</div>
<p>其中系数，也称为预测变量，由参数 <span class="math notranslate nohighlight">\(\beta_i\)</span> 表示。例如，<span class="math notranslate nohighlight">\(\beta_0\)</span> 是线性模型的截距。 <span class="math notranslate nohighlight">\(X_i\)</span> 称为预测变量或自变量，<span class="math notranslate nohighlight">\(Y\)</span> 通常称为目标、输出、响应或因变量。重要的是要注意 <span class="math notranslate nohighlight">\(\boldsymbol{X}\)</span> 和 <span class="math notranslate nohighlight">\(Y\)</span> 都是观测数据，并且它们是成对的 <span class="math notranslate nohighlight">\(\{y_j, x_j\}\)</span>。也就是说，如果我们改变 <span class="math notranslate nohighlight">\(Y\)</span> 的顺序而不改变 <span class="math notranslate nohighlight">\(X\)</span>，我们将破坏数据中的一些信息。</p>
<p>我们称之为线性回归，因为参数（不是预测变量）以线性方式进入模型。同样对于具有单个预测变量的模型，我们可以将此模型视为将一条线拟合到 <span class="math notranslate nohighlight">\((X, y)\)</span> 数据，对于更高维度的平面或更一般的超平面。</p>
<p>或者，我们可以使用矩阵表示法表示公式 <a class="reference internal" href="#equation-eq-expanded-regression">(25)</a>：</p>
<div class="math notranslate nohighlight" id="equation-eq-linear-model-matrix">
<span class="eqno">(26)<a class="headerlink" href="#equation-eq-linear-model-matrix" title="Permalink to this equation">¶</a></span>\[\mu = \mathbf{X}\boldsymbol{\beta} \]</div>
<p>这里我们取系数列向量 <span class="math notranslate nohighlight">\(\beta\)</span> 和预测变量矩阵 <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> 之间的矩阵向量乘积。</p>
<p>你可能在其他（非贝叶斯）场合看到的另一种表达方式是将公式 <a class="reference internal" href="#equation-eq-expanded-regression">(25)</a> 重写为对某些线性预测的噪声观测：</p>
<div class="math notranslate nohighlight" id="equation-eq-linear-model-engine">
<span class="eqno">(27)<a class="headerlink" href="#equation-eq-linear-model-engine" title="Permalink to this equation">¶</a></span>\[Y = \mathbf{X}\boldsymbol{\beta} + \epsilon,\; \epsilon \sim \mathcal{N}(0, \sigma)\]</div>
<p>公式 <a class="reference internal" href="#equation-eq-linear-model-engine">(27)</a> 中的公式将线性回归的确定性部分（线性预测）和随机部分（噪声）分开。然而，我们更喜欢公式 <a class="reference internal" href="#equation-eq-expanded-regression">(25)</a>，因为它更清楚地显示了生成过程。</p>
<div class="admonition-design-matrix admonition">
<p class="admonition-title">Design Matrix </p>
<p>公式 <a class="reference internal" href="#equation-eq-linear-model-matrix">(26)</a> 中的矩阵 <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> 被称为设计矩阵，它是给定对象集的解释变量值的矩阵，加上一列表示截距的附加列。每行代表一个独特的观测结果（例如，企鹅），连续的列对应于变量（如 <code class="docutils literal notranslate"><span class="pre">鳍状肢长度（</span> <span class="pre">Flipper</span> <span class="pre">Length</span> <span class="pre">）</span></code> ）及其针对该对象的特定值。</p>
<p>设计矩阵不限于连续预测变量。对于类别型预测变量（ 即只有几个类别 ）的离散预测变量，将其转换为设计矩阵的常用方法称为虚拟编码（ Dummy Encoding ）或单热编码（ One Hot Encoding ）。例如，在企鹅截距模型（ 见代码 <a class="reference internal" href="#mass-forest-plot"><span class="std std-ref">mass_forest_plot</span></a> ）中，我们并没有使用 <code class="docutils literal notranslate"><span class="pre">mu</span> <span class="pre">=</span> <span class="pre">μ[species.codes]</span></code> ，而是使用 <code class="docutils literal notranslate"><span class="pre">mu</span> <span class="pre">=</span> <span class="pre">pd.get_dummies(penguins["species"])</span> <span class="pre">@</span> <span class="pre">μ</span></code> 将类别变量转换成了设计矩阵，其中 <code class="docutils literal notranslate"><span class="pre">@</span></code> 是用于执行矩阵乘法的 Python 运算符。在 Python 中也有几个执行独热编码的函数，例如，<code class="docutils literal notranslate"><span class="pre">sklearn.preprocessing.OneHotEncoder</span></code>。</p>
<p>或者，可以对类别型预测变量进行编码，以使结果列和关联系数表示线性对比度。例如，两个类别型预测变量的不同设计矩阵编码与 <code class="docutils literal notranslate"><span class="pre">ANOVA</span></code> 的零假设检验设置中的 I、II 和 III 型平方和相关。</p>
</div>
<p>如果在 “三维空间” 中绘制公式 <a class="reference internal" href="#equation-eq-expanded-regression">(25)</a>，我们会得到 <a class="reference internal" href="#fig-3d-linear-regression"><span class="std std-numref">Fig. 38</span></a>，它显示了似然函数的被估参数，如何根据观测数据 <span class="math notranslate nohighlight">\(x\)</span> 发生变化。需要说明的是，在本章中，我们仅使用了线性关系来建模 <span class="math notranslate nohighlight">\(x\)</span> 和 <span class="math notranslate nohighlight">\(Y\)</span> 之间的关系，并使用高斯分布作为似然，但在很多其他模型架构中，更可能会选择不同的选择，这一点将在第 [4] 章（chap3）中有所体现。</p>
<div class="figure align-default" id="fig-3d-linear-regression">
<a class="reference internal image-reference" href="../_images/3d_linear_regression.png"><img alt="../_images/3d_linear_regression.png" src="../_images/3d_linear_regression.png" style="width: 7.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 38 </span><span class="caption-text">在 <span class="math notranslate nohighlight">\(3\)</span> 个点处评估使用了高斯似然的线性回归。请注意，此图仅显示了 <span class="math notranslate nohighlight">\(x\)</span> 的每个值处可能的一种高斯分布，在完成整个贝叶斯模型拟合后，将最终得到高斯分布，该高斯分布的参数遵循的并非一定是高斯分布。</span><a class="headerlink" href="#fig-3d-linear-regression" title="Permalink to this image">¶</a></p>
</div>
<div class="section" id="linear-regression-intro">
<span id="id11"></span><h3>3.2.1 线性企鹅模型<a class="headerlink" href="#linear-regression-intro" title="Permalink to this headline">¶</a></h3>
<p>如果回顾企鹅示例，我们对使用额外数据来估计企鹅的平均体重更感兴趣。我们在代码 <a class="reference internal" href="#non-centered-regression"><span class="std std-ref">non_centered_regression</span></a> 中编写了一个线性回归模型，其中包括两个新参数 <span class="math notranslate nohighlight">\(\beta_0\)</span> 和 <span class="math notranslate nohighlight">\(\beta_1\)</span>，通常称为截距和斜率。对于这个例子，我们设置了 <span class="math notranslate nohighlight">\(\mathcal{N}(0, 4000)\)</span> 的宽泛先验，这也与我们没有领域知识的假设一致。随后运行采样器，它现在估计了三个参数 <span class="math notranslate nohighlight">\(\sigma\)</span> 、<span class="math notranslate nohighlight">\(\beta_1\)</span> 和 <span class="math notranslate nohighlight">\(\beta_0\)</span>。</p>
<div class="literal-block-wrapper docutils container" id="non-centered-regression">
<div class="code-block-caption"><span class="caption-number">Listing 25 </span><span class="caption-text">non_centered_regression</span><a class="headerlink" href="#non-centered-regression" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">adelie_flipper_length_obs</span> <span class="o">=</span> <span class="n">penguins</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">adelie_mask</span><span class="p">,</span> <span class="s2">"flipper_length_mm"</span><span class="p">]</span>

<span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">model_adelie_flipper_regression</span><span class="p">:</span>
    <span class="c1"># pm.Data allows us to change the underlying value in a later code block</span>
    <span class="n">adelie_flipper_length</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Data</span><span class="p">(</span><span class="s2">"adelie_flipper_length"</span><span class="p">,</span>
                                    <span class="n">adelie_flipper_length_obs</span><span class="p">)</span>
    <span class="n">σ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">HalfStudentT</span><span class="p">(</span><span class="s2">"σ"</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">2000</span><span class="p">)</span>
    <span class="n">β_0</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s2">"β_0"</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">4000</span><span class="p">)</span>
    <span class="n">β_1</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s2">"β_1"</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">4000</span><span class="p">)</span>
    <span class="n">μ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Deterministic</span><span class="p">(</span><span class="s2">"μ"</span><span class="p">,</span> <span class="n">β_0</span> <span class="o">+</span> <span class="n">β_1</span> <span class="o">*</span> <span class="n">adelie_flipper_length</span><span class="p">)</span>

    <span class="n">mass</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s2">"mass"</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">μ</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">σ</span><span class="p">,</span> <span class="n">observed</span> <span class="o">=</span> <span class="n">adelie_mass_obs</span><span class="p">)</span>

    <span class="n">inf_data_adelie_flipper_regression</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">return_inferencedata</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>为了节省篇幅，本书中不会每次都展示诊断程序，但你不应盲目相信采样器。相反，你应该将运行诊断程序作为工作流程中的固定步骤，以验证你是否有可靠的后验近似。</p>
<div class="figure align-default" id="fig-adelie-coefficient-posterior-plots">
<a class="reference internal image-reference" href="../_images/adelie_coefficient_posterior_plots.png"><img alt="../_images/adelie_coefficient_posterior_plots.png" src="../_images/adelie_coefficient_posterior_plots.png" style="width: 5in;"/></a>
<p class="caption"><span class="caption-number">Fig. 39 </span><span class="caption-text"><code class="docutils literal notranslate"><span class="pre">model_adelie_flipper_regression</span></code> 中的线性回归系数的后验分布。</span><a class="headerlink" href="#fig-adelie-coefficient-posterior-plots" title="Permalink to this image">¶</a></p>
</div>
<p>在采样器完成运行后，我们可以绘制 <a class="reference internal" href="#fig-adelie-coefficient-posterior-plots"><span class="std std-numref">Fig. 39</span></a>，它显示了检查 <span class="math notranslate nohighlight">\(\beta_0\)</span> 和 <span class="math notranslate nohighlight">\(\beta_1\)</span> 的完整后验图。</p>
<p>系数 <span class="math notranslate nohighlight">\(\beta_1\)</span> 表示，对于 <code class="docutils literal notranslate"><span class="pre">Adelie</span> <span class="pre">种</span></code>来说，鳍状肢长度的每毫米变化，理论上上我们预计会产生 <span class="math notranslate nohighlight">\(32\)</span> 克的体重变化，尽管在 <span class="math notranslate nohighlight">\(22\)</span> 克到 <span class="math notranslate nohighlight">\(41\)</span> 克之间的任何地方都是可能发生的变化。此外，从 <a class="reference internal" href="#fig-adelie-coefficient-posterior-plots"><span class="std std-numref">Fig. 39</span></a> 中可以看到 $<span class="math notranslate nohighlight">\(94\%\)</span><span class="math notranslate nohighlight">\( 的最高密度区间未覆盖 \)</span>0$ 克，这支持了我们的假设，即体重和鳍状肢长度之间存在关系。这一观察对于解释 “鳍状肢长度和体重之间如何相关” 非常有用。但我们应该注意：<strong>不要过度解释系数或认为线性模型必然意味着因果关系</strong>。例如，如果对一只企鹅进行脚蹼的扩展手术，这不一定会造成体重增加，而实际上由于企鹅获取食物的障碍，体重反而可能降低。相反的关系也不一定正确，给企鹅提供更多食物有助于其拥有更大的鳍状肢，但也可能使其成为一只更胖的企鹅。</p>
<p>现在看一下 <span class="math notranslate nohighlight">\(\beta_0\)</span>，它代表什么？根据后验估计结果，如果看到一只鳍状肢长度为 <span class="math notranslate nohighlight">\(0\)</span> 毫米的<code class="docutils literal notranslate"><span class="pre">Adelie</span> <span class="pre">种</span></code>企鹅，我们预计这只不可能的企鹅的体重在 <span class="math notranslate nohighlight">\(-4213\)</span> 到 <span class="math notranslate nohighlight">\(-546\)</span> 克之间。根据模型，这个陈述是正确的，但负的体重并没有意义。这不一定是问题，没有规定模型中的每个参数都必须可解释，也没有规定模型对每个参数值都必须提供合理预测。</p>
<p>在我们整书旅程中的当下，上述特定模型的有限目的只是估计鳍状肢长度和<code class="docutils literal notranslate"><span class="pre">企鹅体重</span></code>之间的关系，而通过后验估计，我们已经成功实现了这个目标。</p>
<div class="admonition- admonition">
<p class="admonition-title">模型: 数学和现实之间的平衡 </p>
<p>在企鹅示例中，即使模型允许，企鹅体重低于 <span class="math notranslate nohighlight">\(0\)</span>（ 甚至接近 <span class="math notranslate nohighlight">\(0\)</span> ）也是没有意义的。由于建模和拟合时使用了远离 <span class="math notranslate nohighlight">\(0\)</span> 的体重值，所以当我们想要推断接近 <span class="math notranslate nohighlight">\(0\)</span> 或低于 <span class="math notranslate nohighlight">\(0\)</span> 的结果时，不应该对模型失败感到惊讶。模型不一定必须为所有可能的值提供合理预测，它只需要为构建它时的有限目的提供合理预测。</p>
</div>
<p>本节中，我们设想加入预测变量会更好地预测企鹅的体重。我们可以通过 <a class="reference internal" href="#fig-singlespecies-singleregression-forest-sigma-comparison"><span class="std std-numref">Fig. 40</span></a> 比较固定均值模型和线性变化均值模型的 <span class="math notranslate nohighlight">\(\sigma\)</span> 后验估计来验证此设想，我们对似然的标准差估计已经从平均约 <span class="math notranslate nohighlight">\(460\)</span> 克降到了 <span class="math notranslate nohighlight">\(380\)</span> 克。</p>
<div class="figure align-default" id="fig-singlespecies-singleregression-forest-sigma-comparison">
<a class="reference internal image-reference" href="../_images/SingleSpecies_SingleRegression_Forest_Sigma_Comparison.png"><img alt="../_images/SingleSpecies_SingleRegression_Forest_Sigma_Comparison.png" src="../_images/SingleSpecies_SingleRegression_Forest_Sigma_Comparison.png" style="width: 7.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 40 </span><span class="caption-text">在估计企鹅体重时,通过使用鳍状肢长度作为预测变量，估计误差从略高于 <span class="math notranslate nohighlight">\(460\)</span> 克的均值减少到大约 <span class="math notranslate nohighlight">\(380\)</span> 克。直觉上这是有道理的，就像我们得到了关于估计量的信息，可以利用这些信息来做出更好的估计。</span><a class="headerlink" href="#fig-singlespecies-singleregression-forest-sigma-comparison" title="Permalink to this image">¶</a></p>
</div>
<div class="figure align-default" id="fig-flipper-length-mass-regression">
<a class="reference internal image-reference" href="../_images/Flipper_length_mass_regression.png"><img alt="../_images/Flipper_length_mass_regression.png" src="../_images/Flipper_length_mass_regression.png" style="width: 7.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 41 </span><span class="caption-text">观测到的鳍状肢长度与 <code class="docutils literal notranslate"><span class="pre">Adelie</span> <span class="pre">种</span></code> 的体重数据作散点图，似然的均值估计为黑线，均值的 <span class="math notranslate nohighlight">\(94\%\)</span> HDI 为灰色区间。请注意估计的均值如何随着鳍状肢长度变化而变化。</span><a class="headerlink" href="#fig-flipper-length-mass-regression" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="section" id="chp2-predictions">
<span id="id12"></span><h3>3.2.2 预测<a class="headerlink" href="#chp2-predictions" title="Permalink to this headline">¶</a></h3>
<p>在 <a class="reference internal" href="#linear-regression-intro"><span class="std std-ref">3.2.1 线性企鹅模型</span></a> 中，我们估计了鳍状肢长度和体重之间的线性关系。回归的另一用途是利用此关系进行预测。在本例中，给定企鹅的鳍状肢长度，我们能够预测它的体重吗？事实上可以。我们可以使用 <code class="docutils literal notranslate"><span class="pre">model_adelie_flipper_regression</span></code> 的结果来执行此预测操作。</p>
<p>由于在贝叶斯统计中，我们处理的是都是分布，因此最终不会得到关于体重的单个预测值，而是所有可能体重值的分布。该分布就是公式 <a class="reference internal" href="chp_01.html#equation-eq-post-pred-dist">(6)</a> 中定义的后验预测分布。</p>
<p>在实践中，我们通常不会（也可能无法）解析地计算预测，但使用概率编程语言，可以用后验分布样本来估计预测值的分布。例如，如果有一只平均鳍状肢长度的企鹅，并且想使用 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 预测其可能的体重，我们可以编写代码 <a class="reference internal" href="#penguins-ppd"><span class="std std-ref">penguins_ppd</span></a>：</p>
<div class="literal-block-wrapper docutils container" id="penguins-ppd">
<div class="code-block-caption"><span class="caption-number">Listing 26 </span><span class="caption-text">penguins_ppd</span><a class="headerlink" href="#penguins-ppd" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">model_adelie_flipper_regression</span><span class="p">:</span>
    <span class="c1"># Change the underlying value to the mean observed flipper length</span>
    <span class="c1"># for our posterior predictive samples</span>
    <span class="n">pm</span><span class="o">.</span><span class="n">set_data</span><span class="p">({</span><span class="s2">"adelie_flipper_length"</span><span class="p">:</span> <span class="p">[</span><span class="n">adelie_flipper_length_obs</span><span class="o">.</span><span class="n">mean</span><span class="p">()]})</span>
    <span class="n">posterior_predictions</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample_posterior_predictive</span><span class="p">(</span>
        <span class="n">inf_data_adelie_flipper_regression</span><span class="o">.</span><span class="n">posterior</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s2">"mass"</span><span class="p">,</span> <span class="s2">"μ"</span><span class="p">])</span>
</pre></div>
</div>
</div>
<p>在代码 <a class="reference internal" href="#penguins-ppd"><span class="std std-ref">penguins_ppd</span></a> 的第一行中，我们将鳍状肢长度的值固定为观测到的鳍状肢的平均长度。然后使用回归模型 <code class="docutils literal notranslate"><span class="pre">model_adelie_flipper_regression</span></code>，可以在该固定值处生成企鹅体重的后验预测样本。在 <a class="reference internal" href="#fig-flipper-length-mass-posterior-predictive"><span class="std std-numref">Fig. 42</span></a> 中，我们绘制了具有平均鳍状肢长度的企鹅，其体重的后验预测分布，沿着均值的后验。</p>
<div class="figure align-default" id="fig-flipper-length-mass-posterior-predictive">
<a class="reference internal image-reference" href="../_images/Flipper_length_mass_posterior_predictive.png"><img alt="../_images/Flipper_length_mass_posterior_predictive.png" src="../_images/Flipper_length_mass_posterior_predictive.png" style="width: 7.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 42 </span><span class="caption-text">在平均鳍状肢长度处评估的均值参数 <span class="math notranslate nohighlight">\(\mu\)</span> 的后验分布，标记为蓝色；同时，在平均鳍状肢长度处评估的企鹅体重的后验预测分布标记为黑色。可以看出，黑色曲线更宽，因为它描述了（给定鳍状肢长度时）所以可能预测结果的分布，而蓝色曲线仅表达了其中均值的分布。</span><a class="headerlink" href="#fig-flipper-length-mass-posterior-predictive" title="Permalink to this image">¶</a></p>
</div>
<p>简而言之，我们不仅可以使用代码 <a class="reference internal" href="#non-centered-regression"><span class="std std-ref">non_centered_regression</span></a> 中的模型来估计鳍状肢长度和企鹅体重之间的关系，还可以在任意鳍状肢长度处获得其对应的企鹅体重估计值。</p>
<p>换句话说，我们可以利用贝叶斯估计得出的 <span class="math notranslate nohighlight">\(\beta_1\)</span> 和 <span class="math notranslate nohighlight">\(\beta_0\)</span> 系数，通过后验预测分布来预测任意鳍状肢长度的企鹅体重。</p>
<p>因此，后验预测分布在贝叶斯环境中是一个特别强大的工具，它让我们不仅可以预测最可能的值，还可以预测包含不确定性的合理值分布，如公式 <a class="reference internal" href="chp_01.html#equation-eq-post-pred-dist">(6)</a> 。</p>
</div>
<div class="section" id="centering">
<span id="id13"></span><h3>3.2.3 中心化处理<a class="headerlink" href="#centering" title="Permalink to this headline">¶</a></h3>
<p>我们在代码 <a class="reference internal" href="#non-centered-regression"><span class="std std-ref">non_centered_regression</span></a> 中的模型在估计鳍状肢长度和企鹅体重之间的相关性以及预测给定鳍状肢长度下的企鹅体重方面效果很好。</p>
<p>遗憾的是，数据和模型提供的对 <span class="math notranslate nohighlight">\(\beta_0\)</span> 的估计并不是特别有用。但我们可以通过数据转换来使 <span class="math notranslate nohighlight">\(\beta_0\)</span> 更易于解释。通常我们会选择中心化处理，即采纳一组数据并将其均值中心化为零，如代码 <a class="reference internal" href="#flipper-centering"><span class="std std-ref">flipper_centering</span></a> 所示。</p>
<div class="literal-block-wrapper docutils container" id="flipper-centering">
<div class="code-block-caption"><span class="caption-number">Listing 27 </span><span class="caption-text">flipper_centering</span><a class="headerlink" href="#flipper-centering" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">adelie_flipper_length_c</span> <span class="o">=</span> <span class="p">(</span><span class="n">adelie_flipper_length_obs</span> <span class="o">-</span>
                           <span class="n">adelie_flipper_length_obs</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
</pre></div>
</div>
</div>
<p>使用中心化后的预测变量再次拟合模型，这次使用 <code class="docutils literal notranslate"><span class="pre">TFP</span></code>。</p>
<div class="literal-block-wrapper docutils container" id="tfp-penguins-centered-predictor">
<div class="code-block-caption"><span class="caption-number">Listing 28 </span><span class="caption-text">tfp_penguins_centered_predictor</span><a class="headerlink" href="#tfp-penguins-centered-predictor" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">gen_adelie_flipper_model</span><span class="p">(</span><span class="n">adelie_flipper_length</span><span class="p">):</span>
    <span class="n">adelie_flipper_length</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">adelie_flipper_length</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="nd">@tfd</span><span class="o">.</span><span class="n">JointDistributionCoroutine</span>
    <span class="k">def</span> <span class="nf">jd_adelie_flipper_regression</span><span class="p">():</span>
        <span class="n">σ</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">root</span><span class="p">(</span>
            <span class="n">tfd</span><span class="o">.</span><span class="n">HalfStudentT</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">"sigma"</span><span class="p">))</span>
        <span class="n">β_1</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">root</span><span class="p">(</span><span class="n">tfd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">4000</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">"beta_1"</span><span class="p">))</span>
        <span class="n">β_0</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">root</span><span class="p">(</span><span class="n">tfd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">4000</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">"beta_0"</span><span class="p">))</span>
        <span class="n">μ</span> <span class="o">=</span> <span class="n">β_0</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">+</span> <span class="n">β_1</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">adelie_flipper_length</span>
        <span class="n">mass</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Independent</span><span class="p">(</span>
            <span class="n">tfd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">μ</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">σ</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">]),</span>
            <span class="n">reinterpreted_batch_ndims</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="s2">"mass"</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">jd_adelie_flipper_regression</span>

<span class="c1"># If use non-centered predictor, this will give the same model as</span>
<span class="c1"># model_adelie_flipper_regression</span>
<span class="n">jd_adelie_flipper_regression</span> <span class="o">=</span> <span class="n">gen_adelie_flipper_model</span><span class="p">(</span>
    <span class="n">adelie_flipper_length_c</span><span class="p">)</span>

<span class="n">mcmc_samples</span><span class="p">,</span> <span class="n">sampler_stats</span> <span class="o">=</span> <span class="n">run_mcmc</span><span class="p">(</span>
    <span class="mi">1000</span><span class="p">,</span> <span class="n">jd_adelie_flipper_regression</span><span class="p">,</span> <span class="n">n_chains</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">num_adaptation_steps</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
    <span class="n">mass</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">adelie_mass_obs</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

<span class="n">inf_data_adelie_flipper_length_c</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="https://arviz-devs.github.io/arviz/api/generated/arviz.from_dict.html#arviz.from_dict" title="arviz.from_dict"><span class="n">az</span><span class="o">.</span><span class="n">from_dict</span></a><span class="p">(</span>
    <span class="n">posterior</span><span class="o">=</span><span class="p">{</span>
        <span class="n">k</span><span class="p">:</span><a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.swapaxes.html#numpy.swapaxes" title="numpy.swapaxes"><span class="n">np</span><span class="o">.</span><span class="n">swapaxes</span></a><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">mcmc_samples</span><span class="o">.</span><span class="n">_asdict</span><span class="p">()</span><span class="o">.</span><span class="n">items</span><span class="p">()},</span>
    <span class="n">sample_stats</span><span class="o">=</span><span class="p">{</span>
        <span class="n">k</span><span class="p">:</span><a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.swapaxes.html#numpy.swapaxes" title="numpy.swapaxes"><span class="n">np</span><span class="o">.</span><span class="n">swapaxes</span></a><span class="p">(</span><span class="n">sampler_stats</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">"target_log_prob"</span><span class="p">,</span> <span class="s2">"diverging"</span><span class="p">,</span> <span class="s2">"accept_ratio"</span><span class="p">,</span> <span class="s2">"n_steps"</span><span class="p">]}</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="figure align-default" id="fig-singlespecies-multipleregression-centered">
<a class="reference internal image-reference" href="../_images/SingleSpecies_MultipleRegression_Centered.png"><img alt="../_images/SingleSpecies_MultipleRegression_Centered.png" src="../_images/SingleSpecies_MultipleRegression_Centered.png" style="width: 7.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 43 </span><span class="caption-text">来自代码 <a class="reference internal" href="#tfp-penguins-centered-predictor"><span class="std std-ref">tfp_penguins_centered_predictor</span></a> 的系数估计。
注意，<span class="math notranslate nohighlight">\(beta\_1\)</span> 的分布与 <a class="reference internal" href="#fig-adelie-coefficient-posterior-plots"><span class="std std-numref">Fig. 39</span></a> 中相同，但 <span class="math notranslate nohighlight">\(beta\_0\)</span> 的分布发生了偏移。因为我们在鳍状肢长度的均值处做了中心化处理，<span class="math notranslate nohighlight">\(beta\_0\)</span> 现在代表具有平均鳍状肢长度的企鹅的概率体重分布。</span><a class="headerlink" href="#fig-singlespecies-multipleregression-centered" title="Permalink to this image">¶</a></p>
</div>
<p>在代码 <a class="reference internal" href="#tfp-penguins-centered-predictor"><span class="std std-ref">tfp_penguins_centered_predictor</span></a> 中定义的数学模型与代码 <a class="reference internal" href="#non-centered-regression"><span class="std std-ref">non_centered_regression</span></a> 中的 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 模型 <code class="docutils literal notranslate"><span class="pre">model_adelie_flipper_regression</span></code> 相同，唯一区别是对预测变量做的中心化处理。然而，在概率编程语言方面，<code class="docutils literal notranslate"><span class="pre">TFP</span></code> 的结构需要在各行中添加 <code class="docutils literal notranslate"><span class="pre">tensor_x[...,</span> <span class="pre">None]</span></code> 以扩展一批标量，以便它们能够与一批向量一起广播。具体来说，<code class="docutils literal notranslate"><span class="pre">None</span></code> 会添加一个新轴，这也可以使用 <code class="docutils literal notranslate"><span class="pre">np.newaxis</span></code> 或 <code class="docutils literal notranslate"><span class="pre">tf.newaxis</span></code> 来完成。此外，<code class="docutils literal notranslate"><span class="pre">TFP</span></code> 还将模型包装在一个函数中，以便轻松地以不同的预测变量作为条件。当然，此处使用中心化后的鳍状肢长度作为预测变量，但其实也可以项 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 一样使用非中心化的方式，两者结果是相似的。</p>
<p>当我们再次绘制系数时，<span class="math notranslate nohighlight">\(\beta_1\)</span> 与 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 模型相同，但 <span class="math notranslate nohighlight">\(\beta_0\)</span> 的分布发生了变化。由于我们将输入的数据中心化到了其均值上，<span class="math notranslate nohighlight">\(\beta_0\)</span> 的分布与我们对非中心化数据集的组均值的预测相同。通过将数据中心化，现在可以直接将 <span class="math notranslate nohighlight">\(\beta_0\)</span> 解释为具有平均鳍状肢长度的 <code class="docutils literal notranslate"><span class="pre">Adelie</span> <span class="pre">种</span></code>企鹅的平均体重分布。</p>
<p>转换输入变量的想法也可以在任意选择的值上执行。例如，我们可以减去最小鳍状肢长度后拟合模型。在这种转换中，会将 <span class="math notranslate nohighlight">\(\beta_0\)</span> 的解释更改为观测到的最小鳍状肢长度的均值分布。</p>
<p>为了更深入地讨论线性回归中的转换，我们推荐应用回归分析和广义线性模型 <span id="id14">[<a class="reference internal" href="references.html#id60">31</a>]</span>。</p>
</div>
</div>
<div class="section" id="multiple-linear-regression">
<span id="id15"></span><h2>3.3 多元线性回归<a class="headerlink" href="#multiple-linear-regression" title="Permalink to this headline">¶</a></h2>
<p>在许多物种中，不同性别之间存在双态性或差异。企鹅性别双态性的研究实际上是收集 <code class="docutils literal notranslate"><span class="pre">Palmer</span> <span class="pre">Penguin</span> <span class="pre">数据集</span></code> <span id="id16">[<a class="reference internal" href="references.html#id65">32</a>]</span> 的出发点之一。为了更仔细地研究企鹅的双态性，我们添加第二个预测变量：性别，将其编码为类别型变量，看看我们是否可以更精确地估计企鹅的体重。</p>
<div class="literal-block-wrapper docutils container" id="penguin-mass-multi">
<div class="code-block-caption"><span class="caption-number">Listing 29 </span><span class="caption-text">penguin_mass_multi</span><a class="headerlink" href="#penguin-mass-multi" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Binary encoding of the categorical predictor</span>
<span class="n">sex_obs</span> <span class="o">=</span> <span class="n">penguins</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">adelie_mask</span> <span class="p">,</span><span class="s2">"sex"</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">({</span><span class="s2">"male"</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span> <span class="s2">"female"</span><span class="p">:</span><span class="mi">1</span><span class="p">})</span>

<span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">model_penguin_mass_categorical</span><span class="p">:</span>
    <span class="n">σ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">HalfStudentT</span><span class="p">(</span><span class="s2">"σ"</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">2000</span><span class="p">)</span>
    <span class="n">β_0</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s2">"β_0"</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3000</span><span class="p">)</span>
    <span class="n">β_1</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s2">"β_1"</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3000</span><span class="p">)</span>
    <span class="n">β_2</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s2">"β_2"</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3000</span><span class="p">)</span>

    <span class="n">μ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Deterministic</span><span class="p">(</span>
        <span class="s2">"μ"</span><span class="p">,</span> <span class="n">β_0</span> <span class="o">+</span> <span class="n">β_1</span> <span class="o">*</span> <span class="n">adelie_flipper_length_obs</span> <span class="o">+</span> <span class="n">β_2</span> <span class="o">*</span> <span class="n">sex_obs</span><span class="p">)</span>

    <span class="n">mass</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s2">"mass"</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">μ</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">σ</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">adelie_mass_obs</span><span class="p">)</span>

    <span class="n">inf_data_penguin_mass_categorical</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span>
        <span class="n">target_accept</span><span class="o">=</span><span class="mf">.9</span><span class="p">,</span> <span class="n">return_inferencedata</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>你会注意到一个新参数 <span class="math notranslate nohighlight">\(\beta_{2}\)</span> 对 <span class="math notranslate nohighlight">\(\mu\)</span> 的值也有贡献。由于性别是一个类别型预测变量（ 本例中为“雄性”和“雌性”），我们将其分别编码为 <span class="math notranslate nohighlight">\(0\)</span> 和 <span class="math notranslate nohighlight">\(1\)</span>。对于该模型，意味着对于雌性企鹅来说，<span class="math notranslate nohighlight">\(\mu\)</span> 的值是 <span class="math notranslate nohighlight">\(3\)</span> 个项的总和，而对于雄性企鹅来说，是两个项的总和（因为 <span class="math notranslate nohighlight">\(\beta_2\)</span> 项将归零）。</p>
<div class="figure align-default" id="fig-adelie-sex-coefficient-posterior">
<a class="reference internal image-reference" href="../_images/adelie_sex_coefficient_posterior.png"><img alt="../_images/adelie_sex_coefficient_posterior.png" src="../_images/adelie_sex_coefficient_posterior.png" style="width: 7.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 44 </span><span class="caption-text">估计模型中的性别预测变量系数 <span class="math notranslate nohighlight">\(\beta_{2}\)</span> 。雄性企鹅编码为 <span class="math notranslate nohighlight">\(0\)</span>，雌性企鹅编码为 <span class="math notranslate nohighlight">\(1\)</span> ，这表示我们预计，具有相同鳍状肢长度的雄性和雌性 <code class="docutils literal notranslate"><span class="pre">Adelie</span> <span class="pre">种</span></code> 企鹅之间存在额外的体重差别。</span><a class="headerlink" href="#fig-adelie-sex-coefficient-posterior" title="Permalink to this image">¶</a></p>
</div>
<div class="admonition-syntactic-linear-sugar admonition">
<p class="admonition-title">Syntactic Linear Sugar </p>
<p>线性模型的使用如此广泛，以至于有人为回归专门编写了语法、方法和库。其中一个典型库是 <code class="docutils literal notranslate"><span class="pre">Bambi</span></code>（ 贝叶斯模型构建接口，BAyesian Model-Building Interface 的缩写 ）<span id="id17">[<a class="reference internal" href="references.html#id118">33</a>]</span>）。 <code class="docutils literal notranslate"><span class="pre">Bambi</span></code> 是一个 <code class="docutils literal notranslate"><span class="pre">Python</span></code> 包，使用形式化语法来拟合广义线性层次模型，类似于在 <code class="docutils literal notranslate"><span class="pre">R</span></code> 包中可以找到的内容，例如 <code class="docutils literal notranslate"><span class="pre">lme4</span> <span class="pre">包</span></code> <span id="id18">[<a class="reference internal" href="references.html#id82">34</a>]</span>、<code class="docutils literal notranslate"><span class="pre">nlme</span> <span class="pre">包</span></code> <span id="id19">[<a class="reference internal" href="references.html#id81">35</a>]</span>、<code class="docutils literal notranslate"><span class="pre">rstanarm</span> <span class="pre">包</span></code> <span id="id20">[<a class="reference internal" href="references.html#id83">36</a>]</span> 或 <code class="docutils literal notranslate"><span class="pre">brms</span> <span class="pre">包</span></code> <span id="id21">[<a class="reference internal" href="references.html#id84">37</a>]</span>）。 <code class="docutils literal notranslate"><span class="pre">Bambi</span></code> 在底层使用 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 并提供更高级别的 API。要编写同一个模型，在忽略代码 <a class="reference internal" href="#penguin-mass-multi"><span class="std std-ref">penguin_mass_multi</span></a> 中的先验 <a class="footnote-reference brackets" href="#id44" id="id22">4</a> 时，可以用 <code class="docutils literal notranslate"><span class="pre">Bambi</span></code> 编程为：</p>
<div class="literal-block-wrapper docutils container" id="bambi-categorical">
<div class="code-block-caption"><span class="caption-number">Listing 30 </span><span class="caption-text">bambi_categorical</span><a class="headerlink" href="#bambi-categorical" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">bambi</span> <span class="k">as</span> <span class="nn">bmb</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">bmb</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="s2">"body_mass_g ~ flipper_length_mm + sex"</span><span class="p">,</span>
                  <span class="n">penguins</span><span class="p">[</span><span class="n">adelie_mask</span><span class="p">])</span>
<span class="n">trace</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
</pre></div>
</div>
</div>
<p>如果不人为提供先验，软件包会像上述代码一样自动分配先验。在 <code class="docutils literal notranslate"><span class="pre">Bambi</span></code> 内部几乎存储了 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 生成的所有对象，使用户可以轻松检索、检查和修改这些对象。此外，<code class="docutils literal notranslate"><span class="pre">Bambi</span></code> 返回一个 <code class="docutils literal notranslate"><span class="pre">az.InferenceData</span></code> 对象，可以直接与 <code class="docutils literal notranslate"><span class="pre">ArviZ</span></code> 一起使用。</p>
</div>
<p>由于我们将 “雄性” 编码为 <span class="math notranslate nohighlight">\(0\)</span>，因此来自 <code class="docutils literal notranslate"><span class="pre">model_penguin_mass_categorical</span></code> 的后验估计了雄性企鹅与具有相同鳍状肢长度的雌性企鹅相比的体重差异。最后一部分非常重要，通过添加第二个预测变量，我们现在有了一个多元线性回归，而同时在解释系数时必须更加小心。在这种情况下，系数通常提供了：<strong>如果</strong>所有其他预测变量保持不变的情况下，某个预测变量与结果变量之间的关系 <a class="footnote-reference brackets" href="#id45" id="id23">5</a>。</p>
<div class="figure align-default" id="fig-single-species-categorical-regression">
<a class="reference internal image-reference" href="../_images/Single_Species_Categorical_Regression.png"><img alt="../_images/Single_Species_Categorical_Regression.png" src="../_images/Single_Species_Categorical_Regression.png" style="width: 7.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 45 </span><span class="caption-text">使用类别型预测变量编码的雄性和雌性 <code class="docutils literal notranslate"><span class="pre">Adelie</span> <span class="pre">种</span></code> 企鹅的鳍状肢长度与体重的多元回归。注意雄性和雌性企鹅之间的体重差异在每个鳍状肢长度上保持不变，该差异相当于 <span class="math notranslate nohighlight">\(\beta_2\)</span> 系数的大小。</span><a class="headerlink" href="#fig-single-species-categorical-regression" title="Permalink to this image">¶</a></p>
</div>
<p>我们可以再次在 <a class="reference internal" href="#fig-singlespecies-multipleregression-forest-sigma-comparison"><span class="std std-numref">Fig. 46</span></a> 中比较三个模型的标准差，看看是否减少了估计中的不确定性，可以看出，额外提供的信息进一步改进了估计。在当前情况下，我们对 <span class="math notranslate nohighlight">\(\sigma\)</span> 的估计从无预测变量模型中的平均 <span class="math notranslate nohighlight">\(462\)</span> 克下降到了多元线性模型中的平均 <span class="math notranslate nohighlight">\(298\)</span> 克。这种不确定性的减少表明，性别确实为估计企鹅体重提供了有用信息。</p>
<div class="literal-block-wrapper docutils container" id="forest-multiple-models">
<div class="code-block-caption"><span class="caption-number">Listing 31 </span><span class="caption-text">forest_multiple_models</span><a class="headerlink" href="#forest-multiple-models" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><a class="sphinx-codeautolink-a" href="https://arviz-devs.github.io/arviz/api/generated/arviz.plot_forest.html#arviz.plot_forest" title="arviz.plot_forest"><span class="n">az</span><span class="o">.</span><span class="n">plot_forest</span></a><span class="p">([</span><span class="n">inf_data_adelie_penguin_mass</span><span class="p">,</span>
        <span class="n">inf_data_adelie_flipper_regression</span><span class="p">,</span>
        <span class="n">inf_data_penguin_mass_categorical</span><span class="p">],</span>
        <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s2">"σ"</span><span class="p">],</span> <span class="n">combined</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="figure align-default" id="fig-singlespecies-multipleregression-forest-sigma-comparison">
<a class="reference internal image-reference" href="../_images/SingleSpecies_MultipleRegression_Forest_Sigma_Comparison.png"><img alt="../_images/SingleSpecies_MultipleRegression_Forest_Sigma_Comparison.png" src="../_images/SingleSpecies_MultipleRegression_Forest_Sigma_Comparison.png" style="width: 7.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 46 </span><span class="caption-text">将性别作为预测变量纳入 <code class="docutils literal notranslate"><span class="pre">model_penguin_mass_categorical</span></code> 中，该模型中 <span class="math notranslate nohighlight">\(\sigma\)</span> 的估计分布以 <span class="math notranslate nohighlight">\(300\)</span> 克为中心，低于无预测变量模型和单预测变量模型的估计值。该图由代码 <a class="reference internal" href="#forest-multiple-models"><span class="std std-ref">forest_multiple_models</span></a> 生成。</span><a class="headerlink" href="#fig-singlespecies-multipleregression-forest-sigma-comparison" title="Permalink to this image">¶</a></p>
</div>
<div class="admonition-more-covariates-is-not-always-better admonition">
<p class="admonition-title">More covariates is not always better </p>
<p>所有模型拟合算法都会找到一个信号，即使它是随机噪声。这种现象被称为过度拟合，它描述了一种情况，即算法可以很容易地将预测变量映射到已见案例中的结果，但无法推广到新的观测结果。在线性回归中，我们可以通过生成 100 个随机预测变量并将它们拟合到随机模拟数据集 <span id="id24">[<a class="reference internal" href="references.html#id33">10</a>]</span> 来证明这一点。即使没有关系，我们也会被引导相信我们的线性模型做得很好。</p>
</div>
<div class="section" id="linear-counter-factuals">
<span id="id25"></span><h3>3.3.1 反事实分析<a class="headerlink" href="#linear-counter-factuals" title="Permalink to this headline">¶</a></h3>
<p>在代码 <a class="reference internal" href="#penguins-ppd"><span class="std std-ref">penguins_ppd</span></a> 中，我们使用单预测变量模型拟合的参数进行预测，并调整鳍状肢长度以获得相应的体重估计。在多元回归中，我们可以做类似的工作。我们可以保持其他所有预测变量固定，然后查看剩下的那个预测变量如何改变预测结果。这种分析方法通常被称为<strong>反事实分析</strong>。</p>
<p>让我们扩展上一节代码 <a class="reference internal" href="#penguin-mass-multi"><span class="std std-ref">penguin_mass_multi</span></a> 的多元回归，这次增加<code class="docutils literal notranslate"><span class="pre">喙长度（</span> <span class="pre">Bill</span> <span class="pre">Length</span> <span class="pre">）</span></code>，并在 <code class="docutils literal notranslate"><span class="pre">TFP</span></code> 中运行反事实分析。模型构建和推断见代码 <a class="reference internal" href="#tfp-flipper-bill-sex"><span class="std std-ref">tfp_flipper_bill_sex</span></a> 。</p>
<div class="literal-block-wrapper docutils container" id="tfp-flipper-bill-sex">
<div class="code-block-caption"><span class="caption-number">Listing 32 </span><span class="caption-text">tfp_flipper_bill_sex</span><a class="headerlink" href="#tfp-flipper-bill-sex" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">gen_jd_flipper_bill_sex</span><span class="p">(</span><span class="n">flipper_length</span><span class="p">,</span> <span class="n">sex</span><span class="p">,</span> <span class="n">bill_length</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">):</span>
    <span class="n">flipper_length</span><span class="p">,</span> <span class="n">sex</span><span class="p">,</span> <span class="n">bill_length</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nest</span><span class="o">.</span><span class="n">map_structure</span><span class="p">(</span>
        <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dtype</span><span class="p">),</span>
        <span class="p">(</span><span class="n">flipper_length</span><span class="p">,</span> <span class="n">sex</span><span class="p">,</span> <span class="n">bill_length</span><span class="p">)</span>
    <span class="p">)</span>

    <span class="nd">@tfd</span><span class="o">.</span><span class="n">JointDistributionCoroutine</span>
    <span class="k">def</span> <span class="nf">jd_flipper_bill_sex</span><span class="p">():</span>
        <span class="n">σ</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">root</span><span class="p">(</span>
            <span class="n">tfd</span><span class="o">.</span><span class="n">HalfStudentT</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">"sigma"</span><span class="p">))</span>
        <span class="n">β_0</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">root</span><span class="p">(</span><span class="n">tfd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">3000</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">"beta_0"</span><span class="p">))</span>
        <span class="n">β_1</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">root</span><span class="p">(</span><span class="n">tfd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">3000</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">"beta_1"</span><span class="p">))</span>
        <span class="n">β_2</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">root</span><span class="p">(</span><span class="n">tfd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">3000</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">"beta_2"</span><span class="p">))</span>
        <span class="n">β_3</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">root</span><span class="p">(</span><span class="n">tfd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">3000</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">"beta_3"</span><span class="p">))</span>
        <span class="n">μ</span> <span class="o">=</span> <span class="p">(</span><span class="n">β_0</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span>
             <span class="o">+</span> <span class="n">β_1</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">flipper_length</span>
             <span class="o">+</span> <span class="n">β_2</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">sex</span>
             <span class="o">+</span> <span class="n">β_3</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">bill_length</span>
            <span class="p">)</span>
        <span class="n">mass</span> <span class="o">=</span> <span class="k">yield</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Independent</span><span class="p">(</span>
            <span class="n">tfd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">μ</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">σ</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">]),</span>
            <span class="n">reinterpreted_batch_ndims</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="s2">"mass"</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">jd_flipper_bill_sex</span>

<span class="n">bill_length_obs</span> <span class="o">=</span> <span class="n">penguins</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">adelie_mask</span><span class="p">,</span> <span class="s2">"bill_length_mm"</span><span class="p">]</span>
<span class="n">jd_flipper_bill_sex</span> <span class="o">=</span> <span class="n">gen_jd_flipper_bill_sex</span><span class="p">(</span>
    <span class="n">adelie_flipper_length_obs</span><span class="p">,</span> <span class="n">sex_obs</span><span class="p">,</span> <span class="n">bill_length_obs</span><span class="p">)</span>

<span class="n">mcmc_samples</span><span class="p">,</span> <span class="n">sampler_stats</span> <span class="o">=</span> <span class="n">run_mcmc</span><span class="p">(</span>
    <span class="mi">1000</span><span class="p">,</span> <span class="n">jd_flipper_bill_sex</span><span class="p">,</span> <span class="n">n_chains</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">num_adaptation_steps</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
    <span class="n">mass</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">adelie_mass_obs</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
</pre></div>
</div>
</div>
<p>在该模型中，你会注意到添加了另一个系数 <code class="docutils literal notranslate"><span class="pre">beta_3</span></code> 以对应于预测变量<code class="docutils literal notranslate"><span class="pre">喙长度</span></code>。推断完成后，我们可以固定企鹅性别为<code class="docutils literal notranslate"><span class="pre">雄性</span></code>、喙长度为数据集均值，然后模拟具有不同鳍状肢长度的企鹅体重。这在代码 <a class="reference internal" href="#tfp-flipper-bill-sex-counterfactuals"><span class="std std-ref">tfp_flipper_bill_sex_counterfactuals</span></a> 中实现，结果见 <a class="reference internal" href="#fig-linearcounterfactual"><span class="std std-numref">Fig. 47</span></a> 。由于我们将模型生成过程封装在了 <code class="docutils literal notranslate"><span class="pre">Python</span></code> 函数中（ 一种函数式编程风格的方法 ），因此很容易在新预测变量上做条件化，这对于反事实分析也非常有用。</p>
<div class="literal-block-wrapper docutils container" id="tfp-flipper-bill-sex-counterfactuals">
<div class="code-block-caption"><span class="caption-number">Listing 33 </span><span class="caption-text">tfp_flipper_bill_sex_counterfactuals</span><a class="headerlink" href="#tfp-flipper-bill-sex-counterfactuals" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mean_flipper_length</span> <span class="o">=</span> <span class="n">penguins</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">adelie_mask</span><span class="p">,</span> <span class="s2">"flipper_length_mm"</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="c1"># Counterfactual dimensions is set to 21 to allow us to get the mean exactly</span>
<span class="n">counterfactual_flipper_lengths</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.linspace.html#numpy.linspace" title="numpy.linspace"><span class="n">np</span><span class="o">.</span><span class="n">linspace</span></a><span class="p">(</span>
    <span class="n">mean_flipper_length</span><span class="o">-</span><span class="mi">20</span><span class="p">,</span> <span class="n">mean_flipper_length</span><span class="o">+</span><span class="mi">20</span><span class="p">,</span> <span class="mi">21</span><span class="p">)</span>
<span class="n">sex_male_indicator</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.zeros_like.html#numpy.zeros_like" title="numpy.zeros_like"><span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span></a><span class="p">(</span><span class="n">counterfactual_flipper_lengths</span><span class="p">)</span>
<span class="n">mean_bill_length</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.ones_like.html#numpy.ones_like" title="numpy.ones_like"><span class="n">np</span><span class="o">.</span><span class="n">ones_like</span></a><span class="p">(</span>
    <span class="n">counterfactual_flipper_lengths</span><span class="p">)</span> <span class="o">*</span> <span class="n">bill_length_obs</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="n">jd_flipper_bill_sex_counterfactual</span> <span class="o">=</span> <span class="n">gen_jd_flipper_bill_sex</span><span class="p">(</span>
    <span class="n">counterfactual_flipper_lengths</span><span class="p">,</span> <span class="n">sex_male_indicator</span><span class="p">,</span> <span class="n">mean_bill_length</span><span class="p">)</span>
<span class="n">ppc_samples</span> <span class="o">=</span> <span class="n">jd_flipper_bill_sex_counterfactual</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="n">mcmc_samples</span><span class="p">)</span>
<span class="n">estimated_mass</span> <span class="o">=</span> <span class="n">ppc_samples</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">21</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="figure align-default" id="fig-linearcounterfactual">
<a class="reference internal image-reference" href="../_images/Linear_CounterFactual.png"><img alt="../_images/Linear_CounterFactual.png" src="../_images/Linear_CounterFactual.png" style="width: 7.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 47 </span><span class="caption-text">来自代码 <a class="reference internal" href="#tfp-flipper-bill-sex-counterfactuals"><span class="std std-ref">tfp_flipper_bill_sex_counterfactuals</span></a> 的 <code class="docutils literal notranslate"><span class="pre">Adelie</span> <span class="pre">种</span></code> 企鹅的反事实法体重估计值，其中仅鳍状肢长度变化，所有其他预测变量都保持不变。</span><a class="headerlink" href="#fig-linearcounterfactual" title="Permalink to this image">¶</a></p>
</div>
<p>遵循 McElreath<span id="id26">[<a class="reference internal" href="references.html#id33">10</a>]</span> 的提法， <a class="reference internal" href="#fig-linearcounterfactual"><span class="std std-numref">Fig. 47</span></a> 被称为反事实图。正如“反事实”一词所暗示的那样，我们正在评估与观测数据或事实相反的情况。换句话说，我们正在评估尚未发生的情况。反事实图的最简单用途是调整预测变量并探索预测结果。这是一种很棒的方法，因为它使我们能够探索无法实现的 <em>what-if</em> 场景 <a class="footnote-reference brackets" href="#id46" id="id27">6</a>。但是，我们在解释这种方法时必须谨慎。第一个陷阱是反事实值有可能根本不可能出现，例如，可能永远不会存在鳍状肢长度大于 <span class="math notranslate nohighlight">\(1500\)</span> 毫米的企鹅，但该模型会机械地提供对这种情况的估计。第二个陷阱更隐蔽，我们假设可以独立地改变每个预测变量，但实际上这可能几乎不可能出现。例如，随着企鹅鳍状肢长度的增加，它的喙长度也会增加。反事实法的强大之处在于其允许我们探索尚未发生的结果，或者至少没有被观测到发生的结果。但是它们也可以很容易地为<strong>永远</strong>不会发生的情况生成估计值。模型本身无法区分两者，因此作为建模者，你必须得学会识别它们。</p>
<div class="admonition-correlation-causality admonition">
<p class="admonition-title">相关性（ Correlation ）与因果性（ Causality ）</p>
<p>在解释线性回归时，很容易将其描述为 “<span class="math notranslate nohighlight">\(X\)</span> 的增加<strong>导致</strong> <span class="math notranslate nohighlight">\(Y\)</span> 的增加”，但情况并不一定如此。事实上因果陈述不能仅从回归中得出。在数学上，回归模型将两个（或更多变量）联系在一起，但这种联系不需要是因果关系。例如，增加为植物提供的水量当然可以（并且因果地）增加植物的生长（至少在一定范围内），但没有什么能阻止我们在模型中颠倒这种关系并使用植物的生长来估计降雨量，即使植物生长不会导致降雨 <a class="footnote-reference brackets" href="#id47" id="id28">7</a>。因果推断的统计子领域涉及在随机实验或观测研究背景下做出因果陈述所必需的工具和程序（ 参见 <a class="reference internal" href="chp_07.html#chap6"><span class="std std-ref"> 第 7 章 </span></a> 进行的简要讨论 ）</p>
</div>
</div>
</div>
<div class="section" id="generalized-linear-models">
<span id="id29"></span><h2>3.4 广义线性模型<a class="headerlink" href="#generalized-linear-models" title="Permalink to this headline">¶</a></h2>
<p>到目前为止，我们讨论的所有线性模型都假设观测值的分布为高斯分布，这在许多情况下都能很好地工作。但有时我们可能需要使用其他分布。例如要对受限于某个区间的事物建模，区间 <span class="math notranslate nohighlight">\([0, 1]\)</span> 中的数字类似于概率，或者自然数 <span class="math notranslate nohighlight">\(\{1, 2, 3, \dots \}\)</span> 类似于计数事件。为此，我们使用线性函数 <span class="math notranslate nohighlight">\(\mathbf{X} \mathit{\beta}\)</span>，并使用反向链接函数 <a class="footnote-reference brackets" href="#id48" id="id30">8</a> <span class="math notranslate nohighlight">\(\phi\)</span> 对其进行修改，如公式 <a class="reference internal" href="#equation-eq-generalized-linear-model">(28)</a> 所示：</p>
<div class="math notranslate nohighlight" id="equation-eq-generalized-linear-model">
<span class="eqno">(28)<a class="headerlink" href="#equation-eq-generalized-linear-model" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{split}
\mu =&amp; \phi(\mathbf{X} \beta) \\
Y \sim&amp; \Psi (\mu, \theta)
\end{split}\end{split}\]</div>
<p>其中 <span class="math notranslate nohighlight">\(\Psi\)</span> 是一些由 <span class="math notranslate nohighlight">\(\mu\)</span> 和 <span class="math notranslate nohighlight">\(\theta\)</span> 参数化的分布，表示数据的似然。</p>
<p>反向链接函数的具体目的是将实数范围 <span class="math notranslate nohighlight">\((-\infty, \infty)\)</span> 的输出映射到受限区间范围。换句话说，反向链接函数是我们将线性模型推广到更多模型架构所需的一种 “技巧”。我们在这里处理的仍然是线性模型，因为生成观测数据所使用的分布的期望仍然遵循参数和预测变量的线性函数，只不过现在我们可以将这些模型的使用和应用推广到更多场景 <a class="footnote-reference brackets" href="#id49" id="id31">9</a>。</p>
<div class="section" id="logistic-regression">
<span id="id32"></span><h3>3.4.1 逻辑斯谛回归<a class="headerlink" href="#logistic-regression" title="Permalink to this headline">¶</a></h3>
<p>最常见的广义线性模型之一是逻辑斯谛回归。它在只有两种可能结果之一的数据建模中特别有用。掷硬币中“正面”或“反面”结果的概率是常见的教科书示例。更多“现实世界”中的例子包括：生产中的缺陷可能性、癌症测试的阴性或阳性、火箭发射是否失败 <span id="id33">[<a class="reference internal" href="references.html#id79">38</a>]</span>。</p>
<p>在逻辑斯谛回归中，反向链接函数被称为 <code class="docutils literal notranslate"><span class="pre">逻辑斯谛函数（</span> <span class="pre">logistic</span> <span class="pre">function</span> <span class="pre">）</span></code>，它将 <span class="math notranslate nohighlight">\((-\infty, \infty)\)</span> 映射到 <span class="math notranslate nohighlight">\((0,1)\)</span> 区间。这很方便，因为现在我们可以将线性函数映射到概率值的 <span class="math notranslate nohighlight">\(0\)</span> 到 <span class="math notranslate nohighlight">\(1\)</span> 范围内。</p>
<div class="math notranslate nohighlight" id="equation-eq-logistic">
<span class="eqno">(29)<a class="headerlink" href="#equation-eq-logistic" title="Permalink to this equation">¶</a></span>\[p = \frac{1}{1+e^{-\mathbf{X}\beta}}\]</div>
<div class="figure align-default" id="fig-logistic">
<a class="reference internal image-reference" href="../_images/Logistic.png"><img alt="../_images/Logistic.png" src="../_images/Logistic.png" style="width: 7.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 48 </span><span class="caption-text">一个逻辑斯谛函数示例图。请注意，结果变量已被“压缩”到区间 (0,1) 中。</span><a class="headerlink" href="#fig-logistic" title="Permalink to this image">¶</a></p>
</div>
<p>通过逻辑斯谛回归，我们能够使用线性模型来估计事件的概率。有时，我们想要对给定数据进行分类或预测，此时我们希望将区间 <span class="math notranslate nohighlight">\((-\infty, \infty)\)</span> 内的某个连续预测值转换至 <span class="math notranslate nohighlight">\(0\)</span> 到 <span class="math notranslate nohighlight">\(1\)</span> 之间。然后，可以使用决策边界将其划分为集合 <span class="math notranslate nohighlight">\(\{0 ,1\}\)</span> 中的某一个元素。假设将决策边界设置为 <span class="math notranslate nohighlight">\(0.5\)</span> 的概率，则对于具有截距和单预测变量的模型，我们有：</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{split}
0.5 &amp;= logistic(\beta_{0} + \beta_{1}*x) \\
logit(0.5) &amp;= \beta_{0} + \beta_{1}*x \\
0 &amp;= \beta_{0} + \beta_{1}*x \\
x &amp;= -\frac{\beta_{0}}{\beta_{1}} \\
\end{split}\end{split}\]</div>
<p>请注意，<span class="math notranslate nohighlight">\(logit\)</span> 是 <span class="math notranslate nohighlight">\(logistic\)</span> 的逆函数。也就是说，一旦拟合了逻辑斯谛模型，我们就可以使用系数 <span class="math notranslate nohighlight">\(\beta_0\)</span> 和 <span class="math notranslate nohighlight">\(\beta_1\)</span> 轻松计算出类概率大于 <span class="math notranslate nohighlight">\(0.5\)</span> 的 <span class="math notranslate nohighlight">\(x\)</span> 值。</p>
</div>
<div class="section" id="classifying-penguins">
<span id="id34"></span><h3>3.4.2 对企鹅进行分类<a class="headerlink" href="#classifying-penguins" title="Permalink to this headline">¶</a></h3>
<p>在前面部分中，我们使用企鹅性别和喙长度来估计企鹅的体重。现在改变以下该问题：如果给定企鹅的体重、性别和喙长，我们能够预测其物种吗？</p>
<p>让我们使用 <code class="docutils literal notranslate"><span class="pre">Adelie</span></code>和 <code class="docutils literal notranslate"><span class="pre">Chinstrap</span></code> 这两个企鹅物种来完成此二元任务。就像上次一样，首先使用一个简单模型，只有一个预测变量，即喙长度。我们在代码 <a class="reference internal" href="#model-logistic-penguins-bill-length"><span class="std std-ref">model_logistic_penguins_bill_length</span></a> 中编写这个逻辑斯谛模型：</p>
<div class="literal-block-wrapper docutils container" id="model-logistic-penguins-bill-length">
<div class="code-block-caption"><span class="caption-number">Listing 34 </span><span class="caption-text">model_logistic_penguins_bill_length</span><a class="headerlink" href="#model-logistic-penguins-bill-length" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">species_filter</span> <span class="o">=</span> <span class="n">penguins</span><span class="p">[</span><span class="s2">"species"</span><span class="p">]</span><span class="o">.</span><span class="n">isin</span><span class="p">([</span><span class="s2">"Adelie"</span><span class="p">,</span> <span class="s2">"Chinstrap"</span><span class="p">])</span>
<span class="n">bill_length_obs</span> <span class="o">=</span> <span class="n">penguins</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">species_filter</span><span class="p">,</span> <span class="s2">"bill_length_mm"</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">species</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Categorical</span><span class="p">(</span><span class="n">penguins</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">species_filter</span><span class="p">,</span> <span class="s2">"species"</span><span class="p">])</span>

<span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">model_logistic_penguins_bill_length</span><span class="p">:</span>
    <span class="n">β_0</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s2">"β_0"</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">β_1</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s2">"β_1"</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

    <span class="n">μ</span> <span class="o">=</span> <span class="n">β_0</span> <span class="o">+</span> <span class="n">pm</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">bill_length_obs</span><span class="p">,</span> <span class="n">β_1</span><span class="p">)</span>

    <span class="c1"># A`PPL`ication of our sigmoid  link function</span>
    <span class="n">θ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Deterministic</span><span class="p">(</span><span class="s2">"θ"</span><span class="p">,</span> <span class="n">pm</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">μ</span><span class="p">))</span>

    <span class="c1"># Useful for plotting the decision boundary later</span>
    <span class="n">bd</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Deterministic</span><span class="p">(</span><span class="s2">"bd"</span><span class="p">,</span> <span class="o">-</span><span class="n">β_0</span><span class="o">/</span><span class="n">β_1</span><span class="p">)</span>

    <span class="c1"># Note the change in likelihood</span>
    <span class="n">yl</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Bernoulli</span><span class="p">(</span><span class="s2">"yl"</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">θ</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">species</span><span class="o">.</span><span class="n">codes</span><span class="p">)</span>

    <span class="n">prior_predictive_logistic_penguins_bill_length</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample_prior_predictive</span><span class="p">()</span>
    <span class="n">trace_logistic_penguins_bill_length</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">5000</span><span class="p">,</span> <span class="n">chains</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">inf_data_logistic_penguins_bill_length</span> <span class="o">=</span> <span class="n">az</span><span class="o">.</span><span class="n">from_PyMC3</span><span class="p">(</span>
        <span class="n">prior</span><span class="o">=</span><span class="n">prior_predictive_logistic_penguins_bill_length</span><span class="p">,</span>
        <span class="n">trace</span><span class="o">=</span><span class="n">trace_logistic_penguins_bill_length</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>在广义线性模型中，从参数先验到响应值的映射有时难以理解，此时可以利用先验预测样本来帮助我们可视化预期的观测结果，这被称之为先验预测检查。</p>
<p>在企鹅分类的例子中，通过先验预测检查可以发现：在看到任何数据之前，在所有喙长度上属于 <code class="docutils literal notranslate"><span class="pre">Gentoo</span> <span class="pre">种</span></code> 和 <code class="docutils literal notranslate"><span class="pre">Adelie</span> <span class="pre">种</span></code> 的预期都是合理的。我们通过先验预测检查可以双重检查先验设置和模型是否能够切实表达我们的建模意图。在看到数据之前， <a class="reference internal" href="#fig-prior-predictive-logistic"><span class="std std-numref">Fig. 49</span></a> 中这些类大致上是均匀的，这也是我们所期望的。</p>
<div class="figure align-default" id="fig-prior-predictive-logistic">
<a class="reference internal image-reference" href="../_images/Prior_Predictive_Logistic.png"><img alt="../_images/Prior_Predictive_Logistic.png" src="../_images/Prior_Predictive_Logistic.png" style="width: 7.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 49 </span><span class="caption-text">来自 <code class="docutils literal notranslate"><span class="pre">model_logistic_penguins_bill_length</span></code> 的 <span class="math notranslate nohighlight">\(5000\)</span> 个关于类别预测的先验预测样本。这种似然是离散的，更具体地说是二值的，与之前模型中估计的连续型的企鹅体重有所不同。</span><a class="headerlink" href="#fig-prior-predictive-logistic" title="Permalink to this image">¶</a></p>
</div>
<p>在模型中拟合出参数后，我们可以使用 <code class="docutils literal notranslate"><span class="pre">az.summary(.)</span></code> 函数检查系数（ 参见 <a class="reference internal" href="#table-logistic-penguins-bill-length"><span class="std std-numref">Table 5</span></a> ）。你会发现，此模型的系数并不像线性回归那样可直接解释。在指定正值的 <span class="math notranslate nohighlight">\(\beta_1\)</span> 系数（ 其  <code class="docutils literal notranslate"><span class="pre">HDI</span></code> 不过 <span class="math notranslate nohighlight">\(0\)</span> ）时，我们可以看出喙长和物种存在某种关系。我们可以相当直接地解释决策边界，看到大约 <span class="math notranslate nohighlight">\(44\)</span> 毫米喙长是两个物种之间的标称切分值。在 <a class="reference internal" href="#fig-logistic-bill-length"><span class="std std-numref">Fig. 50</span></a> 中绘制回归的输出更加直观。图中可以看到随着类别变化从左侧 <span class="math notranslate nohighlight">\(0\)</span> 逐步移动到右侧 <span class="math notranslate nohighlight">\(1\)</span> 的逻辑斯谛曲线，以及在给定数据时的预期决策边界。</p>
<div class="figure align-default" id="fig-logistic-bill-length">
<a class="reference internal image-reference" href="../_images/Logistic_bill_length.png"><img alt="../_images/Logistic_bill_length.png" src="../_images/Logistic_bill_length.png" style="width: 7.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 50 </span><span class="caption-text">拟合后的逻辑斯谛回归，显示 <code class="docutils literal notranslate"><span class="pre">model_logistic_penguins_bill_length</span></code> 的概率曲线、观测数据点和决策边界。仅从观测数据来看，两个物种的喙长似乎在 <span class="math notranslate nohighlight">\(45\)</span> 毫米左右存在区分，我们的模型同样识别出围绕该值的这种区分。</span><a class="headerlink" href="#fig-logistic-bill-length" title="Permalink to this image">¶</a></p>
</div>
<table class="table" id="table-logistic-penguins-bill-length">
<caption><span class="caption-number">Table 5 </span><span class="caption-text">Logistic regression coefficients for model_logistic_penguins_bill_length.</span><a class="headerlink" href="#table-logistic-penguins-bill-length" title="Permalink to this table">¶</a></caption>
<colgroup>
<col style="width: 20%"/>
<col style="width: 20%"/>
<col style="width: 20%"/>
<col style="width: 20%"/>
<col style="width: 20%"/>
</colgroup>
<tbody>
<tr class="row-odd"><td></td>
<td><p><strong>mean</strong></p></td>
<td><p><strong>sd</strong></p></td>
<td><p><strong>hdi_3%</strong></p></td>
<td><p><strong>hdi_97%</strong></p></td>
</tr>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\(\beta_0\)</span></p></td>
<td><p>-46.052</p></td>
<td><p>7.073</p></td>
<td><p>-58.932</p></td>
<td><p>-34.123</p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\(\beta_1\)</span></p></td>
<td><p>1.045</p></td>
<td><p>0.162</p></td>
<td><p>0.776</p></td>
<td><p>1.347</p></td>
</tr>
</tbody>
</table>
<p>现在尝试一些不同的东西，我们仍然想对企鹅进行分类，但这次使用企鹅的体重作为预测变量。代码 <a class="reference internal" href="#model-logistic-penguins-mass"><span class="std std-ref">model_logistic_penguins_mass</span></a> 显示了该模型：</p>
<div class="literal-block-wrapper docutils container" id="model-logistic-penguins-mass">
<div class="code-block-caption"><span class="caption-number">Listing 35 </span><span class="caption-text">model_logistic_penguins_mass</span><a class="headerlink" href="#model-logistic-penguins-mass" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mass_obs</span> <span class="o">=</span> <span class="n">penguins</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">species_filter</span><span class="p">,</span> <span class="s2">"body_mass_g"</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>

<span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">model_logistic_penguins_mass</span><span class="p">:</span>
    <span class="n">β_0</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s2">"β_0"</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">β_1</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s2">"β_1"</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

    <span class="n">μ</span> <span class="o">=</span> <span class="n">β_0</span> <span class="o">+</span> <span class="n">pm</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">mass_obs</span><span class="p">,</span> <span class="n">β_1</span><span class="p">)</span>
    <span class="n">θ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Deterministic</span><span class="p">(</span><span class="s2">"θ"</span><span class="p">,</span> <span class="n">pm</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">μ</span><span class="p">))</span>
    <span class="n">bd</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Deterministic</span><span class="p">(</span><span class="s2">"bd"</span><span class="p">,</span> <span class="o">-</span><span class="n">β_0</span><span class="o">/</span><span class="n">β_1</span><span class="p">)</span>

    <span class="n">yl</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Bernoulli</span><span class="p">(</span><span class="s2">"yl"</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">θ</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">species</span><span class="o">.</span><span class="n">codes</span><span class="p">)</span>

    <span class="n">inf_data_logistic_penguins_mass</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span>
        <span class="mi">5000</span><span class="p">,</span> <span class="n">target_accept</span><span class="o">=</span><span class="mf">.9</span><span class="p">,</span> <span class="n">return_inferencedata</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<table class="table" id="table-logistic-penguins-mass">
<caption><span class="caption-number">Table 6 </span><span class="caption-text">Logistic regression coefficients for model_logistic_penguins_mass.</span><a class="headerlink" href="#table-logistic-penguins-mass" title="Permalink to this table">¶</a></caption>
<colgroup>
<col style="width: 20%"/>
<col style="width: 20%"/>
<col style="width: 20%"/>
<col style="width: 20%"/>
<col style="width: 20%"/>
</colgroup>
<tbody>
<tr class="row-odd"><td></td>
<td><p><strong>mean</strong></p></td>
<td><p><strong>sd</strong></p></td>
<td><p><strong>hdi_3%</strong></p></td>
<td><p><strong>hdi_97%</strong></p></td>
</tr>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\(\beta_0\)</span></p></td>
<td><p>-1.131</p></td>
<td><p>1.317</p></td>
<td><p>-3.654</p></td>
<td><p>1.268</p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\(\beta_1\)</span></p></td>
<td><p>0.000</p></td>
<td><p>0.000</p></td>
<td><p>0.000</p></td>
<td><p>0.001</p></td>
</tr>
</tbody>
</table>
<p>在 <a class="reference internal" href="#table-logistic-penguins-mass"><span class="std std-numref">Table 6</span></a> 表格展示的摘要信息中， <span class="math notranslate nohighlight">\(\beta_1\)</span> 被估计为 <span class="math notranslate nohighlight">\(0\)</span> ，表明体重预测变量中并没有足够信息来区分两个物种。这不一定是坏事，只是表明模型在两个物种的体重之间没有发现明显的差异。</p>
<p>一旦我们在 <a class="reference internal" href="#fig-logistic-mass"><span class="std std-numref">Fig. 51</span></a> 中绘制数据和逻辑斯谛回归的拟合结果，这一点就会表现得非常明显。</p>
<div class="figure align-default" id="fig-logistic-mass">
<a class="reference internal image-reference" href="../_images/Logistic_mass.png"><img alt="../_images/Logistic_mass.png" src="../_images/Logistic_mass.png" style="width: 7.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 51 </span><span class="caption-text"><code class="docutils literal notranslate"><span class="pre">model_logistic_penguins_mass</span></code> 的观测数据和逻辑斯谛回归图。与 <a class="reference internal" href="#fig-logistic-bill-length"><span class="std std-numref">Fig. 50</span></a> 不同，数据看起来不可分离3。</span><a class="headerlink" href="#fig-logistic-mass" title="Permalink to this image">¶</a></p>
</div>
<p>我们不应该受到这种关系的缺失影响，因为有效的建模就包含一定的试错环节。这不意味着随意试错，以期能够“瞎猫碰个死耗子”，而是意味着可以使用计算工具为你提供进行下一步的线索。</p>
<p>现在尝试同时使用喙长度和体重，在代码 <a class="reference internal" href="#model-logistic-penguins-bill-length-mass"><span class="std std-ref">model_logistic_penguins_bill_length_mass</span></a> 中创建多元逻辑斯谛回归，并在 <a class="reference internal" href="#fig-decision-boundary-logistic-mass-bill-length"><span class="std std-numref">Fig. 52</span></a> 中绘制决策边界。这次图中的坐标轴有点不同， Y 轴不再是分类概率，而是企鹅的体重。这样就可以明显地看到预测变量之间的决策边界。所有这些目视检查都是有帮助的，但也是主观的。我们可以使用一些诊断工具来量化拟合程度。</p>
<div class="literal-block-wrapper docutils container" id="model-logistic-penguins-bill-length-mass">
<div class="code-block-caption"><span class="caption-number">Listing 36 </span><span class="caption-text">model_logistic_penguins_bill_length_mass</span><a class="headerlink" href="#model-logistic-penguins-bill-length-mass" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">penguins</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">species_filter</span><span class="p">,</span> <span class="p">[</span><span class="s2">"bill_length_mm"</span><span class="p">,</span> <span class="s2">"body_mass_g"</span><span class="p">]]</span>

<span class="c1"># Add a column of 1s for the intercept</span>
<span class="n">X</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="s2">"Intercept"</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">values</span>

<span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">model_logistic_penguins_bill_length_mass</span><span class="p">:</span>
    <span class="n">β</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s2">"β"</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

    <span class="n">μ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">β</span><span class="p">)</span>

    <span class="n">θ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Deterministic</span><span class="p">(</span><span class="s2">"θ"</span><span class="p">,</span> <span class="n">pm</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">μ</span><span class="p">))</span>
    <span class="n">bd</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Deterministic</span><span class="p">(</span><span class="s2">"bd"</span><span class="p">,</span> <span class="o">-</span><span class="n">β</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="n">β</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">-</span> <span class="n">β</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">/</span><span class="n">β</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])</span>

    <span class="n">yl</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Bernoulli</span><span class="p">(</span><span class="s2">"yl"</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">θ</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">species</span><span class="o">.</span><span class="n">codes</span><span class="p">)</span>

    <span class="n">inf_data_logistic_penguins_bill_length_mass</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span>
        <span class="mi">1000</span><span class="p">,</span>
        <span class="n">return_inferencedata</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="figure align-default" id="fig-decision-boundary-logistic-mass-bill-length">
<a class="reference internal image-reference" href="../_images/Decision_Boundary_Logistic_mass_bill_length.png"><img alt="../_images/Decision_Boundary_Logistic_mass_bill_length.png" src="../_images/Decision_Boundary_Logistic_mass_bill_length.png" style="width: 7.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 52 </span><span class="caption-text">针对喙长度和体重绘制的物种类别决策边界。可以看到大部分可分离性来自喙长度，尽管体重也添加了一些关于可分离性的额外信息，如线的斜率。</span><a class="headerlink" href="#fig-decision-boundary-logistic-mass-bill-length" title="Permalink to this image">¶</a></p>
</div>
<p>为了评估模型是否适合逻辑斯谛回归，可以使用<code class="docutils literal notranslate"><span class="pre">分离图</span></code> <span id="id35">[<a class="reference internal" href="references.html#id172">39</a>]</span>，如代码 <a class="reference internal" href="#separability-plot"><span class="std std-ref">separability_plot</span></a> 和 <a class="reference internal" href="#fig-penguins-separation-plot"><span class="std std-numref">Fig. 53</span></a> 所示。分离图是一种评估二值观测数据模型校准的方法。它显示了每个类的预测排序，当两个类完美分离时，应当体现为两个不同颜色的矩形。在本示例中，可以看到我们的模型没有一个能够完美地分离两个物种，但包含喙长度的模型比仅包含体重的模型表现得更好。一般来说，完美校准不是贝叶斯分析的目标，使用分离图（以及其他校准评估方法，如 LOO-PIT）的目的是帮助我们比较模型并揭示改进它们的机会。</p>
<div class="literal-block-wrapper docutils container" id="separability-plot">
<div class="code-block-caption"><span class="caption-number">Listing 37 </span><span class="caption-text">separability_plot</span><a class="headerlink" href="#separability-plot" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">models</span> <span class="o">=</span> <span class="p">{</span><span class="s2">"bill"</span><span class="p">:</span> <span class="n">inf_data_logistic_penguins_bill_length</span><span class="p">,</span>
          <span class="s2">"mass"</span><span class="p">:</span> <span class="n">inf_data_logistic_penguins_mass</span><span class="p">,</span>
          <span class="s2">"mass bill"</span><span class="p">:</span> <span class="n">inf_data_logistic_penguins_bill_length_mass</span><span class="p">}</span>

<span class="n">_</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.subplots.html#matplotlib.pyplot.subplots" title="matplotlib.pyplot.subplots"><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span></a><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">for</span> <span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">model</span><span class="p">),</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">models</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">axes</span><span class="p">):</span>
    <a class="sphinx-codeautolink-a" href="https://arviz-devs.github.io/arviz/api/generated/arviz.plot_separation.html#arviz.plot_separation" title="arviz.plot_separation"><span class="n">az</span><span class="o">.</span><span class="n">plot_separation</span></a><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">"p"</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">"C4"</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="figure align-default" id="fig-penguins-separation-plot">
<a class="reference internal image-reference" href="../_images/Penguins_Separation_Plot.png"><img alt="../_images/Penguins_Separation_Plot.png" src="../_images/Penguins_Separation_Plot.png" style="width: 7.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 53 </span><span class="caption-text">三个企鹅模型的分离图。明暗值表示二分类标签。图中明显看出，仅含体重的模型在区分两个物种方面做得很差，而 <code class="docutils literal notranslate"><span class="pre">单喙长度</span></code> 模型和 <code class="docutils literal notranslate"><span class="pre">体重-喙</span></code> 模型表现更好。</span><a class="headerlink" href="#fig-penguins-separation-plot" title="Permalink to this image">¶</a></p>
</div>
<p>我们还可以使用 <code class="docutils literal notranslate"><span class="pre">留一法（</span> <span class="pre">LOO</span> <span class="pre">）</span></code> 来比较刚创建的三个模型：单体重模型、单喙长度模型和代码 <a class="reference internal" href="#penguin-model-loo"><span class="std std-ref">penguin_model_loo</span></a> 和 <a class="reference internal" href="#tab-penguin-loo"><span class="std std-numref">Table 7</span></a> 中的“体重+喙长度”二元预测模型。根据 <code class="docutils literal notranslate"><span class="pre">LOO</span></code>，单体重模型在分离物种方面表现最差，单喙长模型是中间候选模型，“体重+喙长度” 模型表现最好。上面分离图中的结果，现在得到了数值上的确认。</p>
<div class="literal-block-wrapper docutils container" id="penguin-model-loo">
<div class="code-block-caption"><span class="caption-number">Listing 38 </span><span class="caption-text">penguin_model_loo</span><a class="headerlink" href="#penguin-model-loo" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><a class="sphinx-codeautolink-a" href="https://arviz-devs.github.io/arviz/api/generated/arviz.compare.html#arviz.compare" title="arviz.compare"><span class="n">az</span><span class="o">.</span><span class="n">compare</span></a><span class="p">({</span><span class="s2">"mass"</span><span class="p">:</span><span class="n">inf_data_logistic_penguins_mass</span><span class="p">,</span>
            <span class="s2">"bill"</span><span class="p">:</span> <span class="n">inf_data_logistic_penguins_bill_length</span><span class="p">,</span>
            <span class="s2">"mass_bill"</span><span class="p">:</span><span class="n">inf_data_logistic_penguins_bill_length_mass</span><span class="p">})</span>
</pre></div>
</div>
</div>
<table class="table" id="tab-penguin-loo">
<caption><span class="caption-number">Table 7 </span><span class="caption-text">模型比较的汇总。模型按照 ELPD ( loo 列 ) 值从低到高的排序。</span><a class="headerlink" href="#tab-penguin-loo" title="Permalink to this table">¶</a></caption>
<colgroup>
<col style="width: 10%"/>
<col style="width: 10%"/>
<col style="width: 10%"/>
<col style="width: 10%"/>
<col style="width: 10%"/>
<col style="width: 10%"/>
<col style="width: 10%"/>
<col style="width: 10%"/>
<col style="width: 10%"/>
<col style="width: 10%"/>
</colgroup>
<tbody>
<tr class="row-odd"><td></td>
<td><p><strong>rank</strong></p></td>
<td><p><strong>loo</strong></p></td>
<td><p><strong>p_loo</strong></p></td>
<td><p><strong>d_loo</strong></p></td>
<td><p><strong>weight</strong></p></td>
<td><p><strong>se</strong></p></td>
<td><p><strong>dse</strong></p></td>
<td><p><strong>warning</strong></p></td>
<td><p><strong>loo_scale</strong></p></td>
</tr>
<tr class="row-even"><td><p><strong>mass_bill</strong></p></td>
<td><p>0</p></td>
<td><p>-11.3</p></td>
<td><p>1.6</p></td>
<td><p>0.0</p></td>
<td><p>1.0</p></td>
<td><p>3.1</p></td>
<td><p>0.0</p></td>
<td><p>True</p></td>
<td><p>log</p></td>
</tr>
<tr class="row-odd"><td><p><strong>bill</strong></p></td>
<td><p>1</p></td>
<td><p>-27.0</p></td>
<td><p>1.7</p></td>
<td><p>15.6</p></td>
<td><p>0.0</p></td>
<td><p>6.2</p></td>
<td><p>4.9</p></td>
<td><p>True</p></td>
<td><p>log</p></td>
</tr>
<tr class="row-even"><td><p><strong>mass</strong></p></td>
<td><p>2</p></td>
<td><p>-135.8</p></td>
<td><p>2.1</p></td>
<td><p>124.5</p></td>
<td><p>0.0</p></td>
<td><p>5.3</p></td>
<td><p>5.8</p></td>
<td><p>True</p></td>
<td><p>log</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="log-odds">
<span id="id36"></span><h3>3.4.3 解读对数赔率（ Log Odds ）<a class="headerlink" href="#log-odds" title="Permalink to this headline">¶</a></h3>
<p>在逻辑斯谛回归中，斜率告诉你当 <span class="math notranslate nohighlight">\(x\)</span> 增加一个单位时，增加了多少<code class="docutils literal notranslate"><span class="pre">对数赔率（log</span> <span class="pre">odds）</span></code>单位。赔率指事件发生的概率与不发生的概率之比。例如，在企鹅示例中，如果从 <code class="docutils literal notranslate"><span class="pre">Adelie</span> <span class="pre">种</span></code>或 <code class="docutils literal notranslate"><span class="pre">Chinstrap</span> <span class="pre">种</span></code> 企鹅中随机选择一只企鹅，那么我们选中 <code class="docutils literal notranslate"><span class="pre">Adelie</span> <span class="pre">种</span></code>企鹅的概率将为 <span class="math notranslate nohighlight">\(0.68\)</span>，如代码 <a class="reference internal" href="#adelie-prob"><span class="std std-ref">adelie_prob</span></a> 所示</p>
<div class="literal-block-wrapper docutils container" id="adelie-prob">
<div class="code-block-caption"><span class="caption-number">Listing 39 </span><span class="caption-text">adelie_prob</span><a class="headerlink" href="#adelie-prob" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Class counts of each penguin species</span>
<span class="n">counts</span> <span class="o">=</span> <span class="n">penguins</span><span class="p">[</span><span class="s2">"species"</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
<span class="n">adelie_count</span> <span class="o">=</span> <span class="n">counts</span><span class="p">[</span><span class="s2">"Adelie"</span><span class="p">],</span>
<span class="n">chinstrap_count</span> <span class="o">=</span> <span class="n">counts</span><span class="p">[</span><span class="s2">"Chinstrap"</span><span class="p">]</span>
<span class="n">adelie_count</span> <span class="o">/</span> <span class="p">(</span><span class="n">adelie_count</span> <span class="o">+</span> <span class="n">chinstrap_count</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">array</span><span class="p">([</span><span class="mf">0.68224299</span><span class="p">])</span>
</pre></div>
</div>
<p>对于同一事件，赔率将是 <span class="math notranslate nohighlight">\(2.14\)</span>：</p>
<div class="literal-block-wrapper docutils container" id="adelie-odds">
<div class="code-block-caption"><span class="caption-number">Listing 40 </span><span class="caption-text">adelie_odds</span><a class="headerlink" href="#adelie-odds" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">adelie_count</span> <span class="o">/</span> <span class="n">chinstrap_count</span>
</pre></div>
</div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">array</span><span class="p">([</span><span class="mf">2.14705882</span><span class="p">])</span>
</pre></div>
</div>
<p>赔率由与概率相同的组分组成，但以一种更直接地方式，解释了一个事件发生与另一个事件发生的比率。以赔率表示，如果从 <code class="docutils literal notranslate"><span class="pre">Adelie</span> <span class="pre">种</span></code>和 <code class="docutils literal notranslate"><span class="pre">Chinstrap</span> <span class="pre">种</span></code>企鹅中随机采样，则根据代码 <a class="reference internal" href="#adelie-odds"><span class="std std-ref">adelie_odds</span></a> 计算，我们预计最终得到的 <code class="docutils literal notranslate"><span class="pre">Adelie</span> <span class="pre">种</span></code>企鹅的赔率比 <code class="docutils literal notranslate"><span class="pre">Chinstrap</span> <span class="pre">种</span></code> 企鹅高 <span class="math notranslate nohighlight">\(2.14\)</span>。</p>
<p>利用对赔率的了解，我们可以定义 <code class="docutils literal notranslate"><span class="pre">logit</span></code>。 <code class="docutils literal notranslate"><span class="pre">logit</span></code> 是赔率的自然对数，它是公式 <a class="reference internal" href="#equation-eq-logit">(30)</a> 中显示的分数。我们可以用 <code class="docutils literal notranslate"><span class="pre">logit</span></code> 重写公式 <a class="reference internal" href="#equation-eq-logistic">(29)</a> 中的逻辑斯谛回归。</p>
<div class="math notranslate nohighlight" id="equation-eq-logit">
<span class="eqno">(30)<a class="headerlink" href="#equation-eq-logit" title="Permalink to this equation">¶</a></span>\[\log \left(\frac{p}{1-p} \right) = \boldsymbol{X} \beta \]</div>
<p>该替代公式让我们可以将逻辑斯谛回归的系数解释为对数赔率的变化。此时，如果给定喙长度的变化，我们可以计算出观测到 <code class="docutils literal notranslate"><span class="pre">Adelie</span> <span class="pre">种</span></code> 到 <code class="docutils literal notranslate"><span class="pre">Chinstrap</span></code> 种企鹅的概率，如代码 <a class="reference internal" href="#logistic-interpretation"><span class="std std-ref">logistic_interpretation</span></a> 所示。</p>
<p>像这样的转换在数学上很有趣，而且在讨论统计结果时也非常实用，我们将在 <a class="reference internal" href="chp_09.html#section-sharing-results"><span class="std std-ref">9.10 与特定受众分享结果</span></a> 中更深入地讨论这个主题。</p>
<div class="literal-block-wrapper docutils container" id="logistic-interpretation">
<div class="code-block-caption"><span class="caption-number">Listing 41 </span><span class="caption-text">logistic_interpretation</span><a class="headerlink" href="#logistic-interpretation" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="mi">45</span>
<span class="n">β_0</span> <span class="o">=</span> <span class="n">inf_data_logistic_penguins_bill_length</span><span class="o">.</span><span class="n">posterior</span><span class="p">[</span><span class="s2">"β_0"</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">values</span>
<span class="n">β_1</span> <span class="o">=</span> <span class="n">inf_data_logistic_penguins_bill_length</span><span class="o">.</span><span class="n">posterior</span><span class="p">[</span><span class="s2">"β_1"</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">values</span>
<span class="n">bill_length</span> <span class="o">=</span> <span class="mi">45</span>

<span class="n">val_1</span> <span class="o">=</span> <span class="n">β_0</span> <span class="o">+</span> <span class="n">β_1</span><span class="o">*</span><span class="n">bill_length</span>
<span class="n">val_2</span> <span class="o">=</span> <span class="n">β_0</span> <span class="o">+</span> <span class="n">β_1</span><span class="o">*</span><span class="p">(</span><span class="n">bill_length</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>

<span class="sa">f</span><span class="s2">"""(Class Probability change from 45mm Bill Length to 46mm:</span>
<span class="si">{</span><span class="p">(</span><span class="n">special</span><span class="o">.</span><span class="n">expit</span><span class="p">(</span><span class="n">val_2</span><span class="p">)</span> <span class="o">-</span>  <span class="n">special</span><span class="o">.</span><span class="n">expit</span><span class="p">(</span><span class="n">val_1</span><span class="p">))</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s2">.0f</span><span class="si">}</span><span class="s2">%)"""</span>
</pre></div>
</div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="s1">'Class Probability change from 45mm Bill Length to 46mm: 15%'</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="picking-priors-in-regression-models">
<span id="id37"></span><h2>3.5 选择回归模型中的先验<a class="headerlink" href="#picking-priors-in-regression-models" title="Permalink to this headline">¶</a></h2>
<p>熟悉了广义线性模型之后，现在让我们关注一下先验及其对后验估计的影响。我们将从 <span id="id38">[<a class="reference internal" href="references.html#id62">40</a>]</span> 中借用一个例子，特别是其中一项父母吸引力与生女孩的概率之间关系研究<span id="id39">[<a class="reference internal" href="references.html#id63">13</a>]</span>。在这项研究中，研究人员以五分制评估了美国青少年的吸引力。最终，这些受试者中许多人都有了孩子，其中每种吸引力类别对应的性别比例都在代码 <a class="reference internal" href="#uninformative-prior-sex-ratio"><span class="std std-ref">uninformative_prior_sex_ratio</span></a> 中做了计算，其结果以数据点形式显示在 <a class="reference internal" href="#fig-beautyratio"><span class="std std-numref">Fig. 54</span></a> 中。在同一个代码块中，我们还编写了一个单变量回归模型。这一次重点关注如何一起评估先验和似然，而不是单独进行评估。</p>
<div class="figure align-default" id="fig-beautyratio">
<a class="reference internal image-reference" href="../_images/BeautyRatio.png"><img alt="../_images/BeautyRatio.png" src="../_images/BeautyRatio.png" style="width: 7.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 54 </span><span class="caption-text">父母的吸引力数据与子女的性别比例图。</span><a class="headerlink" href="#fig-beautyratio" title="Permalink to this image">¶</a></p>
</div>
<div class="literal-block-wrapper docutils container" id="uninformative-prior-sex-ratio">
<div class="code-block-caption"><span class="caption-number">Listing 42 </span><span class="caption-text">uninformative_prior_sex_ratio</span><a class="headerlink" href="#uninformative-prior-sex-ratio" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.arange.html#numpy.arange" title="numpy.arange"><span class="n">np</span><span class="o">.</span><span class="n">arange</span></a><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/generated/numpy.asarray.html#numpy.asarray" title="numpy.asarray"><span class="n">np</span><span class="o">.</span><span class="n">asarray</span></a><span class="p">([</span><span class="mi">50</span><span class="p">,</span> <span class="mi">44</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">47</span><span class="p">,</span> <span class="mi">56</span><span class="p">])</span>

<span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">model_uninformative_prior_sex_ratio</span><span class="p">:</span>
    <span class="n">σ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Exponential</span><span class="p">(</span><span class="s2">"σ"</span><span class="p">,</span> <span class="mf">.5</span><span class="p">)</span>
    <span class="n">β_1</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s2">"β_1"</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
    <span class="n">β_0</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s2">"β_0"</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>

    <span class="n">μ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Deterministic</span><span class="p">(</span><span class="s2">"μ"</span><span class="p">,</span> <span class="n">β_0</span> <span class="o">+</span> <span class="n">β_1</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span>

    <span class="n">ratio</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s2">"ratio"</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">μ</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">σ</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>

    <span class="n">prior_predictive_uninformative_prior_sex_ratio</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample_prior_predictive</span><span class="p">(</span>
        <span class="n">samples</span><span class="o">=</span><span class="mi">10000</span>
    <span class="p">)</span>
    <span class="n">trace_uninformative_prior_sex_ratio</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
    <span class="n">inf_data_uninformative_prior_sex_ratio</span> <span class="o">=</span> <span class="n">az</span><span class="o">.</span><span class="n">from_PyMC3</span><span class="p">(</span>
        <span class="n">trace</span><span class="o">=</span><span class="n">trace_uninformative_prior_sex_ratio</span><span class="p">,</span>
        <span class="n">prior</span><span class="o">=</span><span class="n">prior_predictive_uninformative_prior_sex_ratio</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="figure align-default" id="fig-posterioruninformativelinearregression">
<a class="reference internal image-reference" href="../_images/PosteriorUninformativeLinearRegression.png"><img alt="../_images/PosteriorUninformativeLinearRegression.png" src="../_images/PosteriorUninformativeLinearRegression.png" style="width: 7.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 55 </span><span class="caption-text">在模糊先验或宽先验的情况下，该模型表明，对于被评为有吸引力的父母，出生性别比率可能存在很大差异。其中一些可能的拟合值存在高达 20% 的变化，这似乎令人难以置信，因为没有其他研究表明对出生性别比有如此大的影响。</span><a class="headerlink" href="#fig-posterioruninformativelinearregression" title="Permalink to this image">¶</a></p>
</div>
<p>名义上，我们将假设出生在男性和女性之间平均分配，并且吸引力对性别比例没有影响。这意味着将截距 <span class="math notranslate nohighlight">\(\beta_0\)</span> 的先验均值设置为 <span class="math notranslate nohighlight">\(50\)</span>，将系数 <span class="math notranslate nohighlight">\(\beta_1\)</span> 的先验均值设置为 <span class="math notranslate nohighlight">\(0\)</span>。我们还设置了宽的离散度来表达我们对截距和吸引力对性别比影响的不确定性。这并不是一个完全<em>无信息的先验</em>，我们在第 <a class="reference internal" href="chp_01.html#make-prior-count"><span class="std std-ref">1.4 量化先验信息的几种选择</span></a> 节中介绍过它，不过它是一个非常宽的先验。</p>
<p>根据上述选择，我们在代码 <a class="reference internal" href="#uninformative-prior-sex-ratio"><span class="std std-ref">uninformative_prior_sex_ratio</span></a>) 中编写了模型、运行推断、并生成样本来估计后验分布。
根据数据和模型，我们估计 <span class="math notranslate nohighlight">\(\beta_1\)</span> 的均值为 <span class="math notranslate nohighlight">\(1.4\)</span>，这意味着与最具吸引力的群体相比，吸引力最小的群体的出生率平均相差 <span class="math notranslate nohighlight">\(7.4\%\)</span> 。在 <a class="reference internal" href="#fig-posterioruninformativelinearregression"><span class="std std-numref">Fig. 55</span></a> 中，如果我们包括不确定性，则在将参数条件化为数据之前，从 <span class="math notranslate nohighlight">\(50\)</span> 条可能的“拟合线”随机样本中，每单位吸引力的出生比率可以变化超过 <span class="math notranslate nohighlight">\(20\%\)</span> 。</p>
<p>从数学角度来看，该结果是有效的。但从常识和我们对该研究之外的出生性别比来理解，这些结果值得怀疑。出生时的“自然”性别比约为 “ <span class="math notranslate nohighlight">\(105\)</span> 个男孩/<span class="math notranslate nohighlight">\(100\)</span> 个女孩” ( 大约 <span class="math notranslate nohighlight">\(103\)</span> 到 <span class="math notranslate nohighlight">\(107\)</span> 个男孩 )，这意味着出生时的性别比为 <span class="math notranslate nohighlight">\(48.5%\)</span> ，标准差为 <span class="math notranslate nohighlight">\(0.5\)</span>。此外，即便与人类生物学更内在联系的因素，也不会对出生率影响到这种大的程度，这主观上削弱了吸引力应该具有这种影响程度的信念。鉴于此信息，两组之间 <span class="math notranslate nohighlight">\(8%\)</span> 的变化将需要特殊的观测。</p>
<p>让我们再次运行模型，但这次使用代码 <a class="reference internal" href="#informative-prior-sex-ratio"><span class="std std-ref">informative_prior_sex_ratio</span></a> 中显示的更具信息性的先验。抽取后验样本，会发现系数的非常集中，并且在考虑可能的比率时，抽取的后验直线落入了更合理的范围内。</p>
<div class="literal-block-wrapper docutils container" id="informative-prior-sex-ratio">
<div class="code-block-caption"><span class="caption-number">Listing 43 </span><span class="caption-text">informative_prior_sex_ratio</span><a class="headerlink" href="#informative-prior-sex-ratio" title="Permalink to this code">¶</a></div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">model_informative_prior_sex_ratio</span><span class="p">:</span>
    <span class="n">σ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Exponential</span><span class="p">(</span><span class="s2">"σ"</span><span class="p">,</span> <span class="mf">.5</span><span class="p">)</span>

    <span class="c1"># Note the now more informative priors</span>
    <span class="n">β_1</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s2">"β_1"</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">.5</span><span class="p">)</span>
    <span class="n">β_0</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s2">"β_0"</span><span class="p">,</span> <span class="mf">48.5</span><span class="p">,</span> <span class="mf">.5</span><span class="p">)</span>

    <span class="n">μ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Deterministic</span><span class="p">(</span><span class="s2">"μ"</span><span class="p">,</span> <span class="n">β_0</span> <span class="o">+</span> <span class="n">β_1</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span>
    <span class="n">ratio</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s2">"ratio"</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">μ</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">σ</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>

    <span class="n">prior_predictive_informative_prior_sex_ratio</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample_prior_predictive</span><span class="p">(</span>
        <span class="n">samples</span><span class="o">=</span><span class="mi">10000</span>
    <span class="p">)</span>
    <span class="n">trace_informative_prior_sex_ratio</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
    <span class="n">inf_data_informative_prior_sex_ratio</span> <span class="o">=</span> <span class="n">az</span><span class="o">.</span><span class="n">from_PyMC3</span><span class="p">(</span>
        <span class="n">trace</span><span class="o">=</span><span class="n">trace_informative_prior_sex_ratio</span><span class="p">,</span>
        <span class="n">prior</span><span class="o">=</span><span class="n">prior_predictive_informative_prior_sex_ratio</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="figure align-default" id="fig-posteriorinformativelinearregression">
<a class="reference internal image-reference" href="../_images/PosteriorInformativeLinearRegression.png"><img alt="../_images/PosteriorInformativeLinearRegression.png" src="../_images/PosteriorInformativeLinearRegression.png" style="width: 7.00in;"/></a>
<p class="caption"><span class="caption-number">Fig. 56 </span><span class="caption-text">根据其他论文和专家知识优化后的先验，平均后验在吸引力比率上几乎没有变化，这表明如果认为父母吸引力对出生率有影响，则应该收集更多数据来展示这种影响。</span><a class="headerlink" href="#fig-posteriorinformativelinearregression" title="Permalink to this image">¶</a></p>
</div>
<p>这次我们看到吸引力对性别的影响几乎可以忽略不计，根本没有足够信息来影响后验。正如在 <a class="reference internal" href="chp_01.html#make-prior-count"><span class="std std-ref">1.4 量化先验信息的几种选择</span></a> 节中提到的，选择先验既是负担也是祝福。无论你认为是哪一种，重要的是使用这种统计工具并做出可解释和有原则的选择。</p>
</div>
<div class="section" id="exercises3">
<span id="id40"></span><h2>3.6 练习<a class="headerlink" href="#exercises3" title="Permalink to this headline">¶</a></h2>
<p><strong>E1.</strong> Comparisons are part of everyday life. What is something you compare on a daily basis and answer the following question:</p>
<ul class="simple">
<li><p>What is the numerical quantification you use for comparison?</p></li>
<li><p>How do you decide on the logical groupings for observations? For   example in the penguin model we use species or sex</p></li>
<li><p>What point estimate would you use to compare them?</p></li>
</ul>
<p><strong>E2.</strong> Referring to Model <a class="reference internal" href="#penguin-mass"><span class="std std-ref">penguin_mass</span></a> complete the following tasks.</p>
<ol class="simple">
<li><p>Compute the values of Monte Carlo Standard Error Mean using   <code class="docutils literal notranslate"><span class="pre">az.summary</span></code>. Given the computed values which of the following   reported values of <span class="math notranslate nohighlight">\(\mu\)</span> would not be well supported as a point   estimate? 3707.235, 3707.2, or 3707.</p></li>
<li><p>Plot the ESS and MCSE per quantiles and describe the results.</p></li>
<li><p>Resample the model using a low number of draws until you get bad   values of <span class="math notranslate nohighlight">\(\hat R\)</span>, and ESS</p></li>
<li><p>Report the HDI <span class="math notranslate nohighlight">\(50\%\)</span> numerically and using <code class="docutils literal notranslate"><span class="pre">az.plot_posterior</span></code></p></li>
</ol>
<p><strong>E3.</strong> In your own words explain how regression can be used to do the following:</p>
<ol class="simple">
<li><p>Covariate estimation</p></li>
<li><p>Prediction</p></li>
<li><p>Counterfactual analysis</p></li>
</ol>
<p>Explain how they are different, the steps to perform each, and situations where they would be useful. Use the penguin example or come up with your own.</p>
<p><strong>E4.</strong> In Code Block <a class="reference internal" href="#flipper-centering"><span class="std std-ref">flipper_centering</span></a> and Code Block <a class="reference internal" href="#tfp-penguins-centered-predictor"><span class="std std-ref">tfp_penguins_centered_predictor</span></a> we centered the flipper length covariate. Refit the model, but instead of centering, subtract the minimum observed flipped length. Compare the posterior estimates of the slope and intercept parameters of the centered model. What is different, what is the same. How does the interpretation of this model change when compared to the centered model?</p>
<p><strong>E5.</strong> Translate the following primitives from <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> to TFP. Assume the model name is <code class="docutils literal notranslate"><span class="pre">pymc_model</span></code></p>
<ol class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">pm.StudentT("x",</span> <span class="pre">0,</span> <span class="pre">10,</span> <span class="pre">20)</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">pm.sample(chains=2)</span></code></p></li>
</ol>
<p>Hint: write the model and inference first in <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code>, and find the similar primitives in TFP using the code shown in this chapter.</p>
<p><strong>E6.</strong> <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> and TFP use different argument names for their distribution parameterizations. For example in <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> the Uniform Distribution is parameterized as <code class="docutils literal notranslate"><span class="pre">pm.Uniform.dist(lower=,</span> <span class="pre">upper=)</span></code> whereas in TFP it is <code class="docutils literal notranslate"><span class="pre">tfd.Uniform(low=,</span> <span class="pre">high=)</span></code>. Use the online documentation to identify the difference in argument names for the following distributions.</p>
<ol class="simple">
<li><p>Normal</p></li>
<li><p>Poisson</p></li>
<li><p>Beta</p></li>
<li><p>Binomial</p></li>
<li><p>Gumbel</p></li>
</ol>
<p><strong>E7.</strong> A common modeling technique for parameterizing Bayesian multiple regressions is to assign a wide prior to the intercept, and assign more informative prior to the slope coefficients.</p>
<p>Try modifying the <code class="docutils literal notranslate"><span class="pre">model_logistic_penguins_bill_length_mass</span></code> model in Code Block <a class="reference internal" href="#model-logistic-penguins-bill-length-mass"><span class="std std-ref">model_logistic_penguins_bill_length_mass</span></a>.</p>
<p>Do you get better inference results? Note that there are divergence with the original parameterization.</p>
<p><strong>E8.</strong> In linear regression models we have two terms. The mean linear function and the noise term. Write down these two terms in mathematical notation, referring to the equations in this chapter for guidance. Explain in your own words what the purpose of these two parts of regression are. In particular why are they useful when there is random noise in any part of the data generating or data collection process.</p>
<p><strong>E9.</strong> Simulate the data using the formula y = 10 + 2x + <span class="math notranslate nohighlight">\(\mathcal{N}(0, 5)\)</span> with integer covariate x generated np.linspace(-10, 20, 100). Fit a linear model of the form <span class="math notranslate nohighlight">\(b_0 + b_1*X + \sigma\)</span>. Use a Normal distribution for the likelihood and covariate priors and a Half Student’s T prior for the noise term as needed. Recover the parameters verifying your results using both a posterior plot and a forest plot.</p>
<p><strong>E10.</strong> Generate diagnostics for the model in Code Block <a class="reference internal" href="#non-centered-regression"><span class="std std-ref">non_centered_regression</span></a> to verify the results shown in the chapter can be trusted. Use a combination of visual and numerical diagnostics.</p>
<p><strong>E11.</strong> Refit the model in Code Block <a class="reference internal" href="#non-centered-regression"><span class="std std-ref">non_centered_regression</span></a> on Gentoo penguins and Chinstrap penguins. How are the posteriors different from each other? How are they different from the Adelie posterior estimation? What inferences can you make about the relationship between flipper length and mass for these other species of penguins? What does the change in <span class="math notranslate nohighlight">\(\sigma\)</span> tell you about the ability of flipper length to estimate mass?</p>
<p><strong>M12.</strong> Using the model in Code Block <a class="reference internal" href="#tfp-flipper-bill-sex-counterfactuals"><span class="std std-ref">tfp_flipper_bill_sex_counterfactuals</span></a> run a counterfactual analysis for female penguin flipper length with mean flipper length and a bill length of 20mm. Plot a kernel density estimate of the posterior predictive samples.</p>
<p><strong>M13.</strong> Duplicate the flipper length covariate in Code Block <a class="reference internal" href="#non-centered-regression"><span class="std std-ref">non_centered_regression</span></a> by adding a <span class="math notranslate nohighlight">\(\beta_2\)</span> coefficient and rerun the model. What do diagnostics such as ESS and rhat indicate about this model with a duplicated coefficient?</p>
<p><strong>M14.</strong> Translate the <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> model in Code Block <a class="reference internal" href="#non-centered-regression"><span class="std std-ref">non_centered_regression</span></a> into Tensorflow Probability. List three of the syntax differences.</p>
<p><strong>M15.</strong> Translate the TFP model in Code Block <a class="reference internal" href="#tfp-penguins-centered-predictor"><span class="std std-ref">tfp_penguins_centered_predictor</span></a> into <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code>. List three of the syntax differences.</p>
<p><strong>M16.</strong> Use a logistic regression with increasing number of covariates to reproduce the prior predictive distributions in <a class="reference internal" href="chp_02.html#fig-prior-predictive-check-01"><span class="std std-numref">Fig. 14</span></a>.</p>
<p>Explain why its the case that a logistic regression with many covariates generate a prior response with extreme values.</p>
<p><strong>H17.</strong> Translate the <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> model in Code Block <a class="reference internal" href="#model-logistic-penguins-bill-length-mass"><span class="std std-ref">model_logistic_penguins_bill_length_mass</span></a> into TFP to classify Adelie and Chinstrap penguins. Reuse the same model to classify Chinstrap and Gentoo penguins. Compare the coefficients, how do they differ?</p>
<p><strong>H18.</strong> In Code Block <a class="reference internal" href="#penguin-mass"><span class="std std-ref">penguin_mass</span></a> our model allowed for negative values mass. Change the model so negative values are no longer possible. Run a prior predictive check to verify that your change was effective. Perform MCMC sampling and plot the posterior. Has the posterior changed from the original model? Given the results why would you choose one model over the other and why?</p>
<p><strong>H19.</strong> The Palmer Penguin dataset includes additional data for the observed penguins such as island and bill depth. Include these covariates into the linear regression model defined in Code Block <a class="reference internal" href="#non-centered-regression"><span class="std std-ref">non_centered_regression</span></a> in two parts, first adding bill depth, and then adding the island covariates.</p>
<p>Do these covariates help estimate Adelie mass more precisely? Justify your answer using the parameter estimates and model comparison tools.</p>
<p><strong>H20.</strong> Similar the exercise 2H19, see if adding bill depth or island covariates to the penguin logistic regression help classify Adelie and Gentoo penguins more precisely. Justify if the additional covariates helped using the numerical and visual tools shown in this chapter.</p>
<p>Nature can be hard to grasp with simple statements.</p>
<hr class="footnotes docutils"/>
<dl class="footnote brackets">
<dt class="label" id="id41"><span class="brackets"><a class="fn-backref" href="#id6">1</a></span></dt>
<dd><p>You can find more information in the TensorFlow tutorials and   documentations. For example,   <a class="reference external" href="https://www.tensorflow.org/probability/examples/JointDistributionAutoBatched_A_Gentle_Tutorial">https://www.tensorflow.org/probability/examples/JointDistributionAutoBatched_A_Gentle_Tutorial</a>   and   <a class="reference external" href="https://www.tensorflow.org/probability/examples/Modeling_with_JointDistribution">https://www.tensorflow.org/probability/examples/Modeling_with_JointDistribution</a>.</p>
</dd>
<dt class="label" id="id42"><span class="brackets"><a class="fn-backref" href="#id7">2</a></span></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">tfd.Sample</span></code> and <code class="docutils literal notranslate"><span class="pre">tfd.Independent</span></code> are distribution constructors   that takes other distributions as input and return a new   distribution. There are other meta distribution but with different   purposes like <code class="docutils literal notranslate"><span class="pre">tfd.Mixture</span></code>, <code class="docutils literal notranslate"><span class="pre">tfd.TransformedDistribution</span></code>, and   <code class="docutils literal notranslate"><span class="pre">tfd.JointDistribution</span></code>. A more comprehensive introduction to   <code class="docutils literal notranslate"><span class="pre">tfp.distributions</span></code> can be found in   <a class="reference external" href="https://www.tensorflow.org/probability/examples/TensorFlow_Distributions_Tutorial">https://www.tensorflow.org/probability/examples/TensorFlow_Distributions_Tutorial</a></p>
</dd>
<dt class="label" id="id43"><span class="brackets"><a class="fn-backref" href="#id9">3</a></span></dt>
<dd><p><a class="reference external" href="https://mc-stan.org/docs/2_23/reference-manual/hmc-algorithm-parameters.html#automatic-parameter-tuning">https://mc-stan.org/docs/2_23/reference-manual/hmc-algorithm-parameters.html#automatic-parameter-tuning</a></p>
</dd>
<dt class="label" id="id44"><span class="brackets"><a class="fn-backref" href="#id22">4</a></span></dt>
<dd><p>If wanted exactly the same model we could specify the priors in   Bambi, not shown here. For our purposes however, the models are   “close enough”.</p>
</dd>
<dt class="label" id="id45"><span class="brackets"><a class="fn-backref" href="#id23">5</a></span></dt>
<dd><p>You can also parse the design matrix differently so that   covariates represents the contrast between 2 categories within a   column.</p>
</dd>
<dt class="label" id="id46"><span class="brackets"><a class="fn-backref" href="#id27">6</a></span></dt>
<dd><p>Maybe because collecting more data is expensive or difficult or   even impossible</p>
</dd>
<dt class="label" id="id47"><span class="brackets"><a class="fn-backref" href="#id28">7</a></span></dt>
<dd><p>Unless we are talking about large systems like rain forests, where   the presence of plants actually have an impact in the weather.</p>
</dd>
<dt class="label" id="id48"><span class="brackets"><a class="fn-backref" href="#id30">8</a></span></dt>
<dd><p>Traditionally people a<code class="docutils literal notranslate"><span class="pre">PPL</span></code>y functions like <span class="math notranslate nohighlight">\(\phi\)</span> to the left side   of Equation <a class="reference internal" href="#equation-eq-generalized-linear-model">(28)</a>, and call them link   functions. We instead prefer to a<code class="docutils literal notranslate"><span class="pre">PPL</span></code>y them to the right-hand side   and then to avoid confusion we use term inverse link function.</p>
</dd>
<dt class="label" id="id49"><span class="brackets"><a class="fn-backref" href="#id31">9</a></span></dt>
<dd><p>Usually in the traditional Generalized Linear Models Literature,   the likelihood of the observation need to be from the Exponential   family, but being Bayesian we are actually not restricted by that   and can use any likelihood that can be parameterized by the expected   value.</p>
</dd>
</dl>
</div>
</div>
<script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./zh_CN"
        },
        predefinedOutput: true
    }
    </script>
<script>kernelName = 'python3'</script>
</div>
<!-- Previous / next buttons -->
<div class="prev-next-area">
<a class="left-prev" href="chp_02.html" id="prev-link" title="previous page">
<i class="fas fa-angle-left"></i>
<div class="prev-next-info">
<p class="prev-next-subtitle">previous</p>
<p class="prev-next-title">第二章: 贝叶斯模型的探索性分析</p>
</div>
</a>
<a class="right-next" href="chp_04.html" id="next-link" title="next page">
<div class="prev-next-info">
<p class="prev-next-subtitle">next</p>
<p class="prev-next-title">第四章：扩展线性模型</p>
</div>
<i class="fas fa-angle-right"></i>
</a>
</div>
</div>
</div>
<footer class="footer">
<p>
    
      By Martin, Kumar, Lao<br/>
    
        © Copyright 2021.<br/>
</p>
</footer>
</main>
</div>
</div>
<script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>
</body>
</html>